{"chunk_id": 0, "text": "Software Engineering: Principles\nand Practice\nHans van Vliet\n(c) Wiley, 2007\nContents\n1 Introduction 1\nChapter 1 Introduction 1\n1.1 What is Software Engineering? . . . . . . . . . . . . . . . . . . . . . 5\n1.2 Phases in the Development of Software . . . . . . . . . . . . . . . . 10\n1.3 Maintenance or Evolution . . . . . . . . . . . . . . . . . . . . . . . . 16\n1.4 From the Trenches . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n1.4.1 Ariane 5, Flight 501 . . . . . . . . . . . . . . . . . . . . . . . 18\n1.4.2 Therac-25 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n1.4.3 The London Ambulance Service . . . . . . . . . . . . . . . . 21\n1.4.4 Who Counts the Votes? . . . . . . . . . . . . . . . . . . . . 23\n1.5 Software Engineering Ethics . . . . . . . . . . . . . . . . . . . . . . 2 5\n1.6 Quo Vadis? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n1.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n1.8 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\nExercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\nI Software Management 33\n2 Introduction to Software Engineering Management 34\nChapter 2 Introduction to Software Engineering Management 34\n2.1 Planning a Software Development Project", "token_count": 512, "start_token": 0, "end_token": 512, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 1, "text": " . . . . . . . . . . . . . . . . . . 30\nI Software Management 33\n2 Introduction to Software Engineering Management 34\nChapter 2 Introduction to Software Engineering Management 34\n2.1 Planning a Software Development Project . . . . . . . . . . . . . . . 37\n2.2 Controlling a Software Development Project . . . . . . . . . . . . . 40\n2.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\nExercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\n3 The Software Life Cycle Revisited 45\nChapter 3 The Software Life Cycle Revisited 45\n3.1 The Waterfall Model . . . . . . . . . . . . . . . . . . . . . . . . . . 48\n3.2 Agile Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\n3.2.1 Prototyping . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n3.2.2 Incremental Development . . . . . . . . . . . . . . . . . . . 56\n3.2.3 Rapid Application Development and DSDM . . . . . . . . . 57\n3.2.4 Extreme Programming . . . . . . . . . . . . . . . . . . . . . 61\n3.3 The Rational Uniﬁed Process (RUP) . . . . . . . . . . . . . . . . . . 6 4\n3.4 Intermezzo: Maintenance or Evolution . . . . . . . . . . . . . . . . . 66\n3.5 Software Product Lines . . . . . . . . . . . . . . . . . . . . . . . . . 70\n3.6 Process Modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71\n", "token_count": 512, "start_token": 462, "end_token": 974, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 2, "text": " . . . . . . . . . . . . 70\n3.6 Process Modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71\n3.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\n3.8 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\nExercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\n4 Conﬁguration Management 78\nChapter 4 Conﬁguration Management 78\n4.1 Tasks and Responsibilities . . . . . . . . . . . . . . . . . . . . . . . . 80\n4.2 Conﬁguration Management Plan . . . . . . . . . . . . . . . . . . . . 85\n4.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\n4.4 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\nExercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\n5 People Management and Team Organization 89\nChapter 5 People Management and Team Organization 89\n5.1 People Management . . . . . . . . . . . . . . . . . . . . . . . . . . 91\n5.1.1 Coordination Mechanisms . . . . . . . . . . . . . . . . . . . 93\n5.1.2 Management Styles . . . . . . . . . . . . . . . . . . . . . . . 94\n5.2 Team Organization . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\n5.2.", "token_count": 512, "start_token": 924, "end_token": 1436, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 3, "text": " . . . . . . . . . . 94\n5.2 Team Organization . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\n5.2.1 Hierarchical Organization . . . . . . . . . . . . . . . . . . . 96\n5.2.2 Matrix Organization . . . . . . . . . . . . . . . . . . . . . . 98\n5.2.3 Chief Programmer Team . . . . . . . . . . . . . . . . . . . . 99\n5.2.4 SWAT Team . . . . . . . . . . . . . . . . . . . . . . . . . . 100\n5.2.5 Agile Team . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\n5.2.6 Open Source Software Development . . . . . . . . . . . . . 101\n5.2.7 General Principles for Organizing a Team . . . . . . . . . . . 103\n5.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104\n5.4 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105\nExercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105\n6 On Managing Software Quality 107\nChapter 6 On Managing Software Quality 107\n6.1 On Measures and Numbers . . . . . . . . . . . . . . . . . . . . . . . 110\n6.2 A Taxonomy of Quality Attributes . . . . . . . . . . . . . . . . . . . 1 16\n6.3 Perspectives on Quality . . . . . . . . . . . . . . . . . . . . . . . . . 12 3\n6.4 The Quality System . . . . . . . . . . . . . . . . . . . . . .", "token_count": 512, "start_token": 1386, "end_token": 1898, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 4, "text": " . . . . . . . . . . . . . . . . . . . 12 3\n6.4 The Quality System . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\n6.5 Software Quality Assurance . . . . . . . . . . . . . . . . . . . . . . . 1 28\n6.6 The Capability Maturity Model (CMM) . . . . . . . . . . . . . . . . 1 30\n6.7 Some Critical Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . 136\n6.8 Getting Started . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137\n6.9 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140\n6.10 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140\nExercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\n7 Cost Estimation 144\nChapter 7 Cost Estimation 144\n7.1 Algorithmic Models . . . . . . . . . . . . . . . . . . . . . . . . . . . 148\n7.1.1 Walston--Felix . . . . . . . . . . . . . . . . . . . . . . . . . 151\n7.1.2 COCOMO . . . . . . . . . . . . . . . . . . . . . . . . . . . 153\n7.1.3 Putnam . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155\n7.1.4 Function Point Analysis . . . . . . . . . . . . . . . . . . . . . 156\n7.1.5 COCOMO 2: Variations on", "token_count": 512, "start_token": 1848, "end_token": 2360, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 5, "text": " . . . 155\n7.1.4 Function Point Analysis . . . . . . . . . . . . . . . . . . . . . 156\n7.1.5 COCOMO 2: Variations on a Theme . . . . . . . . . . . . . 159\n7.2 Guidelines for Estimating Cost . . . . . . . . . . . . . . . . . . . . . 166\n7.3 Distribution of Manpower over Time . . . . . . . . . . . . . . . . . . 169\n7.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171\n7.5 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174\nExercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174\n8 Project Planning and Control 176\nChapter 8 Project Planning and Control 176\n8.1 A Systems View of Project Control . . . . . . . . . . . . . . . . . . . 1 77\n8.2 A Taxonomy of Software Development Projects . . . . . . . . . . . . 179\n8.3 Risk Management . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184\n8.4 Techniques for Project Planning and Control . . . . . . . . . . . . . 189\n8.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194\n8.6 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194\nExercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\nII The Software Life Cycle 197\n9 Requirements Engineering 199\nChapter 9 Requirements Engineering 199\n9.1 Requirements Elicitation . . . . . . .", "token_count": 512, "start_token": 2310, "end_token": 2822, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 6, "text": " . . . . . . . . . . . . . . . . 195\nII The Software Life Cycle 197\n9 Requirements Engineering 199\nChapter 9 Requirements Engineering 199\n9.1 Requirements Elicitation . . . . . . . . . . . . . . . . . . . . . . . . 2 05\n9.1.1 Requirements Engineering Paradigms . . . . . . . . . . . . . 2 10\n9.1.2 Requirements Elicitation Techniques . . . . . . . . . . . . . . 212\n9.1.3 Goals and Viewpoints . . . . . . . . . . . . . . . . . . . . . 220\n9.1.4 Prioritizing Requirements . . . . . . . . . . . . . . . . . . . 223\n9.1.5 COTS selection . . . . . . . . . . . . . . . . . . . . . . . . 224\n9.2 Requirements Documentation and Management . . . . . . . . . . . . 227\n9.2.1 Requirements Management . . . . . . . . . . . . . . . . . . . 234\n9.3 Requirements Speciﬁcation Techniques . . . . . . . . . . . . . . . . 236\n9.3.1 Specifying Non-Functional Requirements . . . . . . . . . . . 238\n9.4 Veriﬁcation and Validation . . . . . . . . . . . . . . . . . . . . . . . 2 39\n9.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240\n9.6 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242\nExercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243\n10 Modeling 246\nChapter 10Modeling 246\n10.1 Classic Modeling Techniques . . . . . . . . . . . . . . . . . . . . . . 248", "token_count": 512, "start_token": 2772, "end_token": 3284, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 7, "text": " . . . . . . . 243\n10 Modeling 246\nChapter 10Modeling 246\n10.1 Classic Modeling Techniques . . . . . . . . . . . . . . . . . . . . . . 248\n10.1.1 Entity--Relationship Modeling . . . . . . . . . . . . . . . . . 248\n10.1.2 Finite State Machines . . . . . . . . . . . . . . . . . . . . . . 250\n10.1.3 Data Flow Diagrams (DFD) . . . . . . . . . . . . . . . . . . 252\n10.1.4 CRC Cards . . . . . . . . . . . . . . . . . . . . . . . . . . . 252\n10.2 On Objects and Related Stuff . . . . . . . . . . . . . . . . . . . . . . 2 54\n10.3 The Uniﬁed Modeling Language . . . . . . . . . . . . . . . . . . . . 26 0\n10.3.1 The Class Diagram . . . . . . . . . . . . . . . . . . . . . . . 260\n10.3.2 The State Machine Diagram . . . . . . . . . . . . . . . . . . 265\n10.3.3 The Sequence Diagram . . . . . . . . . . . . . . . . . . . . . 268\n10.3.4 The Communication Diagram . . . . . . . . . . . . . . . . . 271\n10.3.5 The Component Diagram . . . . . . . . . . . . . . . . . . . 272\n10.3.6 The Use Case . . . . . . . . . . . . . . . . . . . . . . . . . . 273\n10.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274\n10.5 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . .", "token_count": 512, "start_token": 3234, "end_token": 3746, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 8, "text": " . . . . . . . . . . . . . . . . 274\n10.5 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274\nExercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274\n11 Software Architecture 276\nChapter 11Software Architecture 276\n11.1 Software Architecture and the Software Life Cycle . . . . . . . . . . 280\n11.2 Architecture design . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 1\n11.2.1 Architecture as a set of design decisions . . . . . . . . . . . . 284\n11.3 Architectural views . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 5\n11.4 Architectural Styles . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 91\n11.5 Software Architecture Assessment . . . . . . . . . . . . . . . . . . . 306\n11.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309\n11.7 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 310\nExercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 311\n12 Software Design 313\nChapter 12Software Design 313\n12.1 Design Considerations . . . . . . . . . . . . . . . . . . . . . . . . . 31 7\n12.1.1 Abstraction . . . . . . . . . . . . . . . . . . . . . . . . . . . 318\n12.1.2 Modularity . . . . . . . . . . . . . . . . . . . . . . . . . .", "token_count": 512, "start_token": 3696, "end_token": 4208, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 9, "text": " . . . . . . . . . . . . . . . 318\n12.1.2 Modularity . . . . . . . . . . . . . . . . . . . . . . . . . . . 321\n12.1.3 Information Hiding . . . . . . . . . . . . . . . . . . . . . . . 325\n12.1.4 Complexity . . . . . . . . . . . . . . . . . . . . . . . . . . . 325\n12.1.5 System Structure . . . . . . . . . . . . . . . . . . . . . . . . 333\n12.1.6 Object-Oriented Metrics . . . . . . . . . . . . . . . . . . . . 337\n12.2 Classical Design Methods . . . . . . . . . . . . . . . . . . . . . . . . 3 40\n12.2.1 Functional Decomposition . . . . . . . . . . . . . . . . . . . 342\n12.2.2 Data Flow Design (SA/SD) . . . . . . . . . . . . . . . . . . . 346\n12.2.3 Design based on Data Structures . . . . . . . . . . . . . . . . 35 1\n12.3 Object-Oriented Analysis and Design Methods . . . . . . . . . . . . 359\n12.3.1 The Booch Method . . . . . . . . . . . . . . . . . . . . . . . 366\n12.3.2 Fusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 367\n12.3.3 RUP Revisited . . . . . . . . . . . . . . . . . . . . . . . . . 369\n12.4 How to Select a Design Method . . . . . . . . . . . . . . . . . . . . 370\n12.4.1 Object Orientation: Hype or the Answer? . . . . . . . . . . . 373\n12.5", "token_count": 512, "start_token": 4158, "end_token": 4670, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 10, "text": " . . . . . . . . . . . . . . . . . 370\n12.4.1 Object Orientation: Hype or the Answer? . . . . . . . . . . . 373\n12.5 Design Patterns . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 375\n12.6 Design Documentation . . . . . . . . . . . . . . . . . . . . . . . . . 380\n12.7 Veriﬁcation and Validation . . . . . . . . . . . . . . . . . . . . . . . 383\n12.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 384\n12.9 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 388\nExercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 389\n13 Software Testing 394\nChapter 13Software Testing 394\n13.1 Test Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 398\n13.1.1 Test Adequacy Criteria . . . . . . . . . . . . . . . . . . . . . 401\n13.1.2 Fault Detection Versus Conﬁdence Building . . . . . . . . . . 402\n13.1.3 From Fault Detection to Fault Prevention . . . . . . . . . . . 403\n13.2 Testing and the Software Life Cycle . . . . . . . . . . . . . . . . . . 406\n13.2.1 Requirements Engineering . . . . . . . . . . . . . . . . . . . 407\n13.2.2 Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 408\n13.2.3 Implementation . . . . . . . . . . . . .", "token_count": 512, "start_token": 4620, "end_token": 5132, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 11, "text": " . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 408\n13.2.3 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . 409\n13.2.4 Maintenance . . . . . . . . . . . . . . . . . . . . . . . . . . 409\n13.2.5 Test-Driven Development (TDD) . . . . . . . . . . . . . . . 410\n13.3 Veriﬁcation and Validation Planning and Documentatio n . . . . . . . 411\n13.4 Manual Test Techniques . . . . . . . . . . . . . . . . . . . . . . . . 413\n13.4.1 Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 414\n13.4.2 Walkthroughs and Inspections . . . . . . . . . . . . . . . . . 41 5\n13.4.3 Correctness Proofs . . . . . . . . . . . . . . . . . . . . . . . 417\n13.4.4 Stepwise Abstraction . . . . . . . . . . . . . . . . . . . . . . 418\n13.5 Coverage-Based Test Techniques . . . . . . . . . . . . . . . . . . . . 419\n13.5.1 Control-Flow Coverage . . . . . . . . . . . . . . . . . . . . 420\n13.5.2 Dataﬂow Coverage . . . . . . . . . . . . . . . . . . . . . . . 423\n13.5.3 Coverage-Based Testing of Requirements Speciﬁcati ons . . . 424\n13.6 Fault-Based Test Techniques . . . . . . . . . . . . . . . . . . . . . . 425\n13.6.1 Error Seeding . . . . . . . . . . . . . . . . . . . . . . . . . . 425", "token_count": 512, "start_token": 5082, "end_token": 5594, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 12, "text": " . . . . . . . . . . . . . 425\n13.6.1 Error Seeding . . . . . . . . . . . . . . . . . . . . . . . . . . 425\n13.6.2 Mutation Testing . . . . . . . . . . . . . . . . . . . . . . . . 428\n13.7 Error-Based Test Techniques . . . . . . . . . . . . . . . . . . . . . . 429\n13.8 Comparison of Test Techniques . . . . . . . . . . . . . . . . . . . . 4 31\n13.8.1 Comparison of Test Adequacy Criteria . . . . . . . . . . . . 4 32\n13.8.2 Properties of Test Adequacy Criteria . . . . . . . . . . . . . . 434\n13.8.3 Experimental Results . . . . . . . . . . . . . . . . . . . . . . 436\n13.9 Different Test Stages . . . . . . . . . . . . . . . . . . . . . . . . . . 43 8\n13.10Estimating Software Reliability . . . . . . . . . . . . . . . . . . . . . 439\n13.11Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 447\n13.12Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 448\nExercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 449\n14 Software Maintenance 453\nChapter 14Software Maintenance 453\n14.1 Maintenance Categories Revisited . . . . . . . . . . . . . . . . . . . 456\n14.2 Major Causes of Maintenance Problems . . . . . . . . . . . . . . . . 459\n14.3 Reverse Engineering and Refactoring . . . . . . . . . . . . . . . .", "token_count": 512, "start_token": 5544, "end_token": 6056, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 13, "text": "2 Major Causes of Maintenance Problems . . . . . . . . . . . . . . . . 459\n14.3 Reverse Engineering and Refactoring . . . . . . . . . . . . . . . . . . 463\n14.3.1 Refactoring . . . . . . . . . . . . . . . . . . . . . . . . . . . 466\n14.3.2 Inherent Limitations . . . . . . . . . . . . . . . . . . . . . . 469\n14.3.3 Tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 473\n14.4 Software Evolution Revisited . . . . . . . . . . . . . . . . . . . . . . 474\n14.5 Organizational and Managerial Issues . . . . . . . . . . . . . . . . . 476\n14.5.1 Organization of Maintenance Activities . . . . . . . . . . . . 477\n14.5.2 Software Maintenance from a Service Perspective . . . . . . . 480\n14.5.3 Control of Maintenance Tasks . . . . . . . . . . . . . . . . . 486\n14.5.4 Quality Issues . . . . . . . . . . . . . . . . . . . . . . . . . . 489\n14.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 490\n14.7 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 491\nExercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 492\n15 Software Tools 494\nChapter 15Software Tools 494\n15.1 Toolkits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 499\n15.2 Language-Centered", "token_count": 512, "start_token": 6006, "end_token": 6518, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 14, "text": "4\n15.1 Toolkits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 499\n15.2 Language-Centered Environments . . . . . . . . . . . . . . . . . . . 500\n15.3 Integrated Environments and Workbenches . . . . . . . . . . . . . . 501\n15.3.1 Analyst WorkBenches . . . . . . . . . . . . . . . . . . . . . 501\n15.3.2 Programmer Workbenches . . . . . . . . . . . . . . . . . . . 503\n15.3.3 Management WorkBenches . . . . . . . . . . . . . . . . . . 507\n15.3.4 Integrated Project Support Environments . . . . . . . . . . . 508\n15.4 Process-Centered Environments . . . . . . . . . . . . . . . . . . . . 508\n15.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 510\n15.6 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 511\nExercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 512\nBibliography 514\n1\nIntroduction\nLEARNING OBJECTIVES\n/AF To understand the notion of software engineering and why it i s important\n/AF To appreciate the technical (engineering), managerial, an d psychological\naspects of software engineering\n/AF To understand the similarities and differences between sof tware engineering\nand other engineering disciplines\n/AF To know the major phases in a software development project\n/AF To appreciate ethical dimensions in software engineering\n/AF To be aware of the time frame and extent to which new developme nts impact\nsoftware engineering practice\n2 INTRODUCTION\nSoftware engineering concerns methods and techniques to de velop large\nsoftware systems. The engineering metaphor is used to empha size a", "token_count": 512, "start_token": 6468, "end_token": 6980, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 15, "text": " of the time frame and extent to which new developme nts impact\nsoftware engineering practice\n2 INTRODUCTION\nSoftware engineering concerns methods and techniques to de velop large\nsoftware systems. The engineering metaphor is used to empha size a systematic\napproach to develop systems that satisfy organizational re quirements and\nconstraints. This chapter gives a brief overview of the ﬁeld and points at\nemerging trends that inﬂuence the way software is developed .\nComputer science is still a young ﬁeld. The ﬁrst computers we re built in the mid\n1940s, since when the ﬁeld has developed tremendously.\nApplications from the early years of computerization can be characterized as\nfollows: the programs were quite small, certainly when comp ared to those that are\ncurrently being constructed; they were written by one perso n; they were written and\nused by experts in the application area concerned. The probl ems to be solved were\nmostly of a technical nature, and the emphasis was on express ing known algorithms\nefﬁciently in some programming language. Input typically c onsisted of numerical\ndata, read from such media as punched tape or punched cards. T he output, also\nnumeric, was printed on paper. Programs were run off-line. I f the program contained\nerrors, the programmer studied an octal or hexadecimal dump of memory. Sometimes,\nthe execution of the program would be followed by binary read ing machine registers\nat the console.\nIndependent software development companies hardly existe d in those days.\nSoftware was mostly developed by hardware vendors and given away for free. These\nvendors sometimes set up user groups to discuss requirement s, and next incorporated\nthem into their software. This software development suppor t was seen as a service to\ntheir customers.\nPresent-day applications are rather different in many resp ects. Present-day pro-\ngrams are often very large and are being developed by teams th at collaborate over\nperiods spanning several years. These teams may be scattere d across the globe. The\nprogrammers are not the future users of the system they devel op and they have no\nexpert knowledge of the application area in question. The pr oblems that are being\ntackled increasingly concern everyday life: automatic ban k tellers, airline reservation,\nsalary administration", "token_count": 512, "start_token": 6930, "end_token": 7442, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 16, "text": " the system they devel op and they have no\nexpert knowledge of the application area in question. The pr oblems that are being\ntackled increasingly concern everyday life: automatic ban k tellers, airline reservation,\nsalary administration, electronic commerce, automotive s ystems, etc. Putting a man\non the moon was not conceivable without computers.\nIn the 1960s, people started to realize that programming tec hniques had lagged\nbehind the developments in software both in size and complex ity. To many people,\nprogramming was still an art and had never become a craft. An additional problem was\nthat many programmers had not been formally educated in the ﬁ eld. They had learned\nby doing. On the organizational side, attempted solutions t o problems often involved\nadding more and more programmers to the project, the so-call ed ‘million-monkey’\napproach.\nAs a result, software was often delivered too late, programs did not behave as the\nuser expected, programs were rarely adaptable to changed ci rcumstances, and many\nerrors were detected only after the software had been delive red to the customer. This\n3\nbecame known as the ‘software crisis’.\nThis type of problem really became manifest in the 1960s. Und er the auspices\nof NATO, two conferences were devoted to the topic in 1968 and 1969 (Naur and\nRandell, 1968), (Buxton and Randell, 1969). Here, the term ‘ software engineering’ was\ncoined in a somewhat provocative sense. Shouldn’t it be poss ible to build software\nin the way one builds bridges and houses, starting from a theo retical basis and using\nsound and proven design and construction techniques, as in o ther engineering ﬁelds?\nSoftware serves some organizational purpose. The reasons f or embarking on\na software development project vary. Sometimes, a solution to a problem is not\nfeasible without the aid of computers, such as weather forec asting, or automated\nbank telling. Sometimes, software can be used as a vehicle fo r new technologies, such\nas typesetting, the production of chips, or manned space tri ps. In yet other cases\nsoftware may increase user service (library automation, e- commerce) or simply save\nmoney (automated stock control).\nIn many cases, the expected economic", "token_count": 512, "start_token": 7392, "end_token": 7904, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 17, "text": ", the production of chips, or manned space tri ps. In yet other cases\nsoftware may increase user service (library automation, e- commerce) or simply save\nmoney (automated stock control).\nIn many cases, the expected economic gain will be a major driv ing force. It may\nnot, however, always be easy to prove that automation saves m oney (just think of\nofﬁce automation) because apart from direct cost savings, t he economic gain may\nalso manifest itself in such things as a more ﬂexible product ion or a faster or better\nuser service. In either case, it is a value-creating activit y.\nBoehm (1981) estimated the total expenditure on software in the US to be $40\nbillion in 1980. This is approximately 2% of the GNP. In 1985, the total expenditure\nhad risen to $70 billion in the US and $140 billion worldwide. Boehm and Sullivan\n(1999) estimated the annual expenditure on software develo pment in 1998 to be\n$300-400 billion in the US, and twice that amount worlwide.\nSo the cost of software is of crucial importance. This concerns not only the cost of\ndeveloping the software, but also the cost of keeping the sof tware operational once\nit has been delivered to the customer. In the course of time, h ardware costs have\ndecreased dramatically. Hardware costs now typically comp rise less than 20% of total\nexpenditure (ﬁgure 1.1). The remaining 80% comprise all non -hardware costs: the\ncost of programmers, analysts, management, user training, secretarial help, etc.\nAn aspect closely linked with cost is productivity. In the 1980s, the quest for data\nprocessing personnel increased by 12% per year, while the po pulation of people\nworking in data processing and the productivity of those peo ple each grew by\napproximately 4% per year (Boehm, 1987a). This situation ha s not fundamentally\nchanged (Jones, 1999). The net effect is a growing gap betwee n demand and supply.\nThe result is both a backlog with respect to the maintenance o f existing software and\na slowing down in the development of new applications. The co mbined effect may\nhave repercussions on the competitive edge of an organizati on, especially so when\nthere are severe time", "token_count": 512, "start_token": 7854, "end_token": 8366, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 18, "text": " with respect to the maintenance o f existing software and\na slowing down in the development of new applications. The co mbined effect may\nhave repercussions on the competitive edge of an organizati on, especially so when\nthere are severe time-to-market constraints. These develo pments have led to a shift\nfrom producing software to using software. We’ll come back to this topic in section 1.6\nand chapter ??.\nThe issues of cost and productivity of software development deserve our serious\nattention. However, this is not the complete story. Society is increasingly dependent\n4 INTRODUCTION\nFigure 1.1 Relative distribution of hardware/software cos ts. ( Source: B.W. Boehm,\nSoftware Engineering , IEEE Transactions on Computers, 1976 IEEE. )\non software. The quality of the systems we develop increasin gly determines the\nquality of our existence. Consider as an example the followi ng message from a Dutch\nnewspaper on June 6, 1980, under the heading ‘Americans saw t he Russians coming’:\nFor a short period last Tuesday the United States brought the ir atomic\nbombers and nuclear missiles to an increased state of alarm w hen, because\nof a computer error, a false alarm indicated that the Soviet U nion had\nstarted a missile attack.\nEfforts to repair the error were apparently in vain, for on Ju ne 9, 1980, the same\nnewspaper reported:\nFor the second time within a few days, a deranged computer rep orted\nthat the Soviet Union had started a nuclear attack against th e United\nStates. Last Saturday, the DoD afﬁrmed the false message, wh ich resulted\nin the engines of the planes of the strategic air force being s tarted.\nIt is not always the world that is in danger. On a smaller scale , errors in software\nmay have very unfortunate consequences, such as transactio n errors in bank trafﬁc;\nreminders to ﬁnally pay that bill of $0.00; a stock control sy stem that issues orders\ntoo late and thus lays off complete divisions of a factory.\n1.1. WHAT IS SOFTWARE ENGINEERING? 5\nThe latter example indicates that errors in a software syste m may have serious\nﬁnancial consequences for the organization using it. One ex ample of such a �", "token_count": 512, "start_token": 8316, "end_token": 8828, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 19, "text": "1.1. WHAT IS SOFTWARE ENGINEERING? 5\nThe latter example indicates that errors in a software syste m may have serious\nﬁnancial consequences for the organization using it. One ex ample of such a ﬁnancial\nloss is the large US airline company that lost $50M because of an error in their\nseat reservation system. The system erroneously reported t hat cheap seats were sold\nout, while in fact there were plenty available. The problem w as detected only after\nquarterly results lagged considerably behind those of both their own previous periods\nand those of their competitors.\nErrors in automated systems may even have fatal effects. One computer science\nweekly magazine contained the following message in April 19 83:\nThe court in D ¨ usseldorf has discharged a woman (54), who was on trial\nfor murdering her daughter. An erroneous message from a comp uterized\nsystem made the insurance company inform her that she was ser iously\nill. She was said to suffer from an incurable form of syphilis . Moreover,\nshe was said to have infected both her children. In panic, she strangled\nher 15 year old daughter and tried to kill her 13 year old son an d herself.\nThe boy escaped, and with some help he enlisted prevented the woman\nfrom dying of an overdose. The judge blamed the computer erro r and\nconsidered the woman not responsible for her actions.\nThis all marks the enormous importance of the ﬁeld of softwar e engineering.\nBetter methods and techniques for software development may result in large ﬁnancial\nsavings, in more effective methods of software development , in systems that better ﬁt\nuser needs, in more reliable software systems, and thus in a m ore reliable environment\nin which those systems function. Quality and productivity a re two central themes in\nthe ﬁeld of software engineering.\nOn the positive side, it is imperative to point to the enormou s progress that has\nbeen made since the 1960s. Software is ubiquitous and scores of trustworthy systems\nhave been built. These range from small spreadsheet applica tions to typesetting\nsystems, banking systems, Web browsers and the Space Shuttl e software. The\ntechniques and methods discussed in this book have contribu ted their mite to the\nsuccess of these and many other software development projec ts.\n1.1 What", "token_count": 512, "start_token": 8778, "end_token": 9290, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 20, "text": " Web browsers and the Space Shuttl e software. The\ntechniques and methods discussed in this book have contribu ted their mite to the\nsuccess of these and many other software development projec ts.\n1.1 What is Software Engineering?\nIn various texts on this topic, one encounters a deﬁnition of the term software\nengineering. An early deﬁnition was given at the ﬁrst NATO co nference (Naur and\nRandell, 1968):\nSoftware engineering is the establishment and use of sound e ngineering\nprinciples in order to obtain economically software that is reliable and\nworks efﬁciently on real machines.\nThe deﬁnition given in the IEEE Standard Glossary of Software Engineering Terminol-\nogy (IEEE610, 1990) is as follows:\n6 INTRODUCTION\nSoftware engineering is the application of a systematic, di sciplined,\nquantiﬁable approach to the development, operation, and ma intenance\nof software; that is, the application of engineering to soft ware.\nThese and other deﬁnitions of the term software engineering use rather different\nwords. However, the essential characteristics of the ﬁeld a re always, explicitly or\nimplicitly, present:\n/AF Software engineering concerns the development of large pro grams.\n(DeRemer and Kron, 1976) make a distinction between programming-in-the-\nlarge and programming-in-the-small . The borderline between large and small\nobviously is not sharp: a program of 100 lines is small, a prog ram of 50 000 lines\nof code certainly is not. Programming-in-the-small genera lly refers to programs\nwritten by one person in a relatively short period of time. Pr ogramming-in-the-\nlarge, then, refers to multi-person jobs that span, say, mor e than half a year.\nFor example:\n– The NASA Space Shuttle software contains 40M lines of object code\n(this is 30 times as much as the software for the Saturn V proje ct from the\n1960s) (Boehm, 1981);\n– The IBM OS360 operating system took 5000 man years of develop ment\neffort (Brooks, 1995).\nTraditional programming techniques and tools are primaril y aimed at support-\n", "token_count": 512, "start_token": 9240, "end_token": 9752, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 21, "text": "1960s) (Boehm, 1981);\n– The IBM OS360 operating system took 5000 man years of develop ment\neffort (Brooks, 1995).\nTraditional programming techniques and tools are primaril y aimed at support-\ning programming-in-the-small. This not only holds for prog ramming languages,\nbut also for the tools (like ﬂowcharts) and methods (like str uctured program-\nming). These cannot be directly transferred to the developm ent of large\nprograms.\nIn fact, the term program -- in the sense of a self-contained p iece of software\nthat can be invoked by a user or some other system component -- is not\nadequate here. Present-day software development projects result in systems\ncontaining a large number of (interrelated) programs -- or c omponents.\n/AF The central theme is mastering complexity.\nIn general, the problems are such that they cannot be surveye d in their entirety.\nOne is forced to split the problem into parts such that each in dividual part can\nbe grasped, while the communication between the parts remai ns simple. The\ntotal complexity does not decrease in this way, but it does be come manageable.\nIn a stereo system there are components such as an ampliﬁer, a receiver, and a\ntuner, and communication via a thin wire. In software, we str ive for a similar\nseparation of concerns. In a program for library automation , components such\nas user interaction, search processes and data storage coul d for instance be\ndistinguished, with clearly given facilities for data exch ange between those\ncomponents. Note that the complexity of many a piece of softw are is not\n1.1. WHAT IS SOFTWARE ENGINEERING? 7\nso much caused by the intrinsic complexity of the problem (as in the case\nof compiler optimization algorithms or numerical algorith ms to solve partial\ndifferential equations), but rather by the vast number of de tails that must be\ndealt with.\n/AF Software evolves.\nMost software models a part of reality, such as processing re quests in a library\nor tracking money transfers in a bank. This reality evolves. If software is not to\nbecome obsolete fairly quickly, it has to evolve with the rea lity that is being\nmodeled. This means that costs are incurred after delivery o f the software\n", "token_count": 512, "start_token": 9702, "end_token": 10214, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 22, "text": " in a bank. This reality evolves. If software is not to\nbecome obsolete fairly quickly, it has to evolve with the rea lity that is being\nmodeled. This means that costs are incurred after delivery o f the software\nsystem and that we have to bear this evolution in mind during d evelopment.\n/AF The efﬁciency with which software is developed is of crucial importance.\nTotal cost and development time of software projects is high . This also holds\nfor the maintenance of software. The quest for new applicati ons surpasses the\nworkforce resource. The gap between supply and demand is gro wing. Time-\nto-market demands ask for quick delivery. Important themes within the ﬁeld of\nsoftware engineering concern better and more efﬁcient meth ods and tools for\nthe development and maintenance of software, especially me thods and tools\nenabling the use and reuse of components.\n/AF Regular cooperation between people is an integral part of pr ogramming-in-the-large.\nSince the problems are large, many people have to work concur rently at solving\nthose problems. Increasingly often, teams at different geo graphic locations\nwork together in software development. There must be clear a rrangements for\nthe distribution of work, methods of communication, respon sibilities, and so\non. Arrangements alone are not sufﬁcient, though; one also h as to stick to\nthose arrangements. In order to enforce them, standards or p rocedures may\nbe employed. Those procedures and standards can often be sup ported by\ntools. Discipline is one of the keys to the successful comple tion of a software\ndevelopment project.\n/AF The software has to support its users effectively.\nSoftware is developed in order to support users at work. The f unctionality\noffered should ﬁt users’ tasks. Users that are not satisﬁed w ith the system will\ntry to circumvent it or, at best, voice new requirements imme diately. It is not\nsufﬁcient to build the system in the right way, we also have to build the right\nsystem. Effective user support means that we must carefully study users at work,\nin order to determine the proper functional requirements, a nd we must address\nusability and other quality aspects as well, such as", "token_count": 512, "start_token": 10164, "end_token": 10676, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 23, "text": " also have to build the right\nsystem. Effective user support means that we must carefully study users at work,\nin order to determine the proper functional requirements, a nd we must address\nusability and other quality aspects as well, such as reliabi lity, responsiveness,\nand user-friendliness. It also means that software develop ment entails more\nthan delivering software. User manuals and training materi al may have to be\nwritten, and attention must be given to developing the envir onment in which\nthe new system is going to be installed. For example, a new aut omated library\nsystem will affect working procedures within the library.\n8 INTRODUCTION\n/AF Software engineering is a ﬁeld in which members of one cultur e create artifacts on behalf of\nmembers of another culture.\nThis aspect is closely linked to the previous two items. Soft ware engineers are\nexpert in one or more areas such as programming in Java, softw are architecture,\ntesting, or the Uniﬁed Modeling Language. They are generall y not experts in\nlibrary management, avionics, or banking. Yet they have to d evelop systems for\nsuch domains. The thin spread of application domain knowled ge is a common\nsource of problems in software development projects.\nNot only do software engineers lack factual knowledge of the domain for\nwhich they develop software, they lack knowledge of its cult ure as well. For\nexample, a software developer may discover the ‘ofﬁcial’ se t of work practices\nof a certain user community from interviews, written polici es, and the like;\nthese work practices are then built into the software. A cruc ial question with\nrespect to system acceptance and success, however, is wheth er that community\nactually follows those work practices. For an outside obser ver, this question is\nmuch more difﬁcult to answer.\n/AF Software engineering is a balancing act.\nIn most realistic cases, it is illusive to assume that the col lection of requirements\nvoiced at the start of the project is the only factor that coun ts. In fact, the\nterm requirement is a misnomer. It suggests something immut able, while in\nfact most requirements are negotiable. There are numerous b usiness, technical\nand political constraints that may inﬂuence a software deve lopment project", "token_count": 512, "start_token": 10626, "end_token": 11138, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 24, "text": " misnomer. It suggests something immut able, while in\nfact most requirements are negotiable. There are numerous b usiness, technical\nand political constraints that may inﬂuence a software deve lopment project.\nFor example, one may decide to use database technology X rath er than Y,\nsimply because of available expertise with that technology . In extreme cases,\ncharacteristics of available components may determine fun ctionality offered,\nrather than the other way around.\nThe above list shows that software engineering has many face ts. Software engineering\ncertainly is not the same as programming, although programming is an importa nt\ningredient of software engineering. Mathematical aspects play a role since we\nare concerned with the correctness of software. Sound engin eering practices are\nneeded to get useful products. Psychological and sociologi cal aspects play a role in\nthe communication between human and machine, organization and machine, and\nbetween humans. Finally, the development process needs to b e controlled, which is\na management issue.\nThe term ‘software engineering’ hints at possible resembla nces between the\nconstruction of programs and the construction of houses or b ridges. These kinds of\nresemblances do exist. In both cases we work from a set of desi red functions, using\nscientiﬁc and engineering techniques in a creative way. Tec hniques that have been\napplied successfully in the construction of physical artif acts are also helpful when\napplied to the construction of software systems: developme nt of the product in a\nnumber of phases, a careful planning of these phases, contin uous audit of the whole\nprocess, construction from a clear and complete design, etc .\n1.1. WHAT IS SOFTWARE ENGINEERING? 9\nEven in a mature engineering discipline, say bridge design, accidents do happen.\nBridges collapse once in a while. Most problems in bridge des ign occur when designers\nextrapolate beyond their models and expertise. A famous exa mple is the Tacoma\nNarrows Bridge failure in 1940. The designers of that bridge extrapolated beyond\ntheir experience to create more ﬂexible stiffening girders for suspension bridges. They\ndid not think about aerodynamics and the response of the brid ge to wind. As a result,\nthat bridge collapsed shortly after it was ﬁnished.", "token_count": 512, "start_token": 11088, "end_token": 11600, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 25, "text": " ﬂexible stiffening girders for suspension bridges. They\ndid not think about aerodynamics and the response of the brid ge to wind. As a result,\nthat bridge collapsed shortly after it was ﬁnished. This typ e of extrapolation seems to\nbe the rule rather than the exception in software developmen t. We regularly embark\non software development projects that go far beyond our expe rtise.\nThere are additional reasons for considering the construct ion of software as\nsomething quite different from the construction of physica l products. The cost of\nconstructing software is incurred during development and n ot during production.\nCopying software is almost free. Software is logical in natu re rather than physical.\nPhysical products wear out in time and therefore have to be ma intained. Software\ndoes not wear out. The need to maintain software is caused by e rrors detected late\nor by changing requirements of the user. Software reliabili ty is determined by the\nmanifestation of errors already present, not by physical fa ctors such as wear and tear.\nWe may even argue that software wears out because it is being maintained.\nViewing software engineering as a branch of engineering is p roblematic for\nanother reason as well. The engineering metaphor hints at di sciplined work, proper\nplanning, good management, and the like. It suggests we deal with clearly deﬁned\nneeds, that can be fulﬁlled if we follow all the right steps. M any software development\nprojects though involve the translation of some real world p henomenon into digital\nform. The knowledge embedded in this real life phenomenon is tacit, undeﬁned,\nuncodiﬁed, and may have developed over a long period of time. The assumption that\nwe are dealing with a well-deﬁned problem simply does not hol d. Rather, the design\nprocess is open ended, and the solution emerges as we go along . This dichotomy is\nreﬂected in views of the ﬁeld put in the forefront over time (E ischen, 2002). In the\nearly days, the ﬁeld was seen as a craft. As a countermovement , the term software\nengineering was coined, and many factory concepts got intro duced. In the late 1990’s,\nthe pendulum swung back again and the craft", "token_count": 512, "start_token": 11550, "end_token": 12062, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 26, "text": "�eld was seen as a craft. As a countermovement , the term software\nengineering was coined, and many factory concepts got intro duced. In the late 1990’s,\nthe pendulum swung back again and the craft aspect got emphas ized anew, in the\nagile movement (see chapter 3). Both engineering-like and c raft-like aspects have\ntheir place, and we will give a balanced treatment of both.\nTwo characteristics that make software development projec ts extra difﬁcult to\nmanage are visibility and continuity. It is much more difﬁcu lt to see progress in\nsoftware construction than it is to notice progress in build ing a bridge. One often\nhears the phrase that a program ‘is almost ﬁnished’. One equa lly often underestimates\nthe time needed to ﬁnish up the last bits and pieces.\nThis ‘90% complete’ syndrome is very pervasive in software d evelopment. Not\nknowing how to measure real progress, we often use a surrogat e measure, the rate\nof expenditure of resources. For example, a project that has a budget of 100 person-\ndays is perceived as being 50% complete after 50 person-days are expended. Strictly\nspeaking, we then confuse speed with progress. Because of th e imprecise measurement\n10 INTRODUCTION\nof progress and the customary underestimation of total effo rt, problems accumulate\nas time elapses.\nPhysical systems are often continuous in the sense that smal l changes in the\nspeciﬁcation lead to small changes in the product. This is no t true with software.\nSmall changes in the speciﬁcation of software may lead to con siderable changes in\nthe software itself. In a similar way, small errors in softwa re may have considerable\neffects. The Mariner space rocket to Venus for example got lo st because of a typing\nerror in a FORTRAN program. In 1998, the Mars Climate Orbiter got lost, because\none development team used English units such as inches and fe et, while another team\nused metric units.\nWe may likewise draw a comparison between software engineer ing and computer\nscience. Computer science emerged as a separate discipline in the 1960s. It split\nfrom mathematics and has been heavily inﬂuenced by mathemat", "token_count": 512, "start_token": 12012, "end_token": 12524, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 27, "text": "\nused metric units.\nWe may likewise draw a comparison between software engineer ing and computer\nscience. Computer science emerged as a separate discipline in the 1960s. It split\nfrom mathematics and has been heavily inﬂuenced by mathemat ics. Topics studied in\ncomputer science, such as algorithm complexity, formal lan guages, and the semantics\nof programming languages, have a strong mathematical ﬂavor . PhD theses in computer\nscience invariably contain theorems with accompanying pro ofs.\nAs the ﬁeld of software engineering emerged from computer sc ience, it had a\nsimilar inclination to focus on clean aspects of software de velopment that can be\nformalized, in both teaching and research. We used to assume that requirements can\nbe fully stated before the project started, concentrated on systems built from scratch,\nand ignored the reality of trading off quality aspects again st the available budget. Not\nto mention the trenches of software maintenance.\nSoftware engineering and computer science do have a conside rable overlap. The\npractice of software engineering however also has to deal wi th such matters as\nthe management of huge development projects, human factors (regarding both the\ndevelopment team and the prospective users of the system) an d cost estimation and\ncontrol. Software engineers must engineer software.\nSoftware engineering has many things in common both with oth er ﬁelds of\nengineering and with computer science. It also has a face of i ts own in many ways.\n1.2 Phases in the Development of Software\nWhen building a house, the builder does not start with piling up bricks. Rather, the\nrequirements and possibilities of the client are analyzed ﬁ rst, taking into account such\nfactors as family structure, hobbies, ﬁnances and the like. The architect takes these\nfactors into consideration when designing a house. Only aft er the design has been\nagreed upon is the actual construction started.\nIt is expedient to act in the same way when constructing softw are. First, the\nproblem to be solved is analyzed and the requirements are des cribed in a very\nprecise way. Then a design is made based on these requirement s. Finally, the\nconstruction process, i.e. the actual programming of the so lution, is started. There\nare a distinguishable number of phases in the development of software. The phases\nas discussed in this", "token_count": 512, "start_token": 12474, "end_token": 12986, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 28, "text": " these requirement s. Finally, the\nconstruction process, i.e. the actual programming of the so lution, is started. There\nare a distinguishable number of phases in the development of software. The phases\nas discussed in this book are depicted in ﬁgure 1.2.\n1.2. PHASES IN THE DEVELOPMENT OF SOFTWARE 11\nFigure 1.2 A simple view of software development\nThe process model depicted in ﬁgure 1.2 is rather simple. In reality, things wi ll\nusually be more complex. For instance, the design phase is of ten split into a global,\narchitectural design phase and a detailed design phase, and often various test phases\nare distinguished. The basic elements, however, remain as g iven in ﬁgure 1.2. These\nphases have to be passed through in each project. Depending o n the kind of project\nand the working environment, a more detailed scheme may be ne eded.\nIn ﬁgure 1.2, the phases have been depicted sequentially. Fo r a given project these\nactivities are not necessarily separated as strictly as ind icated here. They may and\nusually will overlap. It is, for instance, quite possible to start implementation of one\npart of the system while some of the other parts have not been f ully designed yet.\nAs we will see in section 1.3, there is no strict linear progre ssion from requirements\nengineering to design, from design to implementation, etc. Backtracking to earlier\nphases occurs, because of errors discovered or changing req uirements. One had better\n12 INTRODUCTION\nthink of these phases as a series of workﬂows. Early on, most r esources are spent on\nthe requirements engineering workﬂow. Later on, effort mov es to the implementation\nand testing workﬂows.\nBelow, a short description is given of each of the basic eleme nts from ﬁgure 1.2.\nVarious alternative process models will be discussed in cha pter 3. These alternative\nmodels result from justiﬁable criticism of the simple-mind ed model depicted in\nﬁgure 1.2. The sole aim of our simple model is to provide an ade quate structuring\nof topics to be addressed. The maintenance phase is further d", "token_count": 512, "start_token": 12936, "end_token": 13448, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 29, "text": " criticism of the simple-mind ed model depicted in\nﬁgure 1.2. The sole aim of our simple model is to provide an ade quate structuring\nof topics to be addressed. The maintenance phase is further d iscussed in section 1.3.\nAll elements of our process model will be treated much more el aborately in later\nchapters.\nRequirements engineering . The goal of the requirements engineering phase is to\nget a complete description of the problem to be solved and the requirements posed\nby and on the environment in which the system is going to funct ion. Requirements\nposed by the environment may include hardware and supportin g software or the\nnumber of prospective users of the system to be developed. Al ternatively, analysis\nof the requirements may lead to certain constraints imposed on hardware yet to be\nacquired or to the organization in which the system is to func tion. A description of\nthe problem to be solved includes such things as:\n– the functions of the software to be developed;\n– possible future extensions to the system;\n– the amount, and kind, of documentation required;\n– response time and other performance requirements of the sy stem.\nPart of requirements engineering is a feasibility study . The purpose of the feasibility\nstudy is to assess whether there is a solution to the problem w hich is both economically\nand technically feasible.\nThe more careful we are during the requirements engineering phase, the larger is\nthe chance that the ultimate system will meet expectations. To this end, the various\npeople (among others, the customer, prospective users, des igners, and programmers)\ninvolved have to collaborate intensively. These people oft en have widely different\nbackgrounds, which does not ease communication.\nThe document in which the result of this activity is laid down is called the\nrequirements speciﬁcation .\nDesign. During the design phase, a model of the whole system is devel oped which,\nwhen encoded in some programming language, solves the probl em for the user. To\nthis end, the problem is decomposed into manageable pieces c alled components; the\nfunctions of these components and the interfaces between them are speciﬁed in a\nvery precise way. The design phase is crucial. Requirements engineering and design\nare sometimes seen as an annoying introduction to programmi ng, which is often seen\n1.2. PHASES IN THE DEVEL", "token_count": 512, "start_token": 13398, "end_token": 13910, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 30, "text": "ﬁed in a\nvery precise way. The design phase is crucial. Requirements engineering and design\nare sometimes seen as an annoying introduction to programmi ng, which is often seen\n1.2. PHASES IN THE DEVELOPMENT OF SOFTWARE 13\nas the real work. This attitude has a very negative inﬂuence o n the quality of the\nresulting software.\nEarly design decisions have a major impact on the quality of t he ﬁnal system.\nThese early design decisions may be captured in a global desc ription of the system,\ni.e. its architecture. The architecture may next be evaluated, serve as a template\nfor the development of a family of similar systems, or be used as a skeleton for\nthe development of reusable components. As such, the archit ectural description of\na system is an important milestone document in present-day s oftware development\nprojects.\nDuring the design phase we try to separate the what from the how. We concentrate\non the problem and should not let ourselves be distracted by i mplementation concerns.\nThe result of the design phase, the ( technical) speciﬁcation , serves as a starting\npoint for the implementation phase. If the speciﬁcation is f ormal in nature, it can also\nbe used to derive correctness proofs.\nImplementation. During the implementation phase, we concentrate on the ind ividual\ncomponents. Our starting point is the component’s speciﬁca tion. It is often necessary\nto introduce an extra ‘design’ phase, the step from componen t speciﬁcation to\nexecutable code often being too large. In such cases, we may t ake advantage of\nsome high-level, programming-language-like notation, su ch as a pseudocode. (A\npseudocode is a kind of programming language. Its syntax and semantics are in\ngeneral less strict, so that algorithms can be formulated at a higher, more abstract,\nlevel.)\nIt is important to note that the ﬁrst goal of a programmer shou ld be the\ndevelopment of a well-documented, reliable, easy to read, ﬂ exible, correct, program.\nThe goal is not to produce a very efﬁcient program full of tricks. We will com e back\nto the many dimensions", "token_count": 512, "start_token": 13860, "end_token": 14372, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 31, "text": " well-documented, reliable, easy to read, ﬂ exible, correct, program.\nThe goal is not to produce a very efﬁcient program full of tricks. We will com e back\nto the many dimensions of software quality in chapter 6.\nDuring the design phase, a global structure is imposed throu gh the introduction\nof components and their interfaces. In the more classic prog ramming languages, much\nof this structure tends to get lost in the transition from des ign to code. More recent\nprogramming languages offer possibilities to retain this s tructure in the ﬁnal code\nthrough the concept of modules or classes.\nThe result of the implementation phase is an executable prog ram.\nTesting. Actually, it is wrong to say that testing is a phase followin g implementation.\nThis suggests that you need not bother about testing until im plementation is ﬁnished.\nThis is not true. It is even fair to say that this is one of the bi ggest mistakes you can\nmake.\nAttention has to be paid to testing even during the requireme nts engineering\nphase. During the subsequent phases, testing is continued a nd reﬁned. The earlier\nthat errors are detected, the cheaper it is to correct them.\nTesting at phase boundaries comes in two ﬂavors. We have to te st that the\ntransition between subsequent phases is correct (this is kn own as veriﬁcation ). We\nalso have to check that we are still on the right track as regar ds fulﬁlling user\n14 INTRODUCTION\nrequirements ( validation). The result of adding veriﬁcation and validation activiti es\nto the linear model of ﬁgure 1.2 yields the so-called waterfall model of software\ndevelopment (see also chapter 3).\nMaintenance. After delivery of the software, there are often errors that have still\ngone undetected. Obviously, these errors must be repaired. In addition, the actual\nuse of the system can lead to requests for changes and enhance ments. All these types\nof changes are denoted by the rather unfortunate term mainte nance. Maintenance\nthus concerns all activities needed to keep the system opera tional after it has been\ndelivered to the user.\nAn activity spanning all phases is project management . Like other projects, software\ndevelopment projects", "token_count": 512, "start_token": 14322, "end_token": 14834, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 32, "text": " unfortunate term mainte nance. Maintenance\nthus concerns all activities needed to keep the system opera tional after it has been\ndelivered to the user.\nAn activity spanning all phases is project management . Like other projects, software\ndevelopment projects must be managed properly in order to en sure that the product\nis delivered on time and within budget. The visibility and co ntinuity characteristics\nof software development, as well as the fact that many softwa re development\nprojects are undertaken with insufﬁcient prior experience , seriously impede project\ncontrol. The many examples of software development project s that fail to meet their\nschedule provide ample evidence of the fact that we have by no means satisfactorily\ndealt with this issue yet. Chapters 2--8 deal with major aspe cts of software project\nmanagement, such as project planning, team organization, q uality issues, cost and\nschedule estimation.\nAn important activity not identiﬁed separately is documentation. A number of key\ningredients of the documentation of a software project will be elaborated upon\nin the chapters to follow. Key components of system document ation include the\nproject plan, quality plan, requirements speciﬁcation, ar chitecture description, design\ndocumentation and test plan. For larger projects, a conside rable amount of effort will\nhave to be spent on properly documenting the project. The doc umentation effort\nmust start early on in the project. In practice, documentati on is often seen as a\nbalancing item. Since many projects are pressed for time, th e documentation tends\nto get the worst of it. Software maintainers and developers k now this, and adapt their\nway of working accordingly. As a rule of thumb, Lethbridge et al. (2003) states that,\nthe closer one gets to the code, the more accurate the documen tation must be for\nsoftware engineers to use it. Outdated requirements docume nts and other high-level\ndocumentation may still give valuable clues. They are usefu l to people who have\nto learn about a new system or have to develop test cases, for i nstance. Outdated\nlow-level documentation is worthless, and makes that progr ammers consult the code\nrather than its documentation. Since the system will underg o changes after delivery,\nbecause of errors that went undetected or changing user requ irements, proper and\nup-", "token_count": 512, "start_token": 14784, "end_token": 15296, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 33, "text": " is worthless, and makes that progr ammers consult the code\nrather than its documentation. Since the system will underg o changes after delivery,\nbecause of errors that went undetected or changing user requ irements, proper and\nup-to-date documentation is of crucial importance during m aintenance.\nA particularly noteworthy element of documentation is the u ser documentation.\nSoftware development should be task-oriented in the sense t hat the software to\nbe delivered should support users in their task environment . Likewise, the user\ndocumentation should be task- oriented. User manuals shoul d not just describe the\nfeatures of a system, they should help people to get things do ne (Rettig, 1991). We\n1.2. PHASES IN THE DEVELOPMENT OF SOFTWARE 15\ncannot simply rely on the structure of the interface to organ ize the user documentation\n(just as a programming language reference manual is not an ap propriate source for\nlearning how to program).\nFigure 1.3 depicts the relative effort spent on the various a ctivities up to delivery\nof the system. From this data a very clear trend emerges, the s o-called 40--20--40\nrule: only 20% of the effort is spent on actually programming (coding) the system,\nwhile the preceding phases (requirements engineering and d esign) and testing each\nconsume about 40% of the total effort.\nFigure 1.3 Relative effort for the various activities\nDepending on speciﬁc boundary conditions, properties of th e system to be\nconstructed, and the like, variations to this rule can be fou nd. For iterative development\nprojects, the distinction between requirements engineeri ng, design, implementation\nand (unit) testing gets blurred, for instance. For the major ity of projects, however,\nthis rule of thumb is quite workable.\nThis does not imply that the 40--20--40 rule is the one to be st rived for. Errors\nmade during requirements engineering are the ones that are m ost costly to repair (see\nalso the chapter on testing). It is far better to put more ener gy into the requirements\nengineering phase, than to try to remove errors during the ti me-consuming testing\nphase or, worse still, during maintenance. According to (Bo ehm, 1987b), successful\nprojects follow a 60--15--25 distribution: 60% requiremen ts", "token_count": 512, "start_token": 15246, "end_token": 15758, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 34, "text": " than to try to remove errors during the ti me-consuming testing\nphase or, worse still, during maintenance. According to (Bo ehm, 1987b), successful\nprojects follow a 60--15--25 distribution: 60% requiremen ts engineering and design,\n15% implementation and 25% testing. The message is clear: th e longer you postpone\ncoding, the earlier you are ﬁnished.\nFigure 1.3 does not show the extent of the maintenance effort . When we consider\nthe total cost of a software system over its lifetime, it turn s out that, on average,\nmaintenance alone consumes 50--75% of these costs; see also ﬁgure 1.1. Thus,\nmaintenance alone consumes more than the various developme nt phases taken\ntogether.\n16 INTRODUCTION\n1.3 Maintenance or Evolution\nThe only thing we maintain is user satisfaction\n(Lehman, 1980)\nOnce software has been delivered, it usually still contains errors which, upon\ndiscovery, must be repaired. Note that this type of maintena nce is not caused by\nwearing. Rather, it concerns repair of hidden defects. This type of repair is comparable\nto that encountered after a newly-built house is ﬁrst occupi ed.\nThe story becomes quite different if we start talking about c hanges or enhance-\nments to the system. Repainting our ofﬁce or repairing a leak in the roof of our house\nis called maintenance. Adding a wing to our ofﬁce is seldom ca lled maintenance.\nThis is more than a triﬂing game with words. Over the total lif etime of a software\nsystem, more money is spent on maintaining that system than o n initial development.\nIf all these expenses merely concerned the repair of errors m ade during one of the\ndevelopment phases, our business would be doing very badly i ndeed. Fortunately,\nthis is not the case.\nWe distinguish four kinds of maintenance activities:\n– corrective maintenance -- the repair of actual errors;\n– adaptive maintenance -- adapting the software to changes in the envir onment,\nsuch as new hardware or the next release of an operating or dat abase system;\n– perfective maintenance -- adapting the software to new or changed user\nrequirements, such as extra functions to be provided by the s ystem. Perfective", "token_count": 512, "start_token": 15708, "end_token": 16220, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 35, "text": "such as new hardware or the next release of an operating or dat abase system;\n– perfective maintenance -- adapting the software to new or changed user\nrequirements, such as extra functions to be provided by the s ystem. Perfective\nmaintenance also includes work to increase the system’s per formance or to\nenhance its user interface;\n– preventive maintenance -- increasing the system’s future maintainabi lity.\nUpdating documentation, adding comments, or improving the modular struc-\nture of a system are examples of preventive maintenance acti vities.\nOnly the ﬁrst category may rightfully be termed maintenance . This category, how-\never, accounts only for about a quarter of the total maintena nce effort. Approximately\nanother quarter of the maintenance effort concerns adaptin g software to environmen-\ntal changes, while half of the maintenance cost is spent on ch anges to accommodate\nchanging user requirements, i.e. enhancements to the syste m (see ﬁgure 1.4).\nChanges in both the system’s environment and user requireme nts are inevitable.\nSoftware models part of reality, and reality changes, wheth er we like it or not. So\nthe software has to change too. It has to evolve. A large percentage of what we are\nused to calling maintenance is actually evolution. Mainten ance because of new user\nrequirements occurs in both high and low quality systems. A s uccessful system calls\nfor new, unforeseen functionality, because of its use by man y satisﬁed users. A less\nsuccessful system has to be adapted in order to satisfy its cu stomers.\n1.4. FROM THE TRENCHES 17\nFigure 1.4 Distribution of maintenance activities\nThe result is that the software development process becomes cyclic, hence the\nphrase software life cycle . Backtracking to previous phases, alluded to above, does\nnot only occur during maintenance. During other phases, als o, we will from time to\ntime iterate earlier phases. During design, it may be discov ered that the requirements\nspeciﬁcation is not complete or contains conﬂicting requir ements. During testing,\nerrors introduced in the implementation or design phase may crop up. In these and\nsimilar cases an iteration of earlier phases is needed. We wi ll come back to", "token_count": 512, "start_token": 16170, "end_token": 16682, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 36, "text": " complete or contains conﬂicting requir ements. During testing,\nerrors introduced in the implementation or design phase may crop up. In these and\nsimilar cases an iteration of earlier phases is needed. We wi ll come back to this cyclic\nnature of the software development process in chapter 3, whe n we discuss alternative\nmodels of the software development process.\n1.4 From the Trenches\nAnd such is the way of all superstition, whether in astrology , dreams, omens, divine\njudgments or the like; wherein men, having a delight in such v anities, mark the events\nwhen they are fulﬁlled, but when they fail, though this happe ns much oftener, neglect and\npass them by. But with far more subtlety does this mischief in sinuate itself into philosophy\nand the sciences; in which the ﬁrst conclusion colours and br ings into conformity with\nitself all that come after, though far sounder and better. Be sides, independently of that\ndelight and vanity which I have described, it is the peculiar and perpetual error of the\nhuman intellect to be more moved and excited by afﬁrmatives t han by negatives; whereas\nit ought properly to hold itself indifferently disposed tow ards both alike. Indeed in the\nestablishment of any true axiom, the negative instance is th e more forcible of the two.\nSir Francis Bacon, The New Organon, Aphorisms XLVI (1611)\nHistorical case studies contain a wealth of wisdom about the nature of design and the\nengineering method.\n(Petroski, 1994)\nIn his wonderful book Design Paradigms, Case Histories of Error and Judgment in En gineering,\nHenri Petroski tells us about some of the greatest engineeri ng successes and, especially,\n18 INTRODUCTION\nfailures of all time. Some such failure stories about our pro fession have appeared as\nwell. Four of them are discussed in this section.\nThese stories are interesting because they teach us that sof tware engineering has\nmany facets. Failures in software development projects oft en are not one-dimensional.\nThey are not only caused by a technical slip in some routine. They are not only caused\nby bad management. They are not only the result of human communication problems.\nIt is often a combination of many smaller slips, which accumu", "token_count": 512, "start_token": 16632, "end_token": 17144, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 37, "text": ".\nThey are not only caused by a technical slip in some routine. They are not only caused\nby bad management. They are not only the result of human communication problems.\nIt is often a combination of many smaller slips, which accumu late over time, and\neventually result in a major failure. To paraphrase a famous saying of Fred Brooks\nabout projects getting late:\n‘How does a project really get into trouble?’\n‘One slip at a time.’\nEach of the stories discussed below shows such a cumulative e ffect. Successes\nin software development will not come about if we just employ the brightest\nprogrammers. Or apply the newest design philosophy. Or have the most extensive\nuser consultation. Or even hire the best manager. You have to do all of that. And\neven more.\n1.4.1 Ariane 5, Flight 501\nThe maiden ﬂight of the Ariane 5 launcher took place on June 4, 1996. After about 40\nseconds, at an altitude of less than 4 kilometers, the launch er broke up and exploded.\nThis $500M loss was ultimately caused by an overﬂow in the con version from a\n64-bit ﬂoating point number to a 16-bit signed integer. From a software engineering\npoint of view, the Ariane 5 story is interesting because the f ailure can be attributed to\ndifferent causes, at different levels of understanding: in adequate testing, wrong type\nof reuse, or a wrong design philosophy.\nThe altitude of the launcher and its movements in space are me asured by\nan Inertial Reference System (SRI -- Syst ` eme de R ´ ef ´ erenc e Inertielle). There are\ntwo SRIs operating in parallel. Their hardware and software is identical. Most of\nthe hardware and software for the SRI was retained from the Ar iane 4. The fatal\nconversion took place in a piece of software in the SRI which i s only meaningful\nbefore lift-off. Though this part of the software serves no p urpose after the rocket\nhas been launched, it keeps running for an additional number of seconds. This\nrequirement was stated more than 10 years earlier for a somew hat peculiar reason. It\nallows for a quick restart of the countdown, in the case that i t is interrupted close to\nlift-off. This requirement does", "token_count": 512, "start_token": 17094, "end_token": 17606, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 38, "text": " of seconds. This\nrequirement was stated more than 10 years earlier for a somew hat peculiar reason. It\nallows for a quick restart of the countdown, in the case that i t is interrupted close to\nlift-off. This requirement does not apply to the Ariane 5, bu t the software was left\nunchanged -- after all, it worked. Since the Ariane 5 is much f aster than the Ariane\n4, the rocket reaches a much higher horizontal velocity with in this short period\nafter lift-off, resulting in the above-mentioned overﬂow. Because of this overﬂow,\nthe ﬁrst SRI ceased to function. The second SRI was then activ ated, but since the\nhardware and software of both SRIs are identical, the second SRI failed as well. As a\nconsequence, wrong data were transmitted from the SRI to the on-board computer.\n1.4. FROM THE TRENCHES 19\nOn the basis of these wrong data, full nozzle deﬂections were commanded. These\ncaused a very high aerodynamic load which led to the separati on of the boosters from\nthe main rocket. And this in turn triggered the self-destruc tion of the launcher.\nThere are several levels at which the Ariane 5 failure can be u nderstood and\nexplained:\n/AF It was a software failure, which could have been revealed wit h more extensive\ntesting. This is true: the committee investigating the even t managed to expose\nthe failure using extensive simulations.\n/AF The failure was caused by reusing a ﬂawed component. This is t rue as well but,\nbecause of physical characteristics of the Ariane 4, this ﬂa w had never become\napparent. There had been many successful Ariane 4 ﬂights, us ing essentially\nthe same SRI subsystem. Apparently, reuse is not compositio nal: the successful\nuse of a component in one environment is no guarantee for succ essful reuse of\nthat component in another environment.\n/AF The failure was caused by a ﬂaw in the design. The Ariane softw are follows a\ntypical hardware design philosophy: if a component breaks d own, the cause\nis assumed to be random and it is handled by shutting down that part and\ninvoking a backup component. In the case", "token_count": 512, "start_token": 17556, "end_token": 18068, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 39, "text": " The Ariane softw are follows a\ntypical hardware design philosophy: if a component breaks d own, the cause\nis assumed to be random and it is handled by shutting down that part and\ninvoking a backup component. In the case of a software failur e, which is not\nrandom, an identical backup is of little use. For the softwar e part, a different\nline might have been followed. For instance, the component c ould be asked to\ngive its best estimate of the required information.\n1.4.2 Therac-25\nThe Therac-25 is a computer-controlled radiation machine. It has three modes:\n/AF ﬁeld-light mode. This position merely facilitates the corr ect positioning of the\npatient.\n/AF electron mode. In electron therapy, the computer controls t he (variable) beam\nenergy and current, and magnets spread the beam to a safe conc entration.\n/AF photon (X-ray) mode. In photon mode, the beam energy is ﬁxed. A ‘beam\nﬂattener’ is put between the accelerator and the patient to p roduce a uniform\ntreatment ﬁeld. A very high current (some 100 times higher th an in electron\nmode) is required on one side of the beam ﬂattener to produce a reasonable\ntreatment dose at the other side.\nThe machine has a turntable which rotates the necessary equi pment into position.\nThe basic hazardous situation is obvious from the above: a ph oton beam is issued by\nthe accelerator, while the beam ﬂattener is not in position. The patient is then treated\nwith a dose which is far too high. This happened several times . As a consequence,\nseveral patients have died and others have been seriously in jured.\n20 INTRODUCTION\nOne of the malfunctions of the Therac-25 has become known as ‘ Malfunction\n54’. A patient was set up for treatment. The operator keyed in the necessary data on\nthe console in an adjacent room. While doing so, he made a mist ake: he typed ‘x’ (for\nX-ray mode) instead of ‘e’ (for electron mode). He corrected his mistake by moving\nthe cursor up to the appropriate ﬁeld, typing in the correct", "token_count": 512, "start_token": 18018, "end_token": 18530, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 40, "text": " he typed ‘x’ (for\nX-ray mode) instead of ‘e’ (for electron mode). He corrected his mistake by moving\nthe cursor up to the appropriate ﬁeld, typing in the correct c ode and pressing the\nreturn key a number of times until the cursor was on the comman d line again. He then\npressed ‘B’ (beam on). The machine stopped and issued the mes sage ‘Malfunction 54’.\nThis particular error message indicates a wrong dose, eithe r too high or too low. The\nconsole indicated a substantial underdose. The operator kn ew that the machine often\nhad quirks, and that these could usually be solved by simply p ressing ‘P’ (proceed).\nSo he did. The same error message appeared again. Normally, t he operator would\nhave audio and video contact with the patient in the treatmen t room. Not this time,\nthough: the audio was broken and the video had been turned off . It was later estimated\nthat the patient had received 16 000--25 000 rad on a very smal l surface, instead of\nthe intended dose of 180 rad. The patient became seriously il l and died ﬁve months\nlater.\nThe cause of this hazardous event was traced back to the softw are operating the\nradiation machine. After the operator has ﬁnished data entr y, the physical set up\nof the machine may begin. The bending of the magnets takes abo ut eight seconds.\nAfter the magnets are put into position, it again checks if an ything has changed. If\nthe operator manages to make changes and return the cursor to the command line\nposition within the eight seconds it takes to set the magnets , part of these changes\nwill result in changes in internal system parameters, but th e system nevertheless\n‘thinks’ that nothing has happened and simply continues. Wi th the consequences as\ndescribed above.\nAccidents like this get reported to the Federal Drugs Admini stration (FDA). The\nFDA requested the manufacturer to take appropriate measure s. The ‘ﬁx’ suggested was\nas follows:\nEffective immediately, and until further notice, the key us ed for moving\nthe cursor back through the prescription sequence (i.e. cur sor ‘UP’\ninscribed with an upward pointing arrow) must not", "token_count": 512, "start_token": 18480, "end_token": 18992, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 41, "text": "\nas follows:\nEffective immediately, and until further notice, the key us ed for moving\nthe cursor back through the prescription sequence (i.e. cur sor ‘UP’\ninscribed with an upward pointing arrow) must not be used for editing\nor any other purpose.\nTo avoid accidental use of this key, the key cap must be remove d and the\nswitch contacts ﬁxed in the open position with electrical ta pe or other\ninsulating material. . . .\nDisabling this key means that if any prescription data enter ed is incorrect\nthen an ‘R’ reset command must be used and the whole prescript ion\nreentered.\nThe FDA did not buy this remedy. In particular, they judged th e tone of the notiﬁcation\nnot commensurate with the urgency for doing so. The discussi on between the FDA\nand the manufacturer continued for quite some time before an adequate response was\ngiven to this and other failures of the Therac-25.\n1.4. FROM THE TRENCHES 21\nThe Therac-25 machine and its software evolved from earlier models that were\nless sophisticated. In earlier versions of the software, fo r example, it was not possible\nto move up and down the screen to change individual ﬁelds. Ope rators noticed that\ndifferent treatments often required almost the same data, w hich had to be keyed in all\nover again. To enhance usability, the feature to move the cur sor around and change\nindividual ﬁelds was added. Apparently, user friendliness may conﬂict with safety.\nIn earlier models also, the correct position of the turntabl e and other equipment\nwas ensured by simple electromechanical interlocks. These interlocks are a common\nmechanism to ensure safety. For instance, they are used in li fts to make sure that\nthe doors cannot be opened if the lift is in between ﬂoors. In t he Therac-25, these\nmechanical safety devices were replaced by software. The so ftware was thus made\ninto a single point of failure. This overconﬁdence in softwa re contributed to the\nTherac-25 accidents, together with inadequate software en gineering practices and an\ninadequate reaction of management to incidents.\n1.4.3 The London Ambul", "token_count": 512, "start_token": 18942, "end_token": 19454, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 42, "text": "ﬁdence in softwa re contributed to the\nTherac-25 accidents, together with inadequate software en gineering practices and an\ninadequate reaction of management to incidents.\n1.4.3 The London Ambulance Service\nThe London Ambulance Service (LAS) handles the ambulance tr afﬁc in Greater\nLondon. It covers an area of over 600 square miles and carries over 5000 patients per\nday in 750 vehicles. The LAS receives over 2000 phone calls pe r day, including more\nthan 1300 emergency calls. The system we discuss here is a com puter-aided dispatch\n(CAD) system. Such a CAD system has the following functional ity:\n/AF it handles call taking, accepts and veriﬁes incident detail s including the location\nof the incident;\n/AF it determines which ambulance to send;\n/AF it handles the mobilization of the ambulance and communicat es the details of\nthe incident to the ambulance;\n/AF it takes care of ambulance resource management, in particul ar the positioning\nof vehicles to minimize response times.\nA fully-ﬂedged CAD system is quite complex. In panic, someon e might call and say\nthat an accident has happened in front of Foyle’s, assuming t hat everyone knows\nwhere this bookshop is located. An extensive gazetteer comp onent including a public\ntelephone identiﬁcation helps in solving this type of probl em. The CAD system also\ncontains a radio system, mobile terminals in the ambulances , and an automatic vehicle\nlocation system.\nThe CAD project of the London Ambulance Service was started i n the autumn\nof 1990. The delivery was scheduled for January 1992. At that time, however, the\nsoftware was still far from complete. Over the ﬁrst nine mont hs of 1992, the system\nwas installed piecemeal across a number of different LAS div isions, but it was never\nstable. On 26 and 27 October 1992, there were serious problem s with the system and\n22 INTRODUCTION\nit was decided to revert to a semi-manual mode of operation. O n 4 November 1992,\nthe system crashed. The Regional Health Authority establis hed an Inquiry Team\nto investigate the failures and the history that led to them. They came up with an\n80-page report,", "token_count": 512, "start_token": 19404, "end_token": 19916, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 43, "text": "ual mode of operation. O n 4 November 1992,\nthe system crashed. The Regional Health Authority establis hed an Inquiry Team\nto investigate the failures and the history that led to them. They came up with an\n80-page report, which reads like a suspense novel. Below, we highlight some of the\nissues raised in this report.\nThe envisaged CAD system would be a major undertaking. No oth er emergency\nservice had attempted to go as far. The plan was to move from a w holly manual\nprocess -- in which forms were ﬁlled in and transported from o ne employee to the\nnext via a conveyor belt -- to complete automation, in one sho t. The scheme was\nvery ambitious. The participants seem not to have fully real ized the risks they were\ntaking.\nWay before the project actually started, a management consu ltant ﬁrm had already\nbeen asked for advice. They suggested that a packaged soluti on would cost $1.5M\nand take 19 months. Their report also stated that if a package solution could not\nbe found, the estimates should be signiﬁcantly increased. E ventually, a non-package\nsolution was chosen, but only the numbers from this report we re remembered, or so\nit seems.\nThe advertisement resulted in replies from 35 companies. Th e speciﬁcation and\ntimetable were next discussed with these companies. The pro posed timetable was\n11 months (this is not a typo). Though many suppliers raised c oncerns about the\ntimetable, they were told that it was non-negotiable. Event ually, 17 suppliers provided\nfull proposals. The lowest tender, at approximately $1M, was selected. This tender was\nabout $700 000 cheaper than the next lowest bid. No one seems to have q uestioned\nthis huge difference. The proposal selected superﬁcially s uggests that the company\nhad experience in designing systems for emergency services . This was not a lie: they\nhad developed administrative systems for such services. Th e LAS system also was far\nlarger than anything they had previously handled.\nThe proposed system would impact quite signiﬁcantly on the w ay ambulance\ncrews carried out their jobs. It would therefore be paramoun t to have their full\ncooperation. If the crews did not press the right buttons at", "token_count": 512, "start_token": 19866, "end_token": 20378, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 44, "text": " proposed system would impact quite signiﬁcantly on the w ay ambulance\ncrews carried out their jobs. It would therefore be paramoun t to have their full\ncooperation. If the crews did not press the right buttons at t he right time and in the\nright order, chaos could result. Yet, there was very little u ser involvement during the\nrequirements engineering process.\nThe intended CAD system would operate in an absolutely objec tive and impartial\nway and would always mobilize the optimum resource to any inc ident. This would\novercome many of the then present working practices which ma nagement considered\noutmoded and not in the interest of LAS. For instance, the new system would allocate\nthe nearest available resource regardless of the originati ng station. The following\nscenario may result:\n/AF John’s crew has to go to an accident a few miles east of their ho me base.\n/AF Once there, they are directed to a hospital a few miles furthe r east to deliver\nthe patient.\n1.4. FROM THE TRENCHES 23\n/AF Another call comes in and John happens to be nearest. He is ord ered to travel\nyet a few miles further east.\n/AF And so on.\nIn this way, crews may have to operate further and further awa y from their home base,\nand in unfamiliar territory. They lose time, because they ta ke wrong turns, or may\neven have to stop to ask for directions. They also have furthe r to travel to reach their\nhome station at the end of a shift. Crews didn’t like this aspe ct of the new system.\nThe new system also took away the ﬂexibility local emergency stations had in\ndeciding which resource to allocate. In the new scheme, reso urce management was\nfully centralized and handled by the system. So, suppose Joh n runs down to where\nthe ambulances are parked and the computer has ordered him to take car number 5.\nJohn is in a hurry and maybe he cannot quickly spot car number 5 , or maybe it is\nparked behind some other cars. So John thinks about this pati ent waiting for him and\ndecides to take car number 4 instead. This means trouble.\nThe people responsible for those requirements were misguid ed or naive in\nbelieving that computer systems in themselves can bring abo ut such changes in\n", "token_count": 512, "start_token": 20328, "end_token": 20840, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 45, "text": " waiting for him and\ndecides to take car number 4 instead. This means trouble.\nThe people responsible for those requirements were misguid ed or naive in\nbelieving that computer systems in themselves can bring abo ut such changes in\nhuman practices. Computers are there to help people do their job, not vice versa.\nOperational straitjackets are doomed to fail.\nThe eventual crash on 4 November 1992 was caused by a minor pro gramming\nerror. Some three weeks earlier, a programmer had been worki ng on part of the\nsystem and forgot to remove a small piece of program text. The code in itself did\nno harm. However, it did allocate a small amount of memory eve ry time a vehicle\nmobilization was generated by the system. This memory was no t deallocated. After\nthree weeks, all memory was used up and the system crashed.\nThe LAS project as a whole did not fail because of this program mer mistake.\nThat was just the last straw. The project schedule was far too tight. Management of\nboth the London Ambulance Service and the contractor had lit tle or no experience\nwith software development projects of this size and complex ity. They were far too\noptimistic in their assessment of risks. They assumed that a ll the people who would\ninteract with the system, would do so in exactly the right way , all of the time.\nThey assumed the hardware parts of the system would work exac tly as speciﬁed.\nManagement decided on the functionality of the system, with hardly any consultation\nwith the people that would be its primary users. Any project w ith such characteristics\nis doomed to fail. From the very ﬁrst day.\n1.4.4 Who Counts the Votes?\nIt’s not who votes that counts, it’s who counts the votes\nJosef Stalin\nTraditional, non-automated election systems leave a paper trail that can be used\nfor auditing purposes: have all votes been counted, have the y been counted correctly.\n24 INTRODUCTION\nSuch an audit is done by an independent party. These safeguar ds serve to build trust\nin the outcome.\nBut what if these elections are supported by computers? As a v oter, you then\nsimply press a button. But what next? The recording and count ing is hidden. How\ndo", "token_count": 512, "start_token": 20790, "end_token": 21302, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 46, "text": " serve to build trust\nin the outcome.\nBut what if these elections are supported by computers? As a v oter, you then\nsimply press a button. But what next? The recording and count ing is hidden. How\ndo you know your vote is not tinkered with? How can fraud be avo ided? For the\nindividual, one then needs a voter ballot, for instance a pie ce of paper similar to\nan ATM receipt, that serves to verify the voter’s choice. The ballots of all voters\nmay next be used in an independent audit of the election outco me. Most automated\nelection systems of today do not provide these safeguards.\nWhat if we go one step further, and provide our voters with a we b application to\nplace their votes? Below is a story about a real system of this kind. The application was\ndeveloped in Java. Due to governmental regulations, the vot ing model implemented\nmimicked the traditional one. The application maintains a v oting register containing\nidentiﬁcations of all voters, and a ballot box in which the vo tes are stored. One of the\nregulations that the system had to comply with is anonymity: a vote in the ballot box\nshould not be traceable to a name in the voters’ register. Ano ther regulation concenrs\nsecurity: both registers have to be stored separately.\nThe technical design envisaged two separate databases, one for the voters and one\nfor the ballots. Placing a vote and marking a voter as ‘has vot ed’ should be performed\nin a single transaction: either both actions are done, or nei ther of them. This design\nwould cater for the correctness requirement: the number of v otes in the ballot box\nequals the number of voters being marked ‘has voted’.\nAt least, this is what we hoped for. Tests of the system though showed that,\nseemingly at haphazard moments in time, there were more vote s in the ballot box\nthan there were voters marked as ‘has voted’. So the system al lowed voters more than\none vote.\nTaking a look under the hood, a coding error was revealed in th e voting process.\nPart of the algorithm ran as follows:\n1. Identify the voter.\n2. Match the voter with an entry in the register.\n3. If a match is found,", "token_count": 512, "start_token": 21252, "end_token": 21764, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 47, "text": " a coding error was revealed in th e voting process.\nPart of the algorithm ran as follows:\n1. Identify the voter.\n2. Match the voter with an entry in the register.\n3. If a match is found, check that (s)he has not voted yet.\nThe test in the latter step had the form\n/DA/D3/D8/CT/D6/BA/CV/CT/D8/C1/CS/CT/D2/D8/CX/CU/CX\r/CP/D8/CX/D3/D2/B4/B5/BP/BP/CX/CS/CT/D2/D8/CX/CU/CX\r/CP/D8/CX/D3/D2 /B4/B5\ninstead of\n/CT/D5/D9/CP/D0/D7/B4/DA/D3/D8/CT/D6/BA/CV/CT/D8/C1/CS/CT/D2/D8/CX/CU/CX\r/CP/D8/CX/D3/D2/B4/B5/BP/BP/CX/CS/CT/D2/D8/CX/CU /CX\r/CP/D8/CX/D3/D2 /B4/B5/B5\nIn other words, references were compared, rather than actua l values. This is one way\nto win the elections.\n1.5. SOFTWARE ENGINEERING ETHICS 25\n1.5 Software Engineering Ethics\nSuppose you are testing part of a big software system. You ﬁnd quite a few errors and\nyou’re certainly not ready to deliver. However, your manage r is pressing you. The\nschedule has already slipped by quite a few weeks. Your manag er in turn is pressed\nby his boss. The customer is eagerly awaiting delivery of the system. Your manager\nsuggests that you should deliver the system as is, continue t esting, and replace the\nsystem by a better version within the next month. How would yo u react to this\nscheme? Would you simply give in? Argue with your manager? Go to his boss? Go to\nthe customer?\nThe development", "token_count": 512, "start_token": 21714, "end_token": 22226, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 48, "text": " replace the\nsystem by a better version within the next month. How would yo u react to this\nscheme? Would you simply give in? Argue with your manager? Go to his boss? Go to\nthe customer?\nThe development of complex software systems involves many p eople: software\ndevelopers, testers, technical managers, general manager s, customers, etc. Within this\ntemporary organization, the relationship between individ uals is often asymmetrical:\none person participating in the relationship has more knowl edge about something\nthan the other. For example, a software developer has more kn owledge about the\nsystem under construction than his manager. Such an asymmet ric relationship asks for\ntrust: if the developer says that development of some compon ent is on schedule, his\nmanager cannot but believe this message. At least for a while . Such reliance provides\nopportunities for unethical behavior, such as embezzlemen t. This is the more so if\nthere also is a power relationship between these individual s.\nIt is not surprising then that people within the software eng ineering community\nhave been discussing a software engineering code of ethics. Two large organizations\nof professionals in our ﬁeld, the IEEE Computer Society and A CM, have jointly\ndeveloped such a code. The short version of this code is given in ﬁgure 1.5.\nIn the long version of the code, each of the principles is furt her reﬁned into a set\nof clauses. Some of these clauses are statements of aspirati on: for example, a software\nengineer should strive to fully understand the speciﬁcatio ns of the software on which\nhe works. Aspirations direct professional behavior. They r equire signiﬁcant ethical\njudgment. Other clauses express obligations of profession als in general: for example,\na software engineer should, like any other professional, pr ovide service only in areas\nof his competence. A third type of clause is directed at speci ﬁc professional behavior\nwithin software engineering: for example, a software engin eer should ensure realistic\nestimates of the cost and schedule of any project on which he w orks.\nThere are a number of clauses which bear upon the situation of the tester\nmentioned above:\n/AF Approve software only if you have a well-founded belief that it is safe, meets", "token_count": 512, "start_token": 22176, "end_token": 22688, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 49, "text": " any project on which he w orks.\nThere are a number of clauses which bear upon the situation of the tester\nmentioned above:\n/AF Approve software only if you have a well-founded belief that it is safe, meets\nspeciﬁcations, passes appropriate tests, and does not dimi nish quality of life or\nprivacy or harm the environment (clause 1.03 1).\n/AF Ensure adequate testing, debugging, and review of software and related docu-\nments on which you work (clause 3.10).\n1 Clause 1.03 denotes clause no 3 of principle no 1 (Public).\n26 INTRODUCTION\nPreamble\nThe short version of the code summarizes aspirations at a hig h level of abstraction.\nThe clauses that are included in the full version give exampl es and details of how\nthese aspirations change the way we act as software engineer ing professionals.\nWithout the aspirations, the details can become legalistic and tedious; without\nthe details, the aspirations can become high sounding but em pty; together, the\naspirations and the details form a cohesive code.\nSoftware engineers shall commit themselves to making the an alysis, speciﬁcation,\ndesign, development, testing and maintenance of software a beneﬁcial and\nrespected profession. In accordance with their commitment to the health, safety\nand welfare of the public, software engineers shall adhere t o the following Eight\nPrinciples:\n1. Public. Software engineers shall act consistently with the public i nterest\n2. Client and employer. Software engineers shall act in a manner that is in the\nbest interests of their client and employer consistent with the public interest\n3. Product. Software engineers shall ensure that their products and rel ated\nmodiﬁcations meet the highest professional standards poss ible\n4. Judgment. Software engineers shall maintain integrity and independe nce in\ntheir professional judgment\n5. Management. Software engineering managers and leaders shall subscribe to\nand promote an ethical approach to the management of softwar e development\nand maintenance\n6. Profession. Software engineers shall advance the integrity and reputat ion of\nthe profession consistent with the public interest\n7. Colleagues. Software engineers shall be fair to and supportive of their\ncolleagues\n8. Self. Software engineers shall participate in lifelong learning regarding the\npractice of their profession and shall promote an", "token_count": 512, "start_token": 22638, "end_token": 23150, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 50, "text": " profession consistent with the public interest\n7. Colleagues. Software engineers shall be fair to and supportive of their\ncolleagues\n8. Self. Software engineers shall participate in lifelong learning regarding the\npractice of their profession and shall promote an ethical ap proach to the practice\nof the profession\nFigure 1.5 Software engineering code of ethics\n/AF As a manager, do not ask a software engineer to do anything inc onsistent with\nthis code of ethics (clause 5.11).\n/AF Be accurate in stating the characteristics of software on wh ich you work,\navoiding not only false claims but also claims that might be s upposed to be\nspeculative, vacuous, deceptive, misleading, or doubtful (clause 6.07).\n1.6. QUO VADIS? 27\nThe code is not a simple algorithm to discriminate between ac ceptable and unac-\nceptable behavior. Rather, the principles stated should in ﬂuence you, as a software\nengineer, to consider who is affected by your work. The softw are you develop affects\nthe public. The health, safety and welfare of the public is th e primary concern of\nthis code of ethics. Adhering to this, or a similar, code of et hics is not something to\nmerely consider on a Friday afternoon. It should become a way of life.\nThe code not only addresses software engineers. It also addr esses managers, in\nthat the code indicates what might reasonably be expected fr om professional software\nengineers.\n1.6 Quo Vadis?\nA lot of progress has been made over the past 30 years. For each of the major\nphases, numerous techniques and tools have been developed. A number of these have\nfound widespread use. In their assessment of design and codi ng practices for example,\nDeMarco and Lister found that a number of widely acclaimed te chniques (such as\nthe use of small units, strong component binding and structu red programming) are\nindeed applied in practice and pay off (DeMarco and Lister, 1 989). However, the\nshort sketches in the preceding section (and the more elabor ate discussion in the\nfollowing chapters) show that a lot of research is still need ed to make software\nengineering into a truly mature engineering discipline.\nIt takes some time before technology developed in research l aboratories", "token_count": 512, "start_token": 23100, "end_token": 23612, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 51, "text": " (and the more elabor ate discussion in the\nfollowing chapters) show that a lot of research is still need ed to make software\nengineering into a truly mature engineering discipline.\nIt takes some time before technology developed in research l aboratories gets\napplied in a routine way. This holds for physical products su ch as the transistor,\nbut also for methods, techniques, and tools in the area of sof tware technology. The\nﬁrst version of the UNIX operating system goes right back to 1 971. Only since\nthe late 1980s, has interest in UNIX spread widely. In the ear ly 1960s, studies of\nthe cost of software were ﬁrst made. In the 1980s there was a gr owing interest in\nquantitative models for estimating software costs (see als o the later chapter on cost\nestimation). Dijkstra’s article on programming as a human a ctivity appeared in 1965.\nIn the late 1970s the ﬁrst introductory textbooks on structu red programming were\npublished. The term software engineering was introduced in 1968. In the 1980s large\nnational and international programs were initiated to fost er the transition of this new\ntechnology. The above list can be extended with many other ex amples (Redwine and\nRiddle, 1985). This maturation process generally takes at l east 10 to 15 years.\nIn a seminal article entitled ‘No silver bullet: essence and accidents of software\nengineering’, Brooks (1987) discusses a number of potentia lly fruitful approaches to\ndramatically increase software productivity. His main con clusion is: there is no silver\nbullet. But we need not be afraid of the werewolf either. By a c areful study of the\nmany innovations and an investigation of their true merits, a lot of improvements in\nboth quality and productivity can be achieved. The remainde r of this text is devoted\nto a critical assessment of these technological and non-tec hnological developments.\nSeveral relatively recent developments have a dramatic imp act on the ﬁeld:\n28 INTRODUCTION\n/AF The rise of agile methods. As noted before in this chapter, th e term software\nengineering induces an orderly, factory-like approach to s oftware development.\nThis ignores the fact that for many a project, it is impossibl e to state the\nrequirements upfront. They emerge", "token_count": 512, "start_token": 23562, "end_token": 24074, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 52, "text": " this chapter, th e term software\nengineering induces an orderly, factory-like approach to s oftware development.\nThis ignores the fact that for many a project, it is impossibl e to state the\nrequirements upfront. They emerge as we go along. Armour (20 01) compares\ntraditional software development with shooting down a Zepp elin, and agile\napproaches with shooting down a supersonic plane. To shoot d own a Zeppelin,\nwe collect information on altitude, distance, velocity and the like, relay this\ninformation to the gun, aim, and shoot. This approach does no t work for\nsupersonic planes. We do not know where the intercept will be , and the\nmissile will have to change direction while in the air. It is a challenge to\ntry to successfully combine engineering and craft-like app roaches to software\ndevelopment.\n/AF There is shift from producing software to using software. Time-to-market, cost,\nand sheer complexity encourage organizations to assemble s ystems out of\nexisting components, rather than developing those compone nts from scratch.\nOn one hand, builders build (pieces of) software, on the othe r hand integra-\ntors integrate those pieces into end-user applications. As one consequence,\nconsumers of software often do not talk to developers anymor e. Requirements\ncome from a variety of other sources, such as helpdesk call-l og analysis or\nmarket research (Sawyer, 2001). To the consumer, the softwa re development\nprocess is not interesting any more, only the resulting prod uct counts. This shift\nhas given rise to new topics within software engineering, su ch as Component-\nBased Software Development (CBSD), Commercial Off-The-Sh elve (COTS)\ncomponents, Software Product Lines (SPL), and services.\n/AF Software development is becoming more heterogeneous. In th e old days, a\nsoftware development organization had everything under co ntrol. Or so it\nthought. Nowadays, software is being developed by teams sca ttered across\nthe globe. Part of it may be outsourced to a different organiz ation. Software\nincorporates components acquired from some other supplier , or services found\non the Web. As a consequence, one is not in control anymore.\nTo close this chapter is a list of important periodicals that contain material which", "token_count": 512, "start_token": 24024, "end_token": 24536, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 53, "text": " ation. Software\nincorporates components acquired from some other supplier , or services found\non the Web. As a consequence, one is not in control anymore.\nTo close this chapter is a list of important periodicals that contain material which is\nrelevant to the ﬁeld of software engineering:\n– Transactions on Software Engineering (IEEE), a monthly periodical in which research\nresults are reported;\n– Software (IEEE), a bimonthly journal which is somewhat more general i n scope;\n– Software Engineering Notes , a bimonthly newsletter from the ACM Special Interest\nGroup on Software Engineering;\n– Transactions on Software Engineering and Methodology (ACM), a quarterly journal\nwhich reports research results.\n1.7. SUMMARY 29\n– The Journal of Systems and Software (Elsevier), a monthly journal covering both\nresearch papers and reports of practical experiences;\n– Proceedings of the International Conference on Software En gineering (ACM/IEEE), pro-\nceedings of the most important international conference in the ﬁeld, organized\nevery year;\n– Proceedings of the International Conference on Software Ma intenance (IEEE), organized\nyearly;\n– Software Maintenance and Evolution: Research and Practice (Wiley), bimonthly journal\ndevoted to topics in software maintenance and evolution.\n1.7 Summary\nSoftware engineering is concerned with the problems that ha ve to do with the\nconstruction of large programs. When developing such programs, a phased approach is\nfollowed. First, the problem is analyzed, and then the syste m is designed, implemented\nand tested. This practice has a lot in common with the enginee ring of physical\nproducts. Hence the term software engineering. Software en gineering, however, also\ndiffers from the engineering of physical products in some es sential ways.\nSoftware models part of the real world surrounding us, like b anking or the reser-\nvation of airline seats. This world around us changes over ti me. So the corresponding\nsoftware has to change too. It has to evolve together with the changing reality. Much\nof what we call software maintenance, actually is concerned with ensuring that the\nsoftware keeps pace with the real world being modeled.\nWe thus get a process model in which we iterate earlier phases from time to time.\nWe speak about the software life cycle.\nAgile methods, reuse of components,", "token_count": 512, "start_token": 24486, "end_token": 24998, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 54, "text": " that the\nsoftware keeps pace with the real world being modeled.\nWe thus get a process model in which we iterate earlier phases from time to time.\nWe speak about the software life cycle.\nAgile methods, reuse of components, and globalisation are s ome of the relatively\nrecent trends that have a huge impact on the way we view the ﬁel d. There is a shift\nfrom producing software to using software. A major conseque nce hereof is that a\ndevelopment organization looses control over what it deliv ers.\n1.8 Further Reading\nJohnson (1998) describes the early history of the software i ndustry. The more recent\nstate of the practice is described in (Software, 2003).\nFor a more elaborate discussion of the differences and simil arities between software\nengineering and a mature engineering discipline, viz. brid ge design, see (Spector and\nGifford, 1986). (Leveson, 1992) compares software enginee ring with the development\nof high-pressure steam engines.\nThe four kinds of maintenance activities stem from (Lientz a nd Swanson, 1980).\n30 INTRODUCTION\nThe Ariane failure is described in (J ´ ez ´ equel and Meyer, 19 97). I found the report of\nthe Inquiry Team at /CW/D8/D8/D4/BM/BB/BB/DB/DB/DB/BA\r/D2/CT/D7/BA/CU/D6/BB/BT/CA/BV/C0/C1/CE/BX/CB/BB/D2/CT/DB/D7/BB/D6/CP/D4/D4 /D3/D6/D8 /BH/BC/BD/BA/CW/D8/D1/D0 .\nAn elaborate discussion of the Therac-25 accidents can be fo und in (Leveson and\nTurner, 1993). The Inquiry into the London Ambulance Servic e is described in (Page\net al., 1993). (Neumann, 1995) is a book wholly devoted to com puter-related risks.\nThe bimonthly ACM Software Engineering Notes contains a column ‘Risks to the public\nin computer systems’, edited by Peter Neumann, which report s on large and small\ncatastrop", "token_count": 512, "start_token": 24948, "end_token": 25460, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 55, "text": "er-related risks.\nThe bimonthly ACM Software Engineering Notes contains a column ‘Risks to the public\nin computer systems’, edited by Peter Neumann, which report s on large and small\ncatastrophes caused by automation. (Flowers, 1996) is a col lection of stories about\ninformation systems that failed, including the LAS system. (Kohno et al., 2004) and\n(Raba, 2004) discuss problems with one speciﬁc electronic v oting system. (Petroski,\n1994) is a wonderful book on failures in engineering. (Softw are, 1999) is a special\nissue with stories about successful IT projects.\nThe ACM/IEEE Software Engineering code of ethics is discuss ed in (Gotterbarn,\n1999). The text of the code can also be found at /CW/D8/D8/D4/BM/BB/BB\r/D3/D1/D4/D9/D8/CT/D6/BA/D3/D6/CV/BB/D8/CP/CQ/BB/D7/CT/D4/D6/D3/CU/BB\r/D3/CS/CT/BA/CW/D8/D1 .\n(Epstein, 1997) is a collection of (ﬁctional) stories addre ssing the interaction between\nethics and software engineering. (Oz, 1994) discusses ethi cal questions of a real-life\nproject.\nExercises\n1. Deﬁne the term software engineering.\n2. What are the essential characteristics of software engin eering?\n3. What are the major phases in a software development projec t?\n4. What is the difference between veriﬁcation and validatio n?\n5. Deﬁne four kinds of maintenance activity.\n6. Why is the documentation of a software project important?\n7. Explain the 40--20--40 rule of thumb in software engineer ing.\n8. What is the difference between software development and s oftware mainte-\nnance?\n9. /DI Do you think the linear model of software development is appr opriate? In\nwhich cases do you think an agile approach is more appropriat e? You may\nwish to reconsider this", "token_count": 512, "start_token": 25410, "end_token": 25922, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 56, "text": "te-\nnance?\n9. /DI Do you think the linear model of software development is appr opriate? In\nwhich cases do you think an agile approach is more appropriat e? You may\nwish to reconsider this issue after having read the remainde r of this text.\n10. /DI Discuss the major differences between software engineerin g and some other\nengineering discipline, such as bridge design or house buil ding. Would you\nconsider state-of-the-art software engineering as a true e ngineering discipline?\n11. /DJ Quality and productivity are major issues in software engin eering. It is\n1.8. FURTHER READING 31\noften advocated that automated tools (CASE tools) will dram atically improve\nboth quality and productivity. Study a commercial CASE tool and assess\nthe extent to which it improves the software development pro cess and its\noutcome.\n12. /DI Medical doctors have their Hippocratic oath. Could a simila r ethical\ncommitment by software engineers be instrumental in increa sing the quality\nof software systems?\n13. /DJ Suppose you are involved in an ofﬁce automation project in th e printing\nindustry. The system to be developed is meant to support the w ork of journal\neditors. The management objective for this project is to sav e labor cost; the\neditors’ objective is to increase the quality of their work. Discuss possible\nramiﬁcations of these opposing objectives on the project. Y ou may come\nback to this question after having read chapter 9 or (Hirschh eim and Klein,\n1989).\n14. /DI Discuss the difference between requirements-based softwa re development\nand market-driven software development (Sawyer, 2001).\n15. /DI Discuss the impact of globalisation on software developmen t.\n16. /DJ Study both the technical and user documentation of a system a t your\ndisposal. Are you satisﬁed with them? Discuss their possibl e shortcomings\nand give remedies to improve their quality.\n17. /DJ Take a piece of software you wrote more than a year ago. Is it do cumented\nadequately? Does it have a user manual? Is the design rationa le reﬂected in\nthe technical documentation? Can you build an understandin g of the system\nfrom its documentation", "token_count": 512, "start_token": 25872, "end_token": 26384, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 57, "text": " ago. Is it do cumented\nadequately? Does it have a user manual? Is the design rationa le reﬂected in\nthe technical documentation? Can you build an understandin g of the system\nfrom its documentation that is sufﬁcient for making non-tri vial changes to it?\nRepeat these questions for a system written by one of your col leagues.\n18. /DJ Try to gather quantitative data from your organization that reveals how\nmuch effort is spent on various kinds of maintenance activit y. Are these data\navailable at all? If so, is the pattern like that sketched in s ection 1.3? If not,\ncan you explain the differences?\n19. /DJ A 1999 Computer Society survey lists the following candidat e fundamental\nprinciples of software engineering:\nA. Apply and use quantitative measurements in decision-mak ing.\nB. Build with and for reuse.\nC. Control complexity with multiple perspectives and multi ple levels of\nabstraction.\nD. Deﬁne software artifacts rigorously.\n32 INTRODUCTION\nE. Establish a software process that provides ﬂexibility.\nF. Implement a disciplined approach and improve it continuo usly.\nG. Invest in the understanding of the problem.\nH. Manage quality throughout the life cycle as formally as po ssible.\nI. Minimize software components interaction.\nJ. Produce software in a stepwise fashion.\nK. Set quality objectives for each deliverable product.\nL. Since change is inherent to software, plan for it and manag e it.\nM. Since tradeoffs are inherent to software engineering, ma ke them explicit\nand document them.\nN. To improve design, study previous solutions to similar pr oblems.\nO. Uncertainty is unavoidable in software engineering. Ide ntify and manage\nit.\nFor each of these principles, indicate whether you (strongl y) agree or\n(strongly) disagree, and why. You may wish to re-appraise th ese principles\nafter having studied the rest of this book.\nPart I\nSoftware Management\nCONTENTS\nChapter 2 Introduction to Software Engineering Management 34\nChapter 3 The Software Life Cycle Revisited 45\nChapter 4 Conﬁguration Management 78\nChapter 5 People Management and Team Organization 89\nChapter 6 On Managing Software Quality 107\nChapter 7", "token_count": 512, "start_token": 26334, "end_token": 26846, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 58, "text": "\nChapter 2 Introduction to Software Engineering Management 34\nChapter 3 The Software Life Cycle Revisited 45\nChapter 4 Conﬁguration Management 78\nChapter 5 People Management and Team Organization 89\nChapter 6 On Managing Software Quality 107\nChapter 7 Cost Estimation 144\nChapter 8 Project Planning and Control 176\nSoftware development projects often involve several peopl e for a prolonged period\nof time. Large projects may even range over several years and involve hundreds of\npeople. Such projects must be carefully planned and control led. The main aspects\nthat deserve the continuous attention of project managers a re introduced in chapter\n2, and further dealt with in chapters 3--7: progress, inform ation, people, quality,\ncost and schedule. The management part ends with chapter 8 in which the various\napproaches sketched in chapters 3--7 are reconciled.\n2\nIntroduction to Software\nEngineering Management\nLEARNING OBJECTIVES\n/AF To be aware of the contents of a project plan\n/AF To understand the major dimensions along which a software de velopment\nproject is controlled\n35\nSoftware development projects often involve several peopl e for a prolonged\nperiod of time. Large projects may even range over several ye ars and involve\nhundreds of people. Such projects must be carefully planned and controlled.\nThe main aspects that deserve the continuous attention of pr oject managers\nare introduced in this chapter.\nIt is not easy to complete successfully a software developme nt project. This book\nmainly deals with technical aspects of software developmen t: design, speciﬁcation,\nimplementation and testing of software systems. As we learn to control these aspects\nbetter, we will also learn to satisfy our customer’s demands better. The organizational\nand managerial aspects of software development projects ar e at least as important as\nthe technical aspects, though.\nBefore we embark on a discussion of these organizational and managerial aspects,\nlet us ﬁrst pay some attention to the boundaries of a software development project as\nthey are drawn in this book.\nA software development project is usually not started in com plete isolation.\nThere are other projects within the organization that this p articular project needs\nto be tuned to, priorities between projects have to be decide d upon, etc. The term\ninformation planning is often used to refer to this meta-project planning process .\nAlso in a more technical sense, projects are not started in is", "token_count": 512, "start_token": 26796, "end_token": 27308, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 59, "text": "\nto be tuned to, priorities between projects have to be decide d upon, etc. The term\ninformation planning is often used to refer to this meta-project planning process .\nAlso in a more technical sense, projects are not started in is olation. To increase\ninteroperability between systems, overall guidelines reg arding, e.g., the use of certain\nstandards, data interchange formats, security policies, w eb page layout and the like\nare laid down for the whole organization and imposed on every project. In product\nline development, the architecture of the product line guid es the development of\nindividual products.\nThese project exceeding rules result in a set of boundary con ditions for each\nproject, much like the zoning regulations set the condition s for a building project.\nEstablishing these company-wide rules is a problem on its ow n, and will not be\naddressed here. (We will, however, pay ample attention to so me issues which\ngenerally surpass the boundaries of individual software de velopment projects, such as\nconﬁguration control, quality assurance and product line d evelopment.)\nAlso in a more technical sense, software is not generally dev eloped in isolation.\nIn most cases, software is not written from scratch. It must i nterface with existing\nsoftware, extend existing software, use existing subrouti ne libraries, build upon an\nexisting framework, and so on.\nIn some sense, the notion of a ‘software development project ’ is a misnomer.\nWe do not just develop software, we develop systems. Broadly speaking, a system\ntransforms inputs into outputs. Software is an important in gredient of the systems\nwe develop, but it is by no means the only ingredient. The tech nical and user\ndocumentation, the hardware, the procedures that govern th e use of the system, and\neven the people using the software, may be considered as part of that same system.\nConsider for example a system for library automation. The sy stem will contain\n36 INTRODUCTION TO SOFTWARE ENGINEERING MANAGEMENT\nvarious software components, such as a database component t o store information on\nbooks and customers and an interaction component to process user requests. As well\nas the development of these components, attention should be paid to matters like:\n/AF techniques to identify books electronically, such as a barc ode scheme", "token_count": 512, "start_token": 27258, "end_token": 27770, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 60, "text": " information on\nbooks and customers and an interaction component to process user requests. As well\nas the development of these components, attention should be paid to matters like:\n/AF techniques to identify books electronically, such as a barc ode scheme;\n/AF the selection and acquisition of special hardware both for s canning those\nidentiﬁcations and for producing identiﬁcations for new bo oks;\n/AF setting up a scheme to provide all books with the new identiﬁc ation code;\n/AF instruction of library employees to handle the new types of e quipment (training\nmaterial and courses, operating procedures, and the like);\n/AF production of user-friendly documentation for the library customers.\n/AF web-accessibility issues, such as whether the catalog can b e browsed, or books\ncan be reserved on-line\nWhenever the notion ‘software development project’ is used in the following, it\nshould be understood in this wider sense. This is graphicall y illustrated in ﬁgure 2.1.\ndocumentation\nprocedures\nsoftware\ninput output\ninformation planning\nboundary conditions\npeople\nprogram\nprogram\nFigure 2.1 The systems view of a software development projec t\nThus, our systems encompass a number of components. In a narr ow sense, the\nsoftware component itself may also consist of a number of int eracting components.\nThese latter components correspond to programs as we know th em from introductory\n2.1. PLANNING A SOFTWARE DEVELOPMENT PROJECT 37\ncomputer science textbooks. In general, a software develop ment project results in a\nset of components which collectively provide us with the des ired functionality.\nGiven a project’s boundary conditions, a software developm ent project may get\nstarted. Planning the project is the very ﬁrst step to be unde rtaken. Part of this\nplanning process is to identify the project characteristic s and their impact on the\ndevelopment process. The result of the planning phase is lai d down in a document,\nthe project plan , which aims to provide a clear picture of the project to both t he\ncustomers and the development team. The contents of the proj ect plan are discussed\nin section 2.1.\nDuring the execution of the project, a number of elements hav e to be managed:\ntime, information", "token_count": 512, "start_token": 27720, "end_token": 28232, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 61, "text": " t he\ncustomers and the development team. The contents of the proj ect plan are discussed\nin section 2.1.\nDuring the execution of the project, a number of elements hav e to be managed:\ntime, information, organization, quality, and money (see s ection 2.2). Each of these\nelements is further elaborated upon in a separate chapter.\n2.1 Planning a Software Development Project\nBefore we embark on a software development project, it has to be carefully planned.\nThis entails, amongst other things, an assessment of projec t properties that may affect\nthe development process. A number of properties, however, w ill not be sufﬁciently\nwell understood until the requirements engineering phase h as ended. Like many\nother aspects of a software development project, planning i s not a one-shot activity.\nRather, it is highly dynamic in nature. The project plan can s erve as a guide during\nthe project.\nThe amount of upfront planning depends on characteristics o f the problem at\nhand. In highly explorative projects, where requirements a re largely unknown at the\nstart, too rigorous early planning can be stiﬂing and may inc rease the probability\nof major failures. A strict ‘plan the work and work the plan’ a ttitude does not work\nin these circumstances. Rather, such projects call for a nom inal early planning and\na management style that encourages responding to change. Th is is reﬂected in the\ncontents and size of the project plan. Chapters 3 and 8 furthe r discuss differences\nbetween the so-called agile and planning-driven approache s to software development.\nThe major constituents of a project plan are:\n1. Introduction In the introduction to the project plan, the background and\nhistory of the project are given, together with its aims, the project deliverables,\nthe names of the persons responsible, and a summary of the pro ject.\n2. Process model In chapter 1, we introduced a simple life cycle model in order to\ndiscuss the various activities to be dealt with in a software development project.\nThere exist many variations of this process model, some of wh ich are discussed\nin chapter 3. For each project, one has to decide upon the exac t process model\nto be followed: which activities are being undertaken, whic h milestones can\nbe identi�", "token_count": 512, "start_token": 28182, "end_token": 28694, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 62, "text": " model, some of wh ich are discussed\nin chapter 3. For each project, one has to decide upon the exac t process model\nto be followed: which activities are being undertaken, whic h milestones can\nbe identiﬁed, how do we ascertain whether those milestones a re reached, and\nwhich are the critical paths.\n38 INTRODUCTION TO SOFTWARE ENGINEERING MANAGEMENT\nDifferent types of projects have different characteristic s, and so call for different\nprocess models.\n3. Organization of the project The relationship of the project to other entities\nand the organization of the project itself are dealt with und er this heading.\nThe project will have a relationship with the user organizat ion, the parent\norganization, and possibly with other organizations.\nThe prospective users will from time to time be involved in th e project. The\nproject plan has to state which information, services, reso urces and facilities\nare to be provided by the users and when these are to be provide d.\nWithin the project team, various roles can be identiﬁed: pro ject manager, tester,\nprogrammer, analyst, etc. One has to clearly delineate thes e roles and identify\nthe responsibilities of each of them. If there are gaps in the knowledge required\nto fulﬁll any of these roles, the training and education need ed to ﬁll these gaps\nhave to be identiﬁed. Different forms of team organization a re discussed in\nchapter 5.\n4. Standards, guidelines, procedures Software projects are big projects. Usually,\na lot of people are involved. A strong working discipline is t herefore needed, in\nwhich each person involved follows the standards, guidelin es and procedures\nagreed upon. Besides being stated on paper, many of these can be supported\nor enforced by tools. Of extreme importance are clear agreem ents about\ndocumentation: when is documentation to be delivered, how i s the quality of\nthe documentation to be assessed, how does one ensure that th e documentation\nis kept up-to-date?\nTo a large extent, these standards and procedures will be des cribed in separate\ndocuments, such as the Conﬁguration Control Plan or the Qual ity Assurance\nPlan.\n5. Management activities Management activities are guided by goals and priorities\nset for the project. For", "token_count": 512, "start_token": 28644, "end_token": 29156, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 63, "text": " des cribed in separate\ndocuments, such as the Conﬁguration Control Plan or the Qual ity Assurance\nPlan.\n5. Management activities Management activities are guided by goals and priorities\nset for the project. For example, management will have to sub mit regular reports\non the status and progress of the project. It will also have to follow certain\npriorities in balancing requirements, schedule and cost.\n6. Risks Potential risks have to be identiﬁed as early as possible. Th ere will always\nbe risks: hardware may not be delivered on time, qualiﬁed per sonnel may not\nbe available when required, critical information may be lac king when it is\nneeded, and so on. It is rather naive to suppose that a softwar e development\nproject runs smoothly. Even in well-established ﬁelds like construction, there is\nalways something that goes wrong. One should diagnose the ri sks of a software\nproject early on, and provide measures to deal with them; see also chapter 8.\nThe more uncertain various aspects of the project are, the la rger the risks.\n2.1. PLANNING A SOFTWARE DEVELOPMENT PROJECT 39\n7. Stafﬁng At different points in time, the project will require differ ent amounts\nof personnel, with different skills. The start, duration, a mount and expertise of\npersonnel categories are listed under this heading.\n8. Methods and techniques Under this heading, the methods and techniques to\nbe used during requirements engineering, design, implemen tation and testing\nare given. Typically, the way version and conﬁguration cont rol for software\ncomponents is dealt with is described here too. A large propo rtion of the\ntechnical documentation will be produced during these phas es. One thus has\nto state how this documentation will be taken care of.\nThe necessary test environment and test equipment is descri bed. During testing,\nconsiderable pressure will normally be put on the test equip ment. Therefore,\nthis activity has to be planned carefully. The order in which components are\nintegrated and tested has to be stated explicitly. Also, the procedures to be\nfollowed during acceptance testing, i.e. the testing under user supervision, have\nto be given. Testing will be discussed in chapter 13.\n9. Quality assurance Which", "token_count": 512, "start_token": 29106, "end_token": 29618, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 64, "text": " tested has to be stated explicitly. Also, the procedures to be\nfollowed during acceptance testing, i.e. the testing under user supervision, have\nto be given. Testing will be discussed in chapter 13.\n9. Quality assurance Which organization and procedures will be used to assure\nthat the software being developed meets the quality require ments stated? The\nmany aspects of a Quality Assurance Plan may also be dealt wit h in a separate\ndocument. The topic of quality assurance is discussed in cha pter 6.\n10. Work packages Larger projects must be broken down into activities, manage -\nable pieces that can be allocated to individual team members . Each of these\nactivities has to be identiﬁed in the project plan. The hiera rchical decomposi-\ntion of the project is depicted in a work breakdown structure (see also section\n8.4).\n11. Resources During the project, many resources are needed. The hardware ,\nCPU-cycles and tools needed to support the project are liste d under this entry.\nOne should also indicate the personnel needed for the variou s process phases.\n12. Budget and schedule The total budget for the project has to be allocated to the\nvarious activities as indicated in the work breakdown struc ture. The activities\nalso have to be scheduled in time, e.g. using a PERT chart (see section 8.4). The\nway in which resources and other expenditures are tracked is also indicated\nunder this heading. The topic of cost and time estimation wil l be dealt with\nextensively in chapter 7.\n13. Changes It has been stated before that changes are inevitable. One ha s to\nensure that these changes are dealt with in an orderly way. On e thus needs\nclear procedures on how proposed changes will be handled. If the process is\nagile, every iteration involves changes, and these are deal t with in a lightweight\nmanner. In fact, they are not seen as changes anymore. In more heavyweight\nprocesses, each proposed change must be registered and revi ewed. When a\n40 INTRODUCTION TO SOFTWARE ENGINEERING MANAGEMENT\nchange request has been approved, its impact (cost) has to be estimated. Finally,\nthe change has to be incorporated into the project. Changes t hat are entered\nvia the back door lead to badly structured code, insufﬁcient documentation\nand", "token_count": 512, "start_token": 29568, "end_token": 30080, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 65, "text": " approved, its impact (cost) has to be estimated. Finally,\nthe change has to be incorporated into the project. Changes t hat are entered\nvia the back door lead to badly structured code, insufﬁcient documentation\nand cost and time overruns. Since changes lead to different v ersions of both\ndocumentation and code, the procedures to be followed in dea ling with such\nchanges are often handled in the context of a Conﬁguration Co ntrol Plan.\n14. Delivery The procedures to be followed in handing over the system to th e\ncustomer must be stated.\nThe project plan aims to provide a clear picture of the projec t to both the customers\nand the project team. If the objectives are not clear, they wi ll not be achieved.\nDespite careful planning, surprises will still crop up duri ng the project. However,\ncareful planning early on leads to fewer surprises and makes one less vulnerable to\nthese surprises. The project plan addresses a number of ques tions which anticipate\npossible future events. It gives orderly procedures for dea ling with those events, so\nthat justiﬁable decisions can be reached.\n2.2 Controlling a Software Development Project\nAfter a project plan has been drawn up and approved, the execu tion of the project may\nstart. During the project, control has to be exerted along th e following dimensions:\n– time,\n– information,\n– organization,\n– quality,\n– money.\nProgress of a software development project (the time aspect) is hard to measure.\nBefore the proposed system has been ﬁnished, there is only a ( large) pile of paper.\nUtterances such as ‘90% of the code has been written’ should b e taken with a pinch\nof salt. A much too rosy picture of the actual state of affairs is usually given. The\nphased approach introduced in chapter 1, and its variants, a im at providing the\nmanager with an instrument to measure and control progress. The time needed to\nbuild a system is obviously related to the size of the system, and thus to the total\nmanpower required. Larger systems require more time to deve lop, although we may\ntry to shorten development time by allocating more personne l. Part of the control\nproblem for software development projects is to trade off ti me against people", "token_count": 512, "start_token": 30030, "end_token": 30542, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 66, "text": "power required. Larger systems require more time to deve lop, although we may\ntry to shorten development time by allocating more personne l. Part of the control\nproblem for software development projects is to trade off ti me against people. Adding\nmore people to shorten development time does not come for fre e. The more people\nthat are involved, the more time will be needed for coordinat ion and communication.\nAfter a certain point, adding more people actually lengthen s the development time.\n2.2. CONTROLLING A SOFTWARE DEVELOPMENT PROJECT 41\nPart of the time control problem is phrased in Brooks’ Law: ‘A dding people to a late\nproject only makes it later’. We will come back to this issue i n the chapter on cost\nestimation.\nThe information that has to be managed, above all, is the documentation. Besi des\ntechnical and user documentation, this also entails docume ntation on the project\nitself. Documentation concerning the project includes suc h things as: the current state\nof affairs, changes that have been agreed upon, and decision s that have been made.\nThis type of documentation can best be handled in the context of conﬁguration\nmanagement. In agile projects, less attention is given to do cumentation during\ndevelopment. Necessary knowledge is tacit, it resides in th e heads of the people\ninvolved. But here too, once the system is ready and handed ov er to its customers,\ndocumentation has to be provided.\nAll members of the development team must understand their ro le in the team and\nwhat is expected of them. It is very important that these expe ctations are clear to\nall people involved. Unspoken and unclear expectations lea d to situations in which\nindividual team members set their own goals, either conscio usly or unconsciously.\nThese organizational aspects deserve the continuous attention of the project man ager.\nSecondly, the organization of a team and the coordination of the people involved\nwill, at least partly, depend upon characteristics of the pr oject and its environment.\nThis dependence has to be recognized and taken into account w hen setting up a\nproject team.\nThe quality aspect is of paramount importance. Customers are not satisﬁ ed with\nthe purely technical solutions offered by computer special ists. They want systems that\nﬁt their real needs", "token_count": 512, "start_token": 30492, "end_token": 31004, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 67, "text": " setting up a\nproject team.\nThe quality aspect is of paramount importance. Customers are not satisﬁ ed with\nthe purely technical solutions offered by computer special ists. They want systems that\nﬁt their real needs. The quality requirements for software a nd its development often\nconﬂict with one another. At architecture time, quality req uirements are balanced in a\ndialog with all stakeholders involved. During a project we w ill have to assess whether\nor not the quality requirements are being met. This quality a ssessment has to occur\non a regular basis, so that timely actions can be undertaken. Quality is not an add-on\nfeature, it has to be built in.\nControlling expenses (the money aspect) largely means controlling labor costs.\nThough the cost of hardware and tools cannot be ignored, thes e can usually be\nestimated fairly precisely early in the project. Moreover, these are usually much less\nof an issue than personnel costs.\nEstimating the cost of software thus means that we must estim ate the manpower\nrequired to build the software. The manpower needed is very m uch dependent on\nthe size of the software, for instance measured as the amount of code to be delivered.\nMany other factors, though, inﬂuence this cost or, alternat ively, the productivity\nwith which the software can be produced. A well-balanced tea m with experienced\npeople will be much more productive than a newly-formed team with inexperienced\npeople. Extremely strict quality constraints, such as very high reliability or a very fast\nresponse time, may also severely reduce productivity.\nA number of models have been proposed that try to quantify the effect of\nthose different cost drivers on the manpower required (see c hapter 7). Rather than\n42 INTRODUCTION TO SOFTWARE ENGINEERING MANAGEMENT\nestimating the size ﬁrst, and then its cost, one may also set a cost threshold ﬁrst, and\nwork incrementally, ﬁrst on the most pressing user requirem ents and, if time allows,\non less pressing ones. Or one may agree on a ﬁrst threshold, an d decide whether more\nmoney will be spent when this threshold is reached. These inc remental approaches\nto cost estimation ﬁt in well with agile project development .\nSoftware development is a very labor-intensive", "token_count": 512, "start_token": 30954, "end_token": 31466, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 68, "text": "�rst threshold, an d decide whether more\nmoney will be spent when this threshold is reached. These inc remental approaches\nto cost estimation ﬁt in well with agile project development .\nSoftware development is a very labor-intensive process. On e of our hopes is\nthat better tools and the increased use of those tools will le ad to a signiﬁcant\nincrease in productivity and, consequently, a signiﬁcant d ecrease in the cost involved\nin developing software. A second way, to increase productiv ity dramatically, is to\nuse software rather than build it yourself. Both these topic s will be discussed in\nchapters to follow. As these trends continue, software deve lopment starts to become\na capital-intensive activity, rather than a labor-intensi ve one (Wegner, 1984).\nContinuous assessment of the project with respect to these c ontrol aspects is\nof the utmost importance and will from time to time lead to adj ustments in time,\ncost, organization, information, or quality, or some combi nation thereof. Project\nmanagement is a very dynamic activity.\nIn order to be able to adequately control a project, we need qu antitative data\nwhich is collected while the project is being executed. For i nstance, data about\nerrors discovered during unit testing may help us in estimat ing further test effort\nneeded. Data about the time and effort spent up to a speciﬁc po int will guide us in\nre-estimating the schedule and cost. To measure is to know.\nThese data are also valuable in a post-mortem evaluation of t he project. In a post-\nmortem evaluation we assess the present project in order to i mprove our performance\non projects yet to come: what have we done wrong, what have we l earned, what\nneeds to be done differently on the next project?\nUnfortunately, in practice very little hard data is ever gat hered, let alone retained\nfor later use. Most software development organizations hav e little insight into what\nthey are doing. They tend to operate in a somewhat chaotic way , especially when\nfacing a crisis. By identifying key factors that affect the c ontrollability of the software\ndevelopment process, we may ﬁnd ways to improve on it. This to pic is further treated\nin chapter 6, where we discuss", "token_count": 512, "start_token": 31416, "end_token": 31928, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 69, "text": " when\nfacing a crisis. By identifying key factors that affect the c ontrollability of the software\ndevelopment process, we may ﬁnd ways to improve on it. This to pic is further treated\nin chapter 6, where we discuss the Software Capability Matur ity Model.\n2.3 Summary\nThis chapter provides an introduction to the management of s oftware engineering\nprojects.\nBefore we embark on a software development project, it has to be carefully\nplanned. This planning process results in a document, the pr oject plan, which\nprovides a clear picture of the project to both the customers and the project team.\nOnce the project plan has been drawn up and the project has sta rted, its execution\nmust be controlled. We identiﬁed ﬁve entities that require o ur continuous attention\nfor project control:\n2.3. SUMMARY 43\n/AF Time: How do we assess progress towards the project’s goals? Usually, some\nphased approach is followed which aims to provide managemen t with a means\nto measure and control progress.\n/AF Information: How do we handle the documents that are produce d in the course\nof a project? In planning-based development, maintaining t he integrity of the\nset of documents and handling all change requests require ca reful procedures.\n/AF Organization: How do we organize the project team and coordi nate the\nactivities of team members?\n/AF Quality: How do we deﬁne and assess quality requirements for both the\ndevelopment process and the resulting product?\n/AF Money: How do we estimate the cost of a project? These costs ar e to a large\nextent determined by the size of the software.\nEach of these controlling aspects is further elaborated upo n in a separate chapter\n(chapters 3--7). The various dimensions of project control will then be reconciled in\nchapter 8.\nExercises\n1. In what sense is the phrase ‘software development project ’ a misnomer?\n2. What are the major constituents of a project plan?\n3. List ﬁve dimensions along which a software development pr oject has to be\ncontrolled.\n4. How may software development become a capital-intensive activity, rather\nthan a labor-intensive one?\n5. /DJ Consider a software development project you have been invol ved in.", "token_count": 512, "start_token": 31878, "end_token": 32390, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 70, "text": " pr oject has to be\ncontrolled.\n4. How may software development become a capital-intensive activity, rather\nthan a labor-intensive one?\n5. /DJ Consider a software development project you have been invol ved in. Did\nthe project have a project plan? Did the project plan address the issues listed\nin section 2.1? If some of these issues were not addressed, do you think it\nwould have helped the project if they had been?\n6. /DI Do you think quantitative project data are important? In wha t way can\nthey contribute to project planning?\n7. /DI How would a project plan for an agile project differ from that of a\nplanning-driven project?\n8. /DJ Consider once again a software development project you have been\ninvolved in. To what extent were any environmental issues su ch as user\ntraining and working procedures adequately dealt with in th e project?\n44 INTRODUCTION TO SOFTWARE ENGINEERING MANAGEMENT\n9. /DI A program written for personal use imposes rather less strin gent require-\nments than a product that is also to be used by other people. Ac cording\nto (Brooks, 1995), the latter may require three times as much effort. Discuss\npossible reasons for this considerable increase in cost.\n3\nThe Software Life Cycle\nRevisited\nLEARNING OBJECTIVES\n/AF To be aware of a number of generic models to structure the soft ware develop-\nment process\n/AF To appreciate the pros and cons of these models, in particula r those of the\nclasses of planning-driven and agile methods\n/AF To understand the similarities between software maintenan ce and software\nevolution\n/AF To recognize that it is proﬁtable to apply software product l ine engineering\nwhen developing a series of similar systems\n/AF To be aware of process modeling as a way to describe software d evelopment\nprocesses explicitly\n46 THE SOFTWARE LIFE CYCLE REVISITED\nTo be able to assess progress during software development, o ne opts for a\nphased approach with a number of well-deﬁned milestone even ts. The linear\nordering of activities which underlies the traditional sof tware development\nmodel, the waterfall model, renders it an impossible ideali zation of reality\nthough. It assumes software development proceeds in an orde rly, sequential\nman", "token_count": 512, "start_token": 32340, "end_token": 32852, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 71, "text": " linear\nordering of activities which underlies the traditional sof tware development\nmodel, the waterfall model, renders it an impossible ideali zation of reality\nthough. It assumes software development proceeds in an orde rly, sequential\nmanner. Real projects proceed in far less rational ways. The waterfall model of\nsoftware development is not feasible, much like Escher’s Wa terfall, reproduced\non the front cover, is unfeasible. This chapter discusses va rious alternative\nmodels of the development process.\nIn chapter 1, we introduced a simple model of the software lif e cycle. We distinguished\nseveral consecutive phases: requirements engineering, de sign, implementation, test-\ning, maintenance. It was stated that, in practice, one often uses more sophisticated\nprocess models. In this chapter we continue this discussion . We introduce various\nalternative models to structure the software development p rocess.\nSoftware development projects are often very large project s. A number of people\nwork on such a project for a long time and therefore the whole p rocess needs to\nbe carefully planned and controlled: progress needs to be mo nitored, people and\nresources need to be allocated at the right point in time, etc . Earlier on, it was pointed\nout that progress of a software development project is parti cularly difﬁcult to measure.\nIn order to control progress we use a phased development in wh ich a number\nof clearly identiﬁable milestones are established between the start and ﬁnish of the\nproject. We use a similar mechanism when constructing a hous e: foundations are laid,\nthe ﬁrst ﬂoor is reached, the house is weatherproofed, and so on. Often, the payment\nof installments is coupled to reaching those milestones.\nIn general, the milestones identiﬁed in a software developm ent project correspond\nto the points in time at which certain documents become avail able:\n– after requirements engineering, there is a requirements s peciﬁcation;\n– after the design phase there is a (technical) speciﬁcation of the system;\n– after implementation there is a set of programs;\n– after testing has been completed there is a test report.\nTraditional models for the phased development of software a re, to a large extent,\n‘document-driven’. The pile of paper that", "token_count": 512, "start_token": 32802, "end_token": 33314, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 72, "text": " is a set of programs;\n– after testing has been completed there is a test report.\nTraditional models for the phased development of software a re, to a large extent,\n‘document-driven’. The pile of paper that is produced in the course of the project\nguides the development process. The development process is seen as a series of\ntransformations. It starts with a clear requirements docum ent, and ends with running\ncode. In the next section we discuss the waterfall model, a we ll-known variation of\nthe process model introduced in chapter 1. In this variation , a check is performed\nafter each transformation, to determine whether we are stil l on the right track.\n47\nThese document-driven methods are also known as planning-driven or heavyweight\nmethods. Planning-driven, because of the emphasis on an upf ront plan for the whole\nprocess. Heavyweight, because of the emphasis placed on the process.\nIn many a software development project, change is a fact of li fe. It may even be\nthe case that the client only has a vague idea of the requireme nts for the system he\nasks for. In recent years, a number of lightweight, agile methods have been proposed that\npurposedly deal with these rapidly changing circumstances . These methods advocate\nto not ‘waste’ time on expensive planning and design activit ies early on, but to deliver\nsomething valuable to the customer as quickly as possible. B ased on feedback from\nthe user, next steps are then taken. Agile methods have evolv ed from approaches\nsuch as prototyping and Rapid Application Development that try to dispose of some\nor all of the drawbacks of the document-driven approach ment ioned above. We will\ndiscuss a number of lightweight approaches to software deve lopment in section 3.2.\nEvolutionary models take into account that much of what is ca lled maintenance is\nreally evolution. It would then seem natural to explicitly b ear this anticipated evolution\nin mind from the very start. This is usually not the case. In bo th heavyweight and\nlightweight development approaches, the initial developm ent of a software system\nis in general strictly separated from the subsequent mainte nance phase. The major\ngoal of a software development project then boils down to del ivering a ﬁrst version\nof the system to the user. This may result in", "token_count": 512, "start_token": 33264, "end_token": 33776, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 73, "text": "is in general strictly separated from the subsequent mainte nance phase. The major\ngoal of a software development project then boils down to del ivering a ﬁrst version\nof the system to the user. This may result in excessive mainte nance costs later on.\nIn order to be able to properly assess costs and beneﬁts, tota l life cycle cost rather\nthan just development cost should be our primary focus. Goin g one step further, we\nmay argue that management should concentrate on sets of simi lar products (so-called\nproduct families) rather than individual products, thereb y granting an incentive both\nto the building of reusable parts and the reuse of (parts of) e xisting products when\ndeveloping new ones.\nFrom all the possible life cycle models we have to choose a par ticular one for any\ngiven project. By and large, heavyweight methods better ﬁt ( very) large projects, and\nsituations where the requirements can be decided upon at an e arly stage. Lightweight\nmethods ﬁt situations of rapid change, and projects that do n ot involve more than,\nsay, 50 people. Different project characteristics, and app ropriate ways to control\nthem effectively, are discussed in chapter 8.\nThe choice for a particular life cycle model also involves de ﬁning the individual\nsteps and phases, their possible interaction, their delive rables, etc. By using an\nexplicit process modeling language, which may be supported by tools, we may\nincrease our understanding of the software process, we are p rovided with a handle to\nimprove our control of software development, and we are give n a baseline for process\nimprovement. This type of process modeling is discussed in s ection 3.6. Because\nof the much larger emphasis on planning, this type of modelin g ﬁts in better with\nheavyweight methods.\n48 THE SOFTWARE LIFE CYCLE REVISITED\n3.1 The Waterfall Model\nThe waterfall model is essentially a slight variation of the model introduced in\nchapter 1. The waterfall model is generally attributed to Ro yce (1970). However,\na clearly phased approach to the development of software, in cluding iteration and\nfeedback, could already be found in publications from the ea rly 1960s.\nThe waterfall model particularly expresses the interactio n between subsequent\nphases.", "token_count": 512, "start_token": 33726, "end_token": 34238, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 74, "text": "a clearly phased approach to the development of software, in cluding iteration and\nfeedback, could already be found in publications from the ea rly 1960s.\nThe waterfall model particularly expresses the interactio n between subsequent\nphases. Testing software is not an activity which strictly f ollows the implementation\nphase. In each phase of the software development process, we have to compar e\nthe results obtained against those that are required. In all phases, quality has to be\nassessed and controlled.\nIn ﬁgure 3.1, V & V stands for Veriﬁcation and Validation. Ver iﬁcation asks if the\nsystem meets its requirements (are we building the system ri ght) and thus tries to\nassess the correctness of the transition to the next phase. V alidation asks if the system\nmeets the user’s requirements (are we building the right sys tem).\nFigure 3.1 The waterfall model\n3.1. THE WATERFALL MODEL 49\nBoth the model introduced in chapter 1 and the waterfall mode l place considerable\nemphasis on a careful analysis before the system is actually built. We want to prevent\nputting much energy into constructing a system which later t urns out not to satisfy\nthe user’s requirements.\nWe therefore try to identify and tie down the user’s requirem ents as early as\npossible. These requirements are documented in the require ments speciﬁcation. On\nthe basis of this document we may verify in subsequent phases whether or not these\nrequirements are being met. Since it is difﬁcult in practice , if not impossible, to\ncompletely specify the user’s requirements, a regular test should also be carried out\nwith the prospective user. These tests are termed validatio n. Through these validation\nsteps we may prevent the system under development diverging from the, possibly\nincompletely speciﬁed, user requirements.\nMcCracken and Jackson (1981) compare the waterfall model wi th a shop where\nthe customer is obliged to give an order upon entering. There is no opportunity to\nlook around, compare prices, change one’s mind, or decide up on a different menu for\ntoday’s dinner. Some things can be ordered by mail, but not al l.\nThe waterfall model of software development, like Escher", "token_count": 512, "start_token": 34188, "end_token": 34700, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 75, "text": ", compare prices, change one’s mind, or decide up on a different menu for\ntoday’s dinner. Some things can be ordered by mail, but not al l.\nThe waterfall model of software development, like Escher’s waterfall, is unrealistic.\nThere is ample quantitative evidence that the classical doc ument-driven model has\nmany shortcomings. In many a software development project, the strict sequencing of\nphases advocated by the waterfall model is not actually obey ed. Figure 3.2 shows the\naverage breakdown of activities across life cycle phases fo r a number of projects. In this\nﬁgure, the label ‘coding’ refers to a phase which encompasse s both implementation\nand unit testing.\nActivity Phase\nDesign Coding Integration Acceptance\ntesting testing\nIntegration testing 4.7 43.4 26.1 25.8\nCoding 6.9 70.3 15.9 6.9\nDesign 49.2 34.1 10.3 6.4\nFigure 3.2 Breakdown of activities across life cycle phases , after (Zelkowitz, 1988)\nSo, for example, only 50% of the design effort was found to occ ur during the\nactual design phase, while one-third of the design effort oc curs during the coding\nperiod. Even worse, over 16% of the design effort takes place after the system is\nsupposed to be ﬁnished.\nThe software design behavior of individual designers may be characterized as an\nopportunistic process (Guindon and Curtis, 1988). Designers move back and forth\n50 THE SOFTWARE LIFE CYCLE REVISITED\nacross levels of abstraction ranging from application doma in issues to coding issues.\nMilestone dates seem to be somewhat arbitrary, and a signiﬁc ant part of the activities\ncrosses phase boundaries.\n3.2 Agile Methods\nThe American Kennel’s Club deﬁnition of Agility is: ”The exc iting sport of Agility has\ntaken the world by storm. The Agility ring allows handler and dog to run full speed,\nwhile having to perform accurately and safely on A-Frames, D og Walks, See-Saws\nand a wide variety of jumps and tunnels”. Software engineers are not dogs, but the\nanalogy is clear.\nWhen using a heavyweight development method, it is d", "token_count": 512, "start_token": 34650, "end_token": 35162, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 76, "text": "-Frames, D og Walks, See-Saws\nand a wide variety of jumps and tunnels”. Software engineers are not dogs, but the\nanalogy is clear.\nWhen using a heavyweight development method, it is difﬁcult to change direction.\nOnce the contract has been signed, the development team’s jo b is to deliver the\nfunctionality as laid down in the contract. If reality chang es, or the user gets a\ndifferent insight, such is difﬁcult to accomplish. It does n ot ﬁt the architecture, it\nrequires rework not accounted for, it lengthens the agreed u pon schedule, and so on.\nIt is a train that does not easily change direction.\nThis has been recognized over the years, and methods like pro totyping and evo-\nlutionary development ensued. But these methods still some how carry an engineering\nﬂavor with them. Essentially, they still assume the world is ordered. It may be difﬁcult\nto pinpoint the true requirements right away, but they will a ccrue over time.\nTrue agile methods view the world as fundamentally chaotic. They assume change\nis inevitable. Their focus is to deliver value to the custome r as quickly as possible,\nand not bother about extensive plans and processes that won’ t be followed anyway.\nThe essence of agile methods is laid down in the Manifesto for Agile Software\nDevelopment, published in 2001 by a group of well-known pion eers in this area (Beck\net al., 2001). The key values of the agile movement are:\n/AF Individuals and interactions over processes and tools.\n/AF Working software over comprehensive documentation.\n/AF Customer collaboration over contract negotiation.\n/AF Responding to change over following a plan.\nAgile methods involve the users in every step taken. The deve lopment cycles are\nsmall and incremental. The series of development cycles is n ot extensively planned\nin advance, but the new situation is reviewed at the end of eac h cycle. This includes\nsome, but not too much, planning for the next cycle.\nAt the end of each cycle, the system is up and running. That is, there is a working\nsystem, one that delivers value to its users. This strongly r esembles evolutionary\nprototyping as discussed in section 3.2.1", "token_count": 512, "start_token": 35112, "end_token": 35624, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 77, "text": " end of each cycle, the system is up and running. That is, there is a working\nsystem, one that delivers value to its users. This strongly r esembles evolutionary\nprototyping as discussed in section 3.2.1. But the differen ce in wording does reﬂect\nquite a different attitude. The term prototyping suggests s omething intermediate,\n3.2. AGILE METHODS 51\nnot yet ﬁnal, temporary. ”Working code” carries a more posit ive meaning. It denotes\nsomething of immediate value, even if not perfect yet.\nAgile methods do not have an extensive architectural or desi gn phase up front.\nAfter all, it does not make sense to spend much effort on desig n if you know this will\nquite likely be a waste of time. It is more effective to only do the design as far as\nneeded for the immediate next step. Agile methods often have a separate activity to\nimprove the design after each increment, known as refactoring.\nAgile methods are people-oriented, rather than process-or iented. They emphasize\nthe human element in software development. Team spirit is co nsidered very important.\nTeam relationships are close. Often, an agile team occupies one big room. The users\nare onsite as well. Agile methods have short communication c ycles between developers\nand users, and between developers.\nFinally, agile methods do not spend much energy on documenta tion. It will have\nto change anyhow, so why spend time on something that will soo n be outdated.\nRather, agile methods rely on the tacit knowledge of the peop le involved. If you have\na question, ask one of your pals. Do not struggle with a large p ile of paper, that quite\nlikely will not provide the answer anyway.\nSome people contend that agile methods should be ‘pure’, and exhibit all of the\ncharacteristics mentioned above. Others believe that a mix ture of planning-driven\nand agile methods can be productive as well. We concur with th e latter view. In\nthe following subsections, we ﬁrst discuss prototyping and incremental development,\nearly methods that recognize that a planning-driven approa ch often does not ﬁt the\nvolatile situation at hand. Rapid Application Development and DSDM emphasize\ncustomer collaboration and", "token_count": 512, "start_token": 35574, "end_token": 36086, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 78, "text": "rst discuss prototyping and incremental development,\nearly methods that recognize that a planning-driven approa ch often does not ﬁt the\nvolatile situation at hand. Rapid Application Development and DSDM emphasize\ncustomer collaboration and the role of people in the process , and thus exhibit a\nnumber of key characteristics of agile methods. Finally, XP is a ‘pure’ agile method.\n3.2.1 Prototyping\nIt is often difﬁcult to get and maintain a sufﬁciently accura te perception of the\nrequirements of the prospective user. This is not surprisin g. It is in general not\nsufﬁcient to take the existing situation as the one and only starting point for setting up\nsoftware requirements. An important reason for embarking o n a software development\nproject is that one is not pleased with the present situation . What is wanted instead\nof the present situation is often not easy to determine. This holds even more in cases\nwhere we are concerned with a new application and the custome r does not know\nthe full possibilities of automation. In such cases, the dev elopment of one or more\nprototypes may help.\nAnalogies with the development of other products are appeal ing here. When\ndeveloping a new car or chip, one will also build one or more pr ototypes. These\nprototypes are tested intensively before a real production line is set up. For the\ndevelopment of the push-button telephone, about 2000 proto types were tested,\nwith variations in form, size and positioning of the buttons , size and weight of the\nmouthpiece, etc.\n52 THE SOFTWARE LIFE CYCLE REVISITED\nIt is possible to follow a similar road with software develop ment. In this context\na prototype can be described as a working model of (possibly p arts of) a software\nsystem, which emphasizes certain aspects. There is, howeve r, one big difference\nbetween the development of software and the development of p hysical products\nsuch as cars, chips or telephones: in developing physical pr oducts, the highest costs\nare generally incurred during production, when multiple co pies of the product are\nbeing produced. In software development, making multiple c opies of the product is\nalmost free. If we were to follow the hardware approach to pro totyping in software\ndevelopment, and produce a prototype with the same function", "token_count": 512, "start_token": 36036, "end_token": 36548, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 79, "text": " the product are\nbeing produced. In software development, making multiple c opies of the product is\nalmost free. If we were to follow the hardware approach to pro totyping in software\ndevelopment, and produce a prototype with the same function ality as the ﬁnal\nproduct, we would in fact develop an operational system, wit h correspondingly high\ncosts. It does not then seem plausible to start all over again and develop the ‘real’\nsystem in a different way.\nUsing the deﬁnition given above and with the aim of developin g a software\nprototype relatively cheaply, it is important that certain aspects are emphasized. This\ncan be achieved through, for example:\n– the use of very high-level languages, in which an executabl e version can be\ncreated quickly. This executable but probably rather inefﬁ cient version can be\nused to test the usability of the proposed system;\n– the development of a system with less functionality, in par ticular as regards\nquality attributes such as speed and robustness.\nOne of the main difﬁculties for users is to express their requ irements precisely.\nIt is natural to try to clarify these through prototyping. Th is can be achieved by\ndeveloping the user interface quickly. The prospective use r may then work with a\nsystem that contains the interaction component but not, or t o a much lesser extent,\nthe software that actually processes the input. In this way, the user may get a good\nimpression of what the future system will provide him with, before large investments\nare made to realize the system. Prototyping thus becomes a to ol for requirements\nengineering. This is illustrated graphically in ﬁgure 3.3.\nThis ﬁgure shows that the various phases are gone through in t wo ways. The\nleft-hand side of the ﬁgure is concerned with the prototypin g stages. The iteration\ncorresponds to the user-validation process, whereby new or changed requirements\ntrigger the next cycle. The right-hand side concerns the act ual production of the\noperational system. The difference between the two branche s is that, by using\ndifferent techniques and tools, the left-hand side can be tr aversed much more quickly\nand against much lower costs.\nIn ﬁgure 3.3,", "token_count": 512, "start_token": 36498, "end_token": 37010, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 80, "text": " difference between the two branche s is that, by using\ndifferent techniques and tools, the left-hand side can be tr aversed much more quickly\nand against much lower costs.\nIn ﬁgure 3.3, the prototyping phases and the later productio n phases have been\nclearly separated. This is appropriate, since we will use di fferent techniques during\nthe actual production phase, put much more emphasis on docum entation, and so on.\nIt is even feasible not to carry over the software product fro m the prototyping phases\nto the actual production phase, but to explicitly throw it aw ay after the prototyping\nphases have come to an end. This is known as throwaway prototyping . It is not necessary\n3.2. AGILE METHODS 53\nFigure 3.3 Prototyping as a tool for requirements engineeri ng\nto do so, though. The prototype may evolve to the ﬁnal product . The user starts by\nformulating the raw requirements, on the basis of which a ﬁrs t version of the system is\nproduced. The user starts to work with this system, which lea ds to new, or changed,\nrequirements. The next version is then developed. After a nu mber of such iterations,\nthe user is satisﬁed and the last version developed is the pro duct to be delivered. This\nis known as evolutionary prototyping . In practice, evolutionary prototyping is used much\nmore often than throwaway prototyping. Discarding a (partl y) working system is a\nhurdle which is not easily taken. In agile methods, the phras e working code is often\nused instead of evolutionary prototype.\nBoth throwaway and evolutionary prototyping entail advant ages and disadvan-\ntages. Figure 3.4 summarizes the pattern of pros and cons tha t emerges in case\nstudies that describe experiences of applying a prototypin g approach. Note that\nsome properties can be inﬂuenced in both a positive and a nega tive way. Depending\non circumstances, either or both may occur in an actual proje ct. For example, the\nmaintenance cost may go down because user needs are better sa tisﬁed. On the other\nhand, the maintenance cost may go up because development has been done in a quick\n54 THE SOFTWARE LIFE CYCLE RE", "token_count": 512, "start_token": 36960, "end_token": 37472, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 81, "text": ", the\nmaintenance cost may go down because user needs are better sa tisﬁed. On the other\nhand, the maintenance cost may go up because development has been done in a quick\n54 THE SOFTWARE LIFE CYCLE REVISITED\nand dirty way.\nAdvantages\n- The resulting system is easier to use\n- User needs are better accommodated\n- The resulting system has fewer features\n- Problems are detected earlier\n- The design is of higher quality\n- The resulting system is easier to maintain\n- The development incurs less effort\nDisadvantages\n- The resulting system has more features\n- The performance of the resulting system is worse\n- The design is of lesser quality\n- The resulting system is harder to maintain\n- The prototyping approach requires more experienced team m embers\nFigure 3.4 Pros and cons of prototyping\nUsers as well as developers are generally more positive abou t systems developed\nusing a prototyping approach. This positive attitude conce rns both the development\nprocess and the resulting product. Users feel more involved in the development\nprocess and have fewer conﬂicts with the designers. The exte nsive user involvement\nresults in systems which better satisfy user needs.\nSince users need not express all their requirements up front in a prototyping\napproach, there is less tendency to ask for bells and whistle s. As a consequence,\nthe end result is a leaner system whose functionality closer matches the real user\nrequirements. If users are shown a working system at an early stage and are given the\nopportunity to try it out, chances are that problems are dete cted at an early stage as\nwell. This prevents a waste of manpower which would otherwis e be needed to redo\npart of the work. If users are in a position to inﬂuence and mod ify the design, the\nsystem features will better reﬂect their requirements and t he system will be easier to\nuse.\nThe use of special-purpose prototyping tools or languages m akes it easy to add\nfeatures. Since the time interval between successive versi ons of the prototype is small,\nusers may think that it is easy to realize new features and may specify additional\nrequirements. Both these effects may result in systems havi ng more, rather than fewer,\nfeatures.\n3.2. AGILE METHODS 55\nPrototyping involves", "token_count": 512, "start_token": 37422, "end_token": 37934, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 82, "text": " it is easy to realize new features and may specify additional\nrequirements. Both these effects may result in systems havi ng more, rather than fewer,\nfeatures.\n3.2. AGILE METHODS 55\nPrototyping involves iterative design steps and, because o f the repeated attention\nto the design, its quality may increase. Since it is known a pr iori that the design\nwill evolve during subsequent prototyping steps, greater a ttention will be given to\nquality factors such as ﬂexibility and modularity and, as a r esult, design quality may\nimprove as well. In throwaway prototyping, the quality of th e ﬁnal design is often\nhigher because of the learning experience of the prototypin g steps. Also, this ﬁnal\ndesign step is hardly, if at all, patched up because of rework actions. Because of these\naspects, the resulting systems are often found to be easier t o maintain as well.\nOn the other hand, prototyping generally does not enforce st rict design and\ndevelopment standards. If we are concerned with a short deve lopment time, certain\nnecessary activities will receive less attention. The chan ces are that documentation\nis sacriﬁced for speed. Because of additions resulting from frequent rework steps, the\ndesign quality of an evolutionary prototype may deteriorat e. For that reason too,\nthe resulting systems are less maintainable. Especially in evolutionary prototypes, the\nrobustness of the system will often be less than is customary with a more traditional\napproach. In agile methods, refactoring is applied to count eract this phenomenon.\nFinally, performance tends to be worse because attention is focused on functionality\nand performance measures are either not taken at all or at a po int in time at which\nthey have become too difﬁcult to realize.\nIt is generally felt that prototyping projects require an ex perienced team. Prototyp-\ning involves making far-reaching design decisions, especi ally during early iterations.\nIn each iteration, user requests have to be weighed, both mut ually and against the\nease and cost of their realization. Inexperienced team memb ers are more likely to\nmake poor choices, thereby seriously threatening the succe ss of a prototyping effort.\nFrom this discussion, we may gather the following recommend ations for the", "token_count": 512, "start_token": 37884, "end_token": 38396, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 83, "text": " cost of their realization. Inexperienced team memb ers are more likely to\nmake poor choices, thereby seriously threatening the succe ss of a prototyping effort.\nFrom this discussion, we may gather the following recommend ations for the use\nof prototyping techniques:\n– prototyping is particularly useful in situations where th e user requirements\nare unclear or ambiguous. Prototyping seems a good way to cla rify those\nrequirements;\n– prototyping is also particularly useful for systems with a considerable emphasis\non the user interface and which show a high degree of user inte raction;\n– users and designers must be well aware of the prototyping ap proach and its\npitfalls. Users should realize that changing software is no t all that easy. Users\nshould also realize that a prototype is a prototype and not a p roduction-quality\nsystem. Designers should be aware of the characteristics of prototyping projects\nand not become frustrated by frequent changes in user requir ements;\n– prototyping must also be planned and controlled. We must im pose limits on the\nnumber of iterations. We must establish explicit procedure s for documenting\nand testing prototypes. The positive aspects of the traditi onal approach, which\nmake the process manageable and controllable, should also b e applied in this\ncase.\n56 THE SOFTWARE LIFE CYCLE REVISITED\nBy taking appropriate counter-measures, the potential dis advantages of prototyping\ncan be guarded against. Prototyping is then a viable alterna tive process model for\nmany a software development project.\n3.2.2 Incremental Development\nIn the preceding section, we discussed a way of using prototy pes for which the ﬁnal\nsystem is the last of a series of prototypes. Under careful ma nagement control in\norder to ensure convergence, the next version is planned to a ccommodate new or\nchanged user requirements. There is another way to work towa rds the ﬁnal system in\na number of iterations.\nWe proceed incrementally. The functionality of the system i s produced and\ndelivered to the customer in small increments. Starting fro m the existing situation we\nproceed towards the desired situation in a number of (small) steps. In each of these\nsteps, the phased approach that we know from the waterfall mo del, is employed.\nDeveloping software this way avoids the ‘Big Bang’", "token_count": 512, "start_token": 38346, "end_token": 38858, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 84, "text": "ceed towards the desired situation in a number of (small) steps. In each of these\nsteps, the phased approach that we know from the waterfall mo del, is employed.\nDeveloping software this way avoids the ‘Big Bang’ effect, i .e. for a long time\nnothing happens and then, suddenly, there is a completely ne w situation. Instead of\nbuilding software, the software grows. With this increment al approach, the user is\nclosely involved in planning the next step. Redirecting the project becomes easier\nsince we may incorporate changed circumstances more quickl y.\nIncremental development can also be used to ﬁght the ‘overfu nctionality’ syn-\ndrome. Since users ﬁnd it difﬁcult to formulate their real ne eds, they tend to demand\ntoo much. Lacking the necessary knowledge of the malleabili ty of software and its\ndevelopment process, they may be inclined to think that ever ything can be achieved.\nAs a consequence, essential features appear next to bells an d whistles in the list\nof requirements. Analysts are not able to distinguish one fr om the other, nor are\nthey able to accurately estimate the effort required to impl ement individual features.\nChances then are that much effort is spent on realizing featu res that are not really\nneeded. As a result, many of today’s systems offer a rich func tionality, yet are at the\nsame time ill-suited for the task at hand. For one thing, thes e systems are difﬁcult to\nuse simply because of the complexity incurred by their rich f unctionality.\nWith the incremental approach, attention is ﬁrst focused on the essential features.\nAdditional functionality is only included if and when it is n eeded. Systems thus\ndeveloped tend to be leaner and yet provide sufﬁcient suppor t to their users. With\nthe incremental approach, the most difﬁcult parts are often tackled ﬁrst, or the parts\nthat have the highest risks with respect to a successful comp letion of the project.\nFollowing this line of thought, Boehm (1988) suggests a spir al model of the\nsoftware development process, in which each convolution of the spiral gives rise to\nthe following activities:\n– identify the sub-problem which has", "token_count": 512, "start_token": 38808, "end_token": 39320, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 85, "text": ".\nFollowing this line of thought, Boehm (1988) suggests a spir al model of the\nsoftware development process, in which each convolution of the spiral gives rise to\nthe following activities:\n– identify the sub-problem which has the highest associated risk;\n– ﬁnd a solution for that problem;\n3.2. AGILE METHODS 57\nThe various process models discussed before can be coupled w ith Boehm’s spiral\nmodel in a natural way (see ﬁgure 3.5):\n– If obtaining the proper set of user requirements is seen as t he area with highest\nrisk, follow the spiral a few times around to solve this sub-p roblem (i.e.,\nprototype).\n– If, starting from a precise requirements speciﬁcation, th e main question is to\nobtain a robust and well-documented system, follow the spir al once, using\nthe traditional process model with its phases and correspon ding milestones as\nintermediate steps.\n– If developing software incrementally, track the spiral a n umber of times, once\nfor each increment.\n– During maintenance, the reported errors or changing requi rements are triggers\nto track the spiral.\nViewed this way, the spiral model subsumes the other process models discussed so\nfar.\nIncremental development is strongly advocated by Gilb (198 8). It is doubtful\nwhether the time increment advocated by Gilb, up to a maximum of a few weeks,\nis always reasonable. But the advantages of incremental dev elopment are consider-\nable even with different time increments. Surprises that lu rk within the traditional\napproach and that pose considerable difﬁculties on the mana gement side of software\ndevelopment projects can be greatly diminished when softwa re is developed and\ndelivered incrementally.\n3.2.3 Rapid Application Development and DSDM\nRapid Application Development (RAD) has a lot in common with other iterative\ndevelopment process models. It emphasizes user involvemen t, prototyping, reuse, the\nuse of automated tools, and small development teams. In addi tion to that, it employs\nthe notion of a time box , a ﬁxed time frame within which activities are done. In most\ndevelopment models, a set of requirements is ﬁxed and then th e project attempts to\n", "token_count": 512, "start_token": 39270, "end_token": 39782, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 86, "text": " that, it employs\nthe notion of a time box , a ﬁxed time frame within which activities are done. In most\ndevelopment models, a set of requirements is ﬁxed and then th e project attempts to\nfulﬁll these requirements within some estimated period of t ime. Within RAD, the\ntime frame is decided upon ﬁrst and then the project tries to r ealize the requested\nfunctionality within that time frame. If it turns out that no t all of the functionality can\nbe realized within the time frame, some of the functionality is sacriﬁced. The agreed\ndeadline however is immovable.\nThe RAD life cycle consists of four phases:\n– requirements planning,\n– user design,\n– construction,\n58 THE SOFTWARE LIFE CYCLE REVISITED\nFigure 3.5 The spiral model ( Source: B.W. Boehm, A spiral model of software development a nd\nenhancement, IEEE Computer 21:5 (1988) 1988 IEEE.)\n– cutover.\nThe requirements planning and user design phases have much i n common and may\nbe combined for smaller projects. Together, they typically take less than two months.\nThe main techniques used in these phases are known as Joint Re quirements Planning\n(JRP) and Joint Application Design (JAD). Both these techni ques make heavy use of\nworkshops in which the developers and the prospective users work together (hence the\nadjective Joint).\nThe goal of the JRP workshop is to get the requirements right t he ﬁrst time. For\nthat reason, it is imperative that the key players, i.e. the e nd users of the system,\n3.2. AGILE METHODS 59\nbe present. During the JRP workshop too, requirements are pr ioritized, since it is\nlikely that not all of them will be implemented in the ﬁrst ver sion of the system. This\nrequirement prioritization is known as triage. Triage usually means a process used on\nthe battleﬁeld and in emergency rooms to sort injured people into groups based on\ntheir need for or likely beneﬁt from immediate medical treat ment. In RAD, the triage\nprocess is used to make sure that the most important requirem ents are addressed ﬁrst.\nThe", "token_count": 512, "start_token": 39732, "end_token": 40244, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 87, "text": " based on\ntheir need for or likely beneﬁt from immediate medical treat ment. In RAD, the triage\nprocess is used to make sure that the most important requirem ents are addressed ﬁrst.\nThe result of this process is often a prioritization denoted by the acronym MoSCoW:\n/AF Must haves are requirements that are deﬁnitely needed.\n/AF Should haves are requirements that are important, but not absolutely nee ded\nfor a usable system.\n/AF Could haves are requirements that are only implemented if time allows so .\n/AF Won’t haves are requirements that will be left for the next iteration.\nAs an example, consider the development of a Library Informa tion System. The Must\nhave category would include the ability to borrow and return an item, and to enroll\nas a member. The Should have category might include faciliti es to make a reservation\nfor an item. The ability to handle ﬁnes for items returned lat e might be considered a\nCould have. Finally, functions to proﬁle users and notify th em of newly arrived items\nmight be classiﬁed as Won’t haves.\nIt is customary to have two JAD workshops during the design ph ase. Again, the\nend users play an essential role in these workshops. The ﬁrst JAD workshop yields\nan initial design of the system. The developers then constru ct a prototype, to be\nexperimented with by the users. This prototype is evaluated during the second JAD\nworkshop, improvements are decided upon, and the design is ﬁ nalized.\nThe system is constructed by a so-called SWAT team, a highly s killed team of\nabout four people. SWAT stands for Skilled With Advanced Too ls (see also chapter\n5). The SWAT team becomes involved after the ﬁrst JAD worksho p. The team\ntypically does its job in less than two months. In order to be a ble to do so, heavy\nuse is made of tools and existing components are reused whene ver feasible. Within\nthe time allotted (the time box), the SWAT team constructs a s eries of evolutionary\nprototypes. Developers and users work closely together dur ing this process. Each\nprototype is reviewed by the users and the review sessions re sult in requests for\n", "token_count": 512, "start_token": 40194, "end_token": 40706, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 88, "text": " allotted (the time box), the SWAT team constructs a s eries of evolutionary\nprototypes. Developers and users work closely together dur ing this process. Each\nprototype is reviewed by the users and the review sessions re sult in requests for\nenhanced or changed functionality. The agreed upon time fra me is not exceeded. If\nnecessary, some of the functionality is sacriﬁced instead.\nFor a SWAT team to operate successfully, and deliver a good re sult in a very short\ntime span, it has to feel a deﬁnite ‘ownership’ of the problem to be addressed. In such\na situation, it is not very helpful if time estimates and dead lines are ﬁxed by some\nmanager. Instead, the SWAT team itself estimates the time, t he SWAT team decides\nupon the number and length of the time boxes, and the SWAT team decides which\nfunctionality to implement in each iteration.\nDuring the cutover phase, the ﬁnal testing of the system take s place, users are\ntrained, and the system is installed.\n60 THE SOFTWARE LIFE CYCLE REVISITED\nThere are many variations on the RAD process model described above. For\nexample, it is possible to have explicit time boxes for the co nstruction of each of\nthe intermediate prototypes as well. It is also possible to h ave JRP or JAD sessions\nafter each prototyping cycle. The main ingredients, howeve r, remain: prototyping,\nconsiderable user involvement, SWAT teams, and time boxes.\nJRP and JAD have much in common with a design method known as Pa rticipatory\nDesign (PD), or the Scandinavian school of software develop ment. Both emphasize\nend-user involvement. They differ, however, in their goals . User involvement in JRP\nand JAD is primarily intended to speed up the process of produ cing the right system.\nUser involvement in PD is motivated by a strong interest in th e social context of the\nwork environment.\nA well-known framework that builds on RAD is DSDM. DSDM stand s for\nDynamic Systems Development Method. DSDM is based on the nin e principles\ndepicted in Figure 3.6. DSDM is a non-proﬁt framework, maint ained by the DSDM\nConsortium1 . A high-level description of the framework is given", "token_count": 512, "start_token": 40656, "end_token": 41168, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 89, "text": " nin e principles\ndepicted in Figure 3.6. DSDM is a non-proﬁt framework, maint ained by the DSDM\nConsortium1 . A high-level description of the framework is given in (Stap leton, 2003).\nThe complete set of DSDM practices is only available to membe rs of the DSDM\nConsortium. The DSDM process has ﬁve phases; see also ﬁgure 3 .7:\n/AF In the feasibility study , the suitability of DSDM for the current project is\nassessed. This is different from a more traditional feasibi lity study, where the\nemphasis is whether a solution is feasible at all. So next to q uestions like\n‘Can we build this system at all?’, the question ‘Is DSDM appr opriate for this\nproject?’ has to be answered as well. Characteristics that m ake DSDM a feasible\napproach reﬂect the principles of the method: it must be poss ible to identify the\nusers of the system, the system should not be too large, and no t all requirements\nare known upfront.\n/AF The business study results in a high-level description of the business process es\nrelevant for the system. These are determined using facilit ated workshops\n(like JRP), and result in a high-level baseline. In this phas e, the high-level\narchitecture is determined as well.\n/AF The functional model iteration results in analysis models, prototypes, and\nimplementation of the major functional components. Iterat ion is done in time\nboxes of typically two to six weeks. Each iteration consists of four activities:\n(1) identify what you will do, (2) agree on how you will do it, ( 3) do it, and (4)\ncheck that you have done it.\n/AF During the design and build iteration , the system is engineered to a sufﬁciently\nhigh standard. Here too, work is done in time boxes of typical ly two to six\nweeks, and the same four activities are performed. Though th e emphasis of\nfunctional model iterations is on deciding what to build, and that of design and\nbuild iterations is on a properly engineered solution to tha t, the distinction\nbetween those two types of", "token_count": 512, "start_token": 41118, "end_token": 41630, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 90, "text": " and the same four activities are performed. Though th e emphasis of\nfunctional model iterations is on deciding what to build, and that of design and\nbuild iterations is on a properly engineered solution to tha t, the distinction\nbetween those two types of iteration is not always clearcut.\n1 See www.dsdm.org\n3.2. AGILE METHODS 61\nPrinciple Description\nActive user involvement is\nimperative\nUsers support the team throughout the project, not\njust during requirements elicitation and acceptance\ntesting. A short communication channel is kept\nbetween the development team and the users.\nDSDM teams must be\nempowered to make decisions\nThe team must be able to make quick decisions.\nMomentum is lost if the team has to wait for\nexternal approval of every small decision\nThe focus is on frequent deliv-\nery of products\nFrequent delivery allows for frequent feedback from\nthe user community, and frequent control on the\ndecision-making process by managers\nFitness for business purpose\nis the essential criterion for\nacceptance of deliverables\nThe emphasis is on delivering the right product,\nnot on gold-plating or conformance-to-specs\nIterative and incremental\ndevelopment is necessary to\nconverge on an accurate busi-\nness solution\nRequirements cannot be completely determined\nupfront. Systems need to evolve, and rework is a\nfact of life\nAll changes during develop-\nment are reversible\nA wrong path may be taken, and backtracking is\nthen required to get to a safe point again\nRequirements are baselined at\na high level\nThe high-level requirements are determined during\nthe business study phase, while detailed require-\nments are determined during later iterative phases\nTesting is integrated through-\nout the lifecycle\nTesting is not postponed until after coding has\nﬁnished. It is done incrementally, after each com-\nponent is written\nA collaborative and co-\noperative approach between\nall stakeholders is essential\nResponsibilities are shared, and developers need\nsupport from end-users to decide what to develop\nFigure 3.6 The principles of DSDM\n/AF In the Implementation phase, the system is carried over to the customer\nenvironment. This phase also includes user training.\n3.2.4 Extreme Programming\nExtreme Programming, XP for short, is a pure agile method. XP is based on a", "token_count": 512, "start_token": 41580, "end_token": 42092, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 91, "text": " In the Implementation phase, the system is carried over to the customer\nenvironment. This phase also includes user training.\n3.2.4 Extreme Programming\nExtreme Programming, XP for short, is a pure agile method. XP is based on a number\nof best practices that have been known for long. XP takes thes e practices to extreme\n62 THE SOFTWARE LIFE CYCLE REVISITED\nFeasibility \nStudy \nBusiness \nStudy \nFunctional M odel \nIteration \nDesign & Build \nIteration \nImplementation \nFeasibility \nStudy \nBusiness \nStudy \nFunctional M odel \nIteration \nDesign & Build \nIteration \nImplementation \nFigure 3.7 The DSDM process\nlevels.\nFor instance, we know that code reading by your pals, such as i s done in\nwalkthroughs and code inspections (see also chapter 13) is a very effective test\nmethod. In XP, one does this all the time: two programmers wor k together behind\none computer screen. One of them does the coding, the other on e looks over her\nshoulder, gives advice, notices small slips, asks question s, and the like. They act as\npilot and co-pilot. At any point in time, the roles may shift. This practice is called\npair programming .\nThe full set of XP practices is given in ﬁgure 3.8. Typically, an XP team is not\ntoo big, and occupies one room. Planning meetings are very sh ort, and involve the\nimmediate functionality to be delivered to the customer. Pl anning involves both the\ncustomer and the technical people. The customer has to set pr iorities, determine dates\nof releases, and the like. The customer describes desirable features of the system in\nstories, on index cards. The technical people estimate how l ong it takes to implement\na story, decide on the order in which stories within one relea se will be implemented,\netc.\nIn XP, the design is kept as simple as possible. Since the futu re is, after all, unclear,\nthere is no use to design a grand scheme that will not be follow ed anyhow. So the\n3.2. AGILE METHODS 63\nXP practice Description\nThe Planning Game The scope of the next release is quickly det ermin", "token_count": 512, "start_token": 42042, "end_token": 42554, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 92, "text": "there is no use to design a grand scheme that will not be follow ed anyhow. So the\n3.2. AGILE METHODS 63\nXP practice Description\nThe Planning Game The scope of the next release is quickly det ermined.\nWhen necessary, the plan is updated\nSmall releases First realize a simple system, then release n ext\nversions in short cycles\nMetaphor Use of a simple metaphor for the whole system\nSimple design Make sure the design is as simple as possible at\nany point in time. Remove complexity as soon as\npossible\nTesting Programmers continuously write unit tests, cus-\ntomers write acceptance tests\nRefactoring Restructure the system without changing its\nbehaviour, to improve quality\nPair programming All code is written by two programmers at on e\nmachine\nCollective ownership Anyone can change any code, anywhere, at any\ntime\nContinuous integration The system is integrated and built m any times a\nday\n40-hour week As a rule, work 40 hours a week. Working overtime\nshould be the exception\nOn-site customer Have a real user on the team, full-time\nCoding standards Establish coding standards to ease commun ication\nFigure 3.8 XP Practices\ndesign only covers the current version of the system. After a task is accomplished,\nthe system is checked to see how it can be improved (remove dup licate code, make it\nsimpler, make it more ﬂexible). This is called refactoring. This refactoring need not be\nrestricted to one’s own code. Everyone is responsible for th e whole system. To make\nthis work, one needs to set coding standards.\nWhen a team works on implementing a story, it writes tests to c heck the\nimplementation of that story at the same time. Before the new code is checked in,\nall these tests have to run successfully. After the code has b een checked in, the full\ntest suite is run, and again all tests have to run successfull y. If not, the new code is\nremoved again to ﬁx it. This way, there always is a running sys tem.\nXP is based on ﬁve principles that drive its practices:\n/AF Rapid feedback Feedback is obtained quickly, within hours, or at most a few\ndays. By testing each small piece added, developers immedia tely learn what\n64", "token_count": 512, "start_token": 42504, "end_token": 43016, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 93, "text": " is based on ﬁve principles that drive its practices:\n/AF Rapid feedback Feedback is obtained quickly, within hours, or at most a few\ndays. By testing each small piece added, developers immedia tely learn what\n64 THE SOFTWARE LIFE CYCLE REVISITED\nworks and what doesn’t. By frequently delivering a running s ystem to the\ncustomer, the customer learns what value the system offers, and what next\nfeatures are needed.\n/AF Assume simplicity Today’s job is done today, and tomorrows job is left for\ntomorrow. Don’t build in extra complexity so that a certain c lass becomes more\nﬂexible and may be reused if a certain feature is to be added. I f and when\nthis feature is needed, it will be added, and code will be refa ctored to make it\nsimpler.\n/AF Incremental change In XP, things change in small increments. The plan changes\na little at a time, the design changes a little, the team chang es a little, etc.\n/AF Embracing change By not planning, designing, coding more than is needed\nright now, the most options for the future are kept. Only the m ost pressing\nproblem is tackled today. The rest is left for tomorrow.\n/AF Quality work Quality is a must. The team should ﬁnd pride in delivering\nexcellent quality.\nAs noted before in this chapter, agile methods are suited for certain projects, but\nnot for all. This is certainly also true for XP, the most extre me agile approach. If\nrequirements are unsure, the system is not too big, and the cu stomer can be on site, XP\ndeserves serious consideration. Early sources recommend u sing all of XP’s practices,\nsince they reinforce each other. But nowadays there also exi st many approaches that\nadopt one or a few of XP’s practices.\n3.3 The Rational Uniﬁed Process (RUP)\nThe Rational Uniﬁed Process is an iterative development pro cess, geared towards\nthe development of object-oriented systems. It comes with a lot of tool support,\ninter/intranet sources and templates for different kinds o f documents. It complements\nUML, the Uniﬁed Modeling Language. RUP might be viewed as som", "token_count": 512, "start_token": 42966, "end_token": 43478, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 94, "text": ". It comes with a lot of tool support,\ninter/intranet sources and templates for different kinds o f documents. It complements\nUML, the Uniﬁed Modeling Language. RUP might be viewed as som ewhat inter-\nmediate between document-driven and agile methods. It has a well-deﬁned process,\nincludes reasonably extensive upfront requirements engin eering activities, yet empha-\nsizes stakeholder involvement through its use-case driven nature. Its two-dimensional\nprocess structure is depicted in ﬁgure 3.9.\nRUP distinguishes four phases: inception, elaboration, co nstruction and transition.\nWithin each phase, several iterations may occur. In a second dimension, RUP\ndistinguishes nine so-called workﬂows, such as a requireme nts workﬂow and a test\nworkﬂow. These workﬂows group logical activities, and migh t extend over all phases,\nwith varying levels of attention. For instance, the require ments workﬂow is likely to\nget a lot of attention during the early phases, while the depl oyment workﬂow is most\nrelevant in the transition phase. This is graphically illus trated by the undulating shapes\n3.3. THE RATIONAL UNIFIED PROCESS (RUP) 65\nFigure 3.9 Process structure of RUP ( Source: P. Kruchten, The Rational Uniﬁed Process, An\nIntroduction, 2003, Addison-Wesley)\nnext to each workﬂow in ﬁgure 3.9. This structure allows us to differentiate between\nsuccessive iterations, and stress that different iteratio ns have a different emphasis. It\nrecognizes that requirements engineering, design, etc are ongoing activities rather\nthan phases with a strict start and end time.\nThe inception phase focuses on getting the objectives clear : what is the scope\nof this project, what are its boundaries, what are the accept ance criteria that will be\nused when the system is delivered to its customers? During th is phase too, the overall\ncost, schedule and risks are estimated. Critical use cases a re developed, as well as a\ncandidate architecture. At the end of this phase, the busine ss case for the system must\nbe clear. This might be input to a go", "token_count": 512, "start_token": 43428, "end_token": 43940, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 95, "text": ", schedule and risks are estimated. Critical use cases a re developed, as well as a\ncandidate architecture. At the end of this phase, the busine ss case for the system must\nbe clear. This might be input to a go/no-go decision.\nThe elaboration phase is mainly targeted at analyzing the pr oblem domain, and\nobtaining a sound architecture. At the end of this phase, mos t use cases will be\nidentiﬁed, and all major risks must be resolved.\nThe construction phase is a manufacturing, building proces s. The emphasis\nis on developing deployable products. Complete components are developed and\nthoroughly tested. User manuals are written. At the end of th is phase, the ﬁrst\noperational version of the system, the beta release , is ready.\nIn the transition phase, the system is released to the user co mmunity and beta-\ntested. During this phase, databases may have to be converte d, users are trained and,\nin case of a replacement system, the legacy system being repl aced is phased out.\nRUP is based on a series of best practices that have evolved ov er the years. These\n66 THE SOFTWARE LIFE CYCLE REVISITED\nbest practices are listed in Table 3.10. Many of these best pr actices of course are\nalso present in other development models. A strong point of R UP is that it provides\na balanced integration of them. Given its background, it is n o surprise that RUP is\ngeared towards the development of object-oriented systems . But RUP is suited for\nprojects with widely different characteristics. The tunin g of RUP to the situation at\nhand though is left to the user of the method.\n3.4 Intermezzo: Maintenance or Evolution\nOld payroll programs never die;\nthey just get fat around the middle\nRobert Granholm (Datamation, 1971)\nIn chapter 1, it was pointed out that a considerable maintena nce effort is inevitable.\nEach maintenance task, whether it concerns repairing an err or or adapting a system\nto new user requirements, in principle entails all aspects o f the initial development\ncycle. During maintenance, we also have to analyze the probl em and conceive a\ndesign which is subsequently implemented and tested.\nThe ﬁrst big difference is that these changes are being made t o an existing product.", "token_count": 512, "start_token": 43890, "end_token": 44402, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 96, "text": " development\ncycle. During maintenance, we also have to analyze the probl em and conceive a\ndesign which is subsequently implemented and tested.\nThe ﬁrst big difference is that these changes are being made t o an existing product.\nHowever, during initial development we often do not start fr om scratch either. If an\nexisting organization decides to automate its order admini stration, the system may\nhave to interface with already existing systems for, say, st ock administration and\nbookkeeping. Thus, maintenance activities differ in degre es from initial development,\nrather than fundamentally. This relative difference is eve n more apparent when the\nsystem is prototyped or developed incrementally.\nThe second main difference, time pressure, has a much larger impact. Time\npressure is most strongly felt when repairing errors, for th en it is quite possible that\ncertain parts of the organization have to shut down because t he software is not\noperational. In such cases, we have to work against time to id entify and repair the\nerrors. Often one patches the code and skips a thorough analy sis and design step.\nThe structure of the system tends to suffer from such patches . The system’s entropy\nincreases, which hampers later maintenance activities. Wo rse still, the system’s\ndocumentation may not be updated. Software and the correspo nding documentation\nthen grow apart, which will again hamper future maintenance activities. A more\nelaborate discussion of maintenance issues is given in chap ter 14.\nLehman and his co-workers have extensively studied the dyna mics of software\nsystems that need to be maintained and grow in size. Based on t hose quantitative\nstudies, they formulated the following laws of software evo lution (explained below):\n1. Law of continuing change A system that is being used undergoes continuous\nchange, until it is judged more cost-effective to restructu re the system or replace\nit by a completely new version.\n3.4. INTERMEZZO: MAINTENANCE OR EVOLUTION 67\nBest practice Description\nIterative development Systems are developed in an iterativ e way. This is\nnot an uncontrolled process. Iterations are planned,\nand progress is measured carefully.\nRequirements management RUP has a systematic approach to el iciting, captur-\ning and managing requirements, including possible\nchanges to these requirements.", "token_count": 512, "start_token": 44352, "end_token": 44864, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 97, "text": " is\nnot an uncontrolled process. Iterations are planned,\nand progress is measured carefully.\nRequirements management RUP has a systematic approach to el iciting, captur-\ning and managing requirements, including possible\nchanges to these requirements.\nArchitecture and Use of com-\nponents\nThe early phases of RUP result in an architec-\nture. This architecture is used in the remainder of\nthe project. It is described in different views. RUP\nsupports the development of component-based sys-\ntems, in which each component is a nontrivial piece\nof software with well-deﬁned boundaries.\nModeling and UML Much of RUP is about developing models, such as\na use-case model, a test model, etc. These models\nare described in UML.\nQuality of process and prod-\nuct\nQuality is not an add-on, but the responsibility of\neveryone involved. The testing workﬂow is aimed\nat veryfying that the expected level of quality is\nmet.\nConﬁguration and change\nmanagement\nIterative development projects deliver a vast\namount of products, many of which are frequently\nmodiﬁed. This asks for sound procedures to do so,\nand appropriate tool support.\nUse-case-driven development Use cases describe the behavi our of the system.\nThey play a major role in various workﬂows,\nespecially the requirements, design, test and man-\nagement workﬂow.\nProcess conﬁguration No size ﬁts all. Though RUP can be used ” as-is”,\nit can also be modiﬁed and tailored to better ﬁt\nspeciﬁc circumstances.\nTool support To be effective, a software development needs t ool\nsupport. RUP is supported by a wide variety of\ntools, especially in the area of visual modeling and\nconﬁguration management.\nFigure 3.10 Best practices of RUP\n68 THE SOFTWARE LIFE CYCLE REVISITED\n2. Law of increasing complexity A program that is changed becomes less and less\nstructured (the entropy increases) and thus becomes more co mplex. One has\nto invest extra effort in order to avoid increasing complexi ty.\n3. Law of self regulation Software evolution processes", "token_count": 512, "start_token": 44814, "end_token": 45326, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 98, "text": " program that is changed becomes less and less\nstructured (the entropy increases) and thus becomes more co mplex. One has\nto invest extra effort in order to avoid increasing complexi ty.\n3. Law of self regulation Software evolution processes are self-regulating and\npromote a smooth growth of the software.\n4. Law of conservation of organisational stability (invarian t work rate) The\nglobal progress in software development projects is statis tically invariant.\n5. Law of conservation of familiarity A system develops a constant growth\nincrement to sustain the organization’s familiarity with t he system. When this\nincrement is exceeded, problems concerning quality and usa ge will result.\n6. Law of continuing growth The functionality of a system needs to continuously\nincrease in order to maintain user satisfaction.\n7. Law of declining quality The quality of a system declines, unless it is actively\nmaintained and adapted to its changing environment.\n8. Law of system feedback Software evolution must be seen as a feedback system\nin order to achieve improvements.\nIn an early publication, Lehman (1974) compares the growth o f software systems\nwith that of cities and bureaucracies. He makes a distinctio n between progressive and\nanti-regressive activities in software development. Lehm an considers this model also\napplicable to socio-economic systems. In a city, for instan ce, progressive activities\ncontribute to an increase in the living standard or quality o f life. Anti-regressive\nactivities, such as garbage collection, serve to maintain t he status quo. If insufﬁcient\nattention is paid to those anti-regressive activities, dec line will set in. Anti-regressive\nactivities often are not interesting, politically speakin g. It is an investment in the\nfuture, which had better be left to others. (The same phenome non can be observed\nin the growth of the chemical industry and the resulting poll ution problems.)\nAccording to Lehman, the same kinds of activity occur within a software devel-\nopment project. Generating new code and changing existing c ode are progressive\nactivities. These are interesting, challenging and reward ing activities. They provide\nthe user with new or better functionality. Writing document ation, improving the\nstructure of the code, and maintaining good communication b etween the people\ninvolved are anti-regressive activities.", "token_count": 512, "start_token": 45276, "end_token": 45788, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 99, "text": ", challenging and reward ing activities. They provide\nthe user with new or better functionality. Writing document ation, improving the\nstructure of the code, and maintaining good communication b etween the people\ninvolved are anti-regressive activities. Neglecting thes e activities may not be harmful\nin the short term, but it certainly will be in the long term. Fo r each system, we have\nto look for a proper balance between both kinds of activity.\nThe working of the third law (the law of self regulation) can b e illustrated by\nmeans of ﬁgure 3.11 which depicts the growth pattern of syste m attributes over time.\nSystem attributes include the length (measured in lines of c ode), the number of\nmodules, the number of user-callable functions, etc. The ti me axis may denote the\nrelease number, the number of months the system is operation al, or the like. (The\n3.4. INTERMEZZO: MAINTENANCE OR EVOLUTION 69\nactual data studied by Lehman concern the relation between t he number of modules\nand the release number of the OS360 operating system.)\nThe relation depicted in ﬁgure 3.11 is almost linear. The rip ples in the ﬁgure are\nvery regular as well. Periods of more than linear growth alte rnate with periods of\nless than linear growth. Lehman explains the more than linea r growth by pointing at\nthe pressure from users to get more functionality as fast as p ossible. The developers\nor maintainers tend to bend under this pressure. As a consequ ence, one uses tricks\nand shortcuts in the code, documentation lags behind, error s are introduced and the\nsystem is insufﬁciently tested. After a while, more attenti on is paid to anti-regressive\nactivities: code needs to be refactored and documentation b rought up to date before\nfurther growth is possible. The two kinds of activity stabil ize over time.\nFigure 3.11 Growth of system attributes over time\nThe fourth law (the law of conservation of organisational st ability) seems rather\nsurprising at ﬁrst sight. Lehman and Belady found that such t hings as manpower\nand other resources do not correlate at all to the speed with w hich systems grow or\nchange", "token_count": 512, "start_token": 45738, "end_token": 46250, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 100, "text": " st ability) seems rather\nsurprising at ﬁrst sight. Lehman and Belady found that such t hings as manpower\nand other resources do not correlate at all to the speed with w hich systems grow or\nchange. Apparently, large systems are in some sort of satura ted state. More people\ncan be kept at work but, in the long run, they have no perceived impact on the\nevolution of the system.\nMore than average growth in some version of a system was, in Le hman and\nBelady’s observations, almost always followed by a less tha n average growth in the\nnext version (as expressed in the ﬁfth law -- the law of conser vation of familiarity).\n70 THE SOFTWARE LIFE CYCLE REVISITED\nIn one of the systems they investigated, a substantially hig her growth inevitably led\nto problems: lower reliability, higher costs, etc. Apparen tly, an organization has to\nsustain sufﬁcient familiarity with its software. Here too, a self-regulating feedback\nwas observed.\nFrom the preceding discussion, it follows that we have to be a lert during\nmaintenance. We have to preserve quality at each and every st ep. We may try to\npreclude the dangers sketched above by explicitly engaging ourselves in the various\ndevelopment phases during maintenance. The cyclic process followed during initial\ndevelopment then occurs during maintenance too. As with pro totyping, the time\nneeded to go through the complete cycle will in general be muc h shorter than\nduring initial development. This way of looking at maintena nce closely resembles the\nevolutionary view of software development. Realizing the ﬁ rst version of a software\nsystem is only the ﬁrst step. True enough, this ﬁrst step is mo re costly than most steps\nthat follow, but it is not fundamentally different. In chapt er 1 we already noticed\nthat such an approach may also have positive effects on the so cial and organizational\nenvironment in which software development takes place.\nThe waterfall model gives us a static view of the system to be developed. Reality\nis different. In developing software, and in particular dur ing maintenance, we are\nconcerned with an evolving system. As remarked before: soft ware is not built, it\ngrows.\n3.5 Software Product Lines\nWhen similar products are developed", "token_count": 512, "start_token": 46200, "end_token": 46712, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 101, "text": ". In developing software, and in particular dur ing maintenance, we are\nconcerned with an evolving system. As remarked before: soft ware is not built, it\ngrows.\n3.5 Software Product Lines\nWhen similar products are developed, we may hope to reuse ele ments from earlier\nproducts during the development of new products. Such is not the habit in software\ndevelopment though. In many an organization there is no ince ntive to reuse elements\n(code, design, or any other artefact) from another system si nce that is not what we\nare being paid for. Similarly, there is no incentive to produ ce reusable elements, since\nthe present project is all that counts.\nAs an alternative, we may conceive of the notion of a software product line , a set of\nsoftware systems that share elements. In a software product line, reuse is planned, not\naccidental. To keep the scope within reasonable boundaries , this planned reuse is tied\nto a given domain.\nSuppose we have developed a successful library system for ou r computer science\nfaculty library. Chances are that we will be asked to develop a similar system for,\nsay, the faculty of earth sciences. We reuse as much as possib le from our ﬁrst system.\nLikely also, some ﬁnetuning is needed to satisfy the other fa culty. Possibly, they have\nmaps that may be borrowed and require some speciﬁc way of deal ing with. Next,\nyet another faculty may come by and ask for a third system. And so on. Rather than\nact reactively, and reuse suitable elements from previous e fforts, we may also act\nproactively, and plan for the development of a series of syst ems in the domain of\nlibrary automation right from the beginning.\n3.6. PROCESS MODELING 71\nThis way of doing involves two processes: domain engineerin g and application\nengineering.\nIn domain engineering, we analyse the domain we are going to d evelop for. This\nprocess has a life cycle of its own. It results in a set of reusa ble components that form\nthe basis for the products to be developed. Usually also, a re ference architecture for\nall products to be developed is produced as well. An importan t step in this process\nis to decide on the scope of the product line. Are we going to de ", "token_count": 512, "start_token": 46662, "end_token": 47174, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 102, "text": " to be developed. Usually also, a re ference architecture for\nall products to be developed is produced as well. An importan t step in this process\nis to decide on the scope of the product line. Are we going to de velop a product\nline for just university libraries, or for libraries in gene ral? The former is simpler, but\nhas a more limited market. The latter potentially has a bigge r market, but is likely to\nresult in a more complex overall architecture and more compl ex products. Scoping\nfor product lines is a difﬁcult issue. It is inﬂuenced by the s trategy of the organization\nand requires insight into the likely evolution of the domain . Finally, the domain\nengineering process yields a production plan, a guide of how to develop products\nwithin the product family.\nApplication engineering concerns the development of indiv idual products. It\nusually follows a waterfall-like scheme. Its inputs are the outputs of the domain\nengineering process: the reference architecture, the prod uction plan, and the set of\nreusable assets.\nProduct line organizations often separate domain engineer ing activities from\napplication engineering activities. Effectively, these a ctivities then constitute separate\nprojects. The development of an individual product may resu lt in new or adapted\ncomponents that lead to adaptations at the product family le vel, which in turn affects\nthe development of subsequent products. Consequently, the re are feedback loops\nfrom the application engineering process to the domain engi neering process and vice\nversa.\nSoftware product lines are particularly suitable in domain s where there is a lot of\nvariation in quite similar products, such as mobile phones, television sets, cameras.\nCompanies operating in these domains have pioneered the pro duct line ﬁeld.\nA more elaborate discussion of software reuse and software p roduct lines is given\nin chapter ??. Software architectures are discussed in chapter 11.\n3.6 Process Modeling\nWithout a repeatable process, the only repeatable results y ou are likely to produce are\nerrors.\n(Macala et al., 1996)\nIn the 1980s, Osterweil launched the idea of describing soft ware development\nprocesses as programs. These process programs are written in a process programming\nlanguage. Like other programming languages, process programming la nguages have a\nrigorously deﬁned syntax and semantics. As a", "token_count": 512, "start_token": 47124, "end_token": 47636, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 103, "text": " of describing soft ware development\nprocesses as programs. These process programs are written in a process programming\nlanguage. Like other programming languages, process programming la nguages have a\nrigorously deﬁned syntax and semantics. As a simple example , consider the Pascal-like\n72 THE SOFTWARE LIFE CYCLE REVISITED\ndescription of a review process in ﬁgure 3.12. 2 It describes the consecutive steps of a\nreview process. The process has two inputs: the document to b e reviewed and some\nnumber which serves as a threshold. The routine returns a boo lean indicating whether\nor not another review is to be scheduled.\nfunction review (document, threshold): boolean;\nbegin prepare-review;\nhold-review(document, no-of-problems);\nmake-report;\nreturn no-of-problems\n/BO threshold\nend review;\nFigure 3.12 A process program for the review process\nIn ﬁgure 3.12, the review process is described in terms of the successive activities\nto be performed: ﬁrst, the review is prepared, then the meeti ng is held, and ﬁnally a\nreport is made. We may also describe the process in terms of th e states it can be in.\nAfter the preparation activities (distribution of the docu ment amongst participants,\nscheduling of a meeting, and the like), the document is ready to be reviewed. After\nthe meeting has been held, a report can be written. And after t he report has been\nwritten, further steps can be taken. Figure 3.13 describes t he review process in terms\nof states and transitions between states. The box labeled review process describes\nthe review process proper. The inputs and outputs of the proc ess are indicated by\narrows leading into and out of the box. This ﬁgure uses the UML notation for state\ndiagrams (a variant of the state transition diagram); see se ction 10.3.2.\nPetri nets provide yet another formalism to describe proces s models. Figure 3.14\ngives a Petri net view of the review process. A Petri net is a di rected graph with two\ntypes of node: places and transitions. A place is depicted as a circle. It denotes a\n(partial) state of the system. A place is either marked or unm arked", "token_count": 512, "start_token": 47586, "end_token": 48098, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 104, "text": " A Petri net is a di rected graph with two\ntypes of node: places and transitions. A place is depicted as a circle. It denotes a\n(partial) state of the system. A place is either marked or unm arked. In ﬁgure 3.14, the\nplace code ready is marked, but review scheduled is not. A transition is depicted\nby a straight line. A transition receives input from one or mo re places, and delivers\noutput to one or more places. These inputs and outputs are den oted by arrows leading\nto and from a transition. A transition denotes an activity wh ich can be performed\n(in Petri net terminology, ‘ﬁred’) if all of its input places are marked. Places can\nthus be thought of as preconditions for activities. In ﬁgure 3.14, the review meeting\ncannot be held, since it has not been scheduled yet. Once it ha s been scheduled, the\ncorresponding place is marked and the transition can be ﬁred . The markings are then\nremoved from all of the input places and all of the output plac es are marked instead.\n2 In a review, a document (such as piece of code or a design) is ﬁr st studied individually by a couple of\nreviewers. The problems found are then discussed by the revi ewers and the author of the document (see\nsection 13.4.2).\n3.6. PROCESS MODELING 73\nFigure 3.13 State transition diagram of the review process\nFigure 3.14 Petri net view of the review process\nPetri nets are an attractive modeling technique for process es, since they allow a\ncertain amount of nondeterminism and parallellism. For exa mple, the process in ﬁgure\n3.14 does not specify the order in which coding and schedulin g activities are to be\nperformed. They may go on in parallel; synchronization take s place when both are\nﬁnished.\nA precise description of the software process, be it in a prog ramming-language\nnotation, a graphical notation, or otherwise, serves three main purposes:\n/AF It facilitates understanding and communication. In a softw are development\n74 THE SOFTWARE LIFE CYCLE REVISITED\nproject, people have to work together. They thus need to have a shared", "token_count": 512, "start_token": 48048, "end_token": 48560, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 105, "text": ", or otherwise, serves three main purposes:\n/AF It facilitates understanding and communication. In a softw are development\n74 THE SOFTWARE LIFE CYCLE REVISITED\nproject, people have to work together. They thus need to have a shared view of\nthe processes to be carried out and the roles they are to play i n those processes.\nEither model of the review process given above can be used for this purpose.\n/AF It supports process management and improvement. A precise d escription of\nactivities to be performed can be used by project management to assign tasks\nand to keep track of who is doing what. If the software develop ment process is\nto be improved, you ﬁrst have to know what the current process is, i.e. it has\nto be modeled.\n/AF It may serve as a basis for automated support. This automated support may\nguide or enforce the order in which tasks are being carried ou t. For instance,\na reviewer may automatically be sent a message indicating th at a certain piece\nof code is ready for review as soon as its author releases that code. The\nautomated support may also be used to monitor and track progr ess, collect\nprocess information and metrics, and so on.\nThe description of the review process in ﬁgure 3.12 is very de terministic. It can\nbe completely automated and executed without human interve ntion. In general, the\nwork that is being modeled will be carried out by both humans a nd machines. The\nneutral term enactment is used to denote the execution of the process by either\nhumans or machines. Support for process enactment is often c ombined with support\nfor conﬁguration management (see section 4.1).\nThough the precise modeling of the software process has deﬁn ite advantages, the\nresulting process formality, or even rigidity, holds certa in dangers and limitations as\nwell:\n/AF Many aspects of the software development process are heuris tic or creative in\nnature and do not lend themselves to an algorithmic descript ion. For example,\nthe actual debugging or design processes will be quite difﬁc ult to capture in a\nprocess model.\n/AF A process model is a model and, thus, a simpliﬁcation of reali ty. For example,\nthe above models of the review process do", "token_count": 512, "start_token": 48510, "end_token": 49022, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 106, "text": "ﬁc ult to capture in a\nprocess model.\n/AF A process model is a model and, thus, a simpliﬁcation of reali ty. For example,\nthe above models of the review process do not specify what to d o if the minutes\nof the meeting are not delivered or the review is not held beca use the author\nof the code is on sick-leave, and so on.\n/AF Process models often focus on the transformation of artifac ts, such as code, a\nrequirements speciﬁcation, or a test plan. The progression of stages through\nwhich the artifact evolves then gets confused with the organ ization of the\nprocesses through which people actually develop those arti facts. This argument\nwas used earlier when we criticized the waterfall model. It i s supported by the\nstudies of Zelkowitz and Guindon reported in section 3.1. Pa rnas and Clements\n(1986) use similar arguments when they criticize the view th at the software\ndesign process is a rational one.\n3.7. SUMMARY 75\n/AF Processes that do not directly transform artifacts tend to b e ignored (for\nexample, learning the application domain, handling requir ements that ﬂuctuate\nor conﬂict, and dealing with breakdowns in communication or coordina-\ntion (Curtis et al., 1988).\n/AF Processes are treated as discrete rather than continuous in time (i.e. each\nproject invokes a separate process). This view inhibits the transfer of knowledge\nbetween projects, as was discussed in the previous section.\nProcess modeling has received a lot of attention in the resea rch literature. It is\nindicative of the need for more formal approaches to the desc ription of the software\nprocess. The latest trend in process modeling research is ai med at providing developers\nwith computer guidance and assistance, rather than trying t o fully automate the\nprocess. Such precise descriptions provide a basis for a ran ge of support functions,\nranging from the enactment of design steps to agenda managem ent. This trend to\nsupport people rather than take over ﬁts in well with agile de velopments too.\n3.7 Summary\nIn this chapter we have addressed the software life cycle aga in. There are quite a few\narguments against the strict sequential ordering of phases as discussed in", "token_count": 512, "start_token": 48972, "end_token": 49484, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 107, "text": "�ts in well with agile de velopments too.\n3.7 Summary\nIn this chapter we have addressed the software life cycle aga in. There are quite a few\narguments against the strict sequential ordering of phases as discussed in chapter 1.\nThe traditional approach is, to a large extent, document-dr iven. On the way from\nstart to ﬁnish a number of milestones are identiﬁed. Reachin g those milestones is\ndetermined by the availability of certain documents. These documents then play a\nkey role in controlling the development process. It is a heav yweight process, and\nplanning-driven.\nDaily practice hardly ﬁts this model. Change is inevitable, and we had better\nadopt a development method that accommodates change. In rec ent years, a number\nof agile, lightweight methods have been proposed that consc iously deal with change.\nThese have evolved from methods such as prototyping, increm ental development,\nand Rapid Application Development. A very inﬂuential agile method is eXtreme\nProgramming, or XP.\nIf a series of similar products is developed within a domain, it pays off to\nplan reuse upfront, rather than leave it to individual proje cts to deliver reusable\ncomponents. This had led to the notion of software product li nes, discussed in\nsection 3.5. In software product line engineering, the doma in engineering part takes\ncare of developing reusable assets, while the application e ngineering part produces\nindividual products using those assets.\nFinally, we introduced the notion of process modeling, whic h is aimed at\ndescribing the software development process in a precise an d unambiguous way. Such\ndescriptions are not intended to fully replace human activi ties, but rather to support\nthem.\n76 THE SOFTWARE LIFE CYCLE REVISITED\n3.8 Further Reading\nThe waterfall model is generally attributed to Royce (1970) and became well known\nthrough Boehm (1976). However, a clearly phased approach to the development of\nsoftware, including iteration and feedback, can already be found in earlier publications:\n(Benington, 1983) and (Hosier, 1961).\nAdvantages and disadvantages of prototyping, based on an an alysis of 22 published\ncase studies and 17 ﬁrst-hand accounts, are given in (Gordon", "token_count": 512, "start_token": 49434, "end_token": 49946, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 108, "text": ", 1983) and (Hosier, 1961).\nAdvantages and disadvantages of prototyping, based on an an alysis of 22 published\ncase studies and 17 ﬁrst-hand accounts, are given in (Gordon and Bieman, 1994).\n(Verner and Cerpa, 1997) address the different views held by analysts and managers\nof the pros and cons of prototyping.\nFor a very elaborate discussion of RAD, see (Martin, 1991). D SDM is discussed\nin (Stapleton, 2003). Participatory Design is described in (Floyd et al., 1989).\n(CACM, 1993a) is a special issue on Participatory Design. It contains articles\ndescribing experiences with Participatory Design, as well as a comparison of RAD\nand Participatory Design. (Kruchten, 2003) provides a good introduction to RUP.\nThere are many books about agile methods. The standard book o n XP is by its\ninventor, Kent Beck (2000). A good companion volume is (Jeff ries et al., 2001). Other\nagile methods include Scrum (Schwaber and Beedle, 2002) and the Crystal family of\nmethodologies (Cockburn, 2002). For a comparison of a numbe r of agile methods,\nsee (Abrahamsson et al., 2002). Boehm and Turner (2003) comp are planning-driven\nand agile methods, and give advice on when to use which kind of method.\nLehman and Belady (1985) give an overview of their early work on the laws of\nsoftware evolution. Lehman et al. (1997) and Cook et al. (200 6) provide an updated\nperspective. The formulation given in this chapter is based on (Lehman et al., 1997).\nA factory-like view of software development was suggested a t the very ﬁrst\nconference on Software Engineering (McIlroy, 1968). The te rm ‘software factory’\nis also often associated with Japanese efforts to improve so ftware development\nproductivity (Cusumano, 1989). The notion of software prod uct lines emerged in the\n80’s as a way to increase economy of scale. Clements and North rop (2001) and Pohl\net al. (2005) provide an in-depth discussion of software pro duct line engineering.\n(Osterweil", "token_count": 512, "start_token": 49896, "end_token": 50408, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 109, "text": "’s as a way to increase economy of scale. Clements and North rop (2001) and Pohl\net al. (2005) provide an in-depth discussion of software pro duct line engineering.\n(Osterweil, 1987) launched the idea of describing software development processes\nas programs. Critical appraisals of this view are given in (L ehman, 1987), (Curtis\net al., 1987) and (Curtis, 1989). The current trends in softw are process modeling are\ndescribed in (Fuggetta and Wolf, 1996).\nExercises\n1. Describe the waterfall model of software development.\n2. Describe the Rapid Application Development (RAD) approa ch to software\ndevelopment.\n3.8. FURTHER READING 77\n3. Discuss the main differences between prototyping and inc remental develop-\nment.\n4. Discuss the main differences between incremental develo pment and RUP.\n5. Discuss the law of continuing change.\n6. How does the spiral model subsume prototyping, increment al development,\nand the waterfall model?\n7. Explain the XP practices ‘pair programming’ and ‘refacto ring’.\n8. What is a software product line?\n9. What is the main purpose of having an explicit description of the software\ndevelopment process in a process model?\n10. What is process enactment?\n11. Discuss the key values of the agile movement.\n12. /DJ Suppose you are involved in a large project concerning the de velopment of\na patient planning system for a hospital. You may opt for one o f two strategies.\nThe ﬁrst strategy is to start with a thorough analysis of user requirements,\nafter which the system is built according to these requireme nts. The second\nstrategy starts with a less complete requirements analysis phase, after which\na pilot version is developed. This pilot version is installe d in a few small\ndepartments. Further development of the system is guided by the experience\ngained in working with the pilot version. Discuss the pros an d cons of both\nstrategies. Which strategy do you favor?\n13. /DI Consider the patient planning system project mentioned in t he previous\nexercise. Under what conditions would you opt for an agile ap proach for this\nproject?\n14. Discuss the relative merits", "token_count": 512, "start_token": 50358, "end_token": 50870, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 110, "text": " Which strategy do you favor?\n13. /DI Consider the patient planning system project mentioned in t he previous\nexercise. Under what conditions would you opt for an agile ap proach for this\nproject?\n14. Discuss the relative merits of throwaway prototyping as a means to elicit\nthe ‘true’ user requirements and prototyping as an evolutio nary development\nmethod.\n15. In what ways may the notion of a software product line impa ct the structure\nof the software development process?\n16. /DI Software maintenance increases system entropy. Discuss po ssible ways to\ncounteract this effect.\n17. /DI One of the reasons for using planning-driven approaches in s oftware\ndevelopment projects is that the plan provides some structu re to measure\n78 THE SOFTWARE LIFE CYCLE REVISITED\nproject progress. Do you think this measure is adequate? Can you think of\nbetter ways to measure progress?\n18. /DI Discuss the differences between RAD and Participatory Desi gn (see also\n(Carmel et al., 1993)).\n19. /DJ Describe the requirements engineering process depicted in ﬁgure 9.1 in a\nnotation like a programming language. Be as precise as possi ble. Discuss the\nadvantages and limitations of the resulting process descri ption.\n20. /DJ Describe the requirements engineering process depicted in ﬁgure 9.1 in\na state transition diagram. Discuss the advantages and limi tations of the\nresulting process description.\n4\nConﬁguration Management\nLEARNING OBJECTIVES\n/AF To understand the main tasks and responsibilities of softwa re conﬁguration\nmanagement\n/AF To be aware of the contents of a conﬁguration management plan\n/AF To appreciate the interplay between the role of conﬁguratio n management in\nsoftware development and the capabilities of supporting to ols\n80 CONFIGURATION MANAGEMENT\nCareful procedures are needed to manage the vast number of el ements (source\ncode components, documentation, change requests, etc.) th at are created and\nupdated over the lifetime of a large software system. This is especially true in\ndistributed development projects. It is called conﬁgurati on management.\nIn the course of a software development project, quite a few d ocuments are\nproduced", "token_count": 512, "start_token": 50820, "end_token": 51332, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 111, "text": " lifetime of a large software system. This is especially true in\ndistributed development projects. It is called conﬁgurati on management.\nIn the course of a software development project, quite a few d ocuments are\nproduced. These documents are also changed from time to time . Errors have to be\ncorrected, change requests have to be taken care of, etc. Thu s, at each point in time\nduring a project, different versions of the same document ma y exist in parallel.\nOften too, a software system itself is not monolithic. Softw are systems exist in\ndifferent versions or conﬁgurations. Different versions c ome about when changes are\nimplemented after the system has been delivered to the custo mer. From time to time,\nthe customer is then confronted with a new release. Differen t versions of components\nof a system may also exist during development. For instance, if a change request has\nbeen approved, a programmer may be implementing that change by rewriting one\nor more components. Another programmer, however, may still be using the previous\nversion of those same components.\nDifferent conﬁgurations also come about if a set of componen ts may be assembled\ninto a system in more than one way. Take, for example, the syst em called ACK,\nthe Amsterdam Compiler Kit (Tanenbaum et al., 1983). ACK con sists of a set of\nprograms to develop compilers for ALGOL-like languages. Im portant components of\nACK are:\n– front ends for languages such as Pascal, C, or Modula-2. A fr ont end for language\nX will translate programs in that language into the universa l intermediate code\nEM;\n– different EM-optimizers;\n– back ends, which translate EM-code to assembler-code for a variety of real\nmachines.\nA compiler is then obtained by selecting a front end for a spec iﬁc language, a back\nend for a speciﬁc machine and, optionally, one or more optimi zers. Each compiler is\na conﬁguration, a certain combination of elements from the A CK system. The ACK\nsystem is an example of a product line, from an era before that notion was used.\nThe key tasks of conﬁguration management are discussed in se c", "token_count": 512, "start_token": 51282, "end_token": 51794, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 112, "text": " a certain combination of elements from the A CK system. The ACK\nsystem is an example of a product line, from an era before that notion was used.\nThe key tasks of conﬁguration management are discussed in se ction 4.1. A\nConﬁguration Management Plan lays down the procedures that describe how to\napproach conﬁguration management. The contents of this doc ument are discussed in\nsection 4.2. Conﬁguration management is often supported by tools. The discussion\nof those tools is largely postponed until chapter 15.\n4.1. TASKS AND RESPONSIBILITIES 81\n4.1 Tasks and Responsibilities\nConﬁguration management is concerned with the management o f all artifacts pro-\nduced in the course of a software development project. Thoug h conﬁguration\nmanagement also plays a role during the operational phase of a system, when dif-\nferent combinations of components can be assembled into one system and new\nreleases of a system are generated, the discussion below cen ters around the role of\nconﬁguration management during system development.\nWe will for the moment assume that, at any point in time, there is one ofﬁcial\nversion of the complete set of documents related to the proje ct. This is called the\nbaseline. A baseline is ‘a speciﬁcation or product that has been forma lly reviewed\nand agreed upon, that thereafter serves as the basis for furt her development, and that\ncan be changed only through formal change control procedure s’ (IEEE610, 1990).\nThus, the baseline is the shared project database, containi ng all approved items. The\nbaseline may or may not be stored in a real database and suppor ted by tools to assist\nin retrieving and updating its elements. The items containe d in the baseline are the\nconﬁguration items . A conﬁguration item is ‘an aggregation of hardware, softwa re, or\nboth, that is designated for conﬁguration management and tr eated as a single entity\nin the conﬁguration management process’ (IEEE610, 1990). P ossible conﬁguration\nitems are:\n– source code components,\n", "token_count": 512, "start_token": 51744, "end_token": 52256, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 113, "text": " management and tr eated as a single entity\nin the conﬁguration management process’ (IEEE610, 1990). P ossible conﬁguration\nitems are:\n– source code components,\n– the requirements speciﬁcation,\n– the design documentation,\n– the test plan,\n– test cases,\n– test results,\n– the user manual.\nAt some point in time, the baseline will contain a requiremen ts speciﬁcation. As time\ngoes on, elements will be added: design documents, source co de components, test\nreports, etc. A major task of conﬁguration management is to m aintain the integrity of\nthis set of artifacts.\nThis is especially important if changes are to be incorporat ed. Suppose that,\nduring testing, a major ﬂaw in some component is discovered. We then have to\nretrace our steps and correct not only that component but als o the corresponding\ndesign documents, and possibly even the requirements speci ﬁcation. This may affect\nwork being done by other people still using the old version. W orse still, someone\nelse may wish to make changes to the very same component at the same time.\n82 CONFIGURATION MANAGEMENT\nFigure 4.1 Workﬂow of a change request\nConﬁguration management takes care of controlling the rele ase and change of these\nitems throughout the software life cycle.\nThe way to go about this is to have one shared library or databa se that contains all\napproved items, the so-called baseline. Adding an item to th is database, or changing\nan item, is subject to a formal approval scheme. For larger pr ojects, this is the\nresponsibility of a separate body, the Conﬁguration (or Cha nge) Control Board\n(CCB). The CCB ensures that any change to the baseline is prop erly authorized and\nexecuted. The CCB is staffed with people from the various par ties involved in the\nproject, such as development, testing, and quality assuran ce.\nAny proposed change to the baseline is called a change reques t. A change request\nmay concern an error found in some component, a discrepancy f ound between a\ndesign document and its implementation, an enhancement cau sed by changed user\n", "token_count": 512, "start_token": 52206, "end_token": 52718, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 114, "text": "Any proposed change to the baseline is called a change reques t. A change request\nmay concern an error found in some component, a discrepancy f ound between a\ndesign document and its implementation, an enhancement cau sed by changed user\nrequirements, etc. A change request is handled as follows (s ee also ﬁgure 4.1):\n/AF The proposed change is submitted to the CCB. To be able to asse ss the\nproposed change, the CCB needs information as to how the chan ge affects\nboth the product and the development process. This includes information about\nthe estimated amount of new or changed code, additional test requirements,\nthe relationship to other changes, potential costs, comple xity of the change,\nthe severity of the defect (if it concerns one), resources ne eded, etc. Usually, a\nspecial change request form is provided to specify the infor mation needed by\nthe CCB.\n4.1. TASKS AND RESPONSIBILITIES 83\n/AF The CCB assesses the change request. The change request may b e approved,\nrejected, or deferred if further information is required. I f the request is approved,\nit eventually results in a work package which has to be schedu led.\n/AF The CCB makes sure that all conﬁguration items affected will eventually be\nupdated accordingly. Conﬁguration management provides a m eans to establish\nthe status of all items and, thereby, of the whole project.\nThus, conﬁguration management is not only about keeping tra ck of all the different\nversions of elements of a system; it also encompasses workﬂo w management tasks.\nThe process depicted in the state transition diagram in ﬁgur e 4.1, for example,\ndescribes what goes on in the life cycle of a change request. T he process model thus\ndeﬁned exempliﬁes how the workﬂow of change requests can be m anaged.\nIn a similar vein, the state transition diagram in ﬁgure 4.2 s hows the workﬂow of\ndeveloper tasks during the development of a system componen t. It shows the possible\nstates of a system component and the transitions in between. For example, after a\ncomponent has been coded, it is unit tested.", "token_count": 512, "start_token": 52668, "end_token": 53180, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 115, "text": "��ow of\ndeveloper tasks during the development of a system componen t. It shows the possible\nstates of a system component and the transitions in between. For example, after a\ncomponent has been coded, it is unit tested. If bugs are found during unit testing,\nfurther coding is necessary. Otherwise, the component ente rs the review stage. If the\nreview reveals problems, the coding stage is re-entered. Ot herwise, the component is\nsubmitted to the CCB for formal approval. Finally, if unit te sting does not reveal any\nerrors, the review stage is skipped.\nIf components are kept under conﬁguration control, conﬁgur ation management\ncan be used to manage the workﬂow of development tasks as well . Changes in\nthe status of a component then trigger subsequent activitie s, as indicated in the\ndevelopment workﬂow model.\nWe have to take care that the workﬂow schemes do not unnecessa rily curtail the\nday-to-day working of the people involved in the project. Ne w items should not be\nadded to the baseline until they have been thoroughly review ed and tested. Items\nfrom the shared database may be used freely by the participan ts. If an item has to\nbe changed, the person responsible for implementing the cha nge gets a copy of that\nitem and the item is temporarily locked, so that others can no t simultaneously update\nthe same item. The person implementing the change is free to t inker with the copy.\nAfter the change has been thoroughly tested, it is submitted back to the CCB. Once\nthe CCB has approved it, the revised item is included in the da tabase, the change\nitself is documented with the item, and the item is unlocked a gain. A sequence of\ndocumented changes thus provides a revision history of that item.\nWhen an item is changed, the old version is kept as well. The ol d version still\nhas to be used by others until they have adapted to the change. Also, we may wish\nto go back to the old version if another change is requested. W e thus have different\nversions of one and the same item, and must be able to distingu ish them. This can\nbe done through some numbering scheme, where each new versio n gets identiﬁed by\nthe next higher number.", "token_count": 512, "start_token": 53130, "end_token": 53642, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 116, "text": " different\nversions of one and the same item, and must be able to distingu ish them. This can\nbe done through some numbering scheme, where each new versio n gets identiﬁed by\nthe next higher number. We then get, for a component X, versio ns X.0, X.1, X.2, and\nso on.\n84 CONFIGURATION MANAGEMENT\nFigure 4.2 State transition diagram of development activit ies\nIn a more sophisticated environment, we may even create diff erent branches of\nrevisions. Figure 4.3 gives an example of such a forked devel opment. In the example,\ncomponent X.2.1. is, say, the result of ﬁxing a bug in compone nt X.2. Component X.3\nmay concern an enhancement to X.2. It should be noted that mer ging those parallel\ndevelopment paths again can be difﬁcult. Also, the numberin g schemes soon tend to\nbecome incomprehensible.\nConﬁguration management is generally supported by powerfu l tools. Dart (1990)\nclassiﬁes the functionalities of these software conﬁgurat ion management (SCM) tools\nin eight categories:\n/AF Components. SCM tools support storing, retrieving, and accessing comp o-\nnents. Several versions of a component may be stored, baseli nes can be\nestablished, and branches of revisions may be created.\n/AF Structure. SCM tools support support the representation and use of the\nstructure of a system made up of components and their interfa ces. In terms of\narchitectural viewpoints, this is the implementation view point; see section 11.3.\n4.1. TASKS AND RESPONSIBILITIES 85\nFigure 4.3 Parallel development paths\n/AF Construction. SCM tools support the construction of an executable versio n of\nthe system. By default, the latest version of all conﬁgurati on elements is used,\nbut it is also possible to regenerate older versions of the sy stem.\n/AF Auditing. SCM tools allow one to follow trails: which changes have bee n made\nto this component, who did those changes, and why. This way, a searchable\narchive of the system is maintained.\n/AF Accounting. The", "token_count": 512, "start_token": 53592, "end_token": 54104, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 117, "text": "iting. SCM tools allow one to follow trails: which changes have bee n made\nto this component, who did those changes, and why. This way, a searchable\narchive of the system is maintained.\n/AF Accounting. The searchable archive allows one to gather statistics abo ut\nthe system and the development process. We may for instance s earch for\ncomponents that are changed very often, and hypothesize abo ut the quality of\nthose components.\n/AF Controlling. SCM tools may be used for traceability purposes. If sufﬁcie nt\ninformation is stored, we may trace defects to requirements , analyze the impact\nof changes, and the like.\n/AF Process. SCM tools may support users in selecting tasks and performi ng those\ntasks in the appropriate context. For instance, the tool may assist in assigning\nthe handling of a change request to a certain developer, and a utomatically\nprovide her with a workspace with the components that need to be changed.\n/AF Team. SCM tools may support collaboration, for example by genera ting\na workspace for a group of collaborating developers, by noti cing conﬂicts\nbetween developers, and the like.\nMany SCM tools employ the version-oriented model of conﬁgurations. A physical\nchange in a component then results in a new version, and diffe rent versions are\nthus characterized by their difference. Some tools use logi cal changes, rather than\nphysical ones, as a basic unit of work in conﬁguration manage ment. This so-called\nchange-oriented model gives a more intuitive way of working and may prevent a l ot\nof user errors when conﬁguring a system. Rather than identif ying a conﬁguration by\n86 CONFIGURATION MANAGEMENT\nsome arcane sequence of numbers, it is now identiﬁed by some b aseline plus a set of\nchanges. The set of changes may be empty. We thus specify\nbaseline X plus ‘ﬁx table size problem’\nrather than\n/CU X.3.1, Y.2.7, Z.1.4, . . . /CV .\nAs noted, SCM tools tools also offer help in constructing an e xecutable version of the\nsystem. One writes a", "token_count": 512, "start_token": 54054, "end_token": 54566, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 118, "text": ".3.1, Y.2.7, Z.1.4, . . . /CV .\nAs noted, SCM tools tools also offer help in constructing an e xecutable version of the\nsystem. One writes a ‘program’ that identiﬁes the various co mponents of the required\nsystem and their mutual dependencies. The system in questio n is then generated\nby executing this ‘program’: the components are retrieved a utomatically from the\ndatabase containing the source code components, and all com ponents are translated\nand linked together into an executable system. If the system is smart enough, only\nthose components that have been changed are translated anew .\nEarly SCM tools emphasized the product-oriented tasks of co nﬁguration manage-\nment. They provide functionality to lock and unlock element s, provide for automatic\nnumbering of revisions, and, by default, provide users with the latest version of an\nitem. If an item is changed, they prompt the user and ask him to document the change.\nPresent-day SCM tools increasingly provide the other funct ionalities as well, and\nhave become a key ingredient of managing modern, distribute d and global, software\ndevelopment. Tools for conﬁguration and version managemen t will be discussed more\nextensively in chapter 15.\nOn one hand, conﬁguration management entails procedures on how to handle\nchanges to and versions of documents. On the other hand, it co nsists of tool support\nto maintain the version history and ensure an up to date versi on of the system. In\nplanning-driven development, both aspects are important. In agile projects, emphasis\nis on the tool support part. Agile projects favor continuous integration, whereby\nindividual work of one developer is rapidly integrated with other parts of the system.\nAnd then tests are run to make sure everything still works as e xpected. Such a\ndevelopment cycle can take a few hours, and at most one day. At the end of the day,\none again has a running system that passes all tests. This pro cess is known as the daily\nbuild.\n4.2 Conﬁguration Management Plan\nThe procedures for conﬁguration management are laid down in a document, the\nConﬁguration Management Plan. For the contents of this plan , we will follow", "token_count": 512, "start_token": 54516, "end_token": 55028, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 119, "text": "4.2 Conﬁguration Management Plan\nThe procedures for conﬁguration management are laid down in a document, the\nConﬁguration Management Plan. For the contents of this plan , we will follow the\ncorresponding IEEE Standard (IEEE828, 1990). This documen t describes methods to\nidentify conﬁguration items, to control change requests, a nd to document the imple-\nmentation of those change requests. A sample table of conten ts of the Conﬁguration\nManagement Plan is given in ﬁgure 4.4. The main constituents of this plan are:\nManagement This section describes how the project is being organized. P articular\nattention is paid to responsibilities which directly affec t conﬁguration management:\n4.3. SUMMARY 87\nhow are change requests being handled, how are development p hases closed, how\nis the status of the system maintained, how are interfaces be tween components\nidentiﬁed? Also, the relationship with other functional or ganizations, such as software\ndevelopment and quality assurance, is delineated.\nActivities This section describes how a conﬁguration will be identiﬁed and controlled\nand how its status will be accounted and reported. A conﬁgura tion is identiﬁed by a\nbaseline: a description of the constituents of that conﬁgur ation. Such a conﬁguration\nmust be formally approved by the parties involved.\nClear and precise procedures are needed with respect to the p rocessing of change\nrequests if a software development project is to be controll ed. A Conﬁguration\nControl Board (CCB) usually has the responsibility to evalu ate and approve or reject\nproposed changes. The authority, responsibility, and memb ership of the CCB have to\nbe stated. Since software components are usually incorpora ted in a library, procedures\nfor controlling this library have to be established as well.\nIn order to be able to control a software development project , data have to be\ncollected and processed. Information that is normally requ ired includes: the present\nstatus of components, versions and change requests, as well as reports of approved\nchanges and their implementation.\nChanges to conﬁ", "token_count": 512, "start_token": 54978, "end_token": 55490, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 120, "text": " data have to be\ncollected and processed. Information that is normally requ ired includes: the present\nstatus of components, versions and change requests, as well as reports of approved\nchanges and their implementation.\nChanges to conﬁguration items may affect items outside the s cope of the plan,\nsuch as hardware items. These external items have to be ident iﬁed and their interfaces\ncontrolled. In a similar vein, interfaces to items develope d outside the project have to\nbe identiﬁed and controlled.\n4.3 Summary\nConﬁguration management is concerned with the management o f all artifacts pro-\nduced in the course of a software development project. It ent ails the following major\nactivities:\n/AF Conﬁguration items must be identiﬁed and deﬁned. A conﬁgura tion item is a\ncollection of elements that is treated as one unit for the pur pose of conﬁguration\nmanagement. Examples of possible conﬁguration items are th e requirements\nspeciﬁcation, a software component, a test report, and the u ser documentation.\n/AF The release and change of these items throughout the softwar e life cycle must\nbe controlled. This means that orderly procedures must be es tablished as to\nwhom is authorized to change or release conﬁguration items.\n/AF The status of conﬁguration items and change requests must be recorded and\nreported. For example, the status of a change request may be: proposed,\napproved, rejected, or incorporated.\nFor larger projects, a Conﬁguration Control Board is usuall y established. The CCB\nis responsible for evaluating all change requests and maint aining the integrity of\n88 CONFIGURATION MANAGEMENT\n1. Introduction\na. Purpose\nb. Scope\nc. Deﬁnitions and acronyms\nd. References\n2. SCM management\na. Organization\nb. SCM responsibilities\nc. Applicable policies, directives and procedures\n3. SCM activities\na. Conﬁguration identiﬁcation\nb. Conﬁguration control\nc. Conﬁguration status accounting\nd. Conﬁguration audits and reviews\n", "token_count": 512, "start_token": 55440, "end_token": 55952, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 121, "text": " activities\na. Conﬁguration identiﬁcation\nb. Conﬁguration control\nc. Conﬁguration status accounting\nd. Conﬁguration audits and reviews\ne. Interface control\nf. Subcontractor/vendor control\n4. SCM schedules\n5. SCM resources\n6. SCM plan maintenance\nFigure 4.4 Sample structure of a software conﬁguration mana gement (SCM) plan\n(Source: IEEE Standard for Software Conﬁguration Management Plans, IEEE Std\n828-1990. Reproduced by permission of IEEE. )\nthe complete set of documents that relate to a project. Its ta sks and the further\nprocedures for conﬁguration management are laid down in a se parate document, the\nConﬁguration Management Plan.\nThe history and development of conﬁguration management is c losely tied to\nthe history and development of conﬁguration-management to ols. In the early days,\nthese tools emphasized the logging of physical ﬁle changes. There was little support\nfor process aspects. Present-day conﬁguration-managemen t systems address process\naspects as well (workﬂow management) and many have adopted a change-oriented\nnext to or instead of a version-oriented view of conﬁguratio ns. More and more,\nconﬁguration-management tools function as document-mana gement tools in that\nthey support cooperation among a group of people, possibly d istributed over multiple\nsites, working together on a collection of shared objects.\n4.4. FURTHER READING 89\n4.4 Further Reading\nA readable introduction to the topic of conﬁguration manage ment is given in\n(Babich, 1986). A more recent source is (Jonassen Hass, 2002 ). Estublier et al. (2005)\ngives an excellent overview of the major developments in the ﬁeld. Weber (1996)\nand Wiborg-Weber (1997) describe the change-oriented conﬁ guration management\ntechnology.\nFurther references on technical aspects of conﬁguration ma nagement are given in\na later chapter, when tools for con", "token_count": 512, "start_token": 55902, "end_token": 56414, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 122, "text": "org-Weber (1997) describe the change-oriented conﬁ guration management\ntechnology.\nFurther references on technical aspects of conﬁguration ma nagement are given in\na later chapter, when tools for conﬁguration and version con trol are discussed.\nExercises\n1. What are the main tasks of conﬁguration management?\n2. Describe the role of the Conﬁguration Control Board.\n3. What is a conﬁguration item?\n4. What is a baseline?\n5. Explain the difference between version-oriented and cha nge-oriented conﬁg-\nuration management.\n6. Discuss the main contents of a conﬁguration management pl an.\n7. /DI Discuss differences and similarities between conﬁguratio n management\nduring development and maintenance.\n8. /DI Discuss possible differences between conﬁguration manage ment in a\ntraditional waterfall development model and the evolution ary development\nmodels (see also (Bersoff and Davis, 1991).\n9. /DI Conﬁguration management at the implementation level is oft en supported\nby tools. Can you think of ways in which such tools can also sup port the\ncontrol of other artifacts (design documents, test reports , etc.)?\n10. /DJ Devise a conﬁguration management scheme for a small project (say, less\nthan one person-year) and a large project (say, more than ten person-years).\nGive a rationale for the possible differences between those schemes.\n11. /DJ To what extent could conﬁguration-management tools suppor t the gath-\nering of quantitative project data? To what extent could suc h tools support\nproject control?\n5\nPeople Management and Team\nOrganization\nLEARNING OBJECTIVES\n/AF To be aware of the importance of people issues in software dev elopment\n/AF To know of different ways to organize work\n/AF To know of major types of management styles\n/AF To appreciate different ways to organize a software develop ment team\n91\nFinding the right organizational framework and the right mi x of skills for a\ndevelopment team is a difﬁcult matter. Little well-founded theory is available\nfor this. Yet, many stories of successful and less success", "token_count": 512, "start_token": 56364, "end_token": 56876, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 123, "text": "\n91\nFinding the right organizational framework and the right mi x of skills for a\ndevelopment team is a difﬁcult matter. Little well-founded theory is available\nfor this. Yet, many stories of successful and less successfu l projects discern\nsome of the intricacies of project team issues. This chapter sketches the major\nissues involved.\nPeople are the organization’s most important asset\n(Humphrey, 1997a)\nIn most organizations that develop software, programmers, analysts and other profes-\nsionals work together in a team. An adequate team structure d epends on many factors,\nsuch as the number of people involved, their experience and i nvolvement in the\nproject, the kind of project, individual differences and st yle. These factors also inﬂu-\nence the way projects are to be managed. In this chapter, we di scuss various aspects\nof people management, as well as some of the more common team o rganizations for\nsoftware development projects.\nThe work to be done within the framework of a project, be it a so ftware\ndevelopment project, building a house, or the design of a new car, involves a number\nof tasks. A critical part of management responsibility is to coordinate the tasks of all\nparticipants.\nThis coordination can be carried out in a number of ways. Ther e are both external\nand internal inﬂuences on the coordination mechanism. Inte rnal inﬂuences originate\nfrom characteristics of the project. External inﬂuences or iginate from the project’s\norganizational environment. If these inﬂuences ask for con ﬂicting coordination\nmechanisms, conﬂicts between the project and the environme nt are lurking around\nthe corner.\nConsider as an example a highly innovative software develop ment project, to\nbe carried out within a government agency. The characterist ics of the project may\nask for a ﬂexible, informal type of coordination mechanism, where the commitment\nof specialized individuals, rather than a strict adherence to formal procedures, is a\ncritical success factor. On the other hand, the environment may be geared towards\na bureaucracy with centralized control, which tries to impo se formal procedures\nonto project management. These two mechanisms do not work ha rmoniously. As a\nconsequence", "token_count": 512, "start_token": 56826, "end_token": 57338, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 124, "text": " success factor. On the other hand, the environment may be geared towards\na bureaucracy with centralized control, which tries to impo se formal procedures\nonto project management. These two mechanisms do not work ha rmoniously. As a\nconsequence, management may get crushed between those oppo sing forces.\nSection 5.1 further elaborates the various internal and ext ernal factors that affect\nthe way projects are managed, and emphasizes the need to pay a mple attention to\nthe human element in project management.\nSoftware development involves teamwork. The members of the team have to\ncoordinate their work, communicate their decisions, etc. F or a small project, the team\nwill consist of up to a few individuals. As the size of the proj ect increases, so will\nthe team. Large teams are difﬁcult to manage, though. Coordi nating the work of\na large team is difﬁcult. Communication between team member s tends to increase\nexponentially with the size of the team (see also chapter 7). Therefore, large teams\n92 PEOPLE MANAGEMENT AND TEAM ORGANIZATION\nare usually split into smaller teams in a way that conﬁnes mos t of the coordination\nand communication within the sub-team.\nSection 5.2 discusses several ways to organize a software de velopment team.\nOf these, the hierarchical and matrix organizations can be f ound in other types of\nbusiness too, while the chief programmer, SWAT and agile tea m are rather speciﬁc\nto software development. Though open source projects have n o means to impose\nteam structure, they usually converge to an onion-like orga nization as discussed in\nsection 5.2.6.\nBecause of outsourcing, networked companies and globaliza tion, software devel-\nopment has become a distributed activity. Teams in, say, Ams terdam, Boston and\nBangalore may have to cooperate on the development of the sam e system. How\nshould we split up the tasks between these groups? How to ensu re that communi-\ncation between these groups is effective? Cultural differe nces play a role as well in\nmulti-site development. For instance, people in Asia respe ct authority. In Northern\nAmerica, it is more customary that team members argue with th eir manager. Managers\nas well as team members should be aware of those differences,", "token_count": 512, "start_token": 57288, "end_token": 57800, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 125, "text": "-site development. For instance, people in Asia respe ct authority. In Northern\nAmerica, it is more customary that team members argue with th eir manager. Managers\nas well as team members should be aware of those differences, and act accordingly.\nPeople issues that affect multi-site software development are discussed in chapter ??.\n5.1 People Management\nA team is made up of individuals, each of whom has personal goa ls. It is the task of\nproject management to cast a team out of these individuals, w hereby the individual\ngoals are reconciled into one goal for the project as a whole.\nThough the individual goals of people may differ, it is impor tant to identify\nproject goals at an early stage, and unambiguously communic ate these to the project\nmembers. Project members ought to know what is expected of th em. If there is\nany uncertainty in this respect, team members will determin e their own goals: one\nprogrammer may decide that efﬁciency has highest priority, another may choose\nefﬁcient use of memory, while yet a third will decide that wri ting a lot of code is what\ncounts. Such widely diverging goals may lead to severe probl ems.\nOnce project goals are established and the project is under w ay, performance of\nproject members with respect to the project goals is to be mon itored and assessed.\nThis can be difﬁcult, since much of what is being done is invis ible and progress is\nhard to measure.\nIdeally, we would like to have an indication of the functiona lity delivered\nand deﬁne productivity as the amount of functionality deliv ered per unit of time.\nProductivity is mostly deﬁned as the number of lines of code d elivered per man-\nmonth. Everyone will agree that this measure is not optimal, but nothing better\nhas been found. One of the big dangers of using this measure is that people tend\nto produce as much code as possible. This has a very detriment al effect. The most\nimportant cost driver in software development projects is t he amount of code to be\ndelivered (see also the chapter on cost estimation). Writin g less code is cheaper,\n5.1. PEOPLE MANAGEMENT 93\ntherefore, and reuse of existing code is one way to save time a nd money", "token_count": 512, "start_token": 57750, "end_token": 58262, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 126, "text": " be\ndelivered (see also the chapter on cost estimation). Writin g less code is cheaper,\n5.1. PEOPLE MANAGEMENT 93\ntherefore, and reuse of existing code is one way to save time a nd money. It should\ntherefore be strongly advocated. Using the amount of code de livered per man-month\nas a productivity indicator offers no incentive for softwar e reuse.\nAnother aspect of people assessment occurs in group process es like peer reviews,\ninspections and walkthroughs. These techniques are used du ring veriﬁcation and\nvalidation activities, to discover errors or assess the qua lity of the code or documen-\ntation. In order to make these processes effective it is nece ssary to clearly separate\nthe documents to be assessed from their authors. Weinberg We inberg (1971) used\nthe term egoless programming in this Context. An assessment of the product of\nsomeone’s work should not imply an assessment of that person .\nOne of the major problems in software development is the coor dination of\nactivities of team members. As development projects grow bi gger and become\nmore complex, coordination problems quickly accumulate. T o counteract these\nproblems, management formalizes communication, for examp le by having formal\nproject meetings, strictly monitored inspections, and an o fﬁcial conﬁguration control\nboard. However, informal and interpersonal communication is known to be a primary\nway in which information ﬂows into and through a development organization. It is\nunwise to rule out this type of communication altogether. 1 Informal, interpersonal\ncommunication is most easily accomplished if people are phy sically at close quarters.\nEven worse, people are inclined to trade the ease with which i nformation can be\nobtained against its quality. They will easily accept their neighbor’s advice, even if\nthey know that much better advice can be found on the next ﬂoor . To counteract\nthis tendency, it is wise to bring together diverse stakehol ders in controlled ways, for\nexample by having domain experts in the design team, by havin g users involved in\nthe testing of software, or through participatory design ap proaches. The collocation\nof all stakeholders is a main aspect of agile teams.\nSuccessful software development teams exhibit a mix of qual ities: technical\ncompetence", "token_count": 512, "start_token": 58212, "end_token": 58724, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 127, "text": " in\nthe testing of software, or through participatory design ap proaches. The collocation\nof all stakeholders is a main aspect of agile teams.\nSuccessful software development teams exhibit a mix of qual ities: technical\ncompetence, end-user empathy, and organization awareness . Technical competency\nof course is required to deliver a high-quality system in the ﬁrst place. End-user\nempathy and organizational awareness have to do with recogn ition of the individuals\nand the organization that have to cope with the system. A blen d of these orientations\nin a team helps to ensure sufﬁcient attention is given to each of these aspects (Klein\net al. (2002)).\nTeam management entails a great many aspects, not the least i mportant of which\nconcern the care for the human element. Successes among soft ware development\nprojects can often be traced to a strong focus on cultural and sociological concerns,\nsuch as efforts to create a blame-free culture, or the solici tation of commitment and\npartnership. This chapter touches upon only a few aspects th ereof. (Brooks, 1995)\n1 One shining example hereof is the following anecdote from (W einberg, 1971). The manager of a\nuniversity computing center got complaints about students and programmers chatting and laughing at the\ndepartment’s coffee machine. Being a real manager, and conc erned about productivity, he removed the\ncoffee machine to some remote spot. Quickly thereafter, the load on the computing center consultants\nincreased considerably. The crowd near the coffee machine w as in fact an effective, informal communication\nchannel, through which the majority of problems were solved .\n94 PEOPLE MANAGEMENT AND TEAM ORGANIZATION\nand (DeMarco and Lister, 1999) give many insightful observa tions regarding the\nhuman element of software project management.\nIn the remainder of this section we will conﬁne ourselves to t wo rather general\ntaxonomies for coordination mechanisms and management sty les.\n5.1.1 Coordination Mechanisms\nIn his classic text Structures in Fives: Designing Effective Organizations , Mintzberg dis-\ntinguishes between ﬁve typical organizational conﬁgurati ons. These conﬁgurations\nreﬂect typical, ideal environments. Each of these con", "token_count": 512, "start_token": 58674, "end_token": 59186, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 128, "text": " Effective Organizations , Mintzberg dis-\ntinguishes between ﬁve typical organizational conﬁgurati ons. These conﬁgurations\nreﬂect typical, ideal environments. Each of these conﬁgura tions is associated with a\nspeciﬁc coordination mechanism: a preferred mechanism for coordinating the tasks\nto be carried out within that conﬁguration type. Mintzberg’ s conﬁgurations and\nassociated coordination mechanisms are as follows:\n/AF Simple structure In a simple structure there may be one or a few managers, and\na core of people who do the work. The corresponding coordinat ion mechanism\nis called direct supervision . This conﬁguration is often found in new, relatively\nsmall organizations. There is little specialization, trai ning and formalization.\nCoordination lies with separate people, who are responsibl e for the work of\nothers.\n/AF Machine bureaucracy When the content of the work is completely speciﬁed, it\nbecomes possible to execute and assess tasks on the basis of p recise instructions.\nMass-production and assembly lines are typical examples of this conﬁguration\ntype. There is little training and much specialization and f ormalization. The\ncoordination is achieved through standardization of work processes .\n/AF Divisionalized form In this type of conﬁguration, each division (or project) is\ngranted considerable autonomy as to how the stated goals are to be reached.\nThe operating details are left to the division itself. Coord ination is achieved\nthrough standardization of work outputs . Control is executed by regularly measuring\nthe performance of the division. This coordination mechani sm is possible only\nwhen the end result is speciﬁed precisely.\n/AF Professional bureaucracy If it is not possible to specify either the end result or\nthe work contents, coordination can be achieved through standardization of worker\nskills. In a professional bureaucracy, skilled professionals are given considerable\nfreedom as to how they carry out their job. Hospitals are typi cal examples of\nthis type of conﬁguration.\n/AF Adhocracy In projects that are big or innovative in nature, work is divi ded\namongst many specialists. We may not be able to tell exactly w hat each\nspecialist should do", "token_count": 512, "start_token": 59136, "end_token": 59648, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 129, "text": " conﬁguration.\n/AF Adhocracy In projects that are big or innovative in nature, work is divi ded\namongst many specialists. We may not be able to tell exactly w hat each\nspecialist should do, or how they should carry out the tasks a llocated to them.\nThe project’s success depends on the ability of the group as a whole to reach\na non-speciﬁed goal in a non-speciﬁed way. Coordination is a chieved through\nmutual adjustment .\n5.1. PEOPLE MANAGEMENT 95\nThe coordination mechanisms distinguished by Mintzberg co rrespond to typical\norganizational conﬁgurations, like a hospital, or an assem bly line factory. In his view,\ndifferent organizations call for different coordination m echanisms. Organizations\nare not all alike. Following this line of thought, factors ex ternal to a software\ndevelopment project are likely to exert an inﬂuence on the co ordination mechanisms\nfor that project.\nNote that most real organizations do not ﬁt one single conﬁgu ration type. Different\nparts of one organization may well be organized differently . Also, Mintzberg’s\nconﬁgurations represent abstract ideals. In reality, orga nizations may tend towards\none of these conﬁgurations, but carry aspects of others as we ll.\n5.1.2 Management Styles\nThe development of a software system, the building of a house , and the planning\nof and participation in a family holiday are comparable in th at each concerns a\ncoordinated effort carried out by a group of people. Though t hese projects are likely\nto be dealt with in widely different ways, the basic assumpti ons that underlie their\norganizational structures and management styles have a lot in common.\nThese basic assumptions can be highlighted by distinguishi ng between two\ndimensions in managing people:\n– Relation directedness This concerns attention to an individual and his rela-\ntionship to other individuals within the organization.\n– Task directedness This concerns attention to the results to be achieved and\nthe way in which these results must be achieved.\nBoth relation and task directedness may be high or low. This l eads to four basic\ncombinations, as depicted in ﬁgure 5.", "token_count": 512, "start_token": 59598, "end_token": 60110, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 130, "text": " results to be achieved and\nthe way in which these results must be achieved.\nBoth relation and task directedness may be high or low. This l eads to four basic\ncombinations, as depicted in ﬁgure 5.1. Obviously, these co mbinations correspond to\nextreme orientations. For each dimension, there is a whole s pectrum of possibilities.Figure 5.1 Four basic management styles, cf (Reddin, 1970)\n96 PEOPLE MANAGEMENT AND TEAM ORGANIZATION\nThe style that is most appropriate for a given situation depe nds on the type of\nwork to be done:\n/AF Separation style This management style is usually most effective for routine\nwork. Efﬁciency is the central theme. Management acts like a bureaucrat and\napplies rules and procedures. Work is coordinated hierarch ically. Decision-\nmaking is top-down, formal, and based on authority. A major a dvantage of\nthis style is that it results in a stable project organizatio n. On the other hand,\nreal innovations are difﬁcult to accomplish. This style clo sely corresponds to\nMintzberg’s coordination through standardization of work processes.\n/AF Relation style This style is usually most effective in situations where peo ple\nhave to be motivated, coordinated and trained. The tasks to b e performed are\nbound to individuals. The work is not of a routine character, but innovative,\ncomplex, and specialized. Decision-making is a group proce ss; it involves\nnegotiation and consensus building. An obvious weak spot of this style is that\nit may result in endless chaotic meetings. The manager’s abi lity to moderate\nefﬁcient decision-making is a key success factor. This styl e best ﬁts Mintzberg’s\nmutual adjustment coordination mechanism.\n/AF Commitment style This is most effective if work is done under pressure. For\nthis style to be effective, the manager has to know how to achi eve goals\nwithout arousing resentment. Decision making is not done in meetings. Rather,\ndecisions are implied by the shared vision of the team as to th e goals of the\nproject. A potential weak spot of this style is that, once thi s vision has been\nagreed upon, the team is not responsive to changes in its en", "token_count": 512, "start_token": 60060, "end_token": 60572, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 131, "text": " implied by the shared vision of the team as to th e goals of the\nproject. A potential weak spot of this style is that, once thi s vision has been\nagreed upon, the team is not responsive to changes in its envi ronment, but\nblindly stumbles on along the road mapped out. This style bes t ﬁts Mintzberg’s\nprofessional bureaucracy.\n/AF Integration style This ﬁts situations where the result is uncertain. The work\nis explorative in nature and the various tasks are highly int erdependent. It\nis the manager’s task to stimulate and motivate. Decision-m aking is informal,\nbottom-up. This style promotes creativity, and individual s are challenged to get\nthe best out of themselves. A possible weak spot of this style is that the goals\nof individual team members become disconnected to those of t he project, and\nthat they start to compete with one another. Again, Mintzber g’s coordination\nthrough mutual adjustment ﬁts this situation well.\nEach of the coordination mechanisms and management styles i dentiﬁed may be used\nwithin software development projects. It is only reasonabl e to expect that projects\nwith widely different characteristics ask for different me chanisms. For an experienced\nteam asked to develop a well-speciﬁed application in a famil iar domain, coordination\nmay be achieved through standardization of work processes. For a complex and\ninnovative application, this mechanism is not likely to wor k, though.\nIn chapter 8, we will identify various types of software deve lopment project and\nindicate which type of coordination mechanism and manageme nt style best ﬁts those\n5.2. TEAM ORGANIZATION 97\nprojects. It should be noted that the coordination mechanis ms suggested in chapter 8\nstem from internal factors, i.e. characteristics of the pro ject on hand. As noted before,\nthe project’s environment will also exert inﬂuence on its or ganization.\nNotice that we looked from the manager to the team and its memb ers in the above\ndiscussion. Alternatively, we may look at the relation and t ask maturity of individual\nteam members. Relation maturity concerns the attitude of em ployees towards their\njob and management. Task maturity is concerned with technic al", "token_count": 512, "start_token": 60522, "end_token": 61034, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 132, "text": " in the above\ndiscussion. Alternatively, we may look at the relation and t ask maturity of individual\nteam members. Relation maturity concerns the attitude of em ployees towards their\njob and management. Task maturity is concerned with technic al competence. It\nis important that the manager aligns his dealings with team m embers with their\nrespective relation and task maturity. For example, a fresh graduate may have high\ntask maturity and low relation maturity, and so his introduc tion into a skilled team\nmay warrant some careful guidance.\n5.2 Team Organization\nWithin a team, different roles can be distinguished. There a re managers, testers,\ndesigners, programmers, and so on. Depending on the size of t he project, more than\none role may be carried out by one person, or different people may play the same\nrole. The responsibilities and tasks of each of these roles h ave to be precisely deﬁned\nin the project plan.\nPeople cooperate within a team in order to achieve an optimal result. Yet it is\nadvisable to strictly separate certain roles. It is a good id ea to create a test team\nthat is independent of the development team. Similarly, qua lity assurance should, in\nprinciple, be conducted by people not directly involved in t he development process.\nLarge teams are difﬁcult to manage and are therefore often sp lit up into smaller\nteams. By clearly deﬁning the tasks and responsibilities of the various sub-teams,\ncommunication can be largely conﬁned to communication betw een members of the\nsame sub-team. Quantifying the cost of interpersonal commu nication yields insights\ninto effects of team size on productivity and helps to struct ure large development\nteams effectively. Some simple formulas for doing so are der ived in chapter 7.\nIn the following subsections we discuss several organizati onal forms for software\ndevelopment teams.\n5.2.1 Hierarchical Organization\nIn an environment which is completely dedicated to the produ ction of software,\nwe often encounter hierarchical team structures. Dependin g on the size of the\norganization or project, different levels of management ca n be distinguished.\nFigure 5.2 gives an example of a hierarchical organization. The rectangles denote\nthe various sub-teams in which the actual work is done. Circl ed nodes denote\nmanagers", "token_count": 512, "start_token": 60984, "end_token": 61496, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 133, "text": ", different levels of management ca n be distinguished.\nFigure 5.2 gives an example of a hierarchical organization. The rectangles denote\nthe various sub-teams in which the actual work is done. Circl ed nodes denote\nmanagers. In this example, two levels of management can be di stinguished. At\nthe lower level, different teams are responsible for differ ent parts of the project.\nThe managers at this level have a primary responsibility in c oordinating the work\n98 PEOPLE MANAGEMENT AND TEAM ORGANIZATION\nwithin their respective teams. At the higher level, the work of the different teams is\ncoordinated.\nFigure 5.2 A hierarchical team organization\nThis type of hierarchical organization often reﬂects the gl obal structure of the\nsystem to be developed. If the system has three major subsyst ems, there may be\nthree teams, one for each subsystem, as indicated in ﬁgure 5. 2. As indicated in\nthis ﬁgure, there may also be functional units associated wi th speciﬁc project-wide\nresponsibilities, such as quality assurance and testing.\nIt is not possible to associate the hierarchical organizati on with only one of the\ncoordination mechanisms introduced above. For each unit id entiﬁed, any one of the\ncoordination mechanisms\nmentioned earlier is possible. Also, one need not necessari ly apply the same\nmechanism in each node of the hierarchy. Having different co ordination mechanisms\nwithin one and the same project is not without problems, thou gh.\nBased on an analysis of the characteristics of various subsy stems, the respective\nmanagers may wish to choose a management style and coordinat ion mechanism that\nbest ﬁts those characteristics. If one or more of the subsyst ems is highly innovative\nin nature, their management may opt for a mutual adjustment t ype of coordination.\nThe higher levels within the hierarchy will usually tend tow ards a coordination\nmechanism based on some form of standardization, by imposin g rules and procedures\nas in a machine bureaucracy, or measuring output as in a divis ionalized conﬁguration.\nIn such cases, internal and external powers may well clash at one or more of the\nintermediate levels.\nAnother critical point in any hierarchical organization is the distance between\nthe top and the bottom", "token_count": 512, "start_token": 61446, "end_token": 61958, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 134, "text": "ionalized conﬁguration.\nIn such cases, internal and external powers may well clash at one or more of the\nintermediate levels.\nAnother critical point in any hierarchical organization is the distance between\nthe top and the bottom of the hierarchical pyramid. The ‘real ’ work is generally done\nat the lower levels of this pyramid. The people at these lower levels generally possess\nthe real knowledge of the application. The higher one rises i n the hierarchy, the\nless speciﬁc the knowledge becomes (this is the main reason w hy management at\nthese higher levels tends towards coordination through sta ndardization). Yet, most\n5.2. TEAM ORGANIZATION 99\ndecisions are taken at a fairly high level. In many cases, sig nals from the lower level\nsomehow get subsumed at one of the intermediate levels.\nIf information seeps through the various levels in the hiera rchy, it tends to become\nmore and more rose-colored. The following scenario is not en tirely ﬁctitious:\n– bottom: we have severe troubles in implementing module X;\n– level 1: there are some problems with module X;\n– level 2: progress is steady, I do not foresee any real proble ms;\n– top: everything proceeds according to our plan.\nThese kinds of distortion are difﬁcult to circumvent altoge ther. They are, however,\nreinforced by the fact that the organizational line along wh ich progress is reported\nis also the line along which the performance of team members i s measured and\nevaluated. Everyone is favored by a positive evaluation and is thus inclined to color\nthe reports accordingly. If data on a project’s progress is b eing collected and processed\nby people not directly involved in the assessment of team mem bers, you have a much\nhigher chance that the information collected is of sufﬁcien t reliability.\nAn equally problematic aspect of hierarchical organizatio ns lies in the fact that\none is judged, both socially and ﬁnancially, according to th e level at which one stands\nwithin the organization. It is thus natural to aspire to high er and higher levels within\nthe hierarchy. It is, however, not at all clear that this is de sirable. The Peter Principle\nsays: in a hierarchical organization each employee in gener al rises until reaching", "token_count": 512, "start_token": 61908, "end_token": 62420, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 135, "text": " thus natural to aspire to high er and higher levels within\nthe hierarchy. It is, however, not at all clear that this is de sirable. The Peter Principle\nsays: in a hierarchical organization each employee in gener al rises until reaching a\nlevel at which he is incompetent. A good programmer need not b e a good manager.\nGood programming requires certain skills. To be a good manag er, different skills are\nneeded. In the long run, it seems wiser to maintain people at a level at which they\nperform well, and reward them accordingly.\n5.2.2 Matrix Organization\nIn an environment where software is a mere byproduct, we ofte n encounter some\nsort of matrix organization. People from different departm ents are then allocated to\na software development project, possibly part-time. In thi s type of organization it is\nsometimes difﬁcult to control progress. An employee has to s atisfy several bosses and\nmay have the tendency to play off one boss against another.\nWe may also use a matrix organization in an environment compl etely dedicated\nto software development. The basic unit, then, is a small, sp ecialized group. There\nmay be more than one unit with the same specialization. Possi ble specializations are,\nfor instance, graphics programming, databases, user inter faces, quality control. The\nunits are organized according to their specialty. Projects , on the other hand, may\ninvolve units with different specialties. Individuals are thus organized along two axes,\none representing the various specialist groups and one repr esenting the projects to\nwhich they are assigned. This type of matrix organization is depicted in ﬁgure 5.3.\n100 PEOPLE MANAGEMENT AND TEAM ORGANIZATION\nFigure 5.3 A matrix organization\nIn such a situation, the project manager is responsible for t he successful completion\nof the project. The manager in charge of one or more units with the same specialty has\na longer-term mission, such as maintaining or enlarging the knowledge and expertise\nof the members of his team. Phrased in terms of the basic manag ement dimensions\ndiscussed earlier, the project manager is likely to emphasi ze task directedness, while\nthe unit manager will emphasize relation directedness. Suc h an organization can\nbe very effective, provided there is sufﬁcient mutual trust and the willingness to\ncooperate", "token_count": 512, "start_token": 62370, "end_token": 62882, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 136, "text": " is likely to emphasi ze task directedness, while\nthe unit manager will emphasize relation directedness. Suc h an organization can\nbe very effective, provided there is sufﬁcient mutual trust and the willingness to\ncooperate and pursue the project’s goals.\n5.2.3 Chief Programmer Team\nA team organization known as the chief programmer team was pr oposed by Harlan\nMills around 1970. The kernel of such a team consists of three people. The chief\nprogrammer is team leader. He takes care of the design and imp lements key parts\nof the system. The chief programmer has an assistant who can s tand in for the\nchief programmer, if needed. Thirdly, a librarian takes car e of the administration and\ndocumentation. Besides these three people, an additional ( small) number of experts\nmay be added to the chief programmer team.\nIn this type of organization, fairly high demands are made up on the chief\nprogrammer. The chief programmer has to be very competent in the technical area,\nbut he also has to have sufﬁcient management capabilities. I n other words, are there\nenough chief programmers? Also, questions of competence ma y arise. The chief\nprogrammer plays a very central role. He takes all the decisi ons. The other team\nmembers may well challenge some of his qualities.\nThe early notion of a chief programmer team seems somewhat el itist. It resembles\na surgeon team in its emphasis on highly specialized tasks an d charismatic leadership.\nThe beneﬁts of a team consisting of a small group of peers over huge development\nteams struggling to produce ever larger software systems ma y be regained in a\nmodiﬁed form of the chief programmer team though.\nIn this modiﬁed form, peer group aspects prevail. The develo pment team then\nconsists of a small group of people collectively responsibl e for the task at hand. In\nparticular, jobs are not structured around life cycle stage s. There are no analysts,\n5.2. TEAM ORGANIZATION 101\ndesigners, or programmers, though the role of tester may be a ssigned to a speciﬁc\nperson. Different levels of expertise may occur within the g roup. The most experienced\npersons act as chief programmer and deputy chief programmer , respectively. At the\n", "token_count": 512, "start_token": 62832, "end_token": 63344, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 137, "text": " tester may be a ssigned to a speciﬁc\nperson. Different levels of expertise may occur within the g roup. The most experienced\npersons act as chief programmer and deputy chief programmer , respectively. At the\nother end of the scale, one or two trainees can be assimilated and get the necessary\non-the-job training. A trainee may well act as the team’s lib rarian.\n5.2.4 SWAT Team\nIn projects with an evolutionary or iterative process model such as RAD, a project\norganization known as the SWAT team is sometimes used. SWAT s tands for Skilled\nWith Advanced Tools. We may view the SWAT team as a software de velopment\nversion of a project team in which both task and relation dire ctedness are high.\nA SWAT team is relatively small. It typically has four or ﬁve m embers. Preferably,\nthe team occupies one room. Communication channels are kept very short. The team\ndoes not have lengthy formal meetings with formal minutes. R ather, it uses workshops\nand brainstorming sessions of which little more than a snaps hot of a white-board\ndrawing is retained.\nA SWAT team typically builds incremental versions of a softw are system. In\norder to do so effectively, it employs reusable components, very high-level languages,\nand powerful software generators. The work of team members i s supported and\ncoordinated through groupware or workﬂow management softw are.\nAs in the chief programmer team, the leader of a SWAT team is li ke a foreman\nin the building industry: he is both a manager and a co-worker . The members of a\nSWAT team are generalists. They may have certain specialtie s, but they must also be\nable to do a variety of tasks, such as participate in a worksho p with customers, build\na prototype, and test a piece of software.\nTeam motivation is very important in a SWAT team. A SWAT team o ften adopts\na catchy name, motto or logo. This label then expresses their vision. Individuals\nderive pride and self-esteem from their membership of a SWAT team.\n5.2.5 Agile Team\nAgile approaches to software development grew out of, and ha ve a lot in common\nwith, the various iterative development approaches. In the same vein, an", "token_count": 512, "start_token": 63294, "end_token": 63806, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 138, "text": " their membership of a SWAT team.\n5.2.5 Agile Team\nAgile approaches to software development grew out of, and ha ve a lot in common\nwith, the various iterative development approaches. In the same vein, an agile team\nhas much in common with, e.g., a SWAT team: collocated, short communication\nchannels, a people-oriented attitude rather than a formali stic one. Often, people work\nin pairs, with a pilot and co-pilot, but without a hierarchy.\nBecause agile processes have little discipline enforced on them from the outside,\nthey need discipline to come from within the team. Agile team s need self-discipline.\nIf a pair of programmers develops some code and subsequent te sts fail, they must take\na step back and redo their work. After they have incorporated a piece of work, they\nmust consider the system as a whole and refactor if needed.\n102 PEOPLE MANAGEMENT AND TEAM ORGANIZATION\nFor this to succeed, an agile team needs better people than a t eam that works\naccording to a planning-driven approach. In a planning-dri ven approach, the plan\nworks like a life-jacket that people can fall back upon. In an agile team, no such\nlife-jacket is available, and people must have swimming ski lls. In terms of Cockburn’s\nlevels of understanding (see Figure 5.4), an agile team requ ires level 2 or 3 people,\nand is deemed risky with level 1 people. In planning-driven e nvironments, level 2 or\n3 people are only required during the deﬁnition stages of dev elopment. Thereafter,\nsome level 1 people can be accommodated.\nLevel Description\nFluent -\n3\nPeople at the ﬂuent level move ﬂexibly from one approach to another.\nAs software developers, they are able to revise a method to ﬁt an\nunprecedented new situation\nDetaching\n- 2\nPeople at the detaching level are proﬁcient in\na single approach, and ready to learn alternatives. They are able to\nadapt a method to a precedented new situation\nFollowing\n- 1\nPeople at the following level obey a single approach and get confused\nwhen confronted with something new. They are able to perform\nmethod steps, such as composing a", "token_count": 512, "start_token": 63756, "end_token": 64268, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 139, "text": " able to\nadapt a method to a precedented new situation\nFollowing\n- 1\nPeople at the following level obey a single approach and get confused\nwhen confronted with something new. They are able to perform\nmethod steps, such as composing a pattern or running tests.\nFigure 5.4 Levels of understanding\n5.2.6 Open Source Software Development\nOne of the early books on open source software development is titled The Cathedral\nand the Bazaar (Raymond, 1999). The cathedral refers to traditional, heav yweight,\nhierarchical software development as is common in closed so urce software devel-\nopment. Conversely, open source software development is li ke a bazaar: hordes of\nanarchist developers casually organized in a virtual netwo rked organization. The\nbazaar metaphor was chosen to reﬂect the babbling, chatting , seemingly unorganized\nform of the middle-Eastern marketplace. Though the bazaar m etaphor may ﬁt some\nopen source development groups, many successful open sourc e communities have\nadopted the more organized onion-like structure depicted i n ﬁgure 5.5.\nIn the onion-shaped structure of an open source community, f our layers of\nparticipation are distinguished:\n/AF The Core Team consists of a small team of experienced develop ers that also\nacts as management team. Changes in kernel components of the software can\nonly be made by members of the Core Team.\n5.2. TEAM ORGANIZATION 103\nCore Team\nCo−Developers\nActive Users\nPassive Users\nFigure 5.5 Onion shaped structure of an open source communit y\n/AF The Co-Developers are a larger group of people surrounding t he Core Team.\nCo-Developers review code and do bug ﬁxes.\n/AF The Active Users are users of the most recent release of the sy stem. They\nsubmit bug reports and feature requests, but do not themselv es program the\nsystem.\n/AF Finally, the group of Passive Users is merely using stable re leases of the software.\nThey do not interact with the developers.\nUsually, outer layers contain more people than inner layers . Often, the Core Team\ncounts no more than 5-15 people. For example, Mockus et al. (2 000) reports that the\n15-person Core Team of Apache did over 80% of functionality c", "token_count": 512, "start_token": 64218, "end_token": 64730, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 140, "text": " than inner layers . Often, the Core Team\ncounts no more than 5-15 people. For example, Mockus et al. (2 000) reports that the\n15-person Core Team of Apache did over 80% of functionality c oding.\nThis type of open source project organization is a meritroca cy; i.e., roles of\npeople are based on talent and proven quality. People in one l ayer may move up to\nthe next higher layer. Getting to the core is achieved by a pro cess of earning trust,\nresponsibility and status through competition and demonst rated talent. For example,\nan active user may become co-developer by suggesting qualit y improvements over a\nperiod of time. Likewise, a longstanding record of quality ﬁ xes to the code may earn\nhim or her a position in the core team.\nThe voluntary character of open source development gives ri se to some speciﬁc\nchallenges:\n– Motivation to remain active\n– Disagreement between developers\n104 PEOPLE MANAGEMENT AND TEAM ORGANIZATION\n– Communication between developers\nAn open source community is ”a company without walls” (Fang a nd Neufeld, 2006).\nPeople may freely enter and leave the community. Developers participating in open\nsource projects rarely do so selﬂessly. They expect somethi ng in return, such as the\nability to learn new things, a higher status within their nor mal job, attention because\nthey are part of a successful project, and the like. This shou ld come as no surprise.\nSoftware professionals have high growth needs (Couger and Z awacki, 1980). Open\nsource projects that challenge developer skills, have a wel l-modularized code base,\nand make use of advanced tools have a higher chance of attarct ing a sustainable\ncommunity.\nOne of the worst things that may happen to an open source proje ct is disagreement\nbetween developers. A common obstacle in open source projec ts is disagreement\nabout development speed Godfrey and Tu (2000). Some develop ers may want to\nissue new releases frequently, while others may take a more c autionary stand. Another\npotential source of disagreement is when users start to feel uncomfortable by the\n’undemocratic democracy’ of open source projects. Althoug h many people may submit", "token_count": 512, "start_token": 64680, "end_token": 65192, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 141, "text": " while others may take a more c autionary stand. Another\npotential source of disagreement is when users start to feel uncomfortable by the\n’undemocratic democracy’ of open source projects. Althoug h many people may submit\nbug ﬁxes or feature requests, the power of what actually happ ens usually lies with one\nor a few people in the Core Team. If submissions of a developer get rejected time and\nagain, he may get frustrated and leave the community or decid e to create a fork: the\ndeveloper takes a copy of the source code and starts an indepe ndent development\ntrack.\nCommunication between developers is an issue in every distr ibuted team. But\nin open source projects, the situation is worse because of th e ﬂoating community\nmembership and the lack of formal documentation. A clear mod ularization of the\ncode is an important means to reduce the need for extensive co mmunication. Open\nsource communities further tend to use conﬁguration contro l tools and mailing lists\nfor communication.\n5.2.7 General Principles for Organizing a Team\nNo matter how we try to organize a team, the key point is that it ought to be a team.\nFrom many tests regarding productivity in software develop ment projects, it turns out\nagain and again that factors concerning team capabilities h ave a far greater inﬂuence\nthan anything else. Factors such as morale, group norms and m anagement style play\na more important role than such things as the use of high-leve l languages, product\ncomplexity, and the like (see, for instance, (Lawrence, 198 1)).\nSome general principles for team organization are given in ( Koontz and O’Donnell,\n1972). In particular, these general principles also apply t o the organization of software\ndevelopment projects:\n/AF Use fewer, and better, people Highest productivity is achieved by a relatively\nsmall group of people. This holds for novelists, soccer play ers and bricklayers.\nThere is no reason to believe that it does not equally apply to programmers\n5.3. SUMMARY 105\nand other people working in the software ﬁeld. Also, large gr oups require more\ncommunication, which has a negative effect on productivity and leads to more\nerrors.\n/AF Try to ﬁt tasks", "token_count": 512, "start_token": 65142, "end_token": 65654, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 142, "text": " 105\nand other people working in the software ﬁeld. Also, large gr oups require more\ncommunication, which has a negative effect on productivity and leads to more\nerrors.\n/AF Try to ﬁt tasks to the capabilities and motivation of the peop le available In\nother words: take care that the Peter Principle does not appl y in your situation.\nIn many organizations, excellent programmers can be promot ed only into\nmanagerial positions. It is far better to also offer career p ossibilities in the more\ntechnical areas of software development and maintenance.\n/AF In the long run, an organization is better off if it helps peop le to get the\nmost out of themselves So you should not pursue either of the following:\n– The reverse Peter Principle: people rise within an organiza tion to a level\nat which they become indispensable. For instance, a program mer may\nbecome the only expert in a certain system. If he does not get a chance\nto work on anything else, it is not unlikely that this person, for want of\na more interesting and challenging task, will leave your org anization. At\nthat point, you are in real trouble.\n– The Paul Principle: people rise in an organization to a level at which\ntheir expertise becomes obsolete within ﬁve years. Given th e speed with\nwhich new developments enter the market place in software en gineering,\nand computer science in general, it is very important that pe ople get the\nopportunity to grow and stay abreast of new developments.\n/AF It is wise to select people such that a well-balanced and harm onious team\nresults In general, this means that it is not sufﬁcient only to have a f ew top\nexperts. A soccer team needs regular players as well as stars . Selecting the proper\nmix of people is a complicated task. There are various good te xts available that\nspeciﬁcally address this question (for example, (Weinberg , 1971), (Metzger,\n1987)).\n/AF Someone who does not ﬁt the team should be removed If it turns out that a\nteam does not function as a coherent unit, we are often inclin ed to wait a little\nwhile, see how things develop, and hope for better times to co me. In the long\nrun, this is", "token_count": 512, "start_token": 65604, "end_token": 66116, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 143, "text": " it turns out that a\nteam does not function as a coherent unit, we are often inclin ed to wait a little\nwhile, see how things develop, and hope for better times to co me. In the long\nrun, this is detrimental.\n5.3 Summary\nSoftware is written by humans. Their productivity is partly determined by such\nfactors as the programming language used, machine speed, an d available tools. The\norganizational environment in which one is operating is equ ally important, though.\nGood team management distinguishes itself from bad team man agement above all by\nthe degree to which attention is paid to these human factors. The human element in\n106 PEOPLE MANAGEMENT AND TEAM ORGANIZATION\nsoftware project management was discussed in section 5.1, t ogether with well-known\ntaxonomies of coordination mechanisms and management styl es.\nThere are different ways to organize software developers in a team. These orga-\nnizational forms and some of their caveats were discussed in section 5.2. Hierarchical\nand matrix organizations are not speciﬁc to software develo pment, while the chief\nprogrammer, SWAT and agile teams originated in the software ﬁeld. Each of the\nlatter somehow tries to reconcile the two types of managemen t typically required in\nsoftware development projects: an individualistic, perso nal approach where one tries\nto get the best out of team members, and a hierarchical, top-d own management style\nto get things done in time and within budget. Successful open source projects usually\nhave an onion-shaped organization.\n5.4 Further Reading\nA still very relevant source of information on psychologica l factors related to software\ndevelopment is (Weinberg, 1971). (Brooks, 1995) and (DeMar co and Lister, 1999)\nalso contain a number of valuable observations. Coordinati on problems in software\ndevelopment are discussed in (Kraut and Streeter, 1995). (S oftware, 1996a) and\n(CACM, 1993b) are special journal issues on managing softwa re projects.\n(Mintzberg, 1983) is the classic text on the organization of management. The\nbasic management styles discussed in section 5.1.2 are base d on (Reddin, 1970) and\n(Constantine, 1993).\nThe chief programmer team is described in (B", "token_count": 512, "start_token": 66066, "end_token": 66578, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 144, "text": " classic text on the organization of management. The\nbasic management styles discussed in section 5.1.2 are base d on (Reddin, 1970) and\n(Constantine, 1993).\nThe chief programmer team is described in (Baker, 1972). Its modiﬁed form\nis described in (Macro and Buxton, 1987). SWAT is discussed i n (Martin, 1991).\nAgile teams are described in, amongst others, (Highsmith, 2 004). The three levels\nof understanding are discussed in (Cockburn, 2002). (Softw are, 2005) contains a\nnumber of articles on how to adopt agile methods.\n(SPIP, 2006) contains a collection of articles on open sourc e development\nprocesses. Crowston and Howison (2006) discuss the health o f open source com-\nmunities. Aberdour (2007) discusses ways to achieve qualit y in open source software\ndevelopment.\nExercises\n1. Explain Mintzberg’s classiﬁcation of organizational co nﬁgurations and their\nassociated coordination mechanisms.\n2. Discuss Reddin’s basic management styles.\n3. What are the critical issues in a hierarchical team organi zation?\n4. Highlight the differences between a chief programmer tea m, a SWAT team\nand an agile team.\n5.4. FURTHER READING 107\n5. Which of Reddin’s management styles ﬁts in best with an agi le team?\n6. What is the Peter Principle? Where does it crop up in softwa re development?\n7. Why would an agile team need better people than a team follo wing a\nplanning-based approach?\n8. /DI Consider a software development project you have been invol ved in.\nWhich style of coordination mechanism or management style b est ﬁts this\nproject? Do you consider the management to have been adequat e, or does\nthe discussion in section 5.1 point to possible improvement s?\n9. /DI From a management point of view, discuss possible pros and co ns of having\na technical wizard on your development team.\n10. /DJ Write an essay on the role of people issues in software develo pment. To do\nso, you may consult some of the books that focus on people issu es in software\ndevelopment,", "token_count": 512, "start_token": 66528, "end_token": 67040, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 145, "text": " on your development team.\n10. /DJ Write an essay on the role of people issues in software develo pment. To do\nso, you may consult some of the books that focus on people issu es in software\ndevelopment, such as (Brooks, 1995), (Weinberg, 1971) or (D eMarco and\nLister, 1999).\n11. /DJ Discuss the pros and cons of an organization in which the prim ary depart-\nmentalization is vertical (i.e. by specialty, such as datab ases, human-computer\ninterfaces, or graphics programming) as opposed to one in wh ich the primary\ndepartmentalization is horizontal (for example, design, i mplementation, and\ntesting).\n12. /DI Write an essay on how open source software development proje cts are\nmanaged.\n13. /DI Discuss the pros and cons of letting people rotate between pr ojects from\ndifferent application domains as opposed to letting them be come true experts\nin one particular application domain.\n6\nOn Managing Software Quality\nLEARNING OBJECTIVES\n/AF To appreciate the need for sound measurements in determinin g software quality\n/AF To critically assess various taxonomies of quality attribu tes\n/AF To be able to contrast different views on software quality\n/AF To be aware of international standards pertaining to softwa re quality\n/AF To know about the Capability Maturity Model\n/AF To understand how an organization may set up its own measurem ent program\n109\nSoftware quality is an important topic. With the increasing penetration of\nautomation in everyday life, more and more people are coming into contact\nwith software systems, and the quality of those systems is a m ajor concern.\nQuality cannot be added as an afterthought. It has to be built in from the very\nbeginning. This chapter discusses the many dimensions of qu ality of both the\nsoftware product and the software process.\nIn their landmark book In Search of Excellence , Peters and Waterman identify a\nnumber of key factors that set the very successful companies of the world apart from\nthe less successful ones. One of those key factors is the comm itment to quality of the\nvery successful companies. Apparently, quality pays off.\nLong-term proﬁtability is not the only reason why attention to quality is important\nin software development. Because of the", "token_count": 512, "start_token": 66990, "end_token": 67502, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 146, "text": " factors is the comm itment to quality of the\nvery successful companies. Apparently, quality pays off.\nLong-term proﬁtability is not the only reason why attention to quality is important\nin software development. Because of the sheer complexity of software products and\nthe often frequent changes that have to be incorporated duri ng the development of\nsoftware, continuous attention to, and assessment of, the q uality of the product under\ndevelopment is needed if we ever want to realize satisfactor y products. This need is\naggravated by the increasing penetration of software techn ology into everyday life.\nLow-quality products will leave customers dissatisﬁed, wi ll make users neglect the\nsystems that are supposed to support their work, and may even cost lives.\nOne frightening example of what may happen if software conta ins bugs, has\nbecome known as ‘Malfunction 54’. The Therac-25, a computer ized radiation machine,\nwas blamed in incidents that caused the death of two people an d serious injuries to\nothers. The deadly mystery was eventually traced back to a so ftware bug, named\n‘Malfunction 54’ after the message displayed at the console ; see also section 1.4.2.\nCommitment to quality in software development not only pays off, it is a sheer\nnecessity.\nThis commitment calls for careful development processes. T his attention to the\ndevelopment process is based on the premise that the quality of a product is largely\nbased on the quality of the process that leads to that product , and that this process\ncan indeed be deﬁned, managed, measured, and improved.\nBesides the product--process dichotomy, a conformance--i mprovement dichotomy\ncan be distinguished as well. If we impose certain quality re quirements on the product\nor process, we may devise techniques and procedures to ensur e or test that the\nproduct or process does indeed conform to these objectives. Alternatively, schemes may\nbe aimed at improving the quality of the product or process.\nFigure 6.1 gives examples of these four different approache s to quality. Most\nof software engineering is concerned with improving the qua lity of the products\nwe develop, and the label ‘best practices’ in this ﬁgure refe rs to all of the goodies\nmentioned elsewhere in this book. The other", "token_count": 512, "start_token": 67452, "end_token": 67964, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 147, "text": " engineering is concerned with improving the qua lity of the products\nwe develop, and the label ‘best practices’ in this ﬁgure refe rs to all of the goodies\nmentioned elsewhere in this book. The other three approache s are discussed in this\nchapter.\nBefore we embark on a discussion of the different approaches to quality, we will\nﬁrst elaborate on the notion of software quality itself, and how to measure it. When\n110 ON MANAGING SOFTWARE QUALITY\nFigure 6.1 Different approaches to quality\ntalking about the height of people, the phrase ‘Jasper is 7 ft ’ conveys more information\nthan ‘Jasper is tall’. Likewise, we would like to express all kinds of quality attributes\nin numbers. We would prefer a statement of the form ‘The avail ability of the system\nis 99%’ to a mere ‘The availability of the system is high’. Som e of the caveats of\nthe measurement issues involved are discussed in section 6. 1. In section 6.2, we will\ndiscuss various taxonomies of quality attributes, includi ng ISO 9126. This is by no\nmeans the ﬁnal word on software quality, but it is a good refer ence point to start\nfrom. This discussion also allows us to further illustrate s ome of the problems with\nmeasuring quality in quantitative terms.\n‘Software quality’ is a rather elusive notion. Different pe ople will have different\nperspectives on the quality of a software system. A system te ster may view quality\nas ‘compliance to requirements’, whereas a user may view it a s ‘ﬁtness for use’. Both\nviewpoints are valid, but they need not coincide. As a matter of fact, they probably\nwon’t. Part of the confusion about what the quality of a syste m entails and how it\nshould be assessed, is caused by mixing up these different pe rspectives. Rather than\ndifferentiating between various perspectives on quality, Total Quality Management\n(TQM) advocates an eclectic view: quality is the pursuit of e xcellence in everything.\nSection 6.3 elaborates on the different perspectives on qua lity.\nISO, the International Standards Organization, has establ ished several standards\nthat pertain to the management of quality", "token_count": 512, "start_token": 67914, "end_token": 68426, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 148, "text": " the pursuit of e xcellence in everything.\nSection 6.3 elaborates on the different perspectives on qua lity.\nISO, the International Standards Organization, has establ ished several standards\nthat pertain to the management of quality. The one most appli cable to our ﬁeld,\nthe development and maintenance of software, is ISO 9001. Th is standard will be\ndiscussed in section 6.4.\nISO 9001 can be augmented by more speciﬁc procedures, aimed s peciﬁcally\nat quality assurance and control for software development. The IEEE Standard for\nQuality Assurance Plans is meant to provide such procedures . It is discussed in\nsection 6.5.\nSoftware quality assurance procedures provide the means to review and audit the\nsoftware development process and its products. Quality ass urance by itself does not\nguarantee quality products. Quality assurance merely sees to it that work is done the\n6.1. ON MEASURES AND NUMBERS 111\nway it is supposed to be done.\nThe Capability Maturity Model (CMM) 1 is the best known attempt at directions\non how to improve the development process. It uses a ﬁve-poin t scale to rate\norganizations and indicates key areas of focus in order to pr ogress to a higher\nmaturity level. SPICE and Bootstrap are similar approaches to process improvement.\nCMM is discussed in section 6.6.\nQuality actions within software development organization s are aimed at ﬁnding\nopportunities to improve the development process. These im provements require an\nunderstanding of the development process, which can be obta ined only through\ncarefully collecting and interpreting data that pertain to quality aspects of the process\nand its products. Some hints on how to start such a quality imp rovement program are\ngiven in section 6.8.\n6.1 On Measures and Numbers\nWhen you can measure what you are speaking about, and express it in numbers, you\nknow something about it; but when you cannot measure it, when you cannot express\nit in numbers, your knowledge is of a meagre and unsatisfacto ry kind; it may be the\nbeginning of knowledge, but you have scarcely in your though ts advanced to the stage\nof science.\n[Lord Kelvin, 1900]\nIt is the mark of an instructed mind to", "token_count": 512, "start_token": 68376, "end_token": 68888, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 149, "text": " unsatisfacto ry kind; it may be the\nbeginning of knowledge, but you have scarcely in your though ts advanced to the stage\nof science.\n[Lord Kelvin, 1900]\nIt is the mark of an instructed mind to rest satisﬁed with the d egree of precision which the\nnature of a subject admits, and not to seek exactness when onl y an approximation of the\ntruth is possible.\n[Aristotle, 330 BC]\nSuppose we want to express some quality attribute, say the co mplexity of a program\ntext, in a single numeric value. Larger values are meant to de note more complex\nprograms. If such a mapping\n/BV from programs to numbers can be found, we may\nnext compare the values of /BV /B4 /C8\n/BD\n/B5 and /BV /B4 /C8\n/BE\n/B5 to decide whether program /C8\n/BD\nis more\ncomplex than program /C8\n/BE\n. Since more complex programs will be more difﬁcult to\ncomprehend and maintain, this type of information is very us eful, e.g. for planning\nmaintenance effort.\nWhat then should this mapping be? Consider the program texts in ﬁgure 6.2.\nMost people will concur that text (a) looks less complex than text (b). Is this caused\nby:\n– its length,\n– the number of gotos,\n– the number of if-statements,\n1 Capability Maturity Model and CMM are registered in the U.S. Patent and Trademark Ofﬁce.\n112 ON MANAGING SOFTWARE QUALITY\n1 procedure bubble\n2 ( var a: array [1..n] of integer; n: integer);\n3 var i, j, temp: integer;\n4 begin\n5 for i:= 2 to n do\n6 j:= i;\n(a) 7 while j /BQ 1 and a[j] /BO a[j-1] do\n8 temp:= a[j];\n9 a[j]:= a[j-1];\n10 a[j-1]:= temp;\n11 j:= j-1;\n12 enddo\n13 enddo\n14 end;\n1 procedure", "token_count": 512, "start_token": 68838, "end_token": 69350, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 150, "text": "j];\n9 a[j]:= a[j-1];\n10 a[j-1]:= temp;\n11 j:= j-1;\n12 enddo\n13 enddo\n14 end;\n1 procedure bubble\n2 ( var a: array [1..n] of integer; n: integer);\n3 var i, j, temp: integer;\n4 begin\n5 for i:= 2 to n do\n6 if a[i]\n/AL a[i-1] then goto next endif;\n7 j:= i;\n8 loop: if j\n/AK 1 then goto next endif;\n(b) 9 if a[j] /AL a[j-1] then goto next endif;\n10 temp:= a[j];\n11 a[j]:= a[j-1];\n12 a[j-1]:= temp;\n13 j:= j-1;\n14 goto loop;\n15 next: skip;\n16 enddo\n17 end;\nFigure 6.2 Two versions of a sort routine (a) structured, (b) unstructured\n– a combination of these attributes,\n– something else?\nSuppose we decide that the number of if-statements is what co unts. The result of the\nmapping then is 0 for text (a) and 3 for text (b), and this agree s with our intuition.\nHowever, if we take the sum of the number of if-statements, go tos, and loops, the\n6.1. ON MEASURES AND NUMBERS 113\nresult also agrees with our intuition. Which of these mappin gs is the one sought for?\nIs either of them ‘valid’ to begin with? What does ‘valid’ mea n in this context?\nA number of relevant aspects of measurement, such as attribu tes, units and scale\ntypes can be introduced and related to one another using the m easurement framework\ndepicted in ﬁgure 6.3. This framework also allows us to indic ate how metrics can\nbe used to describe and predict properties of products and pr ocesses, and how to\nvalidate these predictions.\nFigure 6.3 A measurement framework ( Source: B. Kitchenham, S. Lawrence Pﬂeeger & N.\nFenton,", "token_count": 512, "start_token": 69300, "end_token": 69812, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 151, "text": " properties of products and pr ocesses, and how to\nvalidate these predictions.\nFigure 6.3 A measurement framework ( Source: B. Kitchenham, S. Lawrence Pﬂeeger & N.\nFenton, Towards a Framework for Software Measurement Valid ation, IEEE Transactions on\nSoftware Engineering 21, 12 (1995) 1995 IEEE )\nThe model in ﬁgure 6.3 has seven constituents:\n/AF Entity An entity is an object in the ‘real’ world of which we want to kn ow or\npredict certain properties. Entities need not denote mater ial objects; projects\nand software are entities too.\n/AF Attribute Entities have certain properties which we call attributes. Different\nentities may have the same attribute: both people and cars ha ve a weight. And\nof course a single entity can have more than one attribute. Th e forks that adorn\nthe arrow labeled ‘has’\n114 ON MANAGING SOFTWARE QUALITY\nin ﬁgure 6.3 indicate that this relationship is n-to-m.\n/AF Attribute relation Different attributes of one or more entities can be related.\nFor example, the attributes ‘length’ and ‘weight’ of an enti ty ‘snake’ are related.\nSimilarly, the number of man-months spent on a project is rel ated to the cost\nof that project. Also, an attribute of one entity can be relat ed to an attribute of\nanother entity. For example, the experience of a programmer may be related to\nthe cost of a development project he is working on.\n/AF Value The former three constituents of the model reside in the ‘rea l’ world. We\nwant to formally characterize these objects by measuring attributes, i.e. assigning\nvalues to them.\n/AF Unit Obviously, this value is expressed in a certain unit, such as meters, seconds\nor lines of code.\n/AF Scale types This unit in turn belongs to a certain scale type. Some common\nscale types are:\n– Nominal Attributes are merely classiﬁed: the color of my hair is gray ,\nwhite or black.\n– Ordinal There is a (linear) ordering in the possible values of an attr ibute:\none type of material is harder than another, one program is mo re complex\nthan another", "token_count": 512, "start_token": 69762, "end_token": 70274, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 152, "text": " hair is gray ,\nwhite or black.\n– Ordinal There is a (linear) ordering in the possible values of an attr ibute:\none type of material is harder than another, one program is mo re complex\nthan another.\n– Interval The same as ordinal, but the ‘distance’ between successive v alues\nof an attribute is the same, as in a calendar, or the temperatu re measured\nin degrees Fahrenheit.\n– Ratio The same as interval, with the additional requirement that t here\nexists a value 0, as in the age of a software system, or the temp erature\nmeasured in degrees Kelvin.\n– Absolute In this case we simply count the number of occurrences, as in\nthe number of errors detected in a program.\nNote that we can sometimes measure an attribute in different units, where\nthese units lie on different scales. For example, we can meas ure temperature on\nan ordinal scale: it either freezes, or it doesn’t. We can als o measure it on an\ninterval scale: in degrees Fahrenheit or Celsius. Or we can m easure it on a ratio\nscale: in degrees Kelvin.\n/AF Attribute-relation model If there exists a relation between different attributes\nof, possibly different, entities in the ‘real’ world, we may express that relation in\na formal model: the attribute-relation model. This model co mputes (predicts)\nthe value of an attribute in which we are interested from the v alues of one or\nmore other attributes from the model. The fork at the arrow la beled ‘formalizes’\n6.1. ON MEASURES AND NUMBERS 115\nin ﬁgure 6.3 indicates that we can have more than one model for the same\nattribute relation.\nMeasurement is a mapping from the empirical, ‘real’ world to the formal, r elational\nworld. A measure is the number or symbol assigned to an attribute of an entity b y\nthis mapping. The value assigned obviously has a certain uni t, e.g. lines of code. The\nunit in turn belongs to a certain scale, such as the ratio scal e for\nlines of code, or the ordinal scale for the severity of a failu re.\nIn mathematics, the term metric has a very speciﬁc meaning:", "token_count": 512, "start_token": 70224, "end_token": 70736, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 153, "text": " belongs to a certain scale, such as the ratio scal e for\nlines of code, or the ordinal scale for the severity of a failu re.\nIn mathematics, the term metric has a very speciﬁc meaning: it describes how far\napart two points are. In our ﬁeld, the term is often used in a so mewhat sloppy way.\nSometimes it denotes a measure, sometimes the unit of a measu re. We will use the\nterm to denote the combination of:\n– an attribute of an entity,\n– the function which assigns a value to that attribute,\n– the unit in which this value is expressed, and\n– its scale type.\nFor each scale type, certain operations are allowed, while o thers are not. In particular,\nwe can not compute the average for an ordinal scale, but only i ts median (middle\nvalue). Suppose we classify a system as either ‘very complex ’, ‘complex’, ‘average’,\n‘simple’ or ‘very simple’. The assignment of numbers to thes e values is rather arbitrary.\nThe only prerequisite is that a system that is classiﬁed as, s ay, ‘very complex’ is assigned\na larger value than a system classiﬁed as, say, ‘complex’. If we call this mapping\n/CF , the\nonly requirement thus is: /CF (very complex) /BQ /CF (complex) /BQ /BM /BM /BM /BQ /CF (very simple).\nTable 6.1 Example mappings for an ordinal scale\nVery complex Complex Average Simple Very simple\n5 4 3 2 1\n100 10 5 2 1\nTable 6.1 gives an example of two valid assignments of values to this attribute.\nSuppose we have a system with three components, which are cha racterized as ‘very\ncomplex’, ‘average’ and ‘simple’, respectively. By assign ing the values from the ﬁrst\nrow, the average would be 3, so the whole system would be class iﬁed to be of\naverage complexity. Using the values from the second row, th e average would be 35,\nsomething between ‘complex’ and ‘very complex’. The proble m is", "token_count": 512, "start_token": 70686, "end_token": 71198, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 154, "text": " would be class iﬁed to be of\naverage complexity. Using the values from the second row, th e average would be 35,\nsomething between ‘complex’ and ‘very complex’. The proble m is caused by the fact\nthat, with an ordinal scale, we do not know whether successiv e values are equidistant.\nWhen computing an average, we tacitly assume they are.\n116 ON MANAGING SOFTWARE QUALITY\nWe often can not measure the value of an attribute directly. For example, the speed\nof a car can be determined from the values of two other attribu tes: a distance and the\ntime it takes the car to travel that distance. The speed is the n measured indirectly, by\ntaking the quotient of two direct measures. In this case, the attribute-relation model\nformalizes the relation between the distance traveled, tim e, and speed.\nWe may distinguish between internal and external attributes. Internal attributes of\nan entity can be measured purely in terms of that entity itsel f. Modularity, size,\ndefects encountered, and cost are typical examples of inter nal attributes. External\nattributes of an entity are those which can be measured only w ith respect to how\nthat entity relates to its environment. Maintainability an d usability are examples\nof external attributes. Most quality factors we discuss in t his chapter are external\nattributes. External attributes can be measured only indirectly, since they involve the\nmeasurement of other attributes.\nEmpirical relations between objects in the real world shoul d be preserved in the\nnumerical relation system that we use. If we observe that car /BT drives faster than car\n/BU , then we would rather like our function /CB which maps the speed observed to some\nnumber to be such that /CB /B4 /BT /B5 /BQ /CB /B4 /BU /B5 . This is called the representation condition .\nIf a measure satisﬁes the representation condition, it is sa id to be a valid measure .\nThe representation condition can sometimes be checked by a c areful assessment\nof the attribute-relation model. For example, we earlier pr oposed to measure the\ncomplexity of a program text by counting the number of if-sta tements. For this\n(indirect) measure to be valid we have to ascertain that", "token_count": 512, "start_token": 71148, "end_token": 71660, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 155, "text": " attribute-relation model. For example, we earlier pr oposed to measure the\ncomplexity of a program text by counting the number of if-sta tements. For this\n(indirect) measure to be valid we have to ascertain that:\n– any two programs with the same number of if-statements are e qually complex,\nand\n– if program /BT has more if-statements than program /BU , then /BT is more complex\nthan /BU .\nSince neither of these statements is true in the real world, t his complexity measure is\nnot valid.\nThe validity of more complex indirect measures is usually as certained through\nstatistical means. Most of the cost estimation models discu ssed in chapter 7, for\nexample, are validated in this way.\nFinally, the scale type of indirect measures merits some att ention. If different\nmeasures are combined into a new measure, the scale type of th e combined measure\nis the ‘weakest’ of the scale types of its constituents. Many cost estimation formulas\ncontain factors whose scale type is ordinal, such as the inst ability of the requirements\nor the experience of the design team. Strictly speaking, dif ferent values that result from\napplying such a cost estimation formula should then be inter preted as indicating that\ncertain projects require more effort than others. The inten tion though is to interpret\nthem on a ratio scale, i.e. actual effort in man-months. From a measurement-theory\npoint of view, this is not allowed.\n6.2. A TAXONOMY OF QUALITY ATTRIBUTES 117\n6.2 A Taxonomy of Quality Attributes\nSome of the ﬁrst elaborate studies on the notion of ‘software quality’ appeared in the\nlate 1970s (McCall et al., 1977), (Boehm et al., 1978). In the se studies, a number of\naspects of software systems are investigated that somehow r elate to the notion of\nsoftware quality. In the ensuing years, a large number of peo ple have tried to tackle\nthis very same problem. Many taxonomies of quality factors h ave been published. The\nfundamental problems have not been solved satisfactorily, though. The various factors\nthat relate to software quality are hard to deﬁne. It is even h arder to measure them", "token_count": 512, "start_token": 71610, "end_token": 72122, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 156, "text": " quality factors h ave been published. The\nfundamental problems have not been solved satisfactorily, though. The various factors\nthat relate to software quality are hard to deﬁne. It is even h arder to measure them\nquantitatively. On the other hand, real quality can often be identiﬁed surprisingly\neasily.\nIn the IEEE Glossary of Software Engineering Terminology , quality is deﬁned as ‘the\ndegree to which a system, component, or process meets custom er or user needs or\nexpectations’. Applied to software, then, quality should b e measured primarily against\nthe degree to which user requirements are met: correctness, reliability, usability,\nand the like. Software lasts a long time and is adapted from ti me to time in order\nto accommodate changed circumstances. It is important to th e user that this is\npossible within reasonable costs. The customer is therefor e also interested in quality\nfactors which relate to the structure of the system rather th an its use: maintainability,\ntestability, portability, etc.\nWe will start our discussion of quality attributes with McCa ll’s taxonomy. McCall\ndistinguishes between two levels of quality attributes. Hi gher-level quality attributes,\nknown as quality factors , are external attributes and can, therefore, be measured on ly\nindirectly. McCall introduced a second level of quality att ributes, termed quality\ncriteria. Quality criteria can be measured either subjectively or ob jectively. By\ncombining the ratings for the individual quality criteria t hat affect a given quality\nfactor, we obtain a measure for the extent to which that quali ty factor is being\nsatisﬁed. Users and managers tend to be interested in the hig her-level, external\nquality attributes.\nFor example, we can not directly measure the reliability of a software system. We\nmay however directly measure the number of defects encounte red so far. This direct\nmeasure can be used to obtain insight into the reliability of the system. This involves\na theory of how the number of defects encountered relates to r eliability, which can be\nascertained on good grounds. For most other aspects of quali ty though, the relation\nbetween the attributes that can be measured directly and the external attributes we\nare interested in is less obvious, to say the least.\nTable", "token_count": 512, "start_token": 72072, "end_token": 72584, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 157, "text": " be\nascertained on good grounds. For most other aspects of quali ty though, the relation\nbetween the attributes that can be measured directly and the external attributes we\nare interested in is less obvious, to say the least.\nTable 6.2 lists the quality factors and their deﬁnitions, as they are used by McCall\net al. 2 These quality factors can be broadly categorized into three classes. The ﬁrst\nclass contains those factors that pertain to the use of the so ftware after it has become\n2 This is a rather narrow deﬁnition of software reliability. A more complete deﬁnition is contained in the\nIEEE Glossary of Software Engineering Terminology: ‘The ab ility of a system or component to perform\nits required functions under stated conditions for a speciﬁ ed period of time.’ It is often expressed as a\nprobability.\n118 ON MANAGING SOFTWARE QUALITY\nTable 6.2 Quality factors ( Source: J.A. McCall, P.K. Richards & G.F. Walters , Factors\nin Software Quality, RADC-TR-77-369, US Department of Commerce, 1977. )\nCorrectness: The extent to which a program satisﬁes its speciﬁcations an d\nfulﬁlls the user’s mission objectives.\nReliability: The extent to which a program can be expected to perform its\nintended function with required precision.\nEfﬁciency : The amount of computing resources and code required by a pro gram\nto perform a function.\nIntegrity: The extent to which access to software or data by unauthoriz ed\npersons can be controlled.\nUsability: The effort required to learn, operate, prepare input, and i nterpret\noutput of a program.\nMaintainability: The effort required to locate and ﬁx an error in an operation al\nprogram.\nTestability: The effort required to test a program to ensure that it perfo rms its\nintended function.\nFlexibility: The effort required to modify an operational program.\nPortability: The effort required to transfer a program from one hardware and/or\nsoftware environment to another.\nReusability: The extent to which a program (or parts thereof) can be reuse d", "token_count": 512, "start_token": 72534, "end_token": 73046, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 158, "text": " required to modify an operational program.\nPortability: The effort required to transfer a program from one hardware and/or\nsoftware environment to another.\nReusability: The extent to which a program (or parts thereof) can be reuse d in\nother applications.\nInteroperability: The effort required to couple one system with another.\noperational. The second class pertains to the maintainabil ity of the system. The\nthird class contains factors that reﬂect the ease with which a transition to a new\nenvironment can be made. These three categories are depicte d in table 6.3.\nIn ISO standard 9126, a similar effort has been made to deﬁne a set of quality\ncharacteristics and sub-characteristics (see table 6.4). Their deﬁnitions are given in\ntables 6.5 and 6.6. Whereas the quality factors and criteria as deﬁned by McCall and\nothers are heavily interrelated, the\nISO scheme is hierarchical: each sub-characteristic is rel ated to exactly one\ncharacteristic.\nThe ISO quality characteristics strictly refer to a softwar e product. Their deﬁnitions\ndo not capture process quality issues. For example, security can partly be handled by\nprovisions in the software and partly by proper procedures. Only the former is\ncovered by the sub-characteristic ‘security’ of the ISO sch eme. Furthermore, the\nsub-characteristics concern quality aspects that are visible to the user. Reusability, for\nexample, is not included in the ISO scheme.\n6.2. A TAXONOMY OF QUALITY ATTRIBUTES 119\nTable 6.3 Three categories of software quality factors ( Source: J.A. McCall,\nP.K. Richards & G.F. Walters , Factors in Software Quality, RADC-TR-77-369,\nUS Department of Commerce, 1977. )\nProduct operation :\nCorrectness Does it do what I want?\nReliability Does it do it accurately all of the time?\nEfﬁciency Will it run on my hardware as well as it can?\nIntegrity Is it secure?\nUsability Can I run it?\nProduct revision :\nMaintainability Can I ﬁx it?\nTestability Can I test it?\nFlexibility", "token_count": 512, "start_token": 72996, "end_token": 73508, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 159, "text": " hardware as well as it can?\nIntegrity Is it secure?\nUsability Can I run it?\nProduct revision :\nMaintainability Can I ﬁx it?\nTestability Can I test it?\nFlexibility Can I change it?\nProduct transition :\nPortability Will I be able to use it on another machine?\nReusability Will I be able to reuse some of the software?\nInteroperability Will I be able to interface it with another system?\nThe ISO characteristics and subcharacteristics, together with an extensive set of\nmeasures, make up ISO˘s external and internal quality model . Internal quality refers to the\nproduct itself, ultimately the source code. External quali ty refers to the quality when\nthe software is executed. For example, the average number of statements in a method\nis a measure of internal quality, while the number of defects encountered during\ntesting is a measure of external quality.\nUltimately, the user is interested in the quality in use , deﬁned in (ISO9126, 2001) as\n”the user’s view of the quality of the software product when i t is executed in a speciﬁc\nenvironment and a speciﬁc context of use.” It measures the ex tent to which users can\nachieve their goals, rather than mere properties of the soft ware (see also section 6.3).\nQuality in use is modeled in four characteristics: effectiv eness, productivity, safety,\nand satisfaction. The deﬁnitions for these quality in use ch aracteristics are given in\ntable 6.7.\nTheoretically, internal quality, external quality and qua lity in use are linked\ntogether: internal quality indicates external quality, wh ich in turn indicates quality in\nuse. In general, meeting criteria at one level is not sufﬁcie nt for meeting criteria at\nthe next level. For instance, satisfaction is partly determ ined by internal and external\nquality measures, but also includes the user’s attitude tow ards the product. The latter\nhas to be measured separately. Note that internal quality an d external quality can be\nmeasured directly. Quality in use can in general only be meas ured indirectly.\n120 ON MANAGING SOFTWARE QUALITY\nTable 6.4 Quality characteristics and sub-characteristic s\nof the", "token_count": 512, "start_token": 73458, "end_token": 73970, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 160, "text": " an d external quality can be\nmeasured directly. Quality in use can in general only be meas ured indirectly.\n120 ON MANAGING SOFTWARE QUALITY\nTable 6.4 Quality characteristics and sub-characteristic s\nof the external and internal quality model of ISO 9126\nCharacteristic Subcharacteristics\nFunctionality Suitability\nAccuracy\nInteroperability\nSecurity\nFunctionality compliance\nReliability Maturity\nFault tolerance\nRecoverability\nReliability compliance\nUsability Understandability\nLearnability\nOperability\nAttractiveness\nUsability compliance\nEfﬁciency Time behavior\nResource utilization\nEfﬁciency compliance\nMaintainability Analyzability\nChangeability\nStability\nTestability\nMaintainability compliance\nPortability Adaptability\nInstallability\nCo-existence\nReplaceability\nPortability compliance\n6.2. A TAXONOMY OF QUALITY ATTRIBUTES 121\nTable 6.5 Quality characteristics of the external and inter nal quality model of\nISO 9126 ( Source: ISO Standard 9126: Software Quality Characteristics and Metrics.\nReproduced by permission of ISO. )\nFunctionality: The capability of the software product to provide function s\nwhich meet stated and implied needs when the software is used under speciﬁed\nconditions.\nReliability: The capability of the software product to maintain a speciﬁ ed level\nof performance when used under speciﬁed conditions.\nUsability: The capability of the software product to be understood, le arned,\nused and be attractive to the user, when used under speciﬁed c onditions.\nEfﬁciency : The capability of the software product to provide appropri ate\nperformance, relative to the amount of resources used, unde r stated conditions.\nMaintainability: The capability of the software product to be modiﬁed. Modi-\nﬁcations may include corrections, improvements or adaptat ion of the software\nto changes in environment, and in requirements and function al speciﬁcations.\nPortability: The capability of the software product to be transferred fr om one\nenvironment to another.\n122 ON MANAGING SOFTWARE QUALITY\ncontinued on next page\nTable 6.6 Quality sub-characteristics of the external and i nternal quality", "token_count": 512, "start_token": 73920, "end_token": 74432, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 161, "text": " capability of the software product to be transferred fr om one\nenvironment to another.\n122 ON MANAGING SOFTWARE QUALITY\ncontinued on next page\nTable 6.6 Quality sub-characteristics of the external and i nternal quality model\nof ISO 9126 ( Source: ISO Standard 9126: Software Quality Characteristics and Metrics.\nReproduced by permission of ISO. )\nSuitability: The capability of the software product to provide an approp riate\nset of functions for speciﬁed tasks and user objectives.\nAccuracy: The capability of the software product to provide the right or agreed\nresults or effects with the needed degree of precision.\nInteroperability: The capability of the software product to interact with one or\nmore speciﬁed systems.\nSecurity: The capability of the software product to protect informat ion and\ndata so that unauthorised persons or systems cannot read or m odify them and\nauthorised persons or systems are not denied access to them.\nFunctionality compliance : The capability of the software product to adhere to\nstandards, conventions or regulations in laws and similar p rescriptions relating\nto functionality.\nMaturity: The capability of the software product to avoid failure as a result of\nfaults in the software.\nFault tolerance : The capability of the software product to maintain a speciﬁ ed\nlevel of performance in cases of software faults or of infrin gement of its speciﬁed\ninterface.\nRecoverability: The capability of the software product to re-establish a sp eciﬁed\nlevel of performance and recover the data directly affected in the case of a\nfailure. Reliability compliance : The capability of the software product to adhere\nto standards, conventions or regulations relating to relia bility.\nUnderstandability: The capability of the software product to enable the user\nto understand whether the software is suitable, and how it ca n be used for\nparticular tasks and conditions of use.\nLearnability: The capability of the software product to enable the user to learn\nits application.\nOperability: The capability of the software product to enable the user to\noperate and control it.\nAttractiveness: The capability of the software product to be attractive to t he\nuser.\nUsability compliance : The capability of the software product to adhere to\nstandards, conventions, style guides or", "token_count": 512, "start_token": 74382, "end_token": 74894, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 162, "text": "\noperate and control it.\nAttractiveness: The capability of the software product to be attractive to t he\nuser.\nUsability compliance : The capability of the software product to adhere to\nstandards, conventions, style guides or regulations relat ing to usability\n6.2. A TAXONOMY OF QUALITY ATTRIBUTES 123\nTime behavior : The capability of the software product to provide appropri ate\nresponse and processing times and throughput rates when per forming its\nfunction, under stated conditions.\nResource utilization : The capability of the software product to use appropriate\namounts and types of resources when the software performs it s function under\nstated conditions.\nEfﬁciency compliance : The capability of the software product to adhere to\nstandards or conventions relating to efﬁciency.\nAnalysability: The capability of the software product to be diagnosed for\ndeﬁciencies or causes of failures in the software, or for the parts to be modiﬁed\nto be identiﬁed.\nChangeability: The capability of the software product to enable a speciﬁed\nmodiﬁcation to be implemented.\nStability: The capability of the software product to avoid unexpected effects\nfrom modiﬁcations of the software.\nTestability: The capability of the software product to enable modiﬁed so ftware\nto be validated.\nMaintainability compliance : The capability of the software product to adhere\nto standards or conventions relating to maintainability.\nAdaptability: The capability of the software product to be adapted for dif ferent\nspeciﬁed environments without applying actions or means ot her than those\nprovided for this purpose for the software considered.\nInstallability: The capability of the software product to be installed in a s peciﬁed\nenvironment.\nCo-existence: The capability of the software product to co-exist with oth er\nindependent software in a common environment sharing commo n resources.\nReplaceability: The capability of the software product to be used in place\nof another speciﬁed software product for the same purpose in the same\nenvironment.\nPortability compliance : The capability of the software product to adhere to\nstandards or conventions relating to portability.\nQuality factors are not independent. Some factors will impa ct one", "token_count": 512, "start_token": 74844, "end_token": 75356, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 163, "text": " product for the same purpose in the same\nenvironment.\nPortability compliance : The capability of the software product to adhere to\nstandards or conventions relating to portability.\nQuality factors are not independent. Some factors will impa ct one another in a\npositive sense, while others will do so negatively. An examp le from the ﬁrst category\nis reliability versus correctness. Efﬁciency, on the other hand, will in general have\na negative impact on most other quality factors. This means t hat we will have to\nmake trade-offs between quality factors. If high requireme nts are decided upon for\none factor, we may have to relax others. These tradeoffs are t o be resolved at an\nearly stage. An important objective of the software archite cture phase is to bring\nthese quality factors to the forefront and make the tradeoff s explicit, so that the\nstakeholders know what they are in for (see chapter 11). By do ing so, we are better\nable to build in the desired qualities, as opposed to merely a ssess them after the fact.\n124 ON MANAGING SOFTWARE QUALITY\nTable 6.7 Quality characteristics of the quality in use mode l of ISO 9126 ( Source:\nISO Standard 9126: Software Quality Characteristics and Metrics. Reproduced by permission\nof ISO. )\nEffectiveness: The capability of the software product to enable users to ac hieve\nspeciﬁed goals with accuracy and completeness in a speciﬁed context of use.\nProductivity: The capability of the software product to enable users to ex pend\nappropriate amounts of resources in relation to the effecti veness achieved in a\nspeciﬁed context of use.\nSafety: The capability of the software product to achieve acceptab le levels of\nrisk of harm to people, business, software, property or the e nvironment in a\nspeciﬁed context of use.\nSatisfaction: The capability of the software product to satisfy users in a speciﬁed\ncontext of use.\n6.3 Perspectives on Quality\nWhat I (and everybody else) mean by the word quality cannot be broken down into\nsubjects and predicates [. . . ] If quality exists in an object , then you must explain why\nscientiﬁc instruments are unable to detect it", "token_count": 512, "start_token": 75306, "end_token": 75818, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 164, "text": "and everybody else) mean by the word quality cannot be broken down into\nsubjects and predicates [. . . ] If quality exists in an object , then you must explain why\nscientiﬁc instruments are unable to detect it [. . . ] On the ot her hand, if quality is\nsubjective, existing only [in the eye of] the observer, then this Quality is just a fancy\nname for whatever you’d like [. . . ] Quality is not objective. It doesn’t reside in the\nmaterial world [. . . ] Quality is not subjective. It doesn’t r eside merely in the mind.\n[Robert Pirsig, Zen and the Art of Motorcycle Maintenance , 1974]\nUsers will judge the quality of a software system by the degre e to which it helps them\naccomplish tasks and by the sheer joy they have in using it. Th e manager of those\nusers is likely to judge the quality of the same system by its b eneﬁts. These beneﬁts\ncan be expressed in cost savings or in a better and faster serv ice to clients.\nDuring testing, the prevailing quality dimensions will be t he number of defects\nfound and removed, or the reliability measured, or the confo rmance to speciﬁcations.\nTo the maintenance programmer, quality will be related to th e system’s complexity,\nits technical documentation, and the like.\nThese different viewpoints are all valid. They are also difﬁ cult to reconcile. Garvin\ndistinguishes ﬁve deﬁnitions of software quality:\n/AF Transcendent deﬁnition\n/AF User-based deﬁnition\n/AF Product-based deﬁnition\n/AF Manufacturing-based deﬁnition\n6.3. PERSPECTIVES ON QUALITY 125\n/AF Value-based deﬁnition.\nTranscendent quality concerns innate excellence. It is the type of quality assessment\nwe usually apply to novels. We may consider Zen and the Art of Motorcycle Maintenance\nan excellent book, we may try to give words to our admiration b ut these words are\nusually inadequate. The practiced reader gradually develo ps a good feeling for this\ntype of quality. Likewise, the software engineering expert may have developed a", "token_count": 512, "start_token": 75768, "end_token": 76280, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 165, "text": "an excellent book, we may try to give words to our admiration b ut these words are\nusually inadequate. The practiced reader gradually develo ps a good feeling for this\ntype of quality. Likewise, the software engineering expert may have developed a good\nfeeling for the transcendent qualities of software systems .\nThe user-based deﬁnition of quality concerns ‘ﬁtness for us e’ and relates to the\ndegree in which a system addresses the user’s needs. It is a su bjective notion. Since\ndifferent users may have different needs, they may assess a s ystem’s quality rather\ndifferently. The incidental user of a simple word-processi ng package may be quite\nhappy with its functionality and possibilities while a comp uter scientist may be rather\ndisappointed. The reverse situation may befall a complex sy stem like LATEX.\nIn the product-based deﬁnition, quality relates to attribu tes of the software.\nDifferences in quality are caused by differences in the valu es of those attributes. Most\nof the research into software quality concerns this type of q uality. It also underlies\nthe various taxonomies of quality attributes discussed abo ve.\nThe manufacturing-based deﬁnition concerns conformance t o speciﬁcations. It\nis the type of quality deﬁnition used during system testing, whereas the user-based\ndeﬁnition is prevalent during acceptance testing.\nFinally, the value-based deﬁnition deals with costs and pro ﬁts. It concerns\nbalancing time and cost on the one hand, and proﬁt on the other hand. We may\ndistinguish various kinds of beneﬁt, not all of which can be p hrased easily in monetary\nterms:\n/AF Increased efﬁciency Beneﬁts are attributed to cost avoidance or reduction, and\ntheir measures are economic.\n/AF Increased effectiveness This is primarily reﬂected through better information\nfor decision making. It can be measured in economic terms or t hrough key\nperformance indicators, such as a reduced time to market.\n/AF Added value Beneﬁts enhance the strategic position of the organization ,\ne.g. through an increased market share. The contribution of", "token_count": 512, "start_token": 76230, "end_token": 76742, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 166, "text": " terms or t hrough key\nperformance indicators, such as a reduced time to market.\n/AF Added value Beneﬁts enhance the strategic position of the organization ,\ne.g. through an increased market share. The contribution of the information\ntechnology component often can not be isolated.\n/AF Marketable product The system itself may be marketable, or a marketable\nproduct may be identiﬁed as a by-product of system developme nt.\n/AF Corporate IT infrastructure Communication networks, database environments\nand the like provide little beneﬁt by themselves, but serve a s a foundation for\nother systems.\nSoftware developers tend to concentrate on the product-bas ed and manufacturing-\nbased deﬁnitions of quality. The resulting quality require ments can be expressed in\n126 ON MANAGING SOFTWARE QUALITY\nquantiﬁable terms, such as the number of defects found per ma n-month, or the number\nof decisions per module. The quality attributes discussed i n the previous section fall\ninto these categories. Such quality requirements however c an not be directly mapped\nonto the, rather subjective, quality viewpoints of the user s, such as ‘ﬁtness for use’.\nNevertheless, users and software developers will have to co me to an agreement on\nthe quality requirements to be met.\nOne way to try to bridge this gap is to deﬁne a common language b etween\nusers and software developers in which quality requirement s can be expressed. This\napproach is taken in (Bass et al., 2003), where quality requi rements are expressed in\nso-called quality-attribute scenarios. Figure 6.4 gives o ne example of how a quality\nattribute can be expressed in user terms. Quality attribute scenarios have a role\nnot only in specifying requirements, but also in testing whe ther these requirements\nare (going to be) met. For example, quality attribute scenar ios are heavily used in\narchitecture assessments (see also chapter 11).\nQuality attribute: Usability\nSource: End user\nStimulus: Learn system features\nArtifact: System\nEnvironment: At runtime\nResponse: Learn tasks supplied by the system for new employees\nResponse measure: days on the job\nTest: 90% successful completion of assigned tasks in employee tes t for the\nsystem, within twice the average time of an experienced user", "token_count": 512, "start_token": 76692, "end_token": 77204, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 167, "text": " runtime\nResponse: Learn tasks supplied by the system for new employees\nResponse measure: days on the job\nTest: 90% successful completion of assigned tasks in employee tes t for the\nsystem, within twice the average time of an experienced user\nWorst: 1 to 7 days\nPlan: less than 1 day (to passing of test)\nBest: less than 2 hours\nFigure 6.4 A quality attribute scenario that can be used by bo th users and developers\nQuality is not only deﬁned at the level of the whole system. In component-based\ndevelopment, quality is deﬁned at the level of a component. F or services, quality is\ndeﬁned at the level of an individual service. The environmen t of the component or\nservice, i.e. some other component or service, will require certain qualities as well.\nSo for components and services, there is a requires and a prov ides aspect to quality.\nSince a component or service generally does not know the cont ext in which it is\ngoing to be embedded, it is difﬁcult to decide on the ‘right’ q uality level. One might\n6.3. PERSPECTIVES ON QUALITY 127\nthen choose to offer different levels of quality. For exampl e, a service handling video\nstreaming may be fast with low image quality, or slow with hig h image quality. The\nuser of that service then selects the appropriate quality of service (QoS) level.\nDevelopers tend to have a mechanistic, product-oriented vi ew on quality, whereby\nquality is associated with features of the product. In this v iew, quality is deﬁned by\nlooking from the program to the user (user friendliness, acc eptability, etc.). To assess\nthe quality of systems used in organizations, we have to adop t a process-oriented\nview on quality as well, where quality is deﬁned by looking fr om the user to the\nprogram. This leads to notions like ‘adequacy’ and ‘relevan ce’. For example, a helpdesk\nstaffed with skilled people may contribute considerably to the quality of a system\nas perceived by its users, but this quality attribute genera lly does not follow from a\nproduct-based view on quality.\nA very eclectic view on quality is", "token_count": 512, "start_token": 77154, "end_token": 77666, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 168, "text": "staffed with skilled people may contribute considerably to the quality of a system\nas perceived by its users, but this quality attribute genera lly does not follow from a\nproduct-based view on quality.\nA very eclectic view on quality is taken in Total Quality Mana gement (TQM). In\nTQM, quality applies to each and every aspect of the organiza tion, and it is pursued\nby each and every employee of that organization. TQM has thre e cornerstones:\n1. Customer value strategy Quality is a combination of beneﬁts derived from\na product and sacriﬁces required of the customer. The right b alance between\nthese beneﬁts and sacriﬁces has to be sought. The key stakeho lder in this\nbalancing act is the customer, rather than the customer’s bo ss. The attitude is\nnot ‘We know what is best for the customer’, but ‘Let’s ﬁrst de termine what the\ncustomer needs’.\n2. Organizational systems Systems encompass more than software and hardware.\nOther materials, humans, work practices, belong to the syst em as well. More-\nover, systems cross unit or department boundaries. In the TQ M-view, systems\neliminate complexity rather than people. In TQM, culture is not dominated by\npower struggles. Rather, the organization takes advantage of the employees’\npride in craftsmanship. Human resources are regarded as a cr itical resource\nrather than a mere cost factor.\n3. Continuous improvement A ‘traditional’ environment is reactive: improvement\nis triggered in case of a problem or the development of a new pr oduct. In\nTQM, quality is pursued proactively. Errors are not viewed a s personal failures\nwhich require punishment, but as opportunities for learnin g. Performance is\nnot evaluated in retrospect as either good or bad, but variat ion in performance\nis analyzed statistically to understand causes of poor perf ormance. Authority is\nnot imposed by position and rules, but is earned by communica ting a vision.\nTQM thus stresses improvement rather than conformance. CMM (see section 6.6)\nbuilds on TQM, and many of the requirements engineering tech niques discussed in\nchapter 9 owe a tribute to T", "token_count": 512, "start_token": 77616, "end_token": 78128, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 169, "text": " vision.\nTQM thus stresses improvement rather than conformance. CMM (see section 6.6)\nbuilds on TQM, and many of the requirements engineering tech niques discussed in\nchapter 9 owe a tribute to TQM as well.\n128 ON MANAGING SOFTWARE QUALITY\n6.4 The Quality System\nISO, the International Organization for Standardization, has developed ISO 9000, a\nseries of standards for quality management systems. The ser ies consists of three parts:\nISO 9000:2000, ISO 9001:2000, and ISO 9004:2000. ISO 9000 gi ves fundamentals\nand vocabulary of the series of standards on quality systems . ISO 9001 integrates\nthree earlier standards (labeled ISO 9001, ISO 9002 and ISO 9 003). It speciﬁes\nrequirements for a quality system for any organization that needs to demonstrate\nits ability to deliver products that satisfy customer requi rements. ISO 9004 contains\nguidelines for performance improvement. It is applicable a fter implementation of ISO\n9001.\nISO 9001 is a generic standard. It can be applied to any produc t. A useful\ncomplement for software is ISO/IEC 90003:2004, containing guidelines for the\napplication of ISO 9001 to computer software. It is a joint st andard of ISO and\nIEC, the International Electrotechnical Committee. The sc ope of ISO/IEC 90003\nis described as ”This International Standard speciﬁes requ irements for a quality\nmanagement system where an organization\n/AF needs to demonstrate its ability to consistently provide a p roduct that meets\ncustomer and applicable regulatory requirements, and\n/AF aims to enhance customer satisfaction through the effectiv e application of the\nsystem, including processes for continual improvement of t he system and the\nassurance of conformity to customer and applicable regulat ory requirements.”\nThe standard is very comprehensive. It uses ﬁve perspective s from which the\nmanagement of quality in software engineering is addressed :\n/AF the systemic perspective, dealing with the establishment a nd documentation of\nthe quality system itself. The quality system consists of a n umber of processes,\nsuch as those for software development, operation, and main tenance. These\nprocesses, and the quality system itself, have to be documen ted properly.\n/AF the management perspective", "token_count": 512, "start_token": 78078, "end_token": 78590, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 170, "text": " system consists of a n umber of processes,\nsuch as those for software development, operation, and main tenance. These\nprocesses, and the quality system itself, have to be documen ted properly.\n/AF the management perspective, dealing with the deﬁnition and management of\nthe policies to support quality. The quality management sys tem itself has to be\ndeveloped, implemented, and regularly reviewed. This pers pective describes\nhow this is done.\n/AF the resource perspective, dealing with the resources neede d to implement and\nimprove the quality management system, as well as to meet cus tomer and\nregulatory requirements. The resources include both perso nnel, infrastructure,\nand work environment.\n/AF the product perspective, dealing with the processes to actu ally create quality\nproducts, such as those pertaining to requirements enginee ring, design, testing,\nproduction and servicing. This perspective makes up over 60 % of the standard.\n6.5. SOFTWARE QUALITY ASSURANCE 129\n/AF the improvement perspective, dealing with monitoring, mea suring and analysis\nactivities to maintain and improve quality.\nMany organizations try, or have already tried, to obtain ISO 9000 registration. The\ntime and cost this takes depends on how much the current proce ss deviates from the\nISO standards. If the current quality system is not already c lose to conforming, then\nISO registration may take at least one year. ISO registratio n is granted when a third-\nparty accredited body assesses the quality system and concl udes that it does conform\nto the ISO standard. Reregistration is required every three years and surveillance\naudits are required every six months. ISO registration thus is a fairly drastic and costly\naffair, after which you certainly cannot lean back, but have to keep the organization\nalert.\nSince software development projects have some rather pecul iar characteristics\n(frequent changes in requirements during the development p rocess, the rather invisible\nnature of the product during its development), there is a nee d for quality assurance\nprocedures which are tailored towards software developmen t. This is the topic of the\nnext section.\n6.5 Software Quality Assurance\nThe purpose of Software Quality Assurance (SQA) is to make su re that work gets done\nthe way it is supposed to be done. More speciﬁcally, the", "token_count": 512, "start_token": 78540, "end_token": 79052, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 171, "text": "\n6.5 Software Quality Assurance\nThe purpose of Software Quality Assurance (SQA) is to make su re that work gets done\nthe way it is supposed to be done. More speciﬁcally, the goals of SQA (Humphrey,\n1989) are:\n/AF to improve software quality by appropriately monitoring th e software and its\ndevelopment process;\n/AF to ensure full compliance with the established standards an d procedures for the\nsoftware and the development process;\n/AF to ensure that any inadequacies in the product, the process, or the standards\nare brought to management’s attention so these inadequacie s can be ﬁxed.\nNote that the SQA people themselves are not responsible for p roducing quality\nproducts. Their job is to review and audit, and to provide the project and management\nwith the results of these reviews and audits.\nThere are potential conﬂicts of interest between the SQA org anization and the\ndevelopment organization. The development organization m ay be facing deadlines\nand may want to ship a product, while the SQA people have revea led serious\nquality problems and wish to defer shipment. In such cases, t he opinion of the SQA\norganization should prevail. For SQA to be effective, certa in prerequisites must be\nfulﬁlled:\n/AF It is essential that top management commitment is secured, s o that suggestions\nmade by the SQA organization can be enforced. If this is not th e case, SQA\n130 ON MANAGING SOFTWARE QUALITY\nsoon becomes a costly padding and a mere nuisance to the devel opment\norganization;\n/AF The SQA organization should be independent from the develop ment organi-\nzation. Its reporting line should also be independent;\n/AF The SQA organization should be staffed with technically com petent and\njudicious people. They need to cooperate with the developme nt organization.\nIf the two organizations operate as adversaries, SQA won’t b e effective. We\nmust realize that, in the long run, the aims of the SQA organiz ation and\nthe development organization are the same: the production o f high-quality\nproducts.\nThe review and audit activities and the standards and proced ures that must be\nfollowed are described in the Software Quality Assurance Pl an.\nI", "token_count": 512, "start_token": 79002, "end_token": 79514, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 172, "text": "\nthe development organization are the same: the production o f high-quality\nproducts.\nThe review and audit activities and the standards and proced ures that must be\nfollowed are described in the Software Quality Assurance Pl an.\nIEEE standard 730 offers a framework for the contents of a Qua lity Assurance\nPlan for software development (IEEE730, 1989). Figure 6.5 l ists the entries of such a\ndocument. Appendix ?? contains a fuller description of its various constituents. IEEE\nstandard 730 applies to the development and maintenance of c ritical software. For\nnon-critical software, a subset of the requirements may be u sed.\nIEEE standard 983 (IEEE983, 1986) is a useful complement to s tandard 730. IEEE\nStandard 983 offers further guidelines as to the contents of a quality assurance plan,\nthe implementation of a quality assurance plan, and its eval uation and modiﬁcation.\n1. Purpose\n2. Reference documents\n3. Management\n4. Documentation\n5. Standards, practices, conventions, and metrics\n6. Reviews and audits\n7. Test\n8. Problem reporting and corrective action\n9. Tools, techniques, and methodologies\n10. Code control\n11. Media control\n12. Supplier control\n13. Records collection, maintenance, and retention\n14. Training\n15. Risk management\nFigure 6.5 Main ingredients of IEEE Std 730\n6.6. THE CAPABILITY MATURITY MODEL (CMM) 131\nThe Software Quality Assurance Plan describes how the quali ty of the software\nis to be assessed. Some quality factors can be determined obj ectively. Most factors at\npresent can be determined only subjectively. Most often the n, we will try to assess the\nquality by reading documents, by inspections, by walkthrou ghs and by peer reviews.\nIn a number of cases, we may proﬁtably employ tools during qua lity assurance, in\nparticular, for static and dynamic analysis of program code . The actual techniques to\nbe applied here will be discussed in the chapter on testing.\n6.6 The Capability Maturity Model (CMM)\nConsider the following course of events in a hypothetical so ftware development\nproject. Some organization is to develop a distributed libr ary automation system.\nA centralized computer hosts both the", "token_count": 512, "start_token": 79464, "end_token": 79976, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 173, "text": ".6 The Capability Maturity Model (CMM)\nConsider the following course of events in a hypothetical so ftware development\nproject. Some organization is to develop a distributed libr ary automation system.\nA centralized computer hosts both the software and the datab ase. A number of\nlocal libraries are connected to the central machine throug h a web-based interface.\nThe organization has some experience with library automati on, albeit only with\nstand-alone systems.\nIn the course of the project, a number of problems manifest th emselves. At ﬁrst\nthey seem to be disconnected and they do not alarm management . It turns out that\nthe requirements analysis has not been all that thorough. Lo cal requirements turn out\nto differ on some minor points. Though the ﬁrst such deviatio ns can be handled quite\neasily, keeping track of all change requests becomes a real p roblem after a while.\nWhen part of the system has been realized, the team starts to t est the web-interface.\nThe interface turns out to be too complex and time-consuming .\nThe project gets into a crisis eventually. Management has no proper means to\nhandle the situation. It tries to cut back on both functional ity and quality in a\nsomewhat haphazard way. In the end, a rather unsatisfactory system is delivered two\nmonths late. During the subsequent maintenance phase, a num ber of problems are\nsolved, but the system never becomes a real success.\nThough the above description is hypothetical, it is not all t hat unrealistic. Many\nan organization has insufﬁcient control over its software d evelopment process. If a\nproject gets into trouble, it is usually discovered quite la te and the organization has\nno other means but to react in a somewhat chaotic way. More oft en than not, speed\nis confused with progress.\nAn important step in trying to address these problems is to re alize that the\nsoftware development process can indeed be controlled, mea sured, and improved.\nIn order to gauge the process of improving the software devel opment process,\nWatts Humphrey developed a software maturity framework whi ch has evolved into\nthe Capability Maturity Model (CMM). This framework owes tribute to Total Quality\nManagement (TQM), which in turn is based on principles of sta tistical quality control\nas formulated by", "token_count": 512, "start_token": 79926, "end_token": 80438, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 174, "text": " framework whi ch has evolved into\nthe Capability Maturity Model (CMM). This framework owes tribute to Total Quality\nManagement (TQM), which in turn is based on principles of sta tistical quality control\nas formulated by Walter Shewart in the 1930s and further deve loped by W. Edwards\nDeming and Joseph Juran in the 1980s. Originally, there were separate CMM models\nfor software engineering, systems engineering, and severa l others. These have now\n132 ON MANAGING SOFTWARE QUALITY\nbeen integrated, and carry the label CMMI 3. The version described here is CMMI\nversion 1.1 for software engineering and systems engineeri ng (CMMI Product Team,\n2002). CMM and CMMI were developed at the Software Engineeri ng Institute (SEI)\nof Carnegie Mellon University.\nIn CMM (and CMMI), the software process is characterized int o one of ﬁve\nmaturity levels , evolutionary levels toward achieving a mature software pr ocess. To\nachieve a certain maturity level, a number of process areas must be in place. These\nprocess areas indicate important issues that have to be addr essed in order to reach\nthat level. Taken together, the process areas of a level achi eve the set of goals for that\nlevel. Figure 6.6 lists the maturity levels and associated p rocess areas of CMMI.\nCMMI’s maturity levels can be characterized as follows:\n/AF Initial At the initial process level, the organization operates wit hout formalized\nprocedures, project plans, or cost estimates. Tools are not adequately integrated.\nMany problems are overlooked or forgotten, and maintenance poses real\nproblems. Software development at this level can be charact erized as being\nad-hoc. Performance can be improved by instituting basic pr oject management\ncontrols:\n– Requirements management involves establishing and maintaining an\nagreement with the customer on the requirements of the syste m. Since\nrequirements inevitably change, controlling and document ing these\nrequirements is important.\n– Project planning involves making plans for executing and managing the\nproject. To be able to do any planning, an approved statement of work to\nbe done is required. From this statement of work, estimates f or the size of\nthe project, resources needed, and schedule are determined , and risks to\nthe project are identiﬁed.", "token_count": 512, "start_token": 80388, "end_token": 80900, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 175, "text": " an approved statement of work to\nbe done is required. From this statement of work, estimates f or the size of\nthe project, resources needed, and schedule are determined , and risks to\nthe project are identiﬁed. The results are documented in the project plan.\nThis plan is used to manage the project; it is updated when nec essary.\n– Project monitoring and control is concerned with the visibility of actual\nprogress. Intermediate results have to be reviewed and trac ked with\nrespect to the project plan. When necessary, the project pla n has to be\nrealigned with reality.\n– Supplier agreement management . Where applicable, work done by\nsuppliers has to be managed: plans for their part of the work h ave to be\nmade, and progress of their part of the job has to be monitored .\n– Measurement and analysis is concerned with making sure measurements\nare made and their results used. First, objectives for measu rement and the\nway measures should be collected, stored and analyzed are es tablished.\nNext, the collection, storage, and analysis of data must be i mplemented.\nFinally, the results are used for decision making, and corre ctive actions\nare taken where needed.\n3 CMMI is a service mark of Carnegie Mellon University.\n6.6. THE CAPABILITY MATURITY MODEL (CMM) 133\nLevel 5: Optimizing level\nOrganizational innovation and deployment\nCausal analysis and resolution\nLevel 4: Quantitatively managed level\nOrganizational process performance\nQuantitative project management\nLevel 3: Defined level\nRequirements development\nTechnical solution\nProduct integration\nVerification\nOrganization process definition\nLevel 1: Initial level\nDecision analysis and resolution\nRisk management\nIntegrated project management\nOrganizational training\nValidation\nOrganization process focus\nMeasurement and analysis\nLevel 2: Repeatable level\nRequirements management\nProject planning\nProject monitoring and control\nSupplier agreement management\nProcess and product quality assurance\nConfiguration management\nFigure 6.6 Maturity levels and associated process areas of C MMI\n– Process and product quality assurance involves reviewing and auditing\nproducts and processes to validate that they comply with agr eed upon\nstandards and procedures.\n134 ON MANAGING SOFTWARE QUALITY\n– Conﬁguration management is concerned with establishing and maintain-\ning the integrity of all work", "token_count": 512, "start_token": 80850, "end_token": 81362, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 176, "text": " to validate that they comply with agr eed upon\nstandards and procedures.\n134 ON MANAGING SOFTWARE QUALITY\n– Conﬁguration management is concerned with establishing and maintain-\ning the integrity of all work items during the entire project life cycle.\nThis involves identiﬁcation of conﬁguration items and base lines, and\nprocedures to control changes to them.\n/AF Repeatable The main difference between the initial process level and th e\nrepeatable process level is that the repeatable level provi des control over the\nway plans and commitments are established. Through prior ex perience in doing\nsimilar work, the organization has achieved control over co sts, schedules, and\nchange requests, and earlier successes can be repeated. The introduction of\nnew tools, the development of a new type of product, and major organizational\nchanges however still represent major risks at this level. T he process areas\nneeded to advance to the next level are aimed at standardizin g the software\nprocess across the projects of the organization:\n– Requirements development involves the production and analysis of\nrequirements. Requirements have to be elicited, analyzed, validated, and\ncommunicated to appropriate stakeholders. Requirements d evelopment\nis not a one-shot activity. Rather, requirements are identi ﬁed and reﬁned\nthroughout the whole life cycle.\n– Technical solution is about design and implementation. Decisions con-\ncerning the architecture, custom development as opposed to an off the\nshelf solution, and modularization issues are typical ingr edienst of this\nprocess area.\n– Product integration concerns the assembling of a complete product out\nof its components. This can be one stage after all components have been\ndeveloped, or it can proceed incrementally. An important el ement of\nproduct integration is the management of interfaces, to mak e sure that\nthe components properly ﬁt together.\n– Veriﬁcation is concerned with ensuring that the product meets its requir e-\nments. Peer reviews are an effective means for early defect d etection and\nremoval. Peer reviews, such as walkthroughs and inspection s, are practices\nin which peers try to identify errors and areas where changes are needed.\n– Validation is concerned with establishing that the product fulﬁlls its\nintended use. As far as possible, validation", "token_count": 512, "start_token": 81312, "end_token": 81824, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 177, "text": " and inspection s, are practices\nin which peers try to identify errors and areas where changes are needed.\n– Validation is concerned with establishing that the product fulﬁlls its\nintended use. As far as possible, validation activities sho uld be done in\nthe intended environment in which the product is going to be u sed.\n– Organization process focus is concerned with organization process\nimprovement. Measurements, lessons learned, project post mortems, prod-\nuct evaluation reports are typical sources of information t o guide\nimprovement activities. The responsibility for guiding an d implementing\nthese activities is typically assigned to a process group. I n this way,\n6.6. THE CAPABILITY MATURITY MODEL (CMM) 135\nimprovement of the organization’s process capabilities is made a respon-\nsibility of the organization as a whole, rather than the indi vidual project\nmanager.\n– Organization process deﬁnition . The organization develops and main-\ntains a set of software process assets, such as process eleme nts, life cycle\nmodels, guidelines for tailoring a process model. Each proj ect uses a\nprocess built out of these process assets.\n– Organizational training . The purpose of the training program is to\ndevelop the necessary skills and knowledge of individuals t o perform\ntheir roles. Training needs are identiﬁed at the level of the organization,\nproject and individual. The fulﬁllment of these needs is add ressed as well.\n– Integrated project management involves developing a project-speciﬁc\nsoftware process from the organization’s set of standard pr ocesses, as well\nas the actual management of the project using the tailored pr ocess. Since\nthe software processes of different projects have a common a ncestor,\nprojects may now share data and lessons learned.\n– Risk management concerns the identiﬁcation of potential problems, so\nthat timely actions can be taken to mitigate adverse effects .\n– Decision analysis and resolution is concerned with establishing guide-\nlines as to which issues should be subjected to formal evalua tion processes,\nand the application of those formal processes. The selectio n of COTS\ncomponents and architectural reviews are example arease wh ere formal\nevaluation processes might be applied.\n/AF Deﬁned At the deﬁ", "token_count": 512, "start_token": 81774, "end_token": 82286, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 178, "text": " the application of those formal processes. The selectio n of COTS\ncomponents and architectural reviews are example arease wh ere formal\nevaluation processes might be applied.\n/AF Deﬁned At the deﬁned process level, a set of standard processes for t he\ndevelopment and maintenance of software is in place. The org anization has\nachieved a solid foundation, and may now start to examine the ir processes and\ndecide how to improve them. Major steps to advance to the next level are:\n– Organizational process performance , whose purpose is to establish and\nmaintain a quantitative understanding of the performance o f the set\nof standard processes. Individual projects are measured, a nd compared\nagainst expected results as documented in a baseline. The in formation is\nnot only used to assess a project, but also to quantitatively manage it.\n– Quantitative project management , which involves the setting of per-\nformance goals, measuring process performance, analyzing these mea-\nsurements, and making the appropriate adjustments to the pr ocess in\norder to bring it in line with the deﬁned limits. There is, the refore, an\norganization-wide measurement program and the results of i t are used\nto continuously improve the process. An example process mea sure is the\nnumber of lines of code reviewed per hour.\n136 ON MANAGING SOFTWARE QUALITY\n/AF Quantitatively managed At the quantitatively managed process level, quan-\ntitative data is gathered and analyzed on a routine basis. Ev erything is under\ncontrol, and attention may therefore shift from being react ive -- what happens\nto the present project? -- to being proactive -- what can we do to improve\nfuture projects? The focus shifts to opportunities for cont inuous improvement:\n– Organizational innovation and deployment is concerned with the iden-\ntiﬁcation and deployment of improvements. Technical impro vements\nrelate to new technologies and their orderly transition int o the organi-\nzation. Process improvements relate to the process in order to improve\nthe quality of the products, the productivity of the softwar e development\norganization, and reduction of the time needed to develop pr oducts.\n– Causal analysis and resolution is concerned with identifying common\ncauses of defects, and preventing them from recurring.\n/AF Optimizing At the ﬁnal, optimizing", "token_count": 512, "start_token": 82236, "end_token": 82748, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 179, "text": " reduction of the time needed to develop pr oducts.\n– Causal analysis and resolution is concerned with identifying common\ncauses of defects, and preventing them from recurring.\n/AF Optimizing At the ﬁnal, optimizing, level, a stable base has been reache d from\nwhich further improvements can be made. The step to the optim izing process\nlevel is a paradigm shift. Whereas attention at the other lev els is focused on\nways to improve the product, emphasis at the optimizing leve l has shifted from\nthe product to the process. The data gathered can now be used t o improve the\nsoftware development process itself.\nIn 1989, Humphrey investigated the state of software engine ering practice with\nrespect to the CMM (Humphrey et al., 1989). Although this stu dy concerned the\nDoD software community, there is little reason to expect tha t the situation was\nmuch rosier in another environment. According to his ﬁnding s, software engineering\npractice at that time was largely at the initial level. There were a few organizations\noperating at the repeatable level, and a few projects operat ing at the deﬁned level.\nNo organization or project operated at the managed or optimi zing levels.\nIn the ensuing years, a lot has happened. Many organizations have initiated a\nsoftware process improvement program (SPI) to achieve a hig her maturity level. Most\nof these improvement programs concern a move to the repeatab le or deﬁned level.\nThe number of organizations at these levels has signiﬁcantl y increased since 1989.\nThere are still few organizations or projects at the managed or optimizing level.\nReports from practical experience show that it takes about t wo years to move up\na level. The cost ranges from $500 to $2000 per employee per ye ar. The beneﬁts,\nhowever, seem to easily outweigh the cost. Several companie s have reported a return\non investment of at least 5 to 1: every dollar invested in a pro cess improvement\nprogram resulted in cost savings of at least $5.\nTo address the needs of small companies and small project tea ms, the Soft-\nware Engineering Institute developed the Personal Softwar e Process (PSP), a\nself-improvement process designed to help individuals to i mprove the way they\nwork. Like the CMM,", "token_count": 512, "start_token": 82698, "end_token": 83210, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 180, "text": " small project tea ms, the Soft-\nware Engineering Institute developed the Personal Softwar e Process (PSP), a\nself-improvement process designed to help individuals to i mprove the way they\nwork. Like the CMM, the PSP distinguishes between several ma turity levels. The ﬁrst\nstep in PSP is to establish some basic measurements, such as d evelopment time and\n6.7. SOME CRITICAL NOTES 137\ndefects found, using simple forms to collect these data. At t he next level, these data\nare used to estimate time and quality. At still higher levels , the personal data are used\nto improve the individual’s performance.\nThe basic principles of the CMM and the PSP are thus very simil ar: know thy\nprocess, measure thy performance, and base thy improvement actions on an analysis\nof the data gathered.\nBOOTSTRAP and SPICE are two other CMM-like maturity models. BOOT-\nSTRAP uses a separate maturity rating for each of its practic es. One of the interesting\nfeatures of BOOTSTRAP is that all assessment results are col lected in a database,\nthus allowing an organization to position itself by compari ng its scores with those of\nsimilar organizations.\nSPICE is an international initiative and has become an inter national standard\n(ISO/IEC 15504). SPICE stands for Software Process Improve ment and Capability\ndEtermination. SPICE distinguishes different process cat egories, such as the manage-\nment process, customer--supplier process and engineering process. The capability\n(maturity) level is determined for each process category an d each process. Like\nBOOTSTRAP, SPICE thus results in a maturity proﬁle. The SPIC E methodology\nplaces heavy emphasis on the way process assessments are per formed.\n6.7 Some Critical Notes\nSoftware development organizations exist to develop softw are rather than processes.\n(Fayad, 1997)\nThe massive attention of organizations to obtaining CMM or I SO 9000 certiﬁcation\nholds the danger that focus shifts from developing software to developing processes.\nA certiﬁed organization, however, does not guarantee the qu ality of the software\ndeveloped under it. A mature development process is not a sil ver bullet. A framed\ncertiﬁcate deﬁnitely", "token_count": 512, "start_token": 83160, "end_token": 83672, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 181, "text": "ﬁed organization, however, does not guarantee the qu ality of the software\ndeveloped under it. A mature development process is not a sil ver bullet. A framed\ncertiﬁcate deﬁnitely is not.\nThe SEI’s Capability Maturity Model seems most appropriate for the really big\ncompanies. It is doubtful whether small companies can affor d the time and money\nrequired by a process improvement program as advocated by CM M. It is also\ndoubtful whether they can afford to implement some of the pro cess areas, such\nas the ‘organization process focus’ process area, which req uires the setting up an\norganization process group. Though the Personal Software P rocess may alleviate part\nof this criticism, the PSP does not have the same status as the CMM.\nCMM is focused on discipline: structured work processes, st rict plans, standard-\nization. This ﬁts bigger companies better than small ones. I t also better ﬁts activities\nthat lend themselves to a strict approach, such as conﬁgurat ion management and\ntesting. Requirements analysis and design ask for a certain amount of creativity, and\na pure CMM approach may have a stiﬂing effect here. The dichot omy noted in\nchapter 1 between factory-like and craft-like aspects of so ftware engineering surfaces\nhere as well.\n138 ON MANAGING SOFTWARE QUALITY\nCMM’s original maturity levels constitute a rather crude ﬁv e-point scale. If the\nassessment of a level 2 organization reveals that it fails th e level 3 criteria on just one\ntiny issue, the verdict is rather harsh: the organization si mply remains at level 2. This\nmay not improve morale after two years of hard labor and signi ﬁcant investment.\nFor one thing, this implication of maturity assessments pla ces high demands on their\nreliability.\nThe rather crude assessment of organizations on a ﬁve-point scale may have\nother far-reaching consequences. The US government requir es level 3 certiﬁcation\nto qualify for contracts. Will this imply that level 1 and lev el 2 organizations are\nnecessarily performing below standard? If level 3 certiﬁca tion is all that matters, is it\nworthwhile to aim for", "token_count": 512, "start_token": 83622, "end_token": 84134, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 182, "text": "�cation\nto qualify for contracts. Will this imply that level 1 and lev el 2 organizations are\nnecessarily performing below standard? If level 3 certiﬁca tion is all that matters, is it\nworthwhile to aim for level 4 or 5?\nCMM’s original levels are like an instrument panel of an airp lane with one gauge,\nwhich moreover can display only a few discrete values and thu s provides the pilot\nwith very little information. One may also envisage a softwa re maturity ‘instrument\npanel’ with many gauges, each of which shows a lot of detail. B OOTSTRAP and\nSPICE are frameworks that result in a maturity proﬁle rather than a single score. The\nsame holds for CMMI, which comes in two variants: a staged model which, like the\noriginal CMM, just has ﬁve levels of maturity, and a continuous model in which\nprocess improvement is done on a per process area basis.\n6.8 Getting Started\nIn the preceding sections we discussed various ways to revie w the quality of a software\nproduct and the associated development process. The develo pment organization itself\nshould actively pursue the production of quality products, by setting quality goals,\nassessing its own performance and taking actions to improve the development process.\nThis requires an understanding of possible inadequacies in the development\nprocess and possible causes thereof. Such an understanding is to be obtained through\nthe collection of data on both the process and the resulting p roducts, and a proper\ninterpretation of those numbers. It is rather easy to collec t massive amounts of data\nand apply various kinds of curve-ﬁtting techniques to them. In order to be able to\nproperly interpret the trends observed, they should be back ed by sound hypotheses.\nAn, admittedly ridiculous, example is given in ﬁgure 6.7. Th e numbers in this\ntable indicate that black cows produce more milk than white c ows. A rather naive\ninterpretation is that productivity can be improved signiﬁ cantly by repainting all the\nwhite cows.\nThough the example itself is ridiculous, its counterpart in software engineering\nis not all that far-fetched. Many studies, for example, have tried to determine a\nrelation between numbers indicating the complexity of soft ware components and\nthe quality of those components. Quite a", "token_count": 512, "start_token": 84084, "end_token": 84596, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 183, "text": " itself is ridiculous, its counterpart in software engineering\nis not all that far-fetched. Many studies, for example, have tried to determine a\nrelation between numbers indicating the complexity of soft ware components and\nthe quality of those components. Quite a few of those studies found a positive\ncorrelation between such complexity ﬁgures and, say, the nu mber of defects found\nduring testing. A straightforward interpretation of those ﬁndings then is to impose\n6.8. GETTING STARTED 139\nColor Average production\nWhite 10\nBlack 40\nFigure 6.7 Hypothetical relation between the color of cows a nd the average milk\nproduction\nsome upperbound on the complexity allowed for each componen t. However, there\nmay be good reasons for certain components having a high comp lexity. For instance,\n(Redmond and Ah-Chuen, 1990) studied complexity metrics of a large number of\nmodules from the MINIX operating system. Some of these, such as a module that\nhandles escape character sequences from the keyboard, were considered justiﬁably\ncomplex. Experts judged a further decomposition of these mo dules not justiﬁed.\nPutting a mere upperbound on the allowed value of certain com plexity metrics is too\nsimple an approach.\nAn organization has to discover its opportunities for proce ss improvements. The\npreferred way to do so is to follow a stepwise, evolutionary a pproach in which the\nfollowing steps can be identiﬁed:\n1. Formulate hypotheses\n2. Carefully select appropriate metrics\n3. Collect data\n4. Interpret those data\n5. Initiate actions for improvement\nThese steps are repeated, so that the effect of the actions is validated, and further\nhypotheses are formulated. By following this approach, the quest for quality will\npermeate your organization, which will subsequently reap t he beneﬁts.\nOne example of this approach is discussed in (van Genuchten, 1991). He describes\nan empirical study of reasons for delay in software developm ent. The study covered six\ndevelopment projects from one department. Attention was fo cused on the collection\nof data relating to time and effort, viz. differences betwee n plan and reality. A\none-page data collection form was used for this purpose (see ﬁgure 6.8).\nSome", "token_count": 512, "start_token": 84546, "end_token": 85058, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 184, "text": "used on the collection\nof data relating to time and effort, viz. differences betwee n plan and reality. A\none-page data collection form was used for this purpose (see ﬁgure 6.8).\nSome thirty reasons for delay were identiﬁed. These were cla ssiﬁed into six\ncategories after a discussion with the project leaders, and ﬁnalized after a pilot study.\nThe reasons for delay were found to be speciﬁc to the environm ent.\nA total of 160 activities were studied from mid 1988 to mid 198 9. About 50%\nof the activities overran their plan by more than 10%. Compar ison of planned\n140 ON MANAGING SOFTWARE QUALITY\nPlanned Actual Difference Reason\nEffort --- --- --- ---\nStarting date --- --- --- ---\nEnding date --- --- --- ---\nDuration --- --- --- ---\nFigure 6.8 Time sheet for each activity\nand actual ﬁgures showed that the relative differences incr eased towards the end\nof the projects. It was found that one prime reason for the dif ference between\nplan and reality was ‘more time spent on other work than plann ed’. The results\nwere interpreted during a meeting with the project leaders a nd the department\nmanager. The discussion conﬁrmed and quantiﬁed some existi ng impressions. For\nsome, the discussion provided new information. It showed th at maintenance actions\nconstantly interrupted development work. The meeting incl uded a discussion on\npossible actions for improvement. It was decided to schedul e maintenance as far as\npossible in ‘maintenance weeks’ and include those in quarte rly plans. Another analysis\nstudy was started to gain further insights into maintenance activities.\nThis study provides a number of useful insights, some of whic h reinforce\nstatements made earlier:\n/AF The ‘closed loop’ principle states that information system s should be designed\nsuch that those who provide input to the system are also main u sers of its\noutput. Application of this principle results in feedback t o the supplier of data,\nwho is thereby forced to provide accurate input. It also prev ents users from\nasking more than they need. In the above example, the data was both collected\nand analyzed by the project leaders. The", "token_count": 512, "start_token": 85008, "end_token": 85520, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 185, "text": " t o the supplier of data,\nwho is thereby forced to provide accurate input. It also prev ents users from\nasking more than they need. In the above example, the data was both collected\nand analyzed by the project leaders. The outcome was reporte d back to those\nsame project leaders and used as a starting point for further actions.\n/AF Local data collection should be for local use. Data collecte d may vary consider-\nably between departments. Data is best used to gain insight i n the performance\nof the department where the data is collected. Use in another department\nmakes little sense.\n/AF The focus should be on continuous improvement. The data coll ection effort\nwas aimed at locating perceived deﬁciencies in the software development\nprocess. It revealed causes for these deﬁciencies and provi ded an opportunity\nfor improvement. The question is not one of ‘who is right and w ho is wrong’,\nbut rather ‘how can we prevent this from happening again in fu ture projects’.\n/AF The study did not involve massive data collection. Simple da ta sheets were\nused, together with unambiguous deﬁnitions of the meaning o f the various\n6.9. SUMMARY 141\nmetrics. The approach is incremental, whereby the study giv es an opportunity\nfor small improvements, and shows the way for the next study.\n6.9 Summary\nIn this chapter, we paid ample attention to the notion of qual ity. Software quality\ndoes not come for free. It has to be actively pursued. The use o f a well-deﬁned model\nof the software development process and good analysis, desi gn and implementation\ntechniques are a prerequisite. However, quality must also b e controlled and managed.\nTo be able to do so, it has to be deﬁned rigorously. This is not w ithout problems,\nas we have seen in sections 6.2 and 6.3. There exist numerous t axonomies of quality\nattributes. For each of these attributes, we need a precise d eﬁnition, together with a\nmetric that can be used to state quality goals, and to check th at these quality goals are\nindeed being satisﬁed. Most quality attributes relate to as pects that are primarily of\ninterest to the", "token_count": 512, "start_token": 85470, "end_token": 85982, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 186, "text": " a\nmetric that can be used to state quality goals, and to check th at these quality goals are\nindeed being satisﬁed. Most quality attributes relate to as pects that are primarily of\ninterest to the software developers. These engineer-orien ted quality views are difﬁcult\nto reconcile with the user-oriented ‘ﬁtness for use’ aspect s.\nFor most quality attributes, the relation between what is ac tually measured\n(module structure, defects encountered, etc.) and the attr ibute we are interested in is\ninsufﬁciently supported by a sound hypothesis. For example , though programs with a\nlarge number of decisions are often complex, counterexampl es exist which show that\nthe number of decisions (essentially McCabe’s cyclomatic c omplexity) is not a good\nmeasure of program complexity. The issue of software metric s and the associated\nproblems is further dealt with in chapter 12.\nMajor standards for quality systems have been deﬁned by ISO a nd IEEE. These\nstandards give detailed guidelines as regards the manageme nt of quality. Quality\nassurance by itself does not guarantee quality products. It has to be supplemented\nby a quality program within the development organization. S ection 6.8 advocates an\nevolutionary approach to establishing a quality program. S uch an approach allows us\nto gradually build up expertise in the use of quantitative da ta to ﬁnd opportunities for\nprocess improvements.\nWe ﬁnally sketched the software maturity framework develop ed by the Software\nEngineering Institute. This framework offers a means to ass ess the state of software\nengineering practice, as well as a number of steps to improve the software development\nprocess. One of the major contributions of CMM and similar in itiatives is their focus\non continuous improvement . This line of thought has subsequently been successfully\napplied to other areas, resulting in, amongst others, a Peop le-CMM, a Formal\nspeciﬁcations-CMM, and a Measurement-CMM.\n6.10 Further Reading\nFenton and Pﬂeeger (1996) provide a very thorough overview o f the ﬁeld of\nsoftware metrics. The measurement framework discussed in s ection 6.1 is based\n142 ON MAN", "token_count": 512, "start_token": 85932, "end_token": 86444, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 187, "text": " Further Reading\nFenton and Pﬂeeger (1996) provide a very thorough overview o f the ﬁeld of\nsoftware metrics. The measurement framework discussed in s ection 6.1 is based\n142 ON MANAGING SOFTWARE QUALITY\non (Kitchenham et al., 1995). Kaner and Bond (2004) also give s a framework for\nevaluating metrics. (Software, 1997b) and (JSS, 1995) are s pecial journal issues on\nsoftware metrics. Many of the articles in these issues deal w ith the application of\nmetrics in quality programs.\nOne of the ﬁrst major publications on the topic of measuremen t programs\nis (Grady and Caswell, 1987). Success factors for measureme nt programs can be\nfound in (Hall and Fenton, 1997) and (Gopal et al., 2002). Pﬂe eger (1995) elaborates\non the relation between metrics programs and maturity level s. Niessink and van Vliet\n(1998b) give a CMM-like framework for the measurement capab ility of software\norganizations.\nThe best known taxonomies of software quality attributes ar e given in (McCall\net al., 1977) and (Boehm et al., 1978). The ISO quality attrib utes are described\nin (ISO9126, 2001) and (C ˆ ot ´ e et al., 2006). Critical discu ssions of these schemes are\ngiven in (Kitchenham and Pﬂeeger, 1996) and (Fenton and Pﬂee ger, 1996). Suryn\net al. (2004) gives an overview of ISO/IEC 90003.\nGarvin’s quality deﬁnitions are given in (Garvin, 1984). Di fferent kinds of beneﬁt\nin a value-based deﬁnition of quality are discussed in (Simm ons, 1996). For an elabo-\nrate discussion of Total Quality Management, see (Bounds et al., 1994) or (Ishikawa,\n1985).\nThe Capability Maturity Model is based on the seminal work of Watts\nHumphrey (Humphrey, 1988, 1989). For a full description of t he Capability Maturity\nModel Integrated, see (CMMI Product Team", "token_count": 512, "start_token": 86394, "end_token": 86906, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 188, "text": ").\nThe Capability Maturity Model is based on the seminal work of Watts\nHumphrey (Humphrey, 1988, 1989). For a full description of t he Capability Maturity\nModel Integrated, see (CMMI Product Team, 2002). Practical experiences with soft-\nware process improvement programs are discussed in (Wohlwe nd and Rosenbaum,\n1994), (Diaz and Sligo, 1997) and (Fitzgerald and O’Kane, 19 99). Rainer and Hall\n(2003) discuss success factors, and Baddoo and Hall (2003) d iscuss de-motivators\nfor SPI. A survey of beneﬁts and costs of software process imp rovement programs is\ngiven in (Herbsleb et al., 1997) and (Gartner, 2001). High-m aturity, CMM level 5\norganizations are discussed in (Software, 2000).\nThe Personal Software Process (PSP) is described in (Humphr ey, 1996) and\n(Humphrey, 1997a). BOOTSTRAP is described in (Kuvaja et al. , 1994) and SPICE\nin (El Emam et al., 1997).\nCriticisms of CMM-like approaches are found in (Fayad, 1997 ), (Fayad and\nLaitinen, 1997) and (Conradi and Fuggetta, 2002). El Emam an d Madhavji (1995)\ndiscuss the reliability of process assessments.\nProcess improvement is the topic of several special journal issues; see (CACM,\n1997), (Software, 1994). The journal Software Process: Improvement and Practice is wholly\ndevoted to this topic.\nExercises\n1. Deﬁne the following terms: measurement, measure, metric .\n2. What is the difference between an internal and an external attribute?\n6.10. FURTHER READING 143\n3. Deﬁne the term representation condition . Why is it important that a measure\nsatisﬁes the representation condition?\n4. What is the main difference between an ordinal scale and an interval scale?\nAnd between an interval scale and a ratio scale?\n5. What are the main differences between the user-based and p roduct-based\ndeﬁnitions of quality?\n6. Which are the three", "token_count": 512, "start_token": 86856, "end_token": 87368, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 189, "text": " interval scale?\nAnd between an interval scale and a ratio scale?\n5. What are the main differences between the user-based and p roduct-based\ndeﬁnitions of quality?\n6. Which are the three categories of software quality factor s distinguished by\nMcCall?\n7. Discuss the transcendent view of software quality.\n8. Which of Garvin’s deﬁnitions of quality is mostly used by t he software\ndeveloper? And which one is mostly used by the user?\n9. Which quality viewpoint is stressed by ISO 9126?\n10. Discuss the cornerstones of Total Quality Management.\n11. What is the purpose of Software Quality Assurance?\n12. Why should the Software Quality Assurance organization be independent of\nthe development organization?\n13. Why should project members get feedback on the use of qual ity data they\nsubmit to the Quality Assurance Group?\n14. Describe the maturity levels of the Capability Maturity Model.\n15. What is the major difference between level 2 and level 3 of the Capability\nMaturity Model?\n16. What is the difference between the staged and continuous versions of CMMI?\n17. Why is it important to quantify quality requirements?\n18. /DJ Consider a software development project you have been invol ved in. How\nwas quality handled in this project? Were quality requireme nts deﬁned at an\nearly stage? Were these requirements deﬁned such that they c ould be tested\nat a later stage?\n19. /DI Deﬁne measurable properties of a software product that make up the\nquality criteria Modularity and Operability. Do these prop erties constitute\nan objective measure of these criteria? If not, in what ways i s subjectivity\nintroduced?\n144 ON MANAGING SOFTWARE QUALITY\n20. /DI Give a possible stafﬁng for an SQA group, both for a small deve lopment\norganization (less than 25 people) and a large development o rganization\n(more than 100 people).\n21. /DJ Draw up a Quality Assurance Plan for a project you have been in volved in.\n22. /DJ One quality requirement often stated is that the system shou ld be ‘user-\nfriendly’. Discuss possible differences between the devel oper�", "token_count": 512, "start_token": 87318, "end_token": 87830, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 190, "text": "urance Plan for a project you have been in volved in.\n22. /DJ One quality requirement often stated is that the system shou ld be ‘user-\nfriendly’. Discuss possible differences between the devel oper’s point of view\nand the user’s point of view in deﬁning this notion. Think of a lternative ways\nto deﬁne system usability in measurable terms.\n23. /DJ Using the classiﬁcation of the Capability Maturity Model, d etermine the\nmaturity level that best ﬁts your organization. Which steps would you propose\nto advance the organization to a higher maturity level? Are a ny actions being\npursued to get from the current level to a more mature one?\n24. /DJ Write a critical essay on software maturity assessment, as e xempliﬁed by\nthe Capability Maturity Model. The further reading section provides ample\npointers to the literature on this topic.\n25. /DI Discuss differences between SPI approaches for large and sm all companies\n(see also (Conradi and Fuggetta, 2002)).\n26. /DI In 1988 and 1998, two surveys were conducted to assess the sta te of the\nart in software cost estimation in the Netherlands. One of th e questions\nconcerned the various stakeholders involved in developing a cost estimate.\nThe resulting percentages were as follows:\n1988 1998\nManagement 48.9 75.8\nStaff department 22.8 37.4\nDevelopment team 22.6 23.6\nProject manager 36.7 42.3\nCustomer 15.4 15.9\nOther 8.9 8.2\nAverage # of parties involved 1.55 2.03\nIt was concluded that the situation had improved. In 1998, th e average\nnumber of parties involved had increased and this was felt to be a good sign.\nFor each individual category, the percentage had gone up as w ell.\n6.10. FURTHER READING 145\nCan you think of a possibly negative conclusion from this sam e set of data,\ni.e. that the situation has become worse since 1988?\n7\nCost Estimation\nLEARNING OBJECTIVES\n/AF To appreciate the use of quantitative, objective approache s to software cost\nestimation\n/AF To have insight in the factors that affect software developm ent productivity", "token_count": 512, "start_token": 87780, "end_token": 88292, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 191, "text": "?\n7\nCost Estimation\nLEARNING OBJECTIVES\n/AF To appreciate the use of quantitative, objective approache s to software cost\nestimation\n/AF To have insight in the factors that affect software developm ent productivity\n/AF To understand well-known techniques for estimating softwa re cost and effort\n/AF To understand techniques for relating effort to developmen t time\n147\nSoftware development takes time and money. When commission ing a building\nproject, you expect a reliable estimate of the cost and devel opment time up\nfront. Getting reliable cost and schedule estimates for sof tware development\nprojects is still largely a dream. Software development cos t is notoriously\ndifﬁcult to estimate reliably at an early stage. Since progr ess is difﬁcult to ‘see’\n--just when is a piece of software 50% complete? --schedule s lippages often go\nundetected for quite a while, and schedule overruns are the r ule, rather than\nthe exception. In this chapter, we look at various ways to est imate software\ncost and schedule.\nWhen commissioning a house construction, decorating the ba throom, or laying-\nout a garden, we expect a precise estimate of the costs to be in curred before the\noperation is started. A gardener is capable of giving a rough indication of the cost on\nthe basis of, say, the area of land, the desired size of the ter race or grass area, whether\nor not a pond is required, and similar information. The estim ate can be made more\nprecise in further dialog, before the ﬁrst bit of earth is tur ned. If you expect a similar\naccuracy as regards the cost estimate for a software develop ment project, you are in\nfor a surprise.\nEstimating the cost of a software development project is a ra ther unexplored ﬁeld,\nin which one all too often relies on mere guesstimates. There are exceptions to this\nprocedure, fortunately. There now exist a number of algorit hmic models that allow us\nto estimate total cost and development time of a software dev elopment project, based\non estimates for a limited number of relevant cost drivers. S ome of the important\nalgorithmic cost estimation models are discussed in sectio n 7.1.\nIn most cost", "token_count": 512, "start_token": 88242, "end_token": 88754, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 192, "text": " time of a software dev elopment project, based\non estimates for a limited number of relevant cost drivers. S ome of the important\nalgorithmic cost estimation models are discussed in sectio n 7.1.\nIn most cost estimation models, a simple relation between co st and effort is\nassumed. The effort may be measured in man-months, for insta nce, and each man-\nmonth is taken to incur a ﬁxed amount, say, of $5000. The total estimated cost is\nthen obtained by simply multiplying the estimated number of man-months by this\nconstant factor. In this chapter, we freely use the terms cos t and effort as if they are\nsynonymous.\nThe notion of total cost is usually taken to indicate the cost of the initial\nsoftware development effort, i.e. the cost of the requireme nts engineering, design,\nimplementation and testing phases. Thus, maintenance cost s are not taken into\naccount. Unless explicitly stated otherwise, this notion o f cost will also be used by\nus. In the same vein, development time will be taken to mean: t he time between the\nstart of the requirements engineering phase and the point in time when the software\nis delivered to the customer. Lastly, the notion of cost as it is used here, does not\ninclude possible hardware costs either. It concerns only pe rsonnel costs involved in\nsoftware development.\nResearch in the area of cost estimation is far from crystalli zed. Different models\nuse different measures and cost drivers, so that mutual comp arisons are very difﬁcult.\n148 COST ESTIMATION\nSuppose some model uses an equation of the form:\n/BX /BP /BE /BM /BJ /C3/C4/C7/BV\n/BD /BM /BC/BH\nThis equation shows a certain relation between effort neede d ( /BX ) and the size\nof the product ( /C3/C4/C7/BV /BP Kilo Lines Of Code /BP Lines Of Code /BP /BD/BC/BC/BC ). The effort\nmeasure could be the number of man-months needed. Several qu estions come to\nmind immediately: What is a line of code? Do we count machine c ode, or the source\ncode in some high-level language? Do we count comment", "token_count": 512, "start_token": 88704, "end_token": 89216, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 193, "text": " be the number of man-months needed. Several qu estions come to\nmind immediately: What is a line of code? Do we count machine c ode, or the source\ncode in some high-level language? Do we count comment lines, or blank lines that\nincrease readability? Do we take into account holidays, sic k-leave, and the like, in our\nnotion of the man-month, or does it concern a net measure? Dif ferent interpretations\nof these notions may lead to widely different results. Unfor tunately, different models\ndo use different deﬁnitions of these notions. Sometimes, it is not even known which\ndeﬁnitions were used in the derivation of the model.\nTo determine the equations of an algorithmic cost estimatio n model, we may\nfollow several approaches. Firstly, we may base our equatio ns on the results of\nexperiments. In such an experiment, we in general vary one pa rameter, while the\nother parameters are kept constant. In this way, we may try to determine the inﬂuence\nof the parameter that is being varied. As a typical example, w e may consider the\nquestion of whether or not comments help to build up our under standing of a\nprogram. Under careful control of the circumstances, we may pose a number of\nquestions about one and the same program text to two groups of programmers. The\nﬁrst group gets program text without comments, the second gr oup gets the same\nprogram text, with comments. We may check our hypothesis usi ng the results of the\ntwo groups. The, probably realistic, assumption in this exp eriment is that a better and\nfaster understanding of the program text has a positive effe ct on the maintainability\nof that program.\nThis type of laboratory experiment is often performed at uni versities, where stu-\ndents play the role of programmers. It is not self-evident th at the results thus obtained\nalso holds in industrial settings. In practice, there may be a rather complicated interac-\ntion between different relevant factors. Also, the subject s need not be representative.\nFinally, the generalization from laboratory experiments t hat are (of necessity) limited\nin size to big software development projects with which prof essionals are confronted\nis not possible. The general opinion is that results thus", "token_count": 512, "start_token": 89166, "end_token": 89678, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 194, "text": " need not be representative.\nFinally, the generalization from laboratory experiments t hat are (of necessity) limited\nin size to big software development projects with which prof essionals are confronted\nis not possible. The general opinion is that results thus obt ained have limited validity,\nand certainly need further testing.\nA second way to arrive at algorithmic cost estimation models is based on an\nanalysis of real project data, in combination with some theo retical underpinning. An\norganization may collect data about a number of software sys tems that have been\ndeveloped. These data may concern the time spent on the vario us phases that are\nbeing distinguished, the qualiﬁcations of the personnel in volved, the points in time\nat which errors occurred, both during testing and after inst allation, the complexity,\nreliability and other relevant project factors, the size of the resulting code, etc.\nBased on a sound hypothesis of the relations between the vari ous entities involved\nand a (statistical) analysis of these data we may derive equa tions that numerically\n149\ncharacterize these relations. An example of such a relation is the one given above,\nwhich relates /BX to /C3/C4/C7/BV . The usability and reliability of such equations is obvious ly\nvery much dependent upon the reliability of the data on which they are based. Also,\nthe hypothesis that underlies the form of the equation must b e sound.\nThe ﬁndings obtained in this way reﬂect an average, a best pos sible approximation\nbased on available data. We therefore have to be very careful in applying the results\nobtained. If the software to be developed in the course of a ne w project cannot be\ncompared with earlier products because of the degree of inno vation involved, one is\nin for a big surprise. For example, estimating the cost of the Space Shuttle project\ncannot be done through a simple extrapolation from earlier p rojects. We may hope,\nhowever, that the average software development project has a higher predictability\nas regards effort needed and the corresponding cost.\nThe way in which we obtain quantitative relations implies fu rther constraints on\nthe use of these models. The model used is based on an analysis of data from earlier\nprojects. Application of the model to new projects is possib le only insofar as those", "token_count": 512, "start_token": 89628, "end_token": 90140, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 195, "text": " way in which we obtain quantitative relations implies fu rther constraints on\nthe use of these models. The model used is based on an analysis of data from earlier\nprojects. Application of the model to new projects is possib le only insofar as those\nnew projects resemble old projects, i.e. the projects on who se data the model is\nbased. If we have collected data on projects of a certain kind and within a particular\norganization, a model based on these data cannot be used with out amendment for\ndifferent projects in a possibly different organization. A model based on data about\nadministrative projects in a government environment has li ttle predictive value for\nthe development of real-time software in the aerospace indu stry. This is one of the\nreasons why the models of, for example, Walston and Felix (19 77) and Boehm (1981)\n(see section 7.1 for more detailed discussions of these mode ls) yield such different\nresults for one and the same problem description.\nThe lesson to be learned is that blind application of the form ulae from existing\nmodels will not solve your cost estimation problem. Each mod el needs tuning to the\nenvironment in which it is going to be used. This implies the n eed to continuously\ncollect your own project data, and to apply statistical tech niques to calibrate model\nparameters.\nOther reasons for the discrepancies between existing model s are:\n– Most models give a relation between man-months needed and s ize (in lines\nof code). As remarked before, widely different deﬁnitions o f these notions are\nused.\n– The notion ‘effort’ does not always mean the same thing. Som etimes, one\nonly counts the activities starting from the design, i.e. af ter the requirements\nspeciﬁcation has been ﬁxed. Sometimes also, one includes ma intenance effort.\nDespite these discrepancies, the various cost estimation m odels do have a number of\ncharacteristics in common. These common characteristics r eﬂect important factors\nthat bear on development cost and effort. The increased unde rstanding of software\ncosts allows us to identify strategies for improving softwa re productivity, the most\nimportant of which are:\n150 COST ESTIMATION\n/AF Writing less code. System size is one of the main determinant s of effort and\ncost. Techniques that try to", "token_count": 512, "start_token": 90090, "end_token": 90602, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 196, "text": " strategies for improving softwa re productivity, the most\nimportant of which are:\n150 COST ESTIMATION\n/AF Writing less code. System size is one of the main determinant s of effort and\ncost. Techniques that try to reduce size, such as software re use and the use of\nhigh-level languages, can obtain signiﬁcant savings.\n/AF Getting the best from people. Individual and team capabilit ies have a large\nimpact on productivity. The best people are usually a bargai n. Better incentives,\nbetter work environments, training programs and the like pr ovide further\nproductivity improvement opportunities.\n/AF Avoiding rework. Studies have shown that a considerable eff ort is spent redoing\nearlier work. The application of prototyping or evolutiona ry development\nprocess models and the use of modern programming practices ( information\nhiding) can yield considerable savings.\n/AF Developing and using integrated project support environme nts. Tools can help\nus eliminate steps or make steps more efﬁcient.\nIn the next section, we discuss and compare some of the well-k nown algorithmic\nmodels for cost estimation. In many organizations, softwar e cost is estimated by\nhuman experts, who use their expertise and gut feeling, rath er than a formula, to\narrive at a cost estimate. Some of the do’s and don’ts of exper t-based cost estimation\nare discussed in section 7.2.\nGiven an estimate of the size of a project, we will next be inte rested in the\ndevelopment time needed. With a naive view, we may conjectur e that a project with\nan estimated effort of 100 man-months can be done in 1 year wit h a team of 8.5\npeople, but equally well in one month with a team of 100 people . This view is too\nnaive. A project of a certain size corresponds to a certain no minal physical time\nperiod. If we try to shorten this nominal development time to o much, we get into the\n‘impossible region’ and the chance of failure sharply incre ases. This phenomenon is\nfurther discussed in section 7.3.\nThe topics addressed in this chapter ﬁt planning-driven dev elopment projects\nmore than they do agile projects. In agile projects, iterati ons are usually fairly", "token_count": 512, "start_token": 90552, "end_token": 91064, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 197, "text": " phenomenon is\nfurther discussed in section 7.3.\nThe topics addressed in this chapter ﬁt planning-driven dev elopment projects\nmore than they do agile projects. In agile projects, iterati ons are usually fairly small,\nand do not warrant the effort required by the algorithmic mod els discussed in\nsection 7.1. In agile projects (see chapter 3, increments co rrespond to one or a few\nuser stories or scenarios. These user stories are estimated in terms of development\nweeks, bucks, or some artiﬁcial unit, say Points. Next, it is determined which user\nstories will be realized in the current increment, and devel opment proceeds. Usually,\nthe time box agreed upon is sacred, i.e., if some of the user st ories cannot be realized\nwithin the agreed upon time frame, they are moved to a next ite ration. Estimation\naccuracy is assumed to improve in the course of the project.\n7.1 Algorithmic Models\nTo be able to get reliable estimates, we need to extensively r ecord historical data.\nThese historical data can be used to produce estimates for ne w projects. In doing\n7.1. ALGORITHMIC MODELS 151\nso, we predict the expected cost on account of measurable properties of the project at\nhand. Just as the cost of laying out a garden might be a weighte d combination of a\nnumber of relevant attributes (size of the garden, size of th e grass area, yes/no for a\npond), so we would like to estimate the cost of a software deve lopment project. In\nthis section, we discuss efforts to get at algorithmic model s to estimate software cost.\nIn the introduction to this chapter, we noticed that program ming effort is strongly\ncorrelated with program size. There exist various (non-lin ear) models which express\nthis correlation. A general form is\n/BX /BP /B4 /CP /B7 /CQ /C3/C4/C7/BV\n\r\n/B5 /CU /B4 /DC\n/BD\n/BN /BM /BM /BM /BN /DC\n/D2\n/B5\nHere, /C3/C4/C7/BV again denotes the size of the software (lines of code/1000), while /BX", "token_count": 512, "start_token": 91014, "end_token": 91526, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 198, "text": "BM /BM /BM /BN /DC\n/D2\n/B5\nHere, /C3/C4/C7/BV again denotes the size of the software (lines of code/1000), while /BX\ndenotes the effort in man-months. /CP , /CQ and \r are constants, and /CU /B4 /DC\n/BD\n/BN /BM /BM /BM /BN /DC\n/D2\n/B5 is a\ncorrection which depends on the values of the entities /DC\n/BD\n/BN /BM /BM /BM /BN /DC\n/D2\n. In general, the\nbase formula\n/BX /BP /CP /B7 /CQ /C3/C4/C7/BV\n\r\nis obtained through a regression analysis of available proj ect data. Thus, the primary\ncost driver is software size, measured in lines of code. This nominal cost estimate is\ntuned by correcting it for a number of factors that inﬂuence p roductivity (so-called\ncost drivers). For instance, if one of the factors used is ‘ex perience of the programming\nteam’, this could incur a correction to the nominal cost esti mate of 1.50, 1.20, 1.00,\n0.80 and 0.60 for a very low, low, average, high and very high l evel of expertise,\nrespectively.\nFigure 7.1 contains some of the well-known base formulae for the relation between\nsoftware size and effort. For reasons mentioned before, it i s difﬁcult to compare these\nmodels. It is interesting to note, though, that the value of \r ﬂuctuates around the\nvalue 1 in most models.\nOrigin Base formula See section\nHalstead /BX /BP /BC /BM /BJ /C3/C4/C7/BV\n/BD /BM /BH/BC\n12.1.4\nBoehm /BX /BP /BE /BM /BG /C3/C4/C7/BV\n/BD /BM /BC/BH\n7.1.2\nWalston--Felix /BX /BP /BH /BM /BE /C3/C4/", "token_count": 512, "start_token": 91476, "end_token": 91988, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 199, "text": "/C4/C7/BV\n/BD /BM /BC/BH\n7.1.2\nWalston--Felix /BX /BP /BH /BM /BE /C3/C4/C7/BV\n/BC /BM /BL/BD\n7.1.1\nFigure 7.1 Some base formulae for the relation between size a nd effort\nThis phenomenon is well known from the theory of economics. I n a so-called\neconomy of scale, one assumes that it is cheaper to produce la rge quantities of the\nsame product. The ﬁxed costs are then distributed over a larg er number of units, which\n152 COST ESTIMATION\ndecreases the cost per unit. We thus realize an increasing re turn on investment. In\nthe opposite case, we ﬁnd a diseconomy of scale: after a certa in point the production\nof additional units incurs extra costs.\nIn the case of software, the lines of code are the product. If w e assume that\nproducing a lot of code will cost less per line of code, formul ae like those of\nWalston--Felix ( \r /BO /BD ) result. This may occur, for example, because the cost of\nexpensive tools like program generators, programming envi ronments and test tools\ncan be distributed over a larger number of lines of code. Alte rnatively, we may reason\nthat large software projects are more expensive, relativel y speaking. There is a larger\noverhead because of the increased need for communication an d management control,\nbecause of the problems and interfaces getting more complex , and so on. Thus, each\nadditional line of code requires more effort. In such cases, we obtain formulae like\nthose of Boehm and Halstead ( \r /BQ /BD ).\nThere is no really convincing argument for either type of rel ation, though the\nlatter ( \r /BQ /BD ) may seem more plausible. Certainly for large projects, the effort required\ndoes seem to increase more than linearly with size.\nIt is clear that the value of the exponent \r strongly inﬂuences the computed value\n/BX , certainly for large values of /C3/C4/C7/BV . Figure 7.2 gives the values for", "token_count": 512, "start_token": 91938, "end_token": 92450, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 200, "text": " clear that the value of the exponent \r strongly inﬂuences the computed value\n/BX , certainly for large values of /C3/C4/C7/BV . Figure 7.2 gives the values for /BX , as they are\ncomputed for the earlier-mentioned models and some values f or /C3/C4/C7/BV . The reader\nwill notice large differences between the models. For small programs, Halstead’s\nmodel yields the lowest cost estimates. For projects in the o rder of one million lines\nof code, this same model yields a cost estimate which is an ord er of magnitude higher\nthan that of Walston--Felix.\n/C3/C4/C7/BV /BX /BP /BC /BM /BJ /C3/C4/C7/BV\n/BD /BM /BH/BC\n/BX /BP /BE /BM /BG /C3/C4/C7/BV\n/BD /BM /BC/BH\n/BX /BP /BH /BM /BE /C3/C4/C7/BV\n/BC /BM /BL/BD\n1 0.7 2.4 5.2\n10 22.1 26.9 42.3\n50 247.5 145.9 182.8\n100 700.0 302.1 343.6\n1000 22135.9 3390.1 2792.6\nFigure 7.2 /BX versus /C3/C4/C7/BV for various base models\nHowever, we should not immediately conclude that these mode ls are useless. It is\nmuch more likely that there are big differences in the charac teristics between the sets\nof projects on which the various models are based. Recall tha t the actual numbers used\nin those models result from an analysis of real project data. If these data reﬂect widely\ndifferent project types or development environments, so wi ll the models. We cannot\nsimply copy those formulae. Each environment has its own spe ciﬁc characteristics and\n7.1. ALGORITHMIC MODELS 153\ntuning the model parameters to the speciﬁc environment (a pr ocess called calibration)\nis necessary.\nThe most important problem with this type", "token_count": 512, "start_token": 92400, "end_token": 92912, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 201, "text": " characteristics and\n7.1. ALGORITHMIC MODELS 153\ntuning the model parameters to the speciﬁc environment (a pr ocess called calibration)\nis necessary.\nThe most important problem with this type of model is to get a reliable estimate\nof the software size early on. How should we estimate the numb er of pages in a\nnovel not yet written? Even if we know the number of character s, the number of\nlocations and the time interval in which the story takes plac e, we should not expect\na realistic size estimate up front. The further advanced we a re with the project, the\nmore accurate our size estimate will get. If the design is mor e or less ﬁnished, we may\n(possibly) form a reasonable impression of the size of the re sulting software. Only if\nthe system has been delivered, do we know the exact number.\nThe customer, however, needs a reliable cost estimate early on. In such a case,\nlines of code is a measure which is too inexact to act as a base f or a cost estimate. We\ntherefore have to look for an alternative. In section 7.1.4 w e discuss a model based\non quantities which are known at an earlier stage.\nWe may also switch to another model during the execution of a p roject, since we\nmay expect to get more reliable data as the project is making p rogress. We then get a\ncascade of increasingly detailed cost estimation models. C OCOMO 2 is an example\nof this; see section 7.1.5.\n7.1.1 Walston--Felix\nThe base equation of Walston and Felix’ model (Walston and Fe lix, 1977) is\n/BX /BP /BH /BM /BE /C3/C4/C7/BV\n/BC /BM /BL/BD\nSome 60 projects from IBM were used in the derivation of this m odel. These projects\ndiffered widely in size and the software was written in a vari ety of programming\nlanguages. It therefore comes as no surprise that the model, applied to a subset of\nthese 60 projects, yields unsatisfactory results.\nIn an effort to explain these wide-ranging results, Walston and Felix identiﬁed 29\nvariables that clearly inﬂuenced productivity", "token_count": 512, "start_token": 92862, "end_token": 93374, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 202, "text": " applied to a subset of\nthese 60 projects, yields unsatisfactory results.\nIn an effort to explain these wide-ranging results, Walston and Felix identiﬁed 29\nvariables that clearly inﬂuenced productivity. For each of these variables, three levels\nwere distinguished: high, average and low. For a number of pr ojects (51) Walston and\nFelix determined the level of each of these 29 variables, tog ether with the productivity\nobtained (in terms of lines of code per man-month) in those pr ojects. These results\nare given in ﬁgure 7.3 for some of the most important variable s. Thus, the average\nproductivity turned out to be 500 lines of code per man-month for projects with a\nuser interface of low complexity. With a user interface of av erage or high complexity,\nthe productivity is 295 and 124 lines of code per man-month, r espectively. The last\ncolumn contains the productivity change /C8/BV , the absolute value of the difference\nbetween the high and low scores.\nAccording to Walston and Felix, a productivity index /C1 can now be determined\nfor a new project, as follows:\n/C1 /BP\n/BE/BL\n/CG\n/CX /BP/BD\n/CF\n/CX\n/CG\n/CX\n154 COST ESTIMATION\nVariable Value of variable /CY /CW/CX/CV/CW /A0 /D0/D3 /DB /CY\nAverage productivity (LOC) (PC)\nComplexity of user\ninterface\n/BO normal normal /BQ normal\n500 295 124 376\nUser participation during\nrequirements speciﬁcation\nnone some much\n491 267 205 286\nUser-originated changes in\ndesign\nfew many\n297 -- 196 101\nUser-experience with\napplication area\nnone some much\n318 340 206 112\nQualiﬁcation, experience\nof personnel\nlow average high\n132 257 410 278\nPercentage programmers\nparticipating in design\n/BO 25% 25 --50% /BQ 50%\n153 242 391 238\nPrevious experience with\noperational computer\nminimal average extensive\n146 270 312 166\nPrevious experience with\nprogramming languages\nminimal average extensive\n122 225 385", "token_count": 512, "start_token": 93324, "end_token": 93836, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 203, "text": " 25 --50% /BQ 50%\n153 242 391 238\nPrevious experience with\noperational computer\nminimal average extensive\n146 270 312 166\nPrevious experience with\nprogramming languages\nminimal average extensive\n122 225 385 263\nPrevious experience with\napplication of similar or\ngreater size and complexity\nminimal average extensive\n146 221 410 264\nRatio of average team size\nto duration (people/month)\n/BO 0.5 0.5-0.9 /BQ 0.9\n305 310 171 134\nFigure 7.3 Some productivity intervals ( Source: C.E. Walston and C.P. Felix, A method for\nprogramming measurement and estimation , IBM Systems Journal, 1977.)\nThe weights /CF\n/CX\nare deﬁned by\n/CF\n/CX\n/BP /BC /BM /BH /D0/D3/CV /B4 /C8/BV\n/CX\n/B5\nHere, /C8/BV\n/CX\nis the productivity change of factor /CX . For the ﬁrst factor from ﬁgure 7.3\n(complexity of the user interface), the following holds: /C8/BV\n/BD\n/BP /BF/BJ/BI , so /CF\n/BD\n/BP /BD /BM /BE/BL .\nThe variables /CG\n/CX\ncan take on values /B7/BD , /BC and /A0 /BD , where the corresponding factor\nscores as low, average or high (and thus results in a high, ave rage or low productivity,\nrespectively). The productivity index obtained can be tran slated into an expected\nproductivity (lines of code produced per man-month). Detai ls of the latter are not\ngiven in (Walston and Felix, 1977).\n7.1. ALGORITHMIC MODELS 155\nThe number of factors considered in this model is rather high (29 factors out of\n51 projects). Also it is not clear to what extent the various f actors inﬂuence each\nother. Finally, the number of alternatives per factor is onl y three, and does not seem\nto offer enough choice in practical situations.\nNevertheless, the approach taken by Walston and Felix and th eir list of cost", "token_count": 512, "start_token": 93786, "end_token": 94298, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 204, "text": "ence each\nother. Finally, the number of alternatives per factor is onl y three, and does not seem\nto offer enough choice in practical situations.\nNevertheless, the approach taken by Walston and Felix and th eir list of cost\ndrivers have played a very important role in directing later research in this area.\n7.1.2 COCOMO\nCOCOMO (COnstructive COst MOdel) is one of the algorithmic c ost estimation\nmodels best documented. In its simplest form, called Basic C OCOMO, the formula\nthat relates effort to software size, reads\n/BX /BP /CQ /C3/C4/C7/BV\n\r\nHere, /CQ and \r are constants that depend on the kind of project that is being executed.\nCOCOMO distinguishes three classes of project:\n/AF Organic A relatively small team develops software in a known environ ment.\nThe people involved generally have a lot of experience with s imilar projects\nin their organization. They are thus able to contribute at an early stage, since\nthere is no initial overhead. Projects of this type will seld om be very large\nprojects.\n/AF Embedded The product will be embedded in an environment which is very\ninﬂexible and poses severe constraints. An example of this t ype of project might\nbe air trafﬁc control, or an embedded weapon system.\n/AF Semidetached This is an intermediate form. The team may show a mixture of\nexperienced and inexperienced people, the project may be fa irly large, though\nnot excessively large, etc.\nFor the various classes, the parameters of Basic COCOMO take on the following\nvalues:\norganic: /CQ = 2.4, \r = 1.05\nsemidetached: /CQ = 3.0, \r = 1.12\nembedded: /CQ = 3.6, \r = 1.20\nFigure 7.4 gives the estimated effort for projects of each of those three modes, for\ndifferent values of /C3/C4/C7/BV (though an ‘organic’ project of one million lines is not very\nrealistic). Amongst others, we may read from this ﬁgure that the constant \r soon\nstarts to have a major", "token_count": 512, "start_token": 94248, "end_token": 94760, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 205, "text": "/BV (though an ‘organic’ project of one million lines is not very\nrealistic). Amongst others, we may read from this ﬁgure that the constant \r soon\nstarts to have a major impact on the estimate obtained.\nBasic COCOMO yields a simple, and hence a crude, cost estimat e based on\na simple classiﬁcation of projects into three classes. In hi s book Software Engineering\n156 COST ESTIMATION\nKLOC\nEffort in man-months\norganic semidetached embedded\n(/BX /BP /BE /BM /BG /C3/C4/C7/BV\n/BD /BM /BC/BH\n) ( /BX /BP /BF /BM /BC /C3/C4/C7/BV\n/BD /BM /BD/BE\n) ( /BX /BP /BF /BM /BI /C3/C4/C7/BV\n/BD /BM /BE/BC\n)\n1 2.4 3.0 3.6\n10 26.9 39.6 57.1\n50 145.9 239.4 392.9\n100 302.1 521.3 904.2\n1000 3390.0 6872.0 14333.0\nFigure 7.4 Size versus effort in Basic COCOMO\nEconomics, Boehm also discusses two other, more complicated, models, termed Inter-\nmediate COCOMO and Detailed COCOMO, respectively. Both the se models take\ninto account 15 cost drivers --attributes that affect produ ctivity, and hence costs.\nAll these cost drivers yield a multiplicative correction fa ctor to the nominal\nestimate of the effort. (Both these models also use values fo r /CQ which slightly differ\nfrom that of Basic COCOMO.) Suppose we found a nominal effort estimate of 40\nman-months for a certain project. If the complexity of the re sulting software is low,\nthen the model tells us to correct this estimate by a factor of 0.85. A better estimate\nthen would be 34 man-months. On the other hand, if the complex ity is high, we get\nan estimate of /BD /BM /BD/BH /A2 /BG/BC /BP /BG", "token_count": 512, "start_token": 94710, "end_token": 95222, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 206, "text": " better estimate\nthen would be 34 man-months. On the other hand, if the complex ity is high, we get\nan estimate of /BD /BM /BD/BH /A2 /BG/BC /BP /BG/BI man-months.\nThe nominal value of each cost driver in Intermediate COCOMO is 1.00 (see\nalso ﬁgure 7.11. So we may say that Basic COCOMO is based on nom inal values for\neach of the cost drivers.\nOn top of this set of cost drivers, the detailed model adds a fu rther level of\nreﬁnement. First of all, this model is phase-sensitive, the idea being that not all cost\ndrivers inﬂuence each phase of the development cycle in the s ame way. So, rather\nthan having one table with effort multipliers as in Intermed iate COCOMO, Detailed\nCOCOMO uses a set of such tables. These tables show, for each c ost driver, a\nseparate effort multiplier for each major development phas e. Furthermore, Detailed\nCOCOMO uses a hierarchy for the product to be developed, in wh ich some cost\ndrivers have an impact on the estimate at the module level, wh ile others have an\nimpact at the (sub)system level.\nThe COCOMO formulae are based on a combination of expert judg ment, an\nanalysis of available project data, other models, etc. The b asic model does not yield\nvery accurate results for the projects on which the model has been based. The\nintermediate version yields good results and, if one extra c ost driver (volatility of\nthe requirements speciﬁcation) is added, it even yields ver y good results. Further\nvalidation of the COCOMO models using other project data is n ot straightforward,\n7.1. ALGORITHMIC MODELS 157\nFigure 7.5 The Rayleigh-curve for software schedules ( Source: M.L. Shooman , Tutorial\non software cost models, IEEE Catalog nr TH0067-9 (1979), 1979 IEEE.)\nsince the necessary information to determine the ratings of the various cost drivers is\nin general not available. So we are left with the possibility of only testing the basic\nmodel. Here, we obtain fairly", "token_count": 512, "start_token": 95172, "end_token": 95684, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 207, "text": "67-9 (1979), 1979 IEEE.)\nsince the necessary information to determine the ratings of the various cost drivers is\nin general not available. So we are left with the possibility of only testing the basic\nmodel. Here, we obtain fairly large discrepancies between t he effort estimated and\nthe actual effort needed.\nA major advantage of COCOMO is that we know all its details. A m ajor update\nof the COCOMO model, better reﬂecting current and future sof tware practices, is\ndiscussed in section 7.1.5.\n7.1.3 Putnam\nNorden studied the distribution of manpower over time in a nu mber of software\ndevelopment projects in the 1960s. He found that this distri bution often had a very\ncharacteristic shape which is well-approximated by a Rayle igh distribution. Based\nupon this ﬁnding, Putnam developed a cost estimation model i n which the manpower\nrequired (\n/C5/CA ) at time /D8 is given by\n/C5/CA /B4 /D8 /B5 /BP /BE /C3 /CP/D8/CT\n/A0 /CP/D8\n/BE\n/CP is a speed-up factor which determines the initial slope of th e curve, while /C3 denotes\nthe total manpower required, including the maintenance pha se. /C3 equals the volume\nof the area delineated by the Rayleigh curve (see ﬁgure 7.5).\nThe shape of this curve can be explained theoretically as fol lows. Suppose a\nproject consists of a number of problems for which a solution must be found. Let\n/CF /B4 /D8 /B5 be the fraction of problems for which a solution has been foun d at time /D8 . Let\n/D4 /B4 /D8 /B5 be the problem-solving capacity at time /D8 . Progress at time /D8 then is proportional\n158 COST ESTIMATION\nto the product of the available problem-solving capacity an d the fraction of problems\nyet unsolved. If the total amount of work to be done is set to 1, this yields:\nd/CF\nd/D8\n/BP /D4 /B4 /D8 /B5/B4/BD /", "token_count": 512, "start_token": 95634, "end_token": 96146, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 208, "text": "yet unsolved. If the total amount of work to be done is set to 1, this yields:\nd/CF\nd/D8\n/BP /D4 /B4 /D8 /B5/B4/BD /A0 /CF /B4 /D8 /B5/B5\nAfter integration, we get\n/CF /B4 /D8 /B5 /BP /BD /A0 /CT/DC/D4/B4 /A0\n/CI\n/D8\n/D4 /B4 /AB /B5 d/AB /B5\nIf we next assume that the problem-solving capacity is well a pproximated by an\nequation of the form /D4 /B4 /D8 /B5 /BP /CP/D8 , i.e. the problem-solving capacity shows a linear\nincrease over time, the progress is given by a Rayleigh distr ibution:\nd/CF\nd/D8\n/BP /CP/D8/CT\n/A0 /B4 /CP/D8\n/BE\n/B5 /BP /BE\nIntegration of the equation for /C5/CA /B4 /D8 /B5 that was given earlier yields the cumulative\neffort /C1 :\n/C1 /B4 /D8 /B5 /BP /C3 /B4/BD /A0 /CT\n/A0 /CP/D8\n/BE\n/B5\nIn particular, we get /C1 /B4 /BD /B5 /BP /C3 . If we denote the point in time at which the Rayleigh-\ncurve assumes its maximum value by /CC , then /CP /BP /BD /BP /B4/BE /CC\n/BE\n/B5 . This point /CC will be close\nto the point in time at which the software is being delivered t o the customer. The\nvolume of the area delineated by the Rayleigh curve between p oints 0 and /CC then is\na good approximation of the initial development effort. For this, we get\n/BX /BP /C1 /B4 /CC /B5 /BP /BC /BM /BF/BL/BG/BH /C3\nThis result is remarkably close to the often-used rule of th", "token_count": 512, "start_token": 96096, "end_token": 96608, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 209, "text": " get\n/BX /BP /C1 /B4 /CC /B5 /BP /BC /BM /BF/BL/BG/BH /C3\nThis result is remarkably close to the often-used rule of thu mb: 40% of the total effort\nis spent on the actual development, while 60% is spent on main tenance.\nVarious studies indicate that Putnam’s model is well suited to estimating the cost\nof very large software development projects (projects that involve more than 15\nman-years). The model seems to be less suitable for small pro jects.\nA serious objection to Putnam’s model, in our opinion, conce rns the relation it\nassumes between effort and development time if the schedule is compressed relative\nto the nominal schedule estimate: /BX /BP \r/BP/CC\n/BG\n. Compressing a project’s schedule in\nthis model entails an extraordinary large penalty (see also section 7.3).\n7.1.4 Function Point Analysis\nFunction point analysis (FPA) is a method of estimating cost s in which the problems\nassociated with determining the expected amount of code are circumvented. FPA\nis based on counting the number of different data structures that are used. In the\nFPA method, it is assumed that the number of different data st ructures is a good\n7.1. ALGORITHMIC MODELS 159\nsize indicator. FPA is particularly suitable for projects a imed at realizing business\napplications for, in these applications, the structure of t he data plays a very dominant\nrole. The method is less suited to projects in which the struc ture of the data plays a\nless prominent role, and the emphasis is on algorithms (such as compilers and most\nreal-time software).\nThe following ﬁve entities play a central role in the FPA-mod el:\n/AF Number of input types ( /C1 ). The input types refer only to user input that results\nin changes in data structures. It does not concern user input which is solely\nconcerned with controlling the program’s execution. Each i nput type that has\na different format, or is treated differently, is counted. S o, though the records\nof a master ﬁle and those of a mutation ﬁle may have the same for mat, they are", "token_count": 512, "start_token": 96558, "end_token": 97070, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 210, "text": " nput type that has\na different format, or is treated differently, is counted. S o, though the records\nof a master ﬁle and those of a mutation ﬁle may have the same for mat, they are\nstill counted separately.\n/AF Number of output types ( /C7 ). For the output types, the same counting scheme\nis used.\n/AF Number of inquiry types ( /BX ). Inquiry types concern input that controls the\nexecution of the program and does not change internal data st ructures. Examples\nof inquiry types are: menu selection and query criteria.\n/AF Number of logical internal ﬁles ( /C4 ). This concerns internal data generated by\nthe system, and used and maintained by the system, such as, fo r example, an\nindex ﬁle.\n/AF Number of interfaces ( /BY ). This concerns data that is output to another\napplication, or is shared with some other application.\nBy trial and error, weights have been associated with each of these entities. The\nnumber of (unadjusted) function points, /CD/BY/C8 , is a weighted sum of these ﬁve entities:\n/CD/BY/C8 /BP /BG /C1 /B7 /BH /C7 /B7 /BG /BX /B7 /BD/BC /C4 /B7 /BJ /BY\nWith FPA too, a further reﬁnement is possible, by applying co rrections to reﬂect\ndifferences in complexity of the data types. In that case, th e constants used in the\nabove formula depend on the estimated complexity of the data type in question.\nFigure 7.6 gives the counting rules when three levels of comp lexity are distinguished.\nSo, rather than having each input type count as four function points, we may count\nthree, four or six function points, based on an assessment of the complexity of each\ninput type.\nEach input type has a number of data element types (attribute s), and refers to zero\nor more other ﬁle types. The complexity of an input type incre ases as the number of\nits data element types or referenced ﬁle types increases. Fo r input types, the mapping\nof these numbers to complexity levels is given in ﬁgure 7.7. F or the", "token_count": 512, "start_token": 97020, "end_token": 97532, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 211, "text": " incre ases as the number of\nits data element types or referenced ﬁle types increases. Fo r input types, the mapping\nof these numbers to complexity levels is given in ﬁgure 7.7. F or the other ﬁle types,\nthese tables have the same format, with slightly different n umbers along the axes.\n160 COST ESTIMATION\nType Complexity level\nSimple Average Complex\nInput ( /C1 ) 3 4 6\nOutput ( /C7 ) 4 5 7\nInquiry ( /BX ) 3 4 6\nLogical internal ( /C4 ) 7 10 15\nInterfaces ( /BY ) 5 7 10\nFigure 7.6 Counting rules for (unadjusted) function points\n# of ﬁle types # of data elements\n1 --4 5 --15 /BQ 15\n0 or 1 simple simple average\n2 --3 simple average complex\n/BQ 3 average complex complex\nFigure 7.7 Complexity levels for input types\nAs in other cost estimation models, the unadjusted function point measure is\nadjusted by taking into account a number of application char acteristics that inﬂuence\ndevelopment effort. Figure 7.8 contains the 14 characteris tics used in the FPA model.\nThe degree of inﬂuence of each of these characteristics is va lued on a six-point scale,\nranging from zero (no inﬂuence, not present) to ﬁve (strong i nﬂuence). The total\ndegree of inﬂuence /BW/C1 is the sum of the scores for all characteristics. This number is\nthen converted to a technical complexity factor ( /CC/BV/BY ) using the formula\n/CC/BV/BY /BP /BC /BM /BI/BH /B7 /BC /BM /BC/BD /BW/C1\nThe (adjusted) function point measure /BY/C8 is now obtained through\n/BY/C8 /BP /CD/BY/C8 /A2 /CC/BV/BY\nFinally, there is a direct mapping from (adjusted) function points to lines of code. For\ninstance, in (Albrecht, 1979) one function point correspon ds to 65 lines of PL/I, or to\n100 lines of COB", "token_count": 512, "start_token": 97482, "end_token": 97994, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 212, "text": " a direct mapping from (adjusted) function points to lines of code. For\ninstance, in (Albrecht, 1979) one function point correspon ds to 65 lines of PL/I, or to\n100 lines of COBOL, on average.\nIn FPA, it is not simple to decide exactly when two data types s hould be counted\nas separate. Also, the difference between, for example, inp ut types, inquiry types, and\n7.1. ALGORITHMIC MODELS 161\nData communications\nDistributed functions\nPerformance\nHeavily used conﬁguration\nTransaction rate\nOnline data entry\nEnd-user efﬁciency\nOnline update\nComplex processing\nRe-usability\nInstallation ease\nOperational ease\nMultiple sites\nFacilitate change\nFigure 7.8 Application characteristics in FPA\ninterfaces remains somewhat vague. The International Func tion Point User Group\n(IFPUG) has published extensive guidelines on how to classi fy and count the various\nentities involved. This should overcome many of the difﬁcul ties that analysts have in\ncounting function points in a uniform way.\nFurther problems with FPA have to do with its use of ordinal sc ales and the way\ncomplexity is handled. FPA distinguishes three levels of co mponent complexity only.\nA component with 100 elements thus gets at most twice the numb er of function points\nof a component with one element. It has been suggested that a m odel which uses\nthe raw complexity data, i.e. the number of data elements and ﬁle types referenced,\nmight work as well as, or even better than, a model which uses a n ordinal derivative\nthereof. In a sense, complexity is counted twice: both throu gh the complexity level of\nthe component and through one of the application characteri stics. Yet it is felt that\nhighly complex systems are not adequately dealt with, since FPA is predominantly\nconcerned with counting externally visible inputs and outp uts.\nIn applying the FPA cost estimation method, it still remains necessary to calibrate\nthe various entities to your own environment. This holds the more for the corrections\nthat reﬂect different application characteristics, and th e transition from function\npoints to lines of code.\n7.1.5 COCOMO 2: Variations", "token_count": 512, "start_token": 97944, "end_token": 98456, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 213, "text": " to your own environment. This holds the more for the corrections\nthat reﬂect different application characteristics, and th e transition from function\npoints to lines of code.\n7.1.5 COCOMO 2: Variations on a Theme\nCOCOMO 2 is a revision of the 1981 COCOMO model, tuned to the li fe cycle\npractices of the 1990s and 2000s. It reﬂects our cumulative e xperience with and\n162 COST ESTIMATION\nknowledge of cost estimation. By comparing its constituent s with those of previous\ncost estimation models, it also offers us a means to learn abo ut signiﬁcant changes in\nour trade over the past decades.\nCOCOMO 2 provides three increasingly detailed cost estimat ion models. These\nmodels can be used for different types of projects, as well as during different stages of\na single project:\n– the Application Composition model, mainly intended for prototyping efforts,\nfor instance to resolve user interface issues (Its name sugg ests heavy use\nof existing components, presumably in the context of a power ful CASE\nenvironment.)\n– the Early Design model, aimed at the architectural design stage\n– the Post-Architecture model for the actual development stage of a software\nproduct\nThe Post-Architecture model can be considered an update of t he original COCOMO\nmodel; the Early Design model is an FPA-like model; and the Ap plication Composition\nmodel is based on counting system components of a large granu larity, such as screens\nand reports.\nThe Application Composition model is based on counting Obje ct Points. Object\nPoints have nothing to do with objects as in object-oriented development. In this\ncontext, objects are screens, reports, and 3GL modules.\nThe roots of this type of model can be traced back to several va riations on FPA-\ntype size measures. Function points as used in FPA are intend ed to be a user-oriented\nmeasure of system function. The user functions measured are the inputs, outputs,\ninquiries, etc. We may conjecture that these user-function s are technology-dependent,\nand that FPA primarily reﬂects the batch-oriented world of t he 1970s.\nPresent-day administrative systems are perhaps better cha racterized by their\nnumber of", "token_count": 512, "start_token": 98406, "end_token": 98918, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 214, "text": " user-function s are technology-dependent,\nand that FPA primarily reﬂects the batch-oriented world of t he 1970s.\nPresent-day administrative systems are perhaps better cha racterized by their\nnumber of menus or screens. This line of thought has been purs ued in various studies.\nBanker et al. (1991) compared Object Points with Function Po ints for a sample of\nsoftware projects, and found that Object Points did almost a s well as Function Points.\nObject Points, however, are easier to determine, and at an ea rlier point in time.\nTotal effort is estimated in the Application Composition mo del as follows:\n1. Estimate the number of screens, reports, and 3GL componen ts in the applica-\ntion.\n2. Determine the complexity level of each screen and report ( simple, medium or\ndifﬁcult). 3GL components are assumed to be always difﬁcult . The complexity\nof a screen depends on the number of views and tables it contai ns. The\ncomplexity of a report depends on the number of sections and t ables it\ncontains. A classiﬁcation table similar to those in FPA (see ﬁgure 7.9 for an\nexample) is used to determine these complexity levels.\n7.1. ALGORITHMIC MODELS 163\n3. Use the numbers given in ﬁgure 7.10 to determine the relati ve effort (in Object\nPoints) to implement the object.\n4. The sum of the Object Points for the individual objects yie lds the number of\nObject Points for the whole system.\n5. Estimate the reuse percentage, resulting in the number of New Object Points\n(NOP) as follows: /C6/C7/C8 /BP /C7/CQ/CY/CT \r/D8/C8/D3/CX/D2/D8/D7 /A2 /B4/BD/BC/BC /A0 /B1 /CA /CT/D9/D7/CT /B5 /BP /BD/BC/BC .\n6. Determine a productivity rate /C8/CA /C7/BW /BP /C6/C7/C8 /BP man-month. This productivity", "token_count": 512, "start_token": 98868, "end_token": 99380, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 215, "text": "CT /B5 /BP /BD/BC/BC .\n6. Determine a productivity rate /C8/CA /C7/BW /BP /C6/C7/C8 /BP man-month. This productivity\nrate depends on the experience and capability of both the dev elopers and the\nmaturity of the CASE environment they use. It varies from 4 (v ery low) to 50\n(very high).\n7. Estimate the number of man-months needed for the project: /BX /BP /C6/C7/C8 /BP /C8/CA /C7/BW .\n# of views\n# and source of data tables\ntotal /BO 4 total /BO 8 total /AL /BK\n(/BO 2 on server (/BE /A0 /BF on server (/BQ 3 on server\n/BO 3 on client) /BF /A0 /BH on client) /BQ 5 on client)\n/BO 3 simple simple medium\n/BF /A0 /BJ simple medium difﬁcult\n/BQ 8 medium difﬁcult difﬁcult\nFigure 7.9 Complexity levels for screens\nObject type Complexity\nsimple medium difﬁcult\nScreen 1 2 3\nReport 2 5 8\n3GL component 10\nFigure 7.10 Counting Object Points\n164 COST ESTIMATION\nThe Early Design model uses unadjusted function points (UFP s) as its basic size\nmeasure. These unadjusted function points are counted in th e same way they are\ncounted in FPA. Next, the unadjusted function points are con verted to Source Lines\nOf Code (SLOC), using a ratio SLOC/UFP which depends on the pr ogramming\nlanguage used. In a typical environment, each UFP may corres pond to, say, 91 lines of\nPascal, 128 lines of C, 29 lines of C++, or 320 lines of assembl y language. Obviously,\nthese numbers are environment-speciﬁc.\nThe Early Design model does not use the FPA scheme to account f or application\ncharacteristics. Instead, it uses a set of seven cost driver s, which are a combination of\nthe full set of cost drivers of the Post-Architecture model. The intermediate, reduced\nset of cost drivers", "token_count": 512, "start_token": 99330, "end_token": 99842, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 216, "text": " account f or application\ncharacteristics. Instead, it uses a set of seven cost driver s, which are a combination of\nthe full set of cost drivers of the Post-Architecture model. The intermediate, reduced\nset of cost drivers is:\n/AF product reliability and complexity, which is a combination of the required\nsoftware reliability, database size, product complexity a nd documentation\nneeds cost drivers\n/AF required reuse, which is equivalent to its Post-Architectu re counterpart\n/AF platform difﬁculty, which combines execution time, main st orage constraints,\nand platform volatility\n/AF personnel experience, which combines application, platfo rm, and tool experi-\nence\n/AF personnel capability, which combines analyst and programm er capability and\npersonnel continuity.\n/AF facilities, which is a combination of the use of software too ls and multi-site\ndevelopment\n/AF schedule, which again equals its Post-Architecture counte rpart\nThese cost drivers are rated on a seven-point scale, ranging from extra low to extra\nhigh. The values assigned are similar to those in ﬁgure 7.11. Thus, the nominal values\nare always 1.00, and the values become larger or smaller as th e cost driver is estimated\nto deviate further from the nominal rating. After the unadju sted function points have\nbeen converted to Kilo Source Lines Of Code ( /C3 /CB /C4/C7 /BV ), the cumulative effect of\nthe cost drivers is accounted for by the formula\n/BX /BP /C3/CB/C4/C7/BV /A2\n/CH\n/CX\ncost driver\n/CX\nFinally, the Post-Architecture model is the most detailed m odel. Its basic effort\nequation is very similar to that of the original COCOMO model :\n/BX /BP /CP /A2 /C3/CB/C4/C7/BV\n/CQ\n/A2\n/CH\n/CX\ncost driver\n/CX\n7.1. ALGORITHMIC MODELS 165\nIt differs from the original COCOMO model in its set of cost dr ivers, the use of lines\nof code as its base measure, and the range of values of the expo n", "token_count": 512, "start_token": 99792, "end_token": 100304, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 217, "text": " ALGORITHMIC MODELS 165\nIt differs from the original COCOMO model in its set of cost dr ivers, the use of lines\nof code as its base measure, and the range of values of the expo nent /CQ .\nThe differences between the COCOMO and COCOMO 2 set of cost dr ivers\nreﬂect major changes in the ﬁeld. The set of COCOMO 2 cost driv ers and\nthe associated effort multipliers are given in ﬁgure 7.11. T he values of the effort\nmultipliers in this ﬁgure are the result of calibration on a c ertain set of projects. The\nchanges are as follows:\n/AF Four new cost drivers have been introduced: required reusab ility, documentation\nneeds, personnel continuity, and multi-site development. They reﬂect the\ngrowing inﬂuence of the corresponding aspects on developme nt cost.\n/AF Two cost drivers have been dropped: computer turnaround tim e and use of\nmodern programming practices. Nowadays, developers use wo rkstations and\n(batch-processing) turnaround time is no longer an issue. M odern programming\npractices have evolved into the broader notion of mature sof tware engineering\npractices, which are dealt with in the exponent /CQ of the COCOMO 2 effort\nequation.\n/AF The productivity inﬂuence, i.e. the ratio between the highe st and lowest value,\nof some cost drivers has been increased (analyst capability , platform experience,\nlanguage and tools experience) or decreased (programmer ca pability).\nIn COCOMO 2, the user may use both /C3/CB/C4/C7/BV and /CD/BY/C8 as a base measure. It is\nalso possible to use /CD/BY/C8 for part of the system. The /CD/BY/C8 counts are converted to\n/C3/CB/C4/C7/BV counts as in the Early Design model, after which the effort eq uation applies.\nRather than having three ‘modes’, with slightly different v alues for the exponent /CQ\nin the effort equation, COCOMO 2 has a much", "token_count": 512, "start_token": 100254, "end_token": 100766, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 218, "text": " Design model, after which the effort eq uation applies.\nRather than having three ‘modes’, with slightly different v alues for the exponent /CQ\nin the effort equation, COCOMO 2 has a much more elaborate sca ling model. This\nmodel uses ﬁve scale factors /CF\n/CX\n, each of which is rated on a six-point scale from very\nlow (5) to extra high (0). The exponent /CQ for the effort equation is then determined\nby the formula:\n/CQ /BP /BD /BM /BC/BD /B7 /BC /BM /BC/BD /A2\n/CG\n/CX\n/CF\n/CX\nSo, /CQ can take on values in the range 1.01 to 1.26, thus giving a more ﬂexible rating\nscheme than that used in the original COCOMO model.\nThe scale factors used in COCOMO 2 are:\n/AF precedentedness, indicating the novelty of the project to t he development\norganization. Aspects like the experience with similar sys tems, the need for\ninnovative architectures and algorithms, and the concurre nt development of\nhardware and software are reﬂected in this factor.\n/AF development ﬂexibility, reﬂecting the need for conformanc e with pre-established\nand external interface requirements, and a possible premiu m on early comple-\ntion.\n166 COST ESTIMATION\n/AF architecture/risk resolution, which reﬂects the percenta ge of signiﬁcant risks\nthat have been eliminated. In many cases, this percentage wi ll be correlated\nwith the percentage of signiﬁcant module interfaces speciﬁ ed, i.e. architectural\nchoices made.\n/AF team cohesion, accounting for possible difﬁculties in stak eholder interactions.\nThis factor reﬂects aspects like the consistency of stakeho lder objectives and\ncultures, and the experience of the stakeholders in acting a s a team.\n/AF process maturity, reﬂecting the maturity of the project org anization according\nto the Capability Maturity Model (see section 6.6).\nOnly the �", "token_count": 512, "start_token": 100716, "end_token": 101228, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 219, "text": " the stakeholders in acting a s a team.\n/AF process maturity, reﬂecting the maturity of the project org anization according\nto the Capability Maturity Model (see section 6.6).\nOnly the ﬁrst two of these factors were, in a crude form, accou nted for in the original\nCOCOMO model.\nThe original COCOMO model allows us to handle reuse in the fol lowing way.\nThe three main development phases, design, coding and integ ration, are estimated\nto take 40%, 30% and 30% of the average effort, respectively. Reuse can be catered\nfor by separately considering the fractions of the system th at require redesign ( /BW/C5 ),\nrecoding ( /BV/C5 ) and re-integration ( /C1/C5 ). An adjustment factor /BT/BT/BY is then given by\nthe formula\n/BT/BT/BY /BP /BC /BM /BG /BW/C5 /B7 /BC /BM /BF /BV/C5 /B7 /BC /BM /BF /C1/C5\nAn adjusted value /BT/C3/C4/C7/BV , given by\n/BT/C3/C4/C7/BV /BP /C3/C4/C7/BV /A2 /BT/BT/BY /BP /BD/BC/BC\nis next used in the COCOMO formulae, instead of the unadjuste d value /C3/C4/C7/BV . In\nthis way a lower cost estimate is obtained if part of the syste m is reused.\nBy treating reuse this way, it is assumed that developing reu sable components\ndoes not require any extra effort. You may simply reap the ben eﬁts when part of a\nsystem can be reused from an earlier effort. This assumption does not seem to be very\nrealistic. Reuse does not come for free (see also chapter ??).\nCOCOMO 2 uses a more elaborate scheme to handle reuse effects . This scheme\nreﬂects two additional factors that impact the cost of reuse : the quality of the\ncode being reused and the amount of effort needed to test the a pplicability of the\ncomponent to be reused.\n", "token_count": 512, "start_token": 101178, "end_token": 101690, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 220, "text": " This scheme\nreﬂects two additional factors that impact the cost of reuse : the quality of the\ncode being reused and the amount of effort needed to test the a pplicability of the\ncomponent to be reused.\nIf the software to be reused is strongly modular, strongly ma tches the application\nin which it is to be reused, and the code is well-organized and properly documented,\nthen the extra effort needed to reuse this code is relatively low, and estimated to\nbe 10%. This penalty may be as high as 50% if the software exhib its low coupling\nand cohesion, is poorly documented, and so on. This extra eff ort is denoted by the\nsoftware understanding increment /CB/CD .\nThe degree of assessment and assimilation ( /BT/BT ) denotes the effort needed\nto determine whether a component is appropriate for the pres ent application. It\n7.1. ALGORITHMIC MODELS 167\nRating\nCost drivers Very Low Nominal High Very Extra\nlow high high\nProduct factors\nReliability required 0.75 0.88 1.00 1.15 1.39\nDatabase size 0.93 1.00 1.09 1.19\nProduct complexity 0.75 0.88 1.00 1.15 1.30 1.66\nRequired reusability 0.91 1.00 1.14 1.29 1.49\nDocumentation needs 0.89 0.95 1.00 1.06 1.13\nPlatform factors\nExecution time constraints 1.00 1.11 1.31 1.67\nMain storage constraints 1.00 1.06 1.21 1.57\nPlatform volatility 0.87 1.00 1.15 1.30\nPersonnel factors\nAnalyst capability 1.50 1.22 1.00 0.83 0.67\nProgrammer capability 1.37 1.16 1.00 0.87 0.74\nApplication experience 1.22 1.10 1.00 0.89 0.81\nPlatform experience 1.24 1.10 1.00 0.92 0.84\nLanguage and tool experience 1.25 1.12 1.00 0.88 0.81\nPersonnel continuity 1.24 1.10 1.00 0.92 0.84\nProject factors\nUse of software tools 1.24 1.12 1.00 0.86 0.72\nMulti-site development 1.25", "token_count": 512, "start_token": 101640, "end_token": 102152, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 221, "text": "\nPersonnel continuity 1.24 1.10 1.00 0.92 0.84\nProject factors\nUse of software tools 1.24 1.12 1.00 0.86 0.72\nMulti-site development 1.25 1.10 1.00 0.92 0.84 0.78\nRequired development schedule 1.29 1.10 1.00 1.00 1.00\nFigure 7.11 Cost drivers and associated effort multipliers in COCOMO 2 ( Source: B.W.\nBoehm et al. , COCOMO II Model Deﬁnition Manual, University of Southern California,\n1997.)\nranges from 0% (no extra effort required) to 8% (extensive te st, evaluation and\ndocumentation required).\nBoth these percentages are added to the adjustment factor /BT/BT/BY , yielding the\nequivalent kilo number of new lines of code, /BX/C3/C4/C7/BV :\n/BX/C3/C4/C7/BV /BP /C3/C4/C7/BV /A2 /B4 /BT/BT/BY /B7 /CB/CD /B7 /BT/BT /B5 /BP /BD/BC/BC\n168 COST ESTIMATION\n7.2 Guidelines for Estimating Cost\nThe models discussed in the preceeding section are based on d ata about past projects.\nOne of the main problems in applying these models is the sheer lack of quantitative\ndata about past projects. There simply is not enough data ava ilable. Though the\nimportance of such a database is now widely recognized we sti ll do not routinely\ncollect data on current projects. It seems as if we cannot spa re the time to collect data;\nwe have to write software. DeMarco (1982) makes a comparison with the medieval\nbarber who also acted as a physician. He could have made the sa me objection: ‘We\ncannot afford the time to take our patient’s temperature, si nce we have to cut his hair.’\nWe thus have to shift to other methods to estimate costs. Thes e other methods\nare based on the expertise of the estimators. In doing so, cer tain traps have to be\ncircumvented. It is particularly important to prevent poli", "token_count": 512, "start_token": 102102, "end_token": 102614, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 222, "text": " to shift to other methods to estimate costs. Thes e other methods\nare based on the expertise of the estimators. In doing so, cer tain traps have to be\ncircumvented. It is particularly important to prevent poli tical arguments from entering\nthe arena. Typical lines of reasoning that reﬂect political reasoning are:\n/AF We were given 12 months to do the job, so it will take 12 months. This might\nbe seen as a variation of Parkinson’s Law: work ﬁlls the time a vailable.\n/AF We know that our competitor put in a bid of $1M, so we need to sch edule a\nbid of $0.9M. This is sometimes referred to as ‘price to win’.\n/AF We want to show our product at the trade show next year, so the s oftware\nneeds to be written and tested within the next nine months, th ough we realize\nthat this is rather tight. This could be termed the ‘budget’ m ethod of cost\nestimation.\n/AF Actually, the project needs one year, but I can’t sell that to my boss. We know\nthat ten months is acceptable, so we settle for ten months.\nPolitically-colored estimates can have disastrous effect s, as has been shown all too\noften during the short history of our ﬁeld. Political argume nts almost always play a\nrole if estimates are being given by people directly involve d in the project, such as\nthe project manager, or someone reporting to the project man ager. Very soon, then,\nestimates will inﬂuence, or be inﬂuenced by, the future asse ssment of those persons.\nTo quote DeMarco (1982): ”one chief villain is the policy tha t estimates shall be used\nto create incentives.”\nJørgensen (2005) gives the following guidelines for expert -based effort estimation:\n– Do not mix estimation, planning, and bidding,\n– Combine estimation methods,\n– Ask for justiﬁcation,\n– Select experts with experience from similar projects,\n– Accept and assess uncertainty,\n7.2. GUIDELINES FOR ESTIMATING COST 169\n– Provide learning opportunities, and\n– Consider postponing or avoiding effort estimation.\nThe", "token_count": 512, "start_token": 102564, "end_token": 103076, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 223, "text": " experts with experience from similar projects,\n– Accept and assess uncertainty,\n7.2. GUIDELINES FOR ESTIMATING COST 169\n– Provide learning opportunities, and\n– Consider postponing or avoiding effort estimation.\nThe politically-colored estimation methods mentioned abo ve all mix up estimation,\nplanning and bidding. These have different goals, though. E stimation’s only goal is\naccuracy. Planning involves risk assessment and schedule. Bidding is about winning a\ncontract. Though these activities have different goals, th ey are of course related. A\nlow bid for instance generally incurs a tight schedule and hi gher risks.\nAn interesting experiment on the effects of bidding on the re mainder of a project\nis described in (Jørgensen and Grimstad, 2004). In this expe riment, the authors study\nwhat is called the winner’s curse , a phenomenon known from auctions, where players are\nuncertain of the value of a good when they bid. The highest bid wins, but the winner\nmay be left with an item that’s worth less than paid for. The te rm was ﬁrst coined in\nthe 1950s, when oil industries had no accurate way to estimat e the value of their oil\nﬁelds. In the software ﬁeld, it has the following characteri stics:\n– Software providers differ in optimism in their estimates o f most likely cost:\nsome are over-optimistic, some are realistic, and some are p essimistic.\n– Software providers with over-optimistic estimates tend t o have the lowest bids.\n– Software clients require a ﬁxed-price contract.\n– Software clients tend to select a provider with a low bid.\nThe result often is a Pyrrhic victory, a contract that result s in low or negative proﬁts\nto the bidder. But such a contract might also be risky for the c lient. Jørgensen and\nGrimstad (2004) describe an experiment in which they actual ly asked 35 companies\nfor bids on a certain requirements speciﬁcation. Next, four companies were asked to\nimplement the system. They found that the companies with the lowest bids incurred\nthe greatest risks.\nVacuuming a rug in two orthogonal directions is likely to pic k up more dirt\nthan vacuum", "token_count": 512, "start_token": 103026, "end_token": 103538, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 224, "text": " four companies were asked to\nimplement the system. They found that the companies with the lowest bids incurred\nthe greatest risks.\nVacuuming a rug in two orthogonal directions is likely to pic k up more dirt\nthan vacuum that rug twice in the same direction. Likewise, t he combination of\nsufﬁciently different estimation methods gives better est imates. So one may combine\na COCOMO estimate with that of an expert, or estimates from ex perts with a\ndifferent background. In this way, the bias that is inherent in a method or class of\nexperts is mitigated.\nEstimators should be held accountable for their estimates. Lederer and Prasad\n(2000) found that the use of estimates in performance evalua tions of software\nmanagers and professionals is the only practice that leads t o better estimates. In a\nslightly weaker form, one may at least ask for a justiﬁcation of the estimate. Such a\njustiﬁcation could refer to a calibrated model used, or a wor k breakdown structure in\nwhich cost estimates of components are derived from those in similar projects.\nFor lack of hard data, the cost of a software development proj ect is often\nestimated through a comparison with earlier projects. If th e estimator is very\n170 COST ESTIMATION\nexperienced, reasonable cost estimates may result. Howeve r, the learning effect of\nearlier experiences may lead to estimates that are too pessi mistic in this case. We may\nexpect that experience gained with a certain type of applica tion leads to a higher\nproductivity for subsequent projects. Similar applicatio ns thus give rise to lower costs.\n(McClure, 1968) describes a situation in which a team was ask ed to develop a\nFORTRAN compiler for three different machines. The effort n eeded (in man-months)\nfor these three projects is given in ﬁgure 7.12.\nCompiler Number of man-months needed\n1 72\n2 36\n3 14\nFigure 7.12 Learning effect in writing a FORTRAN compiler\nOn the other hand, peculiar circumstances and particular ch aracteristics of a spe-\nciﬁc project tend to get insufﬁcient attention if cost is est imated through comparison\nwith earlier projects. For example, a simple change of", "token_count": 512, "start_token": 103488, "end_token": 104000, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 225, "text": " peculiar circumstances and particular ch aracteristics of a spe-\nciﬁc project tend to get insufﬁcient attention if cost is est imated through comparison\nwith earlier projects. For example, a simple change of scale (automation of a local\nlibrary with 25 000 volumes as opposed to a university librar y with over 1 000 000\nvolumes), slightly harsher performance requirements, a co mpressed schedule (which\nincurs a larger team and thus increases overhead because of c ommunication) may\nhave a signiﬁcant impact on the effort required in terms of ma n-months.\nCareless application of the comparison method of cost estim ation leads to\nestimates like: the cost of this project is equal to the cost o f the previous project.\nWe may also involve more than one expert in the estimation pro cess. In doing\nso, each expert gives an estimate based on his own experience and expertise. Factors\nthat are hard to quantify, such as personality characterist ics and peculiar project\ncharacteristics, may thus be taken into account. Here too, t he quality of the estimate\ncannot exceed the quality of the experts. The experts that pa rticipate in the estimate\nthen should have experience in simliar projects. It does not help all that much to ask\nadvice from an expert in ofﬁce automation type systems to pro vide an estimate for an\nair-trafﬁc control system.\nEstimates incur uncertainty. A cost estimate of, say, 100 ma n months might mean\nthat there is a 75% probability that the real cost of this proj ect is between 80 and 120\nmanmonths. It is not a point estimate. One method that aims to get a more reliable\nestimate is to have the expert produce more than one estimate . We all have the\ntendency to conceive an optimistic estimate as being realis tic. (Have you ever heard\nof a software system that got delivered ahead of time?) To obv iate this tendency,\nwe may employ a technique in which the expert is asked for thre e estimates: an\n7.3. DISTRIBUTION OF MANPOWER OVER TIME 171\noptimistic estimate /CP , a realistic estimate /D1 , and a pessimistic estimate /CQ . Using\na beta-distribution, the expected effort then is /BX /BP", "token_count": 512, "start_token": 103950, "end_token": 104462, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 226, "text": " DISTRIBUTION OF MANPOWER OVER TIME 171\noptimistic estimate /CP , a realistic estimate /D1 , and a pessimistic estimate /CQ . Using\na beta-distribution, the expected effort then is /BX /BP /B4 /CP /B7 /BG /D1 /B7 /CQ /B5 /BP /BI . Though this\nestimate will probably be better than the one simply based on the average of /CP and /CQ ,\nit seems justiﬁed to warn against too much optimism. Softwar e has the tendency to\ngrow, and projects have the tendency to far exceed the estima ted effort.\nTraining improves performance. This holds for skaters as we ll as software cost\nestimators. Studies in other ﬁelds show that inexperienced people tend to overestimate\ntheir abilities and performance. There is no reason to expec t the software ﬁeld to be\nany different. The resulting cost and schedule overruns are all to common. Harrison\n(2004) suggests that a prime reason for more mature organiza tions to have fewer\ncost overruns is not so much higher productivity or better pr ocesses, but greater\nself-knowledge. I concur the same is true for people estimat ing software cost.\nWhile executing a task, people have to make a number of decisi ons. These\ndecisions are strongly inﬂuenced by requirements set or pro posed. The cost estimate\nis one such requirement which will have an impact on the end re sult. We may imagine\na hypothetical case in which model A estimates the cost at 300 man-months. Now\nsuppose the project actually takes 400 man-months. If model B would have estimated\nthe project at 450 man-months, is model B better than model A? It is quite possible\nthat, starting from the estimate given by model B, the eventu al cost would have\nbeen 600 man-months. The project’s behavior is also inﬂuenc ed by the cost estimate.\nChoices made during the execution of a project are inﬂuenced by cost estimates\nderived earlier on. If a cost estimate is not needed, it is wis e not making one either.\n7.3 Distribution of Manpower over Time\nHaving obtained an estimate of the total number of man-month s needed for a given", "token_count": 512, "start_token": 104412, "end_token": 104924, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 227, "text": "derived earlier on. If a cost estimate is not needed, it is wis e not making one either.\n7.3 Distribution of Manpower over Time\nHaving obtained an estimate of the total number of man-month s needed for a given\nproject, we are still left with the question of how many calen dar months it will take.\nFor a project estimated at 20 man-months, the kind of schedul es you might think of,\ninclude:\n– 20 people work on the project for 1 month;\n– 4 people work on the project for 5 months;\n– 1 person works on the project for 20 months.\nThese are not realistic schedules. We noticed earlier that t he manpower needed is not\nevenly distributed over the time period of the project. From the shape of the Rayleigh\ncurve we ﬁnd that we need a slowly increasing manpower during the development\nstages of the project.\nCost estimation models generally provide us with an estimat e of the development\ntime (schedule)\n/CC as well. Contrary to the effort equations, the various model s show\na remarkable consistency when it comes to estimating the dev elopment time, as is\nshown in ﬁgure 7.13.\n172 COST ESTIMATION\nWalston--Felix /CC /BP /BE /BM /BH /BX\n/BC /BM /BF/BH\nCOCOMO (organic) /CC /BP /BE /BM /BH /BX\n/BC /BM /BF/BK\nCOCOMO 2 (nominal schedule) /CC /BP /BF /BM /BC /BX\n/BC /BM /BF/BF/B7/BC /BM /BE /A2 /B4 /CQ /A0 /BD /BM /BC/BD/B5\nPutnam /CC /BP /BE /BM /BG /BX\n/BD /BP /BF\nFigure 7.13 Relation between development time and effort\nThe values /CC thus computed represent nominal development times. It is wo rth-\nwhile studying ways to shorten these nominal schedules. Obv iously, shortening the\ndevelopment time means an increase in the number of people in volved in the project.\nIn terms of the Rayleigh curve model, shortening the develop ment time amounts\nto an increase of the value /CP ,", "token_count": 512, "start_token": 104874, "end_token": 105386, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 228, "text": "iously, shortening the\ndevelopment time means an increase in the number of people in volved in the project.\nIn terms of the Rayleigh curve model, shortening the develop ment time amounts\nto an increase of the value /CP , the speed-up factor which determines the initial slope\nof the curve. The peak of the Rayleigh curve then shifts to the left and at the same\ntime it shifts up. We thus get a faster increase of manpower re quired at the start of\nthe project and a higher maximum workforce.\nSuch a shift does not go unpunished. Different studies show t hat individual\nproductivity decreases as team size grows. There are two maj or causes of this\nphenomenon:\n/AF As the team gets larger, the communication overhead increas es, since more\ntime will be needed for consultation with other team members , tuning of tasks,\nand the like.\n/AF If manpower is added to a team during the execution of a projec t, the total\nteam productivity decreases at ﬁrst. New team members are no t productive\nright from the start. At the same time, they require time from the other team\nmembers during their learning process. Taken together, thi s causes a decrease\nin total productivity.\nThe combination of these two observations leads to the pheno menon that has become\nknown as Brooks’ Law: Adding manpower to a late project only m akes it later.\nBy analyzing a large amount of project data, Conte et al. found the following\nrelation between average productivity /C4 (measured in lines of code per man-month)\nand average team size /C8 (Conte et al., 1986):\n/C4 /BP /BJ/BJ/BJ /C8\n/A0 /BC /BM /BH\nIn other words, individual productivity decreases exponen tially with team size.\nA theoretical underpinning hereof can be given on account of Brooks’ observation\nregarding the number of communication links between the peo ple involved in a\nproject. This number is determined by the size and structure of the team. If, in\na team of size /C8 , each member has to coordinate his activities with those of a ll\n7.4. SUMMARY 173\nother members, the number of communication links is /C8 /B4 /C8 /A0 /BD/", "token_count": 512, "start_token": 105336, "end_token": 105848, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 229, "text": " /C8 , each member has to coordinate his activities with those of a ll\n7.4. SUMMARY 173\nother members, the number of communication links is /C8 /B4 /C8 /A0 /BD/B5 /BP /BE . If each member\nneeds to communicate with one other member only, this number is /C8 /A0 /BD . Less\ncommunication than that seems unreasonable, since we would then have essentially\nindependent teams. (If we draw team members as nodes of a grap h and communication\nlinks as edges, we expect the graph to be connected.)\nThe number of communication links thus varies from roughly /C8 to roughly /C8\n/BE\n/BP /BE .\nIn a true hierarchical organization, this leads to /C8\n/AB\ncommunication paths, with\n/BD /BO /AB /BO /BE .\nFor an individual team member, the number of communication l inks varies from 1\nto /C8 /A0 /BD . If the maximum individual productivity is /C4 and each communication link\nresults in a productivity loss /D0 , the average productivity is\n/C4\n/AD\n/BP /C4 /A0 /D0 /B4 /C8 /A0 /BD/B5\n/AD\nwhere /AD , with /BC /BO /AD /AK /BD , is a measure of the number of communication links. (We\nassume that there is at least one person who communicates wit h more than one other\nperson, so /AD /BQ /BC .) For a team of size /C8 , this leads to a total productivity\n/C4\n/D8/D3/D8\n/BP /C8 /A2 /C4\n/AD\n/BP /C8 /B4 /C4 /A0 /D0 /B4 /C8 /A0 /BD/B5\n/AD\n/B5\nFor a given set of values for /C4 , /D0 and /AD , this is a function which, for increasing\nvalues of /C8 , goes from 0 to some maximum and then decreases again. There t hus is a\ncertain optimum team size /C8\n/D3/D4/D8\nthat leads to a maximum team productivity. The team\nproductivity for different values of the /C8 is given", "token_count": 512, "start_token": 105798, "end_token": 106310, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 230, "text": " decreases again. There t hus is a\ncertain optimum team size /C8\n/D3/D4/D8\nthat leads to a maximum team productivity. The team\nproductivity for different values of the /C8 is given in ﬁgure 7.14. Here, we assume that\nindividual productivity is 500 /C4/C7/BV /BP man-month ( /C4 /BP /BH/BC/BC ), and the productivity\nloss is 10% per communication link ( /D0 /BP /BH/BC ). With full interaction between team\nmembers ( /AD /BP /BD ) this results in an optimum team size of 5.5 persons.\nEverything takes time. We can not shorten a software develop ment project\nindeﬁnitely by exchanging time against people. Boehm sets t he limit at 75% of the\nnominal development time, on empirical grounds. A system th at has to be delivered\ntoo fast, gets into the ‘impossible region’. The chance of su ccess becomes almost nil\nif the schedule is pressed too far. See also ﬁgure 7.15.\nIn any case, a shorter development time induces higher costs . We may use the\nfollowing rule of thumb: compressing the development time b y X% results in a cost\nincrease of X% relative to the nominal cost estimate (Boehm, 1984a).\n7.4 Summary\nIt remains to be seen whether we will ever get one, general, co st estimation model.\nThe number of parameters that impact productivity simply se ems to be too large.\nYet, each organization may develop a model which is well suit ed for projects to\nbe undertaken within that organization. An organization ma y, and should, build a\ndatabase with data on its own projects. Starting with a model like COCOMO 2,\nthe different parameters, i.e. applicable cost drivers and values for the associated\n174 COST ESTIMATION\nTeam size Individual Total\nproductivity productivity\n1 500 500\n2 450 900\n3 400 1200\n4 350 1400\n5 300 1500\n5.5 275 1512\n6 250 1500\n7 200 1400\n8 150 1200\nFigure 7.14 Impact of team size on productivity\neffort multipliers, may then be determined. In the course of time, the model becomes\nmore closely tuned to the", "token_count": 512, "start_token": 106260, "end_token": 106772, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 231, "text": "12\n6 250 1500\n7 200 1400\n8 150 1200\nFigure 7.14 Impact of team size on productivity\neffort multipliers, may then be determined. In the course of time, the model becomes\nmore closely tuned to the organizational environment, resu lting in better and better\nestimates. Reifer (2000) for example describes how COCOMO I I can be adapted to\nestimate Web-based software development projects.\nThough we advocate the use of algorithmic cost estimation mo dels, a word of\ncaution should be made. Present-day models of this kind are n ot all that good yet. At\nbest, they yield estimates which are at most 25% off, 75% of th e time, for projects used to\nderive the model . For the time being, expert-based cost estimates are a viabl e alternative.\nEven when a much better performance is realized, some proble ms remain when\nusing the type of cost estimation model obtained in this way:\n/AF Even though a model like COCOMO 2 looks objective, a fair amou nt of\nsubjectivity is introduced through the need to assign value s to the various\nlevels of a number of cost drivers. Based on an analysis of his torical project\ndata, (Jones, 1986) lists 20 factors which certainly inﬂuen ce productivity, and\nanother 25 for which it is probable. The set of COCOMO 2 cost dr ivers\nalready allows for a variation of 1:800. A much smaller numbe r of relevant cost\ndrivers would reduce a model’s vulnerability to the subject ive assessment of\nproject characteristics.\n/AF The models are based on data from old projects and reﬂect the technology of\nthose projects. In some cases, the project data are even fair ly old. The impact\nof more recent developments cannot easily be taken into acco unt, since we do\nnot have sufﬁcient data on projects which exhibit those char acteristics.\n/AF Almost all models take into account attributes that impact t he initial develop-\nment of software. Attributes which speciﬁcally relate to ma intenance activities\n7.4. SUMMARY 175\nFigure 7.15 The impossible region ( Source: B.W. Boehm , Software Engineering Eco-\nnomics, ﬁg. 27-8/page", "token_count": 512, "start_token": 106722, "end_token": 107234, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 232, "text": " to ma intenance activities\n7.4. SUMMARY 175\nFigure 7.15 The impossible region ( Source: B.W. Boehm , Software Engineering Eco-\nnomics, ﬁg. 27-8/page 471, 1981, Reprinted by permission of Prentic e-Hall, Inc., Englewood Cliffs,\nNJ)\nare seldom taken into account. Also, factors like the amount of documentation\nrequired, the number of business trips (in case of multisite development) are\noften lacking. Yet, these factors may have a signiﬁcant impa ct on the effort\nneeded.\nAlgorithmic models usually result from applying statistic al techniques like regression\nanalysis to a given set of project data. For a new project, the parameters of the\nmodel have to be determined, and the model yields an estimate and, in some cases, a\nconﬁdence interval.\nA problem of a rather different nature is the following: In th e introduction to this\nchapter we compared software cost estimation with cost esti mation for laying out a\ngarden. When laying out a garden, we often follow a rather dif ferent line of thought,\nnamely: given a budget of, say, $10 000, what possibilities a re there? What happens\n176 COST ESTIMATION\nif we trade off a pond against something else?\nSomething similar is also possible with software. Given a bu dget of $100 000 for\nlibrary automation, what possibilities are there? Which us er interface can we expect,\nwhat will the transaction speed be, how reliable will the sys tem be? To be able to\nanswer this type of question, we need to be able to analyze the sensitivity of an\nestimate to varying values of relevant attributes. Given th e uncertainty about which\nattributes are relevant to start with, this trade-off probl em is still largely unsolved.\nFinally, estimating the cost of a software development proj ect is a highly dynamic\nactivity. Not only may we switch from one model to another dur ing the course of a\nproject, estimates will also be adjusted on the basis of expe riences gained. Switching\nto another model during the execution of a project is possibl e, since we may expect\nto get more reliable data while the project is making progres s. We may, for instance,\nimagine using the", "token_count": 512, "start_token": 107184, "end_token": 107696, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 233, "text": "iences gained. Switching\nto another model during the execution of a project is possibl e, since we may expect\nto get more reliable data while the project is making progres s. We may, for instance,\nimagine using the series of increasingly detailed COCOMO 2 m odels.\nWe cannot, and should not, rely on a one-shot statistical cos t estimate. Controlling\na software development project implies a regular check of pr ogress, a regular check of\nestimates made, re-establishing priorities and weighing s takes, as the project is going\non.\n7.5 Further Reading\nEarly cost estimation models are described in (Nelson, 1966 ) and (Wolverton, 1974).\nThe Walston--Felix model is described in (Walston and Felix , 1977). The model of\nPutnam and Norden is described in (Norden, 1970), (Putnam, 1 978). (Boehm, 1981)\nis the deﬁnitive source on the original COCOMO model. COCOMO 2 is described\nin (Boehm et al., 1995) and (Boehm et al. , 1997).\nFunction point analysis (FPA) is developed by Albrecht (Alb recht, 1979; Albrecht\nand Gaffney, 1983). Critical appraisals of FPA can be found i n (Symons, 1988),\n(Kemerer, 1993), (Kemerer and Porter, 1992), (Abran and Rob illard, 1992) and\n(Abran and Robillard, 1996). A detailed discussion of funct ion points, its counting\nprocess and some case studies, is provided by (Garmus and Her ron, 1996).\nThe relation between project behavior and its cost estimate is discussed in\n(Abdel-Hamid et al., 1993). Guidelines for cost estimation are given in (Boehm and\nSullivan, 1999), (Fairley, 2002) and (Jørgensen, 2005). (S oftware, 2000) is a special\nissue devoted to software estimation.\nExercises\n1. In which ways may political arguments inﬂuence cost estim ates?\n2. What does the Walston--Felix model look like?\n3. How may the Rayleigh-curve be related to software cost est imation?\n7.", "token_count": 512, "start_token": 107646, "end_token": 108158, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 234, "text": " arguments inﬂuence cost estim ates?\n2. What does the Walston--Felix model look like?\n3. How may the Rayleigh-curve be related to software cost est imation?\n7.5. FURTHER READING 177\n4. Give a sketch of Function Point Analysis (FPA).\n5. Give a sketch of COCOMO 2.\n6. Discuss the major differences between COCOMO 2 and FPA.\n7. Give a rationale for Brooks’ Law.\n8. In which sense does Function Point Analysis (FPA) reﬂect t he batch-oriented\nworld of the 1970s?\n9. How may early cost estimates inﬂuence the way in which a pro ject is\nexecuted?\n10. Why is it difﬁcult to compare different cost estimation m odels?\n11. Suppose you are involved in a project which is estimated t o take 100 man-\nmonths. How would you estimate the nominal calendar time req uired for this\nproject? Suppose the project is to be ﬁnished within six cale ndar months. Do\nyou think such a schedule compression is feasible?\n12. Why should software cost models be recalibrated from tim e to time?\n13. /DJ How would you calibrate the COCOMO 2 model to ﬁt software deve lop-\nment in your organization?\n14. /DI Suppose you are managing a project which is getting behind sc hedule.\nPossible actions include: renegotiating the time schedule , adding people to\nthe project, and renegotiating quality requirements. In wh ich ways can these\nactions shorten the time schedule? Can you think of other way s to ﬁnish the\nproject on time?\n15. /DI Suppose you have a LOC-based cost estimation model availabl e whose\nparameters are based on projects from your own organization that used\nCOBOL as the implementation language. Can you use this model to estimate\nthe cost of a project whose implementation language is Pasca l? What if the\nmodel is based on projects that used C?\n16. /DI Can you give an intuitive rationale for the values of the COCO MO 2 cost\ndrivers (ﬁgure 7.11) that relate to project attributes?\n8\nProject Planning and Control", "token_count": 512, "start_token": 108108, "end_token": 108620, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 235, "text": " used C?\n16. /DI Can you give an intuitive rationale for the values of the COCO MO 2 cost\ndrivers (ﬁgure 7.11) that relate to project attributes?\n8\nProject Planning and Control\nLEARNING OBJECTIVES\n/AF To appreciate looking at project control from a system point of view\n/AF To be aware of typical project situations, and ways in which p rojects can be\nsuccessfully dealt with in such situations\n/AF To understand how risks can be prevented from becoming probl ems\n/AF To know techniques for the day-to-day planning and control o f software\ndevelopment projects\n8.1. A SYSTEMS VIEW OF PROJECT CONTROL 179\nIn this chapter I try to reconcile the various approaches ske tched in chapters\n3--7. A taxonomy of software development projects is given, together with\nrecommended management practices for dealing with such pro jects. The\nchapter also deals with risk management and some well-known techniques for\nproject planning and control.\nSoftware development projects differ widely. These differ ences are reﬂected in\nthe ways in which these projects are organized and managed. F or some projects,\nthe budget is ﬁxed and the goal of the project is to maximize th e quality of\nthe end product. For others, quality constraints are ﬁxed in advance, and the\ngoal is to produce effectively a system that meets those qual ity constraints. If the\ndeveloping organization has considerable experience with the application domain\nand the requirements are ﬁxed and stable, a tightly structur ed approach may yield\na satisfactory solution. In applications with fuzzy requir ements and little previous\nexperience in the development team, a more agile approach ma y be desirable.\nIt is important to identify those project characteristics e arly on, because they\nwill inﬂuence the way a project is organized, planned and con trolled. In section 8.1,\nwe will discuss project control from a systems point of view. This allows us to\nidentify the major dimensions along which software develop ment projects differ.\nThese dimensions lead to a taxonomy of software development projects, which will\nbe discussed in section 8.2. For each of the project categori es distinguished, we will\nindicate how best to control the various entities identiﬁed in previous chapters. This", "token_count": 512, "start_token": 108570, "end_token": 109082, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 236, "text": "onomy of software development projects, which will\nbe discussed in section 8.2. For each of the project categori es distinguished, we will\nindicate how best to control the various entities identiﬁed in previous chapters. This\ntype of assessment is to be done at the project planning stage .\nThis assessment links global risk categories to preferred c ontrol situations. Daily\npractice, however, is more complex. An actual project faces many risks, each of\nwhich has to be handled in turn. Even risks for which we hoped t o have found an\nadequate solution, may turn into problems later on. Risk fac tors therefore have to\nbe monitored, and contingency plans have to be developed. Th e early identiﬁcation\nof risks and the development and carrying out of strategies t o mitigate these risks is\nknown as risk management . Risk management is discussed in section 8.3.\nSoftware development projects consist of a number of interr elated tasks. Some\nof these will have to be handled sequentially (a module canno t be tested until it has\nbeen implemented), while others may be handled in parallel ( different modules can\nbe implemented concurrently). The dependencies between ta sks can be depicted in\na network from which a project schedule can be derived. These and similar tools for\nthe micro-level planning and control of software developme nt projects are discussed\nin section 8.4.\n8.1 A Systems View of Project Control\nIn the preceding chapters, we discussed several entities th at need to be controlled.\nDuring the execution of a software development project, eac h of these entities needs\n180 PROJECT PLANNING AND CONTROL\nto be monitored and assessed. From time to time, adjustments will have to be made.\nTo be able to do so, we must know which entities can be varied, h ow they can be\nvaried, and what the effect of adjustments is.\nTo this end, we will consider project control from a systems p oint of view. We\nnow consider the software development project itself as a sy stem. Project control\nmay then be described in terms of:\n– the system to be controlled, i.e. the software development project;\n– the entity that controls the system, i.e. the project manag er, his organization\nand the decision rules he uses;\n– information which is used to guide the decision process. Th is information may\ncome from two", "token_count": 512, "start_token": 109032, "end_token": 109544, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 237, "text": " project;\n– the entity that controls the system, i.e. the project manag er, his organization\nand the decision rules he uses;\n– information which is used to guide the decision process. Th is information may\ncome from two sources. It may either come from the system bein g controlled\n(such as a notice of technical problems with a certain compon ent) or it may\nhave a source outside the system (such as a request to shorten development\ntime).\nThe variables that play a role in controlling a system may be c ategorized into three\nclasses: irregular variables, goal variables, and control variables.\nIrregular variables are those variables that are input to th e system being controlled.\nIrregular variables cannot be varied by the entity that cont rols the system. Their\nvalues are determined by the system’s environment. Example s of irregular variables\nare the computer experience of the user or the project stafﬁn g level.\nAn important precondition for effective control is knowled ge of the project’s\ngoals. In developing software, various conﬂicting goals ca n be distinguished. One\npossible goal is to minimize development time . Since time is often pressing, this goal is not\nunusual. Another goal might be to maximize efﬁciency , i.e. development should be done\nas cheaply as possible. Optimal use of resources (mostly man power) is then needed.\nYet a third possible goal is to maximize quality . Each of these goals is possible, but\nthey can be achieved only if it is known which goals are being p ursued. These goals\ncollectively make up the set of goal variables.\nFinally, the decision process is guided by the set of control variables. Control\nvariables are entities which can be manipulated by the proje ct manager in order to\nachieve the goals set forth. Examples of possible control va riables are the tools to be\nused, project organization, efﬁciency of the resulting sof tware.\nIt is not possible to make a rigid separation between the vari ous sets of variables.\nIt depends on the situation at hand whether a particular vari able should be taken as\nan irregular variable, goal variable, or control variable. If the requirements are stable\nand ﬁxed, one may for instance try to control the project by em", "token_count": 512, "start_token": 109494, "end_token": 110006, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 238, "text": " on the situation at hand whether a particular vari able should be taken as\nan irregular variable, goal variable, or control variable. If the requirements are stable\nand ﬁxed, one may for instance try to control the project by em ploying adequate\npersonnel and using a proper set of tools. For another projec t, manpower may be\nﬁxed and one may try to control the project by extending the de livery date, relaxing\nquality constraints, etc.\nHowever, in order to be able to control a project, the differe nt sets of variables\nmust be known. It must be known where control is, and is not, po ssible. This is only\n8.2. A TAXONOMY OF SOFTWARE DEVELOPMENT PROJECTS 181\none prerequisite, though. In systems theory, the following conditions for effective\ncontrol of a system are used:\n– the controlling entity must know the goals of the system;\n– the controlling entity must have sufﬁcient control variet y;\n– the controlling entity must have information on the state, input and output of\nthe system;\n– the controlling entity must have a conceptual control mode l. It must know how\nand to what extent the different variables depend on and inﬂu ence each other.\nWhen all these conditions are met, control can be rational, i n which case there is no\nuncertainty, since the controlling entity is completely in formed about every relevant\naspect. The control problem can then be structured and forma lized. Daily practice of\nsoftware development is different, though. There is insufﬁ cient room for control or\nthe effect of control actions is not known. Control then beco mes much more intuitive\nor primitive. It is based on intuition, experience, and rule s of thumb.\nThe degree to which a software development project can be con trolled increases\nas the control variety increases. This control variety is de termined by the number of\ncontrol variables and the degree to which they can be varied. As noticed before, the\ncontrol variety is project dependent.\nControlling software development means that we must be able to measure both\nthe project and the product. Measuring a project means that w e must we able to\nassess progress. Measuring a product means that we must be ab le to determine the\ndegree to which quality and functional requirements", "token_count": 512, "start_token": 109956, "end_token": 110468, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 239, "text": " able to measure both\nthe project and the product. Measuring a project means that w e must we able to\nassess progress. Measuring a product means that we must be ab le to determine the\ndegree to which quality and functional requirements are bei ng met.\nControlling software development projects implies that ef fective control actions\nare possible. Corrective actions may be required if progres s is not sufﬁcient or the\nsoftware does not comply with its requirements. Effective c ontrol means that we\nknow what the effect of control actions is. If progress is ins ufﬁcient and we decide to\nallocate extra manpower, we must understand the impact of th is extra manpower on\nthe time schedule. If the quality of a certain component is le ss than required and we\ndecide to allocate extra test time, we must know how much test time is required in\norder to achieve the desired quality.\nIn practice, controlling a software development project is not a rational process.\nThe ideal systems theory situation is not met. There are a num ber of uncertainties\nwhich make managing such projects a challenging activity. B elow, we will discuss a\nfew idealized situations, based on the uncertainty of vario us relevant aspects.\n8.2 A Taxonomy of Software Development Projects\nIn the preceding section, we identiﬁed several conditions t hat need to be satisﬁed\nin order to be able to control projects rationally. Since the se conditions are often\nnot met, we will have to rely on a different control mechanism in most cases. The\n182 PROJECT PLANNING AND CONTROL\ncontrol mechanism best suited to any given situation obviou sly depends on relevant\ncharacteristics of the project at hand.\nBased on an analysis of software development project charac teristics that are\nimportant for project control, we will distinguish several project situations, and\nindicate how projects can successfully be controlled in the se situations.\nWe will group project characteristics into three classes: p roduct characteristics,\nprocess characteristics, and resource characteristics. F rom the point of view of project\ncontrol, we are interested in the degree of certainty of those characteristics. For\nexample, if we have clear and stable user requirements, prod uct certainty is high.\nIf part of the problem is to identify user requirements, or th e user requirements\nfrequently change during the development project, product certainty is low.\n", "token_count": 512, "start_token": 110418, "end_token": 110930, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 240, "text": "example, if we have clear and stable user requirements, prod uct certainty is high.\nIf part of the problem is to identify user requirements, or th e user requirements\nfrequently change during the development project, product certainty is low.\nIf product certainty is high, control can be quite rational, insofar as it depends on\nproduct characteristics. Since we know what the product is s upposed to accomplish,\nwe may check compliance with the requirements and execute co rrective actions if\nneeded. If product certainty is low, this is not feasible. We either do not know what\nwe are aiming at, or the target is constantly moving. It is onl y reasonable to expect\nthat control will be different in those cases.\nFor the present discussion, we are interested only in projec t characteristics that\nmay differ between projects. Characteristics common to mos t or all of software\ndevelopment projects, such as the fact that they involve tea mwork, will not lead to\ndifferent control paradigms.\nWe will furthermore combine the characteristics from each o f the three categories\nidentiﬁed above, into one metric, the certainty of the corre sponding category. This\nleaves us with three dimensions along which software develo pment projects may\ndiffer:\n/AF Product certainty Product certainty is largely determined by two factors:\nwhether or not user requirements are clearly speciﬁed, as re gards both func-\ntionality and quality, and the volatility of those user requ irements. Other\nproduct characteristics are felt to have a lesser impact on o ur understanding of\nwhat the end-product should accomplish.\n/AF Process certainty The degree of (development) process certainty is determine d\nby such factors as: the possibility of redirecting the devel opment process, the\ndegree to which the process can be measured and the knowledge we have about\nthe effect of control actions, and the degree to which new, un known tools are\nbeing used.\n/AF Resource certainty The major determinant here is the availability of the\nappropriate qualiﬁed personnel.\nIf we allow each of these certainty factors to take one of two v alues (high and low), we\nget eight control situations, although some of them are not v ery realistic. If we have\nlittle or no certainty about the software to be developed, we can hardly expect to be\ncertain about the process to be", "token_count": 512, "start_token": 110880, "end_token": 111392, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 241, "text": "high and low), we\nget eight control situations, although some of them are not v ery realistic. If we have\nlittle or no certainty about the software to be developed, we can hardly expect to be\ncertain about the process to be followed and the resources ne eded to accomplish our\n8.2. A TAXONOMY OF SOFTWARE DEVELOPMENT PROJECTS 183\ngoals. Similarly, if we do not know how to carry out the develo pment process, we\nalso do not know which resources are needed.\nThis leaves us with four archetypal situations, as depicted in ﬁgure 8.1. Below, we\nwill discuss each of these control situations in turn. In doi ng so, we will pay attention\nto the following aspects of those control situations:\n– the kind of control problem;\n– the primary goals to be set in controlling the project;\n– the coordination mechanism to be used;\n– the development strategy, or process model, to be applied;\n– the way and degree to which cost can be estimated.\nRealization Allocation Design Exploration\nProduct certainty high high high low\nProcess certainty high high low low\nResource certainty high low low low\nFigure 8.1 Four archetypal control situations\n/AF Realization problem If the requirements are known and stable, it is known\nhow the software is to be developed, there is sufﬁcient contr ol variety, the\neffect of control actions is known, and sufﬁcient resources are available, we ﬁnd\nourselves in an ideal situation, a situation not often encou ntered in our ﬁeld.\nThe main emphasis will be on realization: how can we, given th e requirements,\nachieve our goal in the most effective way? As for the develop ment strategy,\nwe may use some linear process model. Feedback to earlier pha ses, as in the\nwaterfall model, is needed only for veriﬁcation and validat ion activities.\nTo coordinate activities in a project of this type, we may use direct supervision.\nWork output can be standardized, since the end result is know n. Similarly, the\nwork processes and worker skills can be ﬁxed in advance. Ther e will thus be\nlittle need for control variety as far as these variables are concerned.\nManagement can be done effectively through a separation sty", "token_count": 512, "start_token": 111342, "end_token": 111854, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 242, "text": " n. Similarly, the\nwork processes and worker skills can be ﬁxed in advance. Ther e will thus be\nlittle need for control variety as far as these variables are concerned.\nManagement can be done effectively through a separation sty le. The work to\nbe done is ﬁxed through rules and procedures. Management can allocate tasks\nand check their proper execution.\n184 PROJECT PLANNING AND CONTROL\nAs for cost estimation, we may successfully use one of the mor e formalized\ncost models. Alternatively, experts in the domain may give a reliable estimate.\nA cost estimation thus obtained can be used to guard the proje ct’s progress and\nyields a target to be achieved.\n/AF Allocation problem This situation differs from the previous one in that there is\nuncertainty as regards the resources. The major problem the n becomes one of\nthe availability of personnel. Controlling a project of thi s kind tends to become\none of controlling capacity. The crucial questions become: How do we get\nthe project staffed? How do we achieve the desired end-produ ct with limited\nmeans?\nAccording to Mintzberg, one has to try to standardize the pro cess as far as\npossible in this case. This makes it easier to move personnel between tasks.\nGuidelines and procedures may be used to describe how the var ious tasks have\nto be carried out.\nAs regards the development strategy, we may again opt for the waterfall model.\nWe may either contract out the work to be done, or try to acquir e the right\ntype and amount of qualiﬁed personnel.\nAs for cost estimation, either some cost estimation model or expert estimates\ncan be used. Since there is uncertainty as regards resources , there is a need for\nsensitivity analyses in order to gain insight into such ques tions as: What will\nhappen to the total cost and development time if we allocate t hree designers\nof level A rather than four designers of level B?\n/AF Design problem If the requirements are ﬁxed and stable, but we do not know\nhow to carry out the process, nor which resources to employ, t he problem is\none of design. Note that the adjective design refers to the design of the project,\nnot the design of the software. We have to answer such questio ns as: which\nmilestones are", "token_count": 512, "start_token": 111804, "end_token": 112316, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 243, "text": " which resources to employ, t he problem is\none of design. Note that the adjective design refers to the design of the project,\nnot the design of the software. We have to answer such questio ns as: which\nmilestones are to be identiﬁed, which documents must be deli vered and when,\nwhat personnel must be allocated, how will responsibilitie s be assigned?\nIn this situation, we have insufﬁcient knowledge of the effe ct of allocating extra\npersonnel, other tools, different methods and techniques. The main problem\nthen becomes one of controlling the development process.\nIn Mintzberg’s classiﬁcation, this can best be pursued thro ugh standardization\nof work outputs. Since the output is ﬁxed, control should be d one through the\nprocess and the resources. The effect of such control action s is not sufﬁciently\nknown, however.\nIn order to make a project of this kind manageable, one needs o vercapacity. As\nfar as the process is concerned, this necessitates margins i n development time\nand budget. Keeping extra personnel is not feasible, in gene ral.\nIn these situations, we will need frequently to measure prog ress towards the\nproject’s goals in order to allow for timely adjustments. Th erefore, we may want\n8.2. A TAXONOMY OF SOFTWARE DEVELOPMENT PROJECTS 185\nto go from a linear development model to an incremental one. T his preference\nwill increase as the uncertainty increases.\nCost estimation will have to rely on past experience. We will usually not have\nenough data to use one of the more formalized cost estimation models. In\nthis situation too, we will need sensitivity analyses. This need will be more\npressing than in the previous situation, since the uncertai nty is greater. The\nproject manager will be interested in the sensitivity of cos t estimates to certain\ncost drivers. He might be interested in such questions as: wh at will happen to\nthe development schedule if two extra analysts are assigned to this project, or:\nwhat will the effect be on the total cost if we shorten the deve lopment time by\n/DC days? By viewing cost estimation in this way, the manager wil l gain insight\nto, and increase his feeling for, possible", "token_count": 512, "start_token": 112266, "end_token": 112778, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 244, "text": "\nwhat will the effect be on the total cost if we shorten the deve lopment time by\n/DC days? By viewing cost estimation in this way, the manager wil l gain insight\nto, and increase his feeling for, possible solution strateg ies.\n/AF Exploration problem If the product certainty, process certainty and resource\ncertainty are all low, we get the most difﬁcult control situa tion.\nBecause of these uncertainties, the work will be explorator y in nature. This\nsituation does not ﬁt a coordination mechanism based on stan dardization.\nIn a situation as complex and uncertain as this one, coordina tion can best be\nachieved through mutual adjustment. The structure is one of adhocracy. Experts\nfrom various disciplines work together to achieve some as ye t unspeciﬁed goal.\nA critical success factor in these cases is the commitment of all people involved.\nWork cannot be split up into neat tasks. Flexibility in work p atterns and work\ncontents is important. Adherence to a strict budget cannot b e enforced upon\nthe team from above. The team members must commit themselves to the\nproject. Management has to place emphasis on their relation s with the team\nmembers.\nControlling a project of this kind is a difﬁcult and challeng ing activity. To\nmake a project of this kind manageable, our goal will be to max imize output,\ngiven the resources available to the project. This maximiza tion may concern\nthe quality of the product, or its functionality, or both.\nSince requirements are not precisely known, some agile appr oach is appropriate\nas a process model. The larger the uncertainty, the more ofte n we will have\nto check whether we are still on the right track. Thus, some de velopment\nstrategy involving many small steps and frequent user feedb ack is to be used.\nCost estimation using some formalized model clearly is not f easible in these\ncircumstances. The use of such models presupposes that we kn ow enough of\nthe project at hand to be able to compare it with previous proj ects. Such is not\nthe case, though.\nWe may rely on expert judgments to achieve a rough cost estima te. Such a\ncost estimate, however, cannot and should not be used as a ﬁxe d anchor", "token_count": 512, "start_token": 112728, "end_token": 113240, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 245, "text": " ects. Such is not\nthe case, though.\nWe may rely on expert judgments to achieve a rough cost estima te. Such a\ncost estimate, however, cannot and should not be used as a ﬁxe d anchor point\nas to when the project should be ﬁnished and how much it may cos t. There\nare simply too many uncertainties involved. Rather, it prov ides us with some\n186 PROJECT PLANNING AND CONTROL\nguidance as to the magnitude of the project. Based on this est imate, effort\nand time can be allocated for the project, for instance to pro duce a certain\nnumber of prototypes, a feasibility study, a pilot implemen tation of part of the\nproduct, or to start a certain number of time boxes. The hope i s that in time\nthe uncertainties will diminish sufﬁciently so that the pro ject shifts to one of\nthe other situations.\nThe four control situations discussed above are once more de picted in ﬁgure 8.2,\ntogether with a short characterization of the various contr ol aspects discussed above.\nFor big projects, it may be effective to use different contro l mechanisms at the\nmacro and micro level, respectively (Karlstr ¨ om and Runeso n, 2005). At the macro\nlevel, management may have to coordinate the work of differe nt teams, and report\nto higher management. This may require an approach in which e xplicit stages and\ncorresponding milestones are distinguished. At the level o f a small subteam though,\none may still apply agile methods to control the day-to-day w ork.\nBy taking the different control aspects into account during the planning stage of a\nsoftware development project, we can tailor the project’s m anagement to the situation\nat hand. In doing so, we recognize that software development projects are not all\nalike. Neglecting those project-speciﬁc characteristics is likely to result in project\nfailures, failures that have often been reported upon in the literature, but equally often\nremain hidden from the public at large.\n8.3 Risk Management\nRisk management is project management for adults\nTim Lister\nIn the previous section, we identiﬁed global risk categorie s and tied them to preferred\ncontrol situations. In this section, the emphasis is on", "token_count": 512, "start_token": 113190, "end_token": 113702, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 246, "text": " Risk Management\nRisk management is project management for adults\nTim Lister\nIn the previous section, we identiﬁed global risk categorie s and tied them to preferred\ncontrol situations. In this section, the emphasis is on indi vidual risks and their\nmanagement during project execution. In some sense too, the discussion below t akes\na more realistic point of view, in that we also consider adver se situations such as\nunrealistically tight schedules and design gold plating.\nPotential risks of a project must be identiﬁed as early as pos sible. It is rather naive\nto suppose that a software project will run smoothly from sta rt to ﬁnish. It won’t. We\nshould identify the risks of a software project early on and p rovide measures to deal\nwith them. Doing so is not a sign of unwarranted pessimism. Ra ther, it is a sign of\nwisdom.\nIn software development, we tend to ignore risks. We assume a n optimistic\nscenario under all circumstances and we do not reserve funds for dealing with risks.\nWe rely on heroics when chaos sets in. If risks are identiﬁed a t all, their severity\nis often underestimated, especially by observers higher in the hierarchy. A designer\nmay have noticed that a certain subsystem poses serious perf ormance problems. His\nmanager assumes that the problem can be solved. His manager’ s manager assumes the\nproblem has been solved.\n8.3. RISK MANAGEMENT 187\nProblem type Realization Allocation Design Exploration\nProduct certainty high high high low\nProcess certainty high high low low\nResource certaintyhigh low low low\nPrimary goal Optimize Acquisition, Control of the Maximize\nin control resource usage training of process result\nEfﬁciency personnel Lower risks\nand schedule\nCoordination, Standardization Standardization Standard ization Mutual\nManagement of product, of product and of process adjustment\nstyle process, and process Commitment\nresources Relation style\nHierarchy,\nseparation style\nDevelopment Waterfall Waterfall Incremental Incremental\nstrategy Prototyping\nAgile\nCost estimation Models Models Expert estimate Expert estim ate\nGuard process Sensitivity Sensitivity Risk analysis\nanalysis analysis Provide\nguidance\nFigure 8.2 Four control situations ( After: F.J. Heemstra , How much", "token_count": 512, "start_token": 113652, "end_token": 114164, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 247, "text": "Agile\nCost estimation Models Models Expert estimate Expert estim ate\nGuard process Sensitivity Sensitivity Risk analysis\nanalysis analysis Provide\nguidance\nFigure 8.2 Four control situations ( After: F.J. Heemstra , How much does software cost,\nKluwer Bedrijfswetenschappen, 1989. )\nA risk is a possible future negative event that may affect the success of an effort.\nSo, a risk is not a problem, yet. It may become one, though, and risk management is\nconcerned with preventing risks from becoming problems. Some common examples of\nrisks and ways to deal with them, are:\n/AF Requirements may be unstable, immature, unrealistic, or ex cessive. If we merely\nlist the requirements and start to realize the system in a lin ear development\nmode, it is likely that a lot of rework will be needed. This res ults in schedule\nand budget overruns, since this rework was not planned. If th e requirements\nvolatility is identiﬁed as a major risk, an evolutionary dev elopment strategy can\nbe chosen. This situation ﬁts the exploration-problem cate gory as identiﬁed in\nthe previous section.\n188 PROJECT PLANNING AND CONTROL\n/AF If there is little or no user involvement during the early dev elopment stages, a\nreal danger is that the system will not meet user needs. If thi s is identiﬁed as a\nrisk, it can be mitigated, e.g. by having users participate i n design reviews.\n/AF If the project involves different or complex domains, the sp read of application\nknowledge within the project team may be an issue. Recognizi ng this risk\nmay result in timely attention and resources for a training p rogram for team\nmembers.\n/AF If the project involves more than one development site, comm unication\nproblems may arise. A common way to deal with this is to pay att ention to\nsocialization issues, for instance by scheduling site visi ts.\nAt the project planning stage, risks are identiﬁed and handl ed. A risk management\nstrategy involves the following steps:\n1. Identify the risk factors. There are many possible risk fa ctors. Each organization\nmay develop its own checklist of such factors. The top", "token_count": 512, "start_token": 114114, "end_token": 114626, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 248, "text": "ed and handl ed. A risk management\nstrategy involves the following steps:\n1. Identify the risk factors. There are many possible risk fa ctors. Each organization\nmay develop its own checklist of such factors. The top ten ris k factors from\n(Boehm, 1989) are listed in ﬁgure 8.3.\n2. Determine the risk exposure. For each risk, we have to dete rmine the probability\n/D4 that it will actually occur and the effect /BX (e.g. in dollars or loss of man\nmonths) that it will have on the project. The risk exposure th en equals /D4 /A2 /BX .\n3. Develop strategies to mitigate the risks. Usually, this w ill only be done for the\n/C6 risks that have the highest risk exposure, or for those risks whose exposure\nexceeds some threshold /AB .\nThere are three general strategies to mitigate risks: avoid ance, transfer, and\nacceptance. We may avoid risks by taking precautions so that they will not\noccur: buy more memory, assign more people, provide for a tra ining program\nfor team members, and the like. We may transfer risks by looki ng for another\nsolution, such as a prototyping approach to handle unstable requirements.\nFinally, we may accept risks. In the latter case, we have to pr ovide for a\ncontingency plan, to be invoked when the risk does become a pr oblem.\n4. Handle risks. Risk factors must be monitored. For some ris ks, the avoidance or\ntransfer actions may succeed, and those risks will never bec ome a problem. We\nmay be less lucky for those risks that we decided up front not t o handle. Also,\nsome of our actions may turn out to be less successful, and ris ks that we hoped\nto have handled adequately may become a problem after all. Fi nally, project\ncharacteristics will change over time, and so will the risks . Risk management\nthus is a cyclic process, and occasionally risks must be hand led by re-assessing\nthe project, invoking a contingency plan, or even a transfer to crisis mode.\nWallace and Keil (2004) give a useful categorization of risk factors. They distinguish\nfour types of risk (see also ﬁgure 8.4):\n8.", "token_count": 512, "start_token": 114576, "end_token": 115088, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 249, "text": " plan, or even a transfer to crisis mode.\nWallace and Keil (2004) give a useful categorization of risk factors. They distinguish\nfour types of risk (see also ﬁgure 8.4):\n8.3. RISK MANAGEMENT 189\nRisk Description\nPersonnel shortfall May manifest itself in a variety of ways , such\nas inexperience with the domain, tools or\ndevelopment techniques to be used, person-\nnel turnover, loss of critical team members,\nor the mere size of a team.\nUnrealistic schedule/budget Estimates may be unrealistic with respect to\nthe requirements.\nWrong functionality May have a variety of causes, such as an\nimperfect understanding of the customer\nneeds, the complexity of communication\nwith the client, insufﬁcient domain knowl-\nedge of the developers and designers.\nWrong user interface In certain situations, the user-frien dliness of\nthe interface is critical to its success.\nGold plating Developers may wish to develop ‘nice’ fea-\ntures not asked for by the customer.\nRequirements volatility If many requirements change durin g devel-\nopment, the amount of rework increases.\nBad external components The quality or functionality of ext ernally\nsupplied components may be below what is\nrequired for this project.\nBad external tasks Subcontractors may deliver inadequate p rod-\nucts, or the skills obtained from outside the\nteam may be inadequate.\nReal-time shortfalls The real-time performance of (parts o f) the\nsystem may be inadequate.\nCapability shortfalls An unstable environment or new or unt ried\ntechnology pose a risk to the development\nschedule.\nFigure 8.3 Top ten risk factors\n/AF C1: Risks related to customers and users. Examples include a lack of user\nparticipation, conﬂicts between users, or a user organizat ion resisting change.\nPart of this can be mitigated through an agile approach. But e qually often, such\nrisks are beyond the project manager’s control.\n190 PROJECT PLANNING AND CONTROL\n/AF C2: Risks that have to do with the scope of the project and its r equirements.\nVarious factors from ﬁgure 8.3 fall into this category: wron g functionality, gold\nplating, requirements", "token_count": 512, "start_token": 115038, "end_token": 115550, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 250, "text": "AF C2: Risks that have to do with the scope of the project and its r equirements.\nVarious factors from ﬁgure 8.3 fall into this category: wron g functionality, gold\nplating, requirements volatility. Project managers shoul d be able to control this\ntype of risk.\n/AF C3: Risks that concern the execution of the project: stafﬁng , methodology,\nplanning, control. Factors like personnel shortfall and an unrealistic schedule\nor budget belong to this category. Again, project managers s hould be able to\ncontrol these risks.\n/AF C4: Risks that result from changes in the environment, such a s changes in\nthe organization in which the system is to be embedded, or dep endencies on\noutsourcing partners. Project managers often have few mean s to control these\nrisks.\nLevel of control\nlow high\nrelative\nimportance\nlow customers and users (C1) scope and requirements (C2)\nhigh environment (C4) execution (C3)\nFigure 8.4 Risk categories\nFrom a study of a large number of projects, Wallace and Keil (2 004) found that risk\ncategories C2 and C3 affect project outcomes most. They also found that execution\nrisks (C3) are much more important in explaining process out come that scope or\nrequirements risks. This would suggest an ordering amongst the types of risks that\nmanagers had better pay attention to: ﬁrst C3, then C2, and ﬁn ally C4 and C1.\nWhen you return to ﬁgure 8.3 after having studied the remaind er of this book,\nyou will note that many of the risk factors listed are extensi vely addressed in various\nchapters. These risk factors surface as cost drivers in cost estimation models, the\nquest for user involvement in requirements engineering and design, the attention for\nprocess models like prototyping and XP, and so on.\nAs Tom Gilb says: ‘If you don’t actively attack the risks, the y will actively attack\nyou’ (Gilb, 1988, p. 72).\n8.4. TECHNIQUES FOR PROJECT PLANNING AND CONTROL 191\n8.4 Techniques for Project Planning and Control\nA project consists of a series of activities. We may graphica lly", "token_count": 512, "start_token": 115500, "end_token": 116012, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 251, "text": ", 1988, p. 72).\n8.4. TECHNIQUES FOR PROJECT PLANNING AND CONTROL 191\n8.4 Techniques for Project Planning and Control\nA project consists of a series of activities. We may graphica lly depict the project and\nits constituent activities by a work breakdown structure (WBS). The WBS reﬂects\nthe decomposition of a project into subtasks down to a level n eeded for effective\nplanning and control. Figure 8.3 contains a very simple exam ple of a work breakdown\nstructure for a software development project. The activiti es depicted at the leaves of\nthe work breakdown structure correspond to unit tasks, whil e the higher-level nodes\nconstitute composite tasks. We will assume that each activi ty has a well-deﬁned\nbeginning and end that is indicated by a milestone, a schedul ed event for which some\nperson is held accountable and which is used to measure and co ntrol progress. The\nend of an activity is often a deliverable, such as a design doc ument, while the start of\nan activity is often triggered by the end of some other activi ty.\nProject\nDesign Test plan Code Test\nCode A Code B\nFigure 8.5 Simple work breakdown structure for a software de velopment project\nActivities usually consume resources, such as people or com puter time, and always\nhave a certain duration. Activities must often be executed i n a speciﬁc order. For\nexample, we can not test a module before it is coded. This type of relation between\ntasks can be expressed as constraints. Usually, the constra ints concern temporal\nrelations between activities. Such constraints are also ca lled precedence relations.\nProject planning involves the scheduling of all activities such that the constraints\nare satisﬁed and resource limits are not exceeded. Several t echniques are available to\nsupport this scheduling task.\n192 PROJECT PLANNING AND CONTROL\nThe activities from the simple WBS of a software development project, together\nwith their duration and temporal constraints, are given in ﬁ gure 8.6. Note that\nﬁgure 8.6 contains more information on temporal relations t han is given in the WBS.\nThough the left-to-right reading of the WBS suggests a certa in time ordering, it does\nnot", "token_count": 512, "start_token": 115962, "end_token": 116474, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 252, "text": "\nﬁgure 8.6 contains more information on temporal relations t han is given in the WBS.\nThough the left-to-right reading of the WBS suggests a certa in time ordering, it does\nnot give the precise precedence relations between activiti es.\nActivity Duration Constraints\nDesign 10 --\nTest plan 5 Design ﬁnished\nCode A 10 Design ﬁnished\nCode B 5 Design ﬁnished\nTest 10 Code ﬁnished, Test plan ﬁnished\nFigure 8.6 Activities, their duration and temporal constra ints\nThe set of activities and their constraints can also be depic ted in a network. For\nour example, this network is given in ﬁgure 8.7. The nodes in t he network denote\nactivities. This type of network is therefore known as an ‘ac tivity-on-node’ network.\nEach node also carries a weight, the duration of the correspo nding activity. An arrow\nfrom node A to node B indicates that activity A has to be ﬁnishe d before activity B\ncan start.\nThese network diagrams are often termed PERT charts . PERT is an acronym for\nProgram Evaluation and Review Technique. PERT charts were d eveloped and ﬁrst\nused successfully in the management of the Polaris missile p rogram in the 1950s.\nWhile the original PERT technique was concerned solely with the time span of\nactivities and their interrelations, subsequent developm ents have led to a variety of\ntechniques that accommodate an increasing number of projec t factors.\nFrom the PERT chart we may compute the earliest possible poin t in time at which\nthe project can be completed. Let us assume that the network h as a unique start node\nB and end node E. If there is more than one node with in-degree 0 (i.e. having no\npredecessors in the network), a new start node B is created wi th outgoing edges to all\nnodes having in-degree 0. This new node B gets a zero weight (d uration). A similar\nprocedure is followed to create the end node E if there is more than one node having\nout-degree 0.\nWe next label each node /CX in the network with an ordered pair of numbers ( /CB\n", "token_count": 512, "start_token": 116424, "end_token": 116936, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 253, "text": " A similar\nprocedure is followed to create the end node E if there is more than one node having\nout-degree 0.\nWe next label each node /CX in the network with an ordered pair of numbers ( /CB\n/CX\n,\n/BY\n/CX\n). /CB\n/CX\nand /BY\n/CX\ndenote the earliest possible time at which activity /CX can start and\nﬁnish, respectively. The algorithm for doing so involves a b readth-ﬁrst search of the\nnetwork (cf. (Boehm, 1981)):\n1. The start node /BU is labeled (0, /BW\n/BU\n), where /BW\n/BU\nis the duration of activity /BU ;\n8.4. TECHNIQUES FOR PROJECT PLANNING AND CONTROL 193\nDesign    10\nTest plan   5\nCode A    10\nCode B    5\nTest    10\nFigure 8.7 Example of a PERT chart\n2. For all unlabeled nodes whose predecessors are all labele d nodes, the earliest\npossible starting time is the latest ﬁnishing time of all the predecessor nodes:\n/CB\n/C6\n/BP /D1/CP/DC\n/CX /BE /C8 /B4 /C6 /B5\n/BY\n/CX\nwhere /C8 /B4 /C6 /B5 is the set of predecessor nodes of /C6 .\nThe corresponding ﬁnishing time is /BY\n/C6\n/BP /CB\n/C6\n/B7 /BW\n/C6\n, where /BW\n/C6\nis the duration\nof activity /C6 .\nNode /C6 is labeled as ( /CB\n/C6\n/BN /BY\n/C6\n).\n3. Repeat Step 2 until all nodes have been labeled.\nThe earliest possible ﬁnishing time of the whole project now equals /BY\n/BX\n, /BX being the\nend node of the network.\nWe may subsequently compute the latest point in time at which activity /C4 should\nﬁnish: for each node /C6 ,\n/C4\n/C6\n/BP /D1", "token_count": 512, "start_token": 116886, "end_token": 117398, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 254, "text": " node of the network.\nWe may subsequently compute the latest point in time at which activity /C4 should\nﬁnish: for each node /C6 ,\n/C4\n/C6\n/BP /D1/CX/D2\n/CX /BE /C9 /B4 /C6 /B5\n/CB\n/CX\nwhere /C9 /B4 /C6 /B5 is the set of successor nodes of /C6 .\nThe results of this computation can be graphically presente d in a Gantt chart\n(these charts are named after their inventor). In a Gantt cha rt, the time span of each\nactivity is depicted by the length of a segment drawn on an adj acent calendar. The\nGantt chart of our software development example is given in ﬁ gure 8.8. The gray\nareas show slack (or ﬂoat) times of activities. It indicates that the corresponding\n194 PROJECT PLANNING AND CONTROL\nactivity may consume more than its estimated time, or start l ater than the earliest\npossible starting time, without affecting the total durati on of the project. For each\nactivity /C6 , the corresponding segment in the Gantt chart starts at time /CB\n/C6\nand ends\nat /C4\n/C6\n.\nActivities without slack time are on a critical path . If activities on a critical path\nare delayed, the total project gets delayed as well. Note tha t there always is at least\none sequence of activities that constitutes a critical path .\n/0/0/0/0\n/0/0/0/0\n/0/0/0/0\n/1/1/1/1\n/1/1/1/1\n/1/1/1/1\n/0/0/0/0\n/0/0/0/0\n/0/0/0/0\n/1/1/1/1\n/1/1/1/1\n/1/1/1/1\nDesign\nTest plan\nCode A\nCode B\nTest\n10 205 30\nFigure 8.8 Example of a Gantt chart\nIn an ‘activity-on-node’ network, the activities are depic ted as nodes, while the\narrows denote precedence", "token_count": 512, "start_token": 117348, "end_token": 117860, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 255, "text": "Code B\nTest\n10 205 30\nFigure 8.8 Example of a Gantt chart\nIn an ‘activity-on-node’ network, the activities are depic ted as nodes, while the\narrows denote precedence relations between activities. Al ternatively, we may depict a\nset of interrelated activities in an ‘activity-on-arrow’ n etwork. In an activity-on-arrow\nnetwork, the arrows denote activities, while the nodes repr esent the completion of\nmilestone events. Figure 8.9 depicts the example as an activ ity-on-arrow network.\nThe latter representation is intuitively appealing, espec ially if the length of an arrow\nreﬂects the duration of the corresponding activity. Note th at this type of network\nmay have to contain dummy activities which are not needed in t he activity-on-node\nnetwork. These dummy activities represent synchronizatio n of interrelated activities.\nIn our example, dummy activities (arrows) are needed to make sure that the activity\ntest is not started until the activities test plan , code A and code B have all been completed.\nThe PERT technique has evolved considerably since its incep tion 50 years ago.\nFor example, as well as expressing a constraint that activit y B may start only after\nan activity A has ended, we may also specify that activity B ma y only start after\n8.4. TECHNIQUES FOR PROJECT PLANNING AND CONTROL 195\nDesign Code A\nCode B\n10\nTest plan\n5\nTest\n10\n5\n10\nFigure 8.9 An activity-on-arrow network\nactivity A has started. We may also extend the technique so th at it handles resource\nconstraints. For instance, if we have only one programmer av ailable, the Gantt chart\nof ﬁgure 8.6 would not work, since it assumes that coding of mo dules A and B is done\nin parallel. The PERT technique may even be extended further to allow for sensitivity\nanalysis. By allowing so-called ‘what-if’ questions (‘wha t if we allocate three designers\nrather than four’, ‘what if coding module A takes two months r ather than one’) we\nget a feeling for the sensitivity of a schedule to certain var iations in resource levels,\n", "token_count": 512, "start_token": 117810, "end_token": 118322, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 256, "text": " we allocate three designers\nrather than four’, ‘what if coding module A takes two months r ather than one’) we\nget a feeling for the sensitivity of a schedule to certain var iations in resource levels,\nschedule overruns, and the like.\nCritical Path Method -- CPM -- is, as the name suggests, a tech nique very similar\nto PERT and developed at around the same time.\nIn our discussion, we presented a Gantt chart as a graphical v isualization of a\nschedule that results from network analysis. Actually, we m ay use a Gantt chart as a\nscheduling mechanism in its own right. We may simply list all activities and indicate\ntheir earliest starting time and latest ending time on the ca lendar. Gantt charts by\nthemselves, however, do not carry information on dependenc ies between activities.\nThis makes it hard to adjust schedules, for instance when a ce rtain activity slips. As far\nas planning goes, we therefore prefer the use of Gantt charts as a means to visualize\nthe result of network analysis.\nUsing the information contained in the Gantt chart and knowl edge of personnel\nresources required for each activity, we may establish a per sonnel plan indicating how\nmany people are required in each unit of time. Since people co sts are a major part\nof project expenditures, this personnel plan provides a dir ect means to plan project\nexpenditures.\nWhen the project is under way, its control is based on monitor ing the project’s\nprogress and expenditures. Time spent per activity per proj ect member can be\nrecorded on time cards. These time cards are the basis for det ermining cumulative\neffort and expenditure. These cumulative data can be compar ed with the planned\nlevels of effort and expenditure. In order to properly judge whether the project is still\non track, management needs progress information as well. Th e most common way to\nprovide this is via milestone reports: activities cannot be considered completed until\n196 PROJECT PLANNING AND CONTROL\na proper report has been produced and accepted.\nThe Gantt chart provides a very direct means to compare actua l project status\nwith the project schedule. Schedule slippage shows itself i mmediately. Slippage of\nactivities on a critical path then necessitates prompt mana gement action: renegotiation\nof the schedule, the project", "token_count": 512, "start_token": 118272, "end_token": 118784, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 257, "text": " actua l project status\nwith the project schedule. Schedule slippage shows itself i mmediately. Slippage of\nactivities on a critical path then necessitates prompt mana gement action: renegotiation\nof the schedule, the project’s deliverables, or both. Note t hat schedule slippage is a\nsneaky affair; projects get behind one day at a time. Note als o that project schedules\nshould at any point in time reﬂect the true project. An accept ed change necessitates\nreconsideration of the schedule.\n8.5 Summary\nIn this chapter we looked at project control from a systems po int of view and\ngained insight into how different kinds of projects can be ma naged and controlled.\nWe identiﬁed four archetypal situations, which demand diff erent process models,\ncoordination mechanisms and management styles.\nReal projects face many risks, and it is a wise project manage r who pays attention\nto them early on. A risk is a possible future negative event th at may affect success.\nIt is not a problem yet, but it may become one. Risk management is concerned with\npreventing risks from becoming problems. It involves the following ste ps:\n1. Identify the risk factors.\n2. Determine the risk exposure, i.e. the probability that a r isk will happen,\nmultiplied by its cost.\n3. Develop strategies to mitigate risks, especially those w ith a high risk exposure.\nRisks may be avoided (e.g. by hiring more people), transferr ed (e.g. by choosing\na different development strategy), or accepted.\n4. Handle the risks: monitor risk factors and take action whe n needed.\nIn section 8.4, we focused on the planning and control of acti vities within a project.\nBy depicting the set of activities and their temporal relati ons in a graph, techniques\nlike PERT offer simple yet powerful means to schedule and con trol these activities\n(see, for example, (Boehm, 1981)).\n8.6 Further Reading\nSome general software project management sources are: (Boe hm, 1981), (Brooks,\n1995), (Humphrey, 1997b) and (Royce, 1998). Highsmith (200 4) focusses on agile\nproject management, while Boehm and Turner (", "token_count": 512, "start_token": 118734, "end_token": 119246, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 258, "text": "Boe hm, 1981), (Brooks,\n1995), (Humphrey, 1997b) and (Royce, 1998). Highsmith (200 4) focusses on agile\nproject management, while Boehm and Turner (2003) and Karls tr ¨ om and Runeson\n(2005) discuss how to combine agile and plan-based approach es.\nThe discussion in section 8.2 is based on (Heemstra, 1989).\n8.6. FURTHER READING 197\n(Boehm, 1989) gives a good overview of software risk managem ent. Risk manage-\nment experiences are reported on in (Software, 1997a). The r isk categories discussed\nin section 8.3 stem from (Wallace and Keil, 2004). Pﬂeeger (2 000) compares software\nrisk management with risk management in other disciplines.\nExercises\n1. List the conditions for effective systems control.\n2. Is the waterfall approach suitable for a realization-typ e problem? If so, why?\n3. Is the waterfall approach suitable for an exploration-ty pe problem? If so, why?\n4. What is risk management?\n5. How can risks be mitigated?\n6. Rephrase the cost drivers of the COCOMO cost estimation mo del as risk\nfactors.\n7. What is a work breakdown structure?\n8. What is a PERT chart?\n9. What is a Gantt chart?\n10. /DJ Classify a project you have been involved in with respect to p roduct\ncertainty, process certainty, and resource certainty. Whi ch of the archetypal\nsituations sketched in section 8.2 best ﬁts this project? In what ways did\nactual project control differ from that suggested for the si tuation identiﬁed?\nCan you explain possible differences?\n11. /DI Consider the patient planning system mentioned in exercise 3.12. Sup-\npose the project team consists of several analysts and two me mbers from\nthe hospital staff. The analysts have a lot of experience in t he design of\nplanning systems, though not for hospitals. As a manager of t his team, which\ncoordination mechanism and management style would you opt f or?\n12. /DI Discuss the pros and cons of a hierarchical as well as a matrix team\norganization for", "token_count": 512, "start_token": 119196, "end_token": 119708, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 259, "text": " though not for hospitals. As a manager of t his team, which\ncoordination mechanism and management style would you opt f or?\n12. /DI Discuss the pros and cons of a hierarchical as well as a matrix team\norganization for the patient planning project.\n13. /DJ Consider a project you have been involved in. Identify the ma jor irregular,\ncontrol, and goal variables for this project. In what ways di d the control\nvariables inﬂuence project control?\n14. /DI Suppose one of your team members is dissatisﬁed with his situ ation. He\nhas been involved in similar projects for several years now. You have assigned\n198 PROJECT PLANNING AND CONTROL\nhim these jobs because he was performing so well. Discuss pos sible actions\nto prevent this employee from leaving the organization.\n15. /DI Why is planning (i.e., the activity) more important than the plan (the\ndocument)?\n16. /DI Suppose you are the manager of a project that is getting serio usly behind\nschedule. Your team is having severe problems with testing a particular\nsubsystem. Your client is pressing you to deliver the system on time. How\nwould you handle this situation? How would you handle the sit uation if\nyou were a member of the team and your manager was not paying se rious\nattention to your signals?\nPart II\nThe Software Life Cycle\nCONTENTS\nChapter 9 Requirements Engineering 199\nChapter 10 Modeling 246\nChapter 11 Software Architecture 276\nChapter 12 Software Design 313\nChapter 13 Software Testing 394\nChapter ?? Software Maintenance 453\nChapter ?? Software Tools 494\nWhen designing a garden, you begin by formulating your requi rements --\nhow large should the grass-area be, should you leave a corner to raise potatoes,\nwhere should the sand-bin be put, do not the requirements int erfere with future\nmaintenance work on the house (!), etc. After that, a design i s drawn up which is\ncarefully documented in a blueprint. Only then will the gard ener cut the ﬁrst sod.\nA similar approach is followed when developing software. In a number of phases\n-- requirements engineering, design, implementation, tes ting -- the software system\nwill take shape. After the software is delivered to the clien t it must be maintained.\nReiteration of", "token_count": 512, "start_token": 119658, "end_token": 120170, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 260, "text": " developing software. In a number of phases\n-- requirements engineering, design, implementation, tes ting -- the software system\nwill take shape. After the software is delivered to the clien t it must be maintained.\nReiteration of phases occurs because changes have to be inco rporated and errors must\nbe corrected. The result is a highly cyclical process, the so -called software life cycle.\nThe various phases of the initial development cycle are the t opics of chapters\n9--13, and chapter 14 is devoted to software maintenance. In each phase, modeling\ntechniques are used to represent the results of that phase. A sample of well-known\n200\nmodeling techniques is discussed in chapter 10. In each phas e also, tools are employed.\nThe main classes of tools and their role in the software devel opment process are\ndiscussed in chapter 15.\n9\nRequirements Engineering\nLEARNING OBJECTIVES\n/AF To understand that requirements engineering is a cyclical p rocess involving\nfour types of activity: elicitation, speciﬁcation, valida tion, and negotiation\n/AF To appreciate the role of social and cognitive issues in requ irements engineering\n/AF To be able to distinguish a number of requirements elicitati on techniques\n/AF To be aware of the contents of a requirements speciﬁcation do cument\n/AF To know various techniques and notations for specifying req uirements\n/AF To know different ways to structure a set of requirements\n202 REQUIREMENTS ENGINEERING\nThis chapter covers requirements engineering, the ﬁrst maj or phase in a\nsoftware development project. The most challenging and dif ﬁcult aspect of\nrequirements engineering is to get a complete description o f the problem\nto be solved. We discuss a number of techniques for eliciting requirements\nfrom the user. Following elicitation, these requirements m ust be negotiated,\nvalidated, and documented.\nThe hardest single part of building a system is deciding what to build\n(Brooks, 1987)\nThe requirements engineering phase is the ﬁrst major step to wards the solution of\na data processing problem. During this phase, the user’s req uirements with respect\nto the future system are carefully identiﬁed and documented . These requirements\nconcern both the functions to be provided and a number of addi tional requirements", "token_count": 512, "start_token": 120120, "end_token": 120632, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 261, "text": " During this phase, the user’s req uirements with respect\nto the future system are carefully identiﬁed and documented . These requirements\nconcern both the functions to be provided and a number of addi tional requirements,\nsuch as those regarding performance, reliability, user doc umentation, user training,\ncost, and so on. During the requirements engineering phase w e do not yet address the\nquestion of how to achieve these user requirements in terms of system compon ents\nand their interaction. This is postponed until the design ph ase.\nA requirement is ‘a condition or capability needed by a user t o solve a problem\nor achieve an objective’ (IEEE610, 1990). The ‘user’ allude d to in this deﬁnition may\nbe an end user of the system, a person behind the screen. Howev er, it may also\ndenote several classes of indirect users, such as people who do not themselves turn\nthe knobs but rather use the information that the system deli vers. It may also denote\nthe client (customer) who pays the bill. During requirement s engineering, different\ntypes of user may be the source of different types of requirem ents. Hopefully, the end\nusers will be the main source of information regarding the fu nctional, task-related\nrequirements. Other requirements, e.g. those that relate t o security issues, may well\nbe phrased by other stakeholders.\nThe word ‘requirement’ suggests that, once stated, it has to be met. In reality,\nthis hardly ever is the case. Most requirements are negotiab le. Time to market, cost,\nconﬂicting quality requirements, and conﬂicting needs of s takeholders all lead to a\nsituation where tradeoffs may have to be made.\nThe result of the requirements engineering phase is documen ted in the require-\nments speciﬁcation . The requirements speciﬁcation reﬂects the mutual underst anding\nof the problem to be solved between the analyst and the client . It is the basis for a\ncontract, be it formal or informal, between the client of the system and the devel-\nopment organization. Eventually, the system delivered wil l be assessed by testing its\ncompliance with the requirements speciﬁ", "token_count": 512, "start_token": 120582, "end_token": 121094, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 262, "text": " basis for a\ncontract, be it formal or informal, between the client of the system and the devel-\nopment organization. Eventually, the system delivered wil l be assessed by testing its\ncompliance with the requirements speciﬁcation.\nThe requirements speciﬁcation serves as a starting point fo r the next phase, the\ndesign phase. In the design phase the architecture of the sys tem is devised in terms\nof system components and interfaces between those componen ts. The design phase\nresults in a speciﬁcation as well: a precise description -- p referably in some formal\nlanguage -- of the design architecture, its components, and its interfaces.\n203\nThe notion ‘speciﬁcation’ thus has several meanings. To pre vent confusion, we\nwill always use the preﬁx ‘requirements’ if it denotes the re sult of the requirements\nengineering phase.\nTo make matters worse, the phase in which the user’s requirem ents are analyzed\nand documented is also sometimes called speciﬁcation. We fe el this to be somewhat\nof a misnomer and will not use the term as such.\nWe use the term requirements engineering rather than the narrower notion of\nrequirements analysis to emphasize that it is an iterative and co-operative proces s\nof analyzing a problem, documenting the resulting observat ions, and checking the\naccuracy of the understanding gained. Requirements engine ering not only involves\ntechnical concerns of how to represent the requirements. So cial and cognitive aspects\nplay a dominant role as well.\nRequirements engineering and design generally cannot be st rictly separated in\ntime. In some cases, the requirements speciﬁcation is very f ormal and can be viewed\nas a high-level design speciﬁcation of the system to be built . Often, a preliminary\ndesign is done after an initial set of requirements has been d etermined. Based on\nthe result of this design effort, the requirements speciﬁca tion may be changed and\nreﬁned. This type of iteration also occurs when prototyping techniques are being\nused. In pure agile development projects, requirements eme rge concurrently with an\nup-and-running system. Well-known techniques such as data ﬂow diagrams and UML\nclass diagrams are used to structure", "token_count": 512, "start_token": 121044, "end_token": 121556, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 263, "text": " techniques are being\nused. In pure agile development projects, requirements eme rge concurrently with an\nup-and-running system. Well-known techniques such as data ﬂow diagrams and UML\nclass diagrams are used to structure and document both requi rements speciﬁcations\nand designs.\nIt is only for ease of presentation that the requirements eng ineering and design\nphases are strictly separated and treated consecutively in this book.\nDuring requirements engineering, a number of quite differe nt matters are being\naddressed. Let us look at an example and consider the (hypoth etical) case of a\nuniversity’s library automating its operation. We will sta rt with the library containing\na number of cabinets. These cabinets hold a huge number of car ds, one per book.\nEach card contains the names of the authors, the book title, I SBN, publication year,\nand other useful data. The cards are ordered alphabetically by the name of the ﬁrst\nauthor of each book.\nThis ordering system in fact presents major problems as it on ly works well if we\nknow the ﬁrst author’s name. If we only know the title, or if we are interested in books\non a certain topic, the author catalog is of little or no help.\nA software solution seems obvious. If we store the data for ea ch book once in a\ndatabase, we may subsequently sort the entries in many diffe rent ways. Appropriate\ntools can enable the user to search the database interactive ly. By providing internet\naccess to the database, service can be greatly enhanced.\nDuring the requirements engineering phase, a number of user requirements will\nbe raised. Some of those requirements will concern updating the database, that is\nadding, deleting and changing records. Others will concern functions to be provided\nto ordinary members of the library, such as:\n– Give a list of all books written by X;\n204 REQUIREMENTS ENGINEERING\n– Give a list of all books whose title contains Y;\n– Give a list of all books on topic Z;\n– Give a list of all books that arrived after date D.\nIt is expedient to try somehow to group user requirements int o a few categories,\nranging from ‘essential requirements’ to ‘nice features’. As noted in chapter 3, users\n", "token_count": 512, "start_token": 121506, "end_token": 122018, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 264, "text": " books that arrived after date D.\nIt is expedient to try somehow to group user requirements int o a few categories,\nranging from ‘essential requirements’ to ‘nice features’. As noted in chapter 3, users\ntend to have difﬁculties in articulating their real needs. C hances are, then, that\nmuch effort is spent on realizing features which later turn o ut to be mere bells and\nwhistles. By using a layered scheme in both the formulation o f user requirements and\ntheir subsequent realization, some of the problems that bes et software development\nprojects can be circumvented. In our library system example , for instance, the\nrequirement ‘Give a list of all books that arrived after date D’ could be classiﬁed as a\nnice feature. Service is not seriously degraded if this func tion is not provided, since\nwe may temporarily place the acquisitions on a dedicated she lf.\nIt is also possible to try to predict a number of future requir ements, which will\nnot be implemented in the present project. It is, however, se nsible to pay attention to\nthese matters at an early stage, so that they can be accommoda ted during the design\nof the system. Possible future requirements of our library s ystem could include such\nthings as:\n– Storing information about books that have been ordered but have not been\nreceived;\n– Storing information about library members, such as their n ame and address,\nand the dates on which books are lent to them, which can then be used to\ngenerate a reminder notice for books not returned on time.\nThe above functions concern the use of the software by librar y members and\nlibrary personnel. There are other stakeholders as well, th ough. For example, library\nmanagement may wish to use the system to get information on me mber proﬁles in\norder to improve the title acquisition process.\nBesides these requirements, which directly relate to the fu nctions of the software to\nbe delivered, a number of other matters should be addressed d uring the requirements\nengineering phase. For our library example, as a minimum, th e following points have\nto be addressed:\n/AF On which machine will the system be implemented, and which op erating\nsystem will be used? If the data is to be stored in some DBMS, wh ", "token_count": 512, "start_token": 121968, "end_token": 122480, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 265, "text": " a minimum, th e following points have\nto be addressed:\n/AF On which machine will the system be implemented, and which op erating\nsystem will be used? If the data is to be stored in some DBMS, wh ich (type of)\nDBMS is to be used? What type of access is to be used and how many access\npoints will be supported?\n/AF Which classes of users can be distinguished? In our example, both library\npersonnel and library members will have to be served. What ki nd of knowledge\ndo these users have? Will certain functions of the system be r estricted to certain\n205\nclasses of user? Normal library members will probably not be allowed to update\nthe database or print the contents of the database.\n/AF What is the size of the database and how is it expected to grow i n the course\nof time? These factors inﬂuence both storage capacity neede d and algorithms\nto be used. For a database containing several thousands of bo oks, some not\nvery efﬁcient searching algorithm might sufﬁce. For the Lib rary of Congress,\nthe situation is quite different, though.\n/AF What response time should the system offer? A search request for a certain\nbook will have to be answered fairly quickly. If the user has t o wait too long for\nan answer, he will become dissatisﬁed and search the shelves directly. Related\nquestions concern the interaction between response time an d the expected\nnumber of question sessions per unit of time.\n/AF How much will a system of this kind cost? In our library exampl e, we should\nnot only pay attention to the direct costs incurred by the sof tware development\neffort. The cost of converting the information contained in the present ﬁle\ncabinets to a suitable database format should not be neglect ed. These, less\nvisible, indirect costs may well outweigh the direct cost of designing and\nimplementing the new system.\nThis relatively simple example already shows that it is not s ufﬁcient to merely list\nthe functional requirements of the new system. The system’s envisioned environment\nand its interaction with that environment should be analyze d as well.\nIn our example, this concerns the library itself, to start wi th. The consequences\nof introducing a system like this one can be", "token_count": 512, "start_token": 122430, "end_token": 122942, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 266, "text": ". The system’s envisioned environment\nand its interaction with that environment should be analyze d as well.\nIn our example, this concerns the library itself, to start wi th. The consequences\nof introducing a system like this one can be much greater than it seems at ﬁrst sight.\nWorking procedures may change, necessitating retraining o f personnel, changes in\npersonnel functions and the overall organizational struct ure. Some members of staff\nmay even become redundant. Checking whether membership fee s have been paid\nmight involve interfacing with the ﬁnancial system, owned b y another department.\nIn general, the setting up of an automated system may have mor e than just technical\nrepercussions. Often, not enough attention is paid to these other repercussions. The\nlack of success of many software development projects can be traced back to a neglect\nof non-technical aspects.\nIn practice, the requirements engineering process often is more complex than\nsketched above:\n/AF Ordinary library automation is a relatively well-known dom ain, where we\nmay expect users to be able to articulate their requirements . But suppose our\nlibrary system also has to support elderly people in their de alings with the\nworld around them, including daily news, relevant governme nt regulations,\ninformation about healthcare, and the like. For the latter t ype of support, a\nmore agile approach seems more appropriate, where the requi rements emerge\nas we go along, rather than being elicited up front.\n206 REQUIREMENTS ENGINEERING\n/AF Much software developed today however is market-driven rather than customer-\ndriven. For example, rather than developing a system for one speciﬁ c library,\nwe could develop a ‘generic’ library application. Requirem ents for this generic\nlibrary application are created by exploring the library do main, while trade-offs\nbetween requirements are based on market considerations, p roduct ﬁt, and the\nlike. We may decide that our system need not address the conce rns of the\nLibrary of Congress (too small a market), while it should deﬁ nitely interface\nwith accounting system Y, since that system is widely used in university\ndepartments, and this is perceived to be an important market for our library\napplication.\n/AF For different reasons (cost, time to market, quality) we may", "token_count": 512, "start_token": 122892, "end_token": 123404, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 267, "text": "\nwith accounting system Y, since that system is widely used in university\ndepartments, and this is perceived to be an important market for our library\napplication.\n/AF For different reasons (cost, time to market, quality) we may want to employ\ncommercial off the shelf (COTS) components in our library sy stem. We then\nhave to tradeoff our requirements against the possibilitie s offered by those\nCOTS components.\nFollowing Sommerville (2005), we distinguish four process es in requirements engi-\nneering:\n/AF Requirements elicitation In general, the requirements analyst is not an expert in\nthe domain being modeled. Through interaction with domain s pecialists, such\nas professional librarians, he has to build himself a sufﬁci ently rich model of that\ndomain. Thus, requirements elicitation is about understanding the problem. The\nfact that different disciplines are involved in this proces s complicates matters.\nIn many cases, the analyst is not a mere outside observer of th e domain to\nbe modeled, simply eliciting facts from domain specialists . He may have to\ntake a stand in a power struggle or decide between conﬂicting requirements,\nthereby actively participating in the construction of the d omain of interest.\nSection 9.1 discusses various issues related to, and a numbe r of techniques used\nin, requirements elicitation.\n/AF Requirements speciﬁcation Once the problem is understood, it has to be\ndescribed. In section 9.2, we give guidelines for the contents of a requ irements\nspeciﬁcation document. This document describes the produc t to be delivered,\nnot the process of how it is developed. Project requirements are described in the\nproject plan, discussed in chapter 2. The collection of requ irements not only\nhas to be documented, it also has to be managed during the cour se of a project.\nQuite a number of techniques exist for specifying requireme nts, ranging from\nvery informal (natural language) to very formal (mathemati cal). Throughout\nthis book, a number of such modeling techniques are discusse d, such as\nobject-oriented techniques in chapter 10, and techniques f or specifying quality\nrequirements in chapter 6. The design techniques discussed in chapter 12\nare often also used for specifying requirements. Section 9. 3 is conﬁned to", "token_count": 512, "start_token": 123354, "end_token": 123866, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 268, "text": " as\nobject-oriented techniques in chapter 10, and techniques f or specifying quality\nrequirements in chapter 6. The design techniques discussed in chapter 12\nare often also used for specifying requirements. Section 9. 3 is conﬁned to a\ndiscussion of some of the basic techniques for modeling requ irements.\n9.1. REQUIREMENTS ELICITATION 207\n/AF Requirements validation and veriﬁcation Once the problem is described, the\ndifferent parties involved have to agree upon its nature. We have to ascertain that\nthe correct requirements are stated (validation) and that t hese requirements are\nstated correctly (veriﬁcation). Some veriﬁcation and vali dation techniques that\ncan be applied at this early stage are sketched in section 9.4 .\n/AF Requirements negotiation Usually, requirements have to be negotiated.\nBecause of time constraints or other factors, a selection ma y have to be\nmade from the list of requirements put forth. Or stakeholder s may have con-\nﬂicts that need to be resolved. Often, stakeholders have con ﬂicting quality\nrequirements whose impact can only be determined by looking at the software\narchitecture. This is further dealt with in chapter 11.\nObviously, these processes involve iteration and feedback . In document-driven\napproaches, these iterations preceed design and implement ation. In agile processes,\ndesign and implementation is part of the iteration and feedb ack loop. In either case,\nthere is a central repository in which the requirements are d ocumented. The major\ninteractions are shown in ﬁgure 9.1.\nThe emphasis in our discussion of requirements engineering will be on modeling\nthe external behavior of the system, i.e. all those parts and aspects of the system\nthat end users consider important. Other views are relevant as well, for in stance, a\nmodel which highlights the way the system supports the busin ess, or a model which\nindicates how a system is deployed on a collection of hardwar e devices. Some of\nthese other views are discussed in chapter 11.\n9.1 Requirements Elicitation\nIn chapter 1, the ﬁrst part of the software life cycle was depi cted as shown in ﬁgure 9.2.\nThe fact that the text ‘requirements speciﬁ", "token_count": 512, "start_token": 123816, "end_token": 124328, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 269, "text": "itation\nIn chapter 1, the ﬁrst part of the software life cycle was depi cted as shown in ﬁgure 9.2.\nThe fact that the text ‘requirements speciﬁcation’ is place d in a rectangle suggests,\nnot unjustly, that it concerns something very concrete and e xplicit. The ‘problem’\nis less well deﬁned, less clear, even fuzzy in many cases. The primary goal of the\nrequirements engineering phase is to elicit the contours an d constituents of this fuzzy\nproblem. This process is also known as conceptual modeling .\nDuring requirements engineering we are modeling part of rea lity. The part of\nreality in which we are interested is referred to as the universe of discourse (UoD).\nExample UoDs are a library system, a factory automation syst em, an assembly line,\nan elevator system.\nThe model constructed during the requirements engineering phase is an explicit\nconceptual model of the UoD. The adjective ‘explicit’ indicates that the mode l must\nbe able to be communicated to the relevant people (such as ana lysts and users).\nTo this end it should contain all relevant information from t he UoD. One of the\npersistent problems of requirements analysis and, for that matter, analysis in general,\nis to account for all of the relevant inﬂuences and leave out i rrelevant details.\n208 REQUIREMENTS ENGINEERING\nManagement\nDocumentation &\nNegotiation\nElicitation Validation\nSpecification\nFigure 9.1 A framework for the requirements engineering pro cess (adapted from\n(Sommerville, 2005))\nFigure 9.2 The ﬁrst part of the software life cycle\n9.1. REQUIREMENTS ELICITATION 209\nIn our library example we could easily have overlooked the fa ct that in a number\nof cases the author’s name as it appears on the cover of a book i s not the ‘canonical’\nauthor’s name. This phenomenon occurs in particular with au thors from countries that\nuse non-Latin scripts. The transcription of the Russian nam e 4EXOB reads ‘Chekhov’\nin English and ‘Tsjechow’ in Dutch. In such cases, librarian s want", "token_count": 512, "start_token": 124278, "end_token": 124790, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 270, "text": " that\nuse non-Latin scripts. The transcription of the Russian nam e 4EXOB reads ‘Chekhov’\nin English and ‘Tsjechow’ in Dutch. In such cases, librarian s want to include the\nauthor’s name twice: once the name is spelled as it appears on the book, and once the\nname is spelled as it is used in the various search processes. An answer to a question\nlike ‘which books by Chekhov does our library possess?’ shou ld also inform us about\nthe non-English titles.\nSubtle mismatches between the analyst’s notion of terms and concepts and their\nproper meaning within the domain being modeled can have prof ound effects. Such\nmismatches can most easily occur in domains we already ‘know ’, such as a library. An\nilluminating discussion of potential problems in (formall y) specifying requirements\nof a library system can be found in (Wing, 1988). Problems not ed include:\n/AF A library employee may also be a member of the library, so the t wo sets of\nsystem users are not disjoint;\n/AF There is a difference between a book (identiﬁed by its ISBN) a nd the (physical)\ncopies of a book owned by the library;\n/AF It is not sufﬁcient to simply denote the status of a book by a bo olean value\npresent/not present (i.e. lent out). For instance, a book or , more properly, a\ncopy of a book, may be lost, stolen, or in repair.\nPeople involved in a UoD have an implicit conceptual model of that UoD. An\nimplicit conceptual model consists of the background knowl edge shared by people in\nthe UoD. The fact that this knowledge is shared gives rise to ‘ of course’ statements by\npeople from within the UoD, because this knowledge is taken f or granted. (‘Of course,\na copy of a book is not the same as a book.’) Part of the implicit conceptual model is\nnot verbalized. It contains tacit knowledge, knowledge tha t is skillfully applied and\nfunctions in the background. Finally, an implicit conceptu al model contains habits,\ncustoms, prejudices and even inconsistencies.\nDuring conceptual", "token_count": 512, "start_token": 124740, "end_token": 125252, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 271, "text": " model is\nnot verbalized. It contains tacit knowledge, knowledge tha t is skillfully applied and\nfunctions in the background. Finally, an implicit conceptu al model contains habits,\ncustoms, prejudices and even inconsistencies.\nDuring conceptual modeling, an implicit conceptual model i s turned into an\nexplicit one. In doing so, the analyst is confronted with two types of problem: analysis\nproblems and negotiation problems. Analysis problems aris e from the fact that part of\nthe implicit conceptual model is not verbalized, that the im plicit conceptual model\nevolves with time, that the user and analyst talk a different language, and that the\nimplicit conceptual model cannot be completely codiﬁed. Ne gotiation problems arise\nbecause people in the UoD may counteract the analysis proces s, because the implicit\nconceptual models of people in the UoD may differ, or because of opposing interests\nof people involved (such as library personnel versus their m anagers). Both types of\nproblems are discussed below.\nThe problem to be addressed by the automated system arises fr om the user, a\nhuman. This person must be able to describe this problem in bo th a correct and\n210 REQUIREMENTS ENGINEERING\ncomplete way. It must be communicated to a person who in gener al has a rather\ndifferent background. The analyst often lacks a sufﬁcientl y profound knowledge of\nthe application domain in which the problem originated. He h as to learn the language\nof the application domain and become acquainted with its ter minology, concepts\nand procedures. Especially in large projects, the applicat ion knowledge tends to be\nthinly spread amongst the specialists involved, which easi ly leads to integration and\ncoordination difﬁculties.\nIn our earlier example, it is the librarian who has to express his wishes. It is\npossible that the inclusion of two author names (‘Tsjechow’ and ‘Chekhov’) is seen as\nan obvious detail which need not be brought forward explicit ly. The analyst at the\nother side of the table may still get the impression that he ha s a complete picture of\nthe system. This type of omission may have severe consequenc es.\nA number of years back a large automated air defense system wa s being\ndeveloped in the US. During one of the ﬁnal tests of this", "token_count": 512, "start_token": 125202, "end_token": 125714, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 272, "text": " picture of\nthe system. This type of omission may have severe consequenc es.\nA number of years back a large automated air defense system wa s being\ndeveloped in the US. During one of the ﬁnal tests of this syste m, an alarm\nsignal was issued. One of the computers detected an unknown m issile. It\nturned out to be the moon. This possibility had not been thoug ht of.\nEliciting correct and complete information is an important prerequisite for success.\nThis turns out to be rather problematic in practice. Asking t he prospective user what\nis wanted does not generally work. More often than not we get a rather incomplete\nand inaccurate picture of the situation. Important reasons for this are the human\nlimitations for processing information, selecting inform ation, and solving problems.\nThese limited human capabilities are yet aggravated by such factors as:\n– the complexity and variation in requirements that can be im posed upon\nsoftware;\n– the differences in background between the client, or user, and the software\nspecialist.\nIn research on human information processing one often uses a model in which human\nmemory consists of two components: a short-term memory in wh ich information\nis being processed, and a long-term memory in which the perma nent knowledge is\nstored. Short-term memory has a limited capacity: one often says that it has about\nseven slots. Long-term memory on the other hand has a very lar ge capacity.\nSo, information is processed in a relatively small part of hu man memory. Long-\nterm memory is thus accessed in an indirect way. In addition, humans also employ\nexternal memories when information is being processed: a bl ackboard, a piece of\npaper, etc.\nIf a person being interviewed during requirements engineer ing only uses his short-\nterm memory, the limitations thereof may have an impact on th e results. This may\neasily occur if no use is being made of external memories. Thi ngs can be forgotten,\nsimply because our short-term memory has limited capacity.\nHumans are also inclined to be prejudiced about selecting an d using information.\nWe are, in particular, inclined to let recent events prevail . In making up a requirements\n9.1. REQUIREMENTS ELICITATION 211\nspeciﬁcation, this leads to requirements bearing on the pre sent situation, presently\n", "token_count": 512, "start_token": 125664, "end_token": 126176, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 273, "text": ", in particular, inclined to let recent events prevail . In making up a requirements\n9.1. REQUIREMENTS ELICITATION 211\nspeciﬁcation, this leads to requirements bearing on the pre sent situation, presently\navailable information, recent events, etc.\nHumans are not very capable of rational thinking. They will s implify things and\nuse a model which does not really ﬁt reality. Other limitatio ns that inﬂuence our\nmodel of reality are determined by such factors as education , prejudice, practice, etc.\nThis same kind of simpliﬁcation occurs when software requir ements are drawn up.\nAnd the result will be limited by the same factors.\nWe cannot always expect the user to be able to precisely state his requirements at\nan early stage. One reason for investigating the opportunit ies of automation is often\nbecause of a certain dissatisfaction with the present situa tion. One is not satisﬁed with\nthe present situation and has the impression that automatio n will help. Whether this\nis true or not -- many data processing problems are organizat ional problems -- simply\nautomating the present situation is not always the solution . Something different is\nwanted, though it is not clear what. Only when insight into th e possibilities of\nautomation is gained, will real requirements show themselv es. This is one of the\nreasons for the sheer size of the maintenance problem. About half of the maintenance\neffort concerns adapting software to (new) requirements of the user. To counteract\nthis trend, software development process models that ackno wledge this learning\nprocess, such as prototyping, incremental development, an d agile methodss are to be\npreferred over those that don’t, i.e. the waterfall model an d its variants.\nThrough a careful analysis, we may hope to build a sound persp ective of user\nrequirements and anticipate future changes. However, no ma tter how much time is\nspent in a dialog with the prospective users, future changes remain hard to foresee. We\nmay even go one step further and stipulate that requirements will never be complete. In\nthis respect, specifying requirements has much in common wi th weather-forecasting:\nthere is a limit to how far the future can be predicted.\nIn a situation where the goal of a software development pro", "token_count": 512, "start_token": 126126, "end_token": 126638, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 274, "text": " requirements will never be complete. In\nthis respect, specifying requirements has much in common wi th weather-forecasting:\nthere is a limit to how far the future can be predicted.\nIn a situation where the goal of a software development proje ct is to improve an\nexisting ‘system’, be it a manual process or a (partly) autom ated one, it is generally\nhelpful to explicitly distinguish two modeling steps. In th e ﬁrst step, the current\nsituation is modeled. Based on an analysis of the strengths a nd weaknesses of the\ncurrent situation, the situation-to-be is next modeled. Bu siness Process Redesign, in\nparticular, stresses the distinction between these two mod eling steps.\nFor the requirements engineering phase to be successful we n eed methods and\ntechniques that try to bypass the difﬁculties sketched abov e. The degree to which\npowerful techniques are required depends on the experience of the people involved in\nthe requirements engineering phase (both users and analyst s) and the expertise of the\nanalyst with the application domain. Section 9.1.2 discuss es a number of techniques\nfor requirements elicitation.\nBut before we discuss these techniques, we ﬁrst elaborate in section 9.1.1 how\ndifferent world views result in different approaches to req uirements engineering.\nIn section 9.1.3 we discuss how requirements relate to highe r level goals, and\nhow different viewpoints may result in different, and somet imes conﬂicting, sets of\nrequirements. Following section 9.1.3 we discuss how to pri oritize requirements, and\n212 REQUIREMENTS ENGINEERING\nhow requirements relate to the selection of COTS components .\n9.1.1 Requirements Engineering Paradigms\nMost requirements engineering methods, and software devel opment methods in\ngeneral, are Taylorian in nature. Around the turn of this cen tury, Taylor introduced\nthe notion of ‘scientiﬁc management’, in which tasks are rec ursively decomposed into\nsimpler tasks and each task has one ‘best way’ to accomplish i t. By careful observations\nand experiments this one best way can be found and formalized into procedures\nand rules. Scientiﬁc management has been successfully appl ied in", "token_count": 512, "start_token": 126588, "end_token": 127100, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 275, "text": " task has one ‘best way’ to accomplish i t. By careful observations\nand experiments this one best way can be found and formalized into procedures\nand rules. Scientiﬁc management has been successfully appl ied in many a factory\noperation. The equivalent in requirements engineering is t o interview domain experts\nand observe end users at work in order to obtain the ‘real’ use r requirements. After\nthis, the experts go to work and implement these requirement s. During the latter\nprocess there is no further need to interact with the user com munity. This view of\nsoftware development is a functional, and rational, one. It s underlying assumption is\nthat there is one objective truth, which merely needs to be di scovered during the\nanalysis process.\nThough this view has its merits in drawing up requirements in purely technical\nrealms, many UoDs of interest involve people as well -- peopl e whose model of the\nworld is incomplete, subjective, irrational, and may conﬂi ct with the world view of\nothers. In such cases, the analyst is not a passive outside ob server of the UoD. Rather,\nhe actively participates in the shaping of the UoD.\nIt is increasingly being recognized that the Taylorian, fun ctional, approach is\nnot the only, and need not be the most appropriate, approach t o the requirements\nengineering process.\nAnalysts have a set of assumptions about the nature of the sub ject of study. Such\na set of assumptions is commonly called a ‘paradigm’. In our ﬁ eld, these assumptions\nconcern the way in which analysts acquire knowledge (episte mological assumptions)\nand their view of the social and technical world (ontologica l assumptions).\nThe assumptions about knowledge result in an objectivist-- subjectivist dimension.\nIf the analyst takes the objectivist point of view, he applie s models and methods\nderived from the natural sciences to arrive at the one and onl y truth. In the subjectivist\nposition, his principal concern is to understand how the ind ividual creates, modiﬁes\nand interprets the world he or she is in.\nThe assumptions about the world result in an order--conﬂict dimension. The\norder point of view emphasizes order, stability, integrati on, and consensus. On the\nother hand", "token_count": 512, "start_token": 127050, "end_token": 127562, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 276, "text": " the world he or she is in.\nThe assumptions about the world result in an order--conﬂict dimension. The\norder point of view emphasizes order, stability, integrati on, and consensus. On the\nother hand, the conﬂict view stresses change, conﬂict, and d isintegration.\nThese two dimensions and their associated extreme position s yield four paradigms\nfor requirements engineering and, more generally, informa tion systems development:\nFunctionalism (objective--order). In the functionalist paradigm, the de veloper is the\nsystem expert who searches for measurable cause--effect re lationships. An empirical\norganizational reality is believed to exist, independent o f the observer. Systems\nare developed to support rational organizational operatio n. Their effectiveness and\n9.1. REQUIREMENTS ELICITATION 213\nefﬁciency can be tested objectively, by tests similar to tho se used in other engineering\ndisciplines.\nSocial-relativism (subjective--order). In this paradigm, the analyst operat es as a\nfacilitator. Reality is not something immutable ‘out there ’, but is constructed in the\nhuman mind. The analyst is a change agent. He seeks to facilit ate the learning of all\npeople involved.\nRadical-structuralism (objective--conﬂict). In the radical paradigm the key assu mp-\ntion is that system development intervenes in the conﬂict be tween two or more social\nclasses for power, prestige, and resources. Systems are oft en developed to support the\ninterests of the owners, at the expense of the interests of la bor. In order to redress\nthe power balance, this paradigm suggests that the analyst s hould act as a labor\npartisan. System requirements should evolve from a coopera tion between labor and\nthe analyst. This approach is thought to lead to systems that enhance craftsmanship\nand working conditions.\nNeohumanism (subjective--conﬂict). The central theme in this paradigm is eman-\ncipation. Systems are developed to remove distorting inﬂue nces and other barriers\nto rational discourse. The system developer acts as a social therapist in an attempt\nto draw together, in an open discussion, a diverse group of in dividuals, including\ncustomers, labor,", "token_count": 512, "start_token": 127512, "end_token": 128024, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 277, "text": "��ue nces and other barriers\nto rational discourse. The system developer acts as a social therapist in an attempt\nto draw together, in an open discussion, a diverse group of in dividuals, including\ncustomers, labor, and various levels of management.\nAdmittedly, these paradigms reﬂect extreme orientations. In practice, some mixture\nof assumptions will usually guide the requirements enginee ring process. Yet it is fair to\nsay that the majority of system development techniques emph asizes the functionalist\nview.\nIn the subjectivist--objectivist dimension, it is importa nt to realize that a good\ndeal of subjectivism may be involved in the shaping of the UoD . If we have to\ndevelop a system to, say, control a copying machine, we may sa fely take a functional\nstand. We may expect such a machine to operate purely rationa lly. In the analysis\nprocess, we list the functions of the machine, its internal s ignals, conditions, and so\non, in order to get a satisfactory picture of the system to be d eveloped. Once these\nrequirements are identiﬁed, they can be frozen and some wate rfall-like process model\ncan be employed to realize the system.\nIf, however, our task is to develop a system to support people in doing their\njob, such as some ofﬁce automation system, a purely function al view of the world\nmay easily lead to ill-conceived systems. In such cases, end -user participation in the\nshaping of the UoD is of paramount importance. Through an ope n dialog with the\npeople concerned, we may encourage the prospective users to inﬂuence the system\nto be developed. Part of the analyst’s job in this case is to re concile the views\nof the participants in the analysis process. Continuous fee dback during the actual\nconstruction phases with possibilities for redirection ma y further enhance the chance\nof success. It is the future users who are going to work with th e system. It is of no\navail to confront them with a system that does not satisfy the ir needs.\n214 REQUIREMENTS ENGINEERING\nAutomation transforms organizations, and thus affects the organization’s employ-\nees. It may raise fears and other emotions with the employees affected. For instance,", "token_count": 512, "start_token": 127974, "end_token": 128486, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 278, "text": " does not satisfy the ir needs.\n214 REQUIREMENTS ENGINEERING\nAutomation transforms organizations, and thus affects the organization’s employ-\nees. It may raise fears and other emotions with the employees affected. For instance,\nour library system potentially gives people access to a lot m ore information than they\npreviously had. Some people though may prefer to have access only to information\nrelated to their tasks and responsibilities. During requir ements engineering, we have\nto be conscious about these effects. The pure functionalist paradigm then is of no\navail.\nA dissatisﬁed user will try to neglect the system or, at best, express additional\nrequirements immediately. The net result is that the envisa ged gain in efﬁciency or\neffectiveness is not reaped.\nAn illuminating and well-documented example of possible ef fects of following a\nfairly radical paradigm is given in (Page et al., 1993); see a lso section 1.4.3. The system\nconcerns the Computer Aided Despatch System for the London A mbulance Service.\nThough the system would signiﬁcantly impact the way ambulan ce crews carried out\ntheir jobs, there was little consultation with them. Some of the consequences of this\napproach were the following (Page et al., 1993, pp 40--41):\n– The system allocated the nearest available resource regar dless of originating\nstation, so crews often had to operate further and further fr om their home base.\nThis resulted in them operating in unfamiliar territory wit h further to go to\nreach their home station at the end of a shift.\n– The new system took away the ﬂexibility crews previously ha d for the station\nto decide on which resource to allocate. This inevitably led to problems when\na different resource was used to the one that was allocated.\n– The lack of voice contact made the whole process more impers onal and\nexacerbated the ‘them and us’ situation.\nIf the conceptual models of the participants differ, we may e ither look for a\ncompromise, or opt for one of the views expressed. It is impos sible to give general\nguidelines on how to handle such cases. Looking for a comprom ise can be a tedious\naffair and may lead to a system that no one is really happy", "token_count": 512, "start_token": 128436, "end_token": 128948, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 279, "text": " one of the views expressed. It is impos sible to give general\nguidelines on how to handle such cases. Looking for a comprom ise can be a tedious\naffair and may lead to a system that no one is really happy with . Opting for one\nparticular view of the world will make one party happy, but ma y result in others\ncompletely neglecting the system developed. Worse yet, the y may decide to develop\na competing system.\n9.1.2 Requirements Elicitation Techniques\nThe two main sources of information for the requirements eli citation process are\nthe users and the (application) domain. These sources both p resuppose that there\nexists something ‘out there’ to start with, and from which re quirements can be\nelicited. In market-driven software development though, t his is often not the case,\nand requirements elicitation in such projects is more like r equirements invention or\nproblem-formulation, guided by marketing and sales consid erations.\n9.1. REQUIREMENTS ELICITATION 215\nFigure 9.3 lists a number of elicitation techniques, which a re elaborated upon\nbelow. The ﬁgure also tells us that the user is the major sourc e of information\nin some techniques, while the domain is predominant in other s. Furthermore, the\nﬁgure indicates whether each technique is particularly use ful to model the current, as\nopposed to the anticipated future, situation.\nYou should generally vacuum a rug in two directions rather th an one; likewise,\nyou should use multiple requirements elicitation techniqu es.\nFigure 9.3 A sample of requirements elicitation techniques\nAsking We may simply ask the users what they expect from the system. A presup-\nposition then is that the user is able to bypass his own limita tions and prejudices.\nAsking may take the form of an interview, a brainstorm, or a qu estionnaire. In an\nopen-ended interview, the user freely talks about his tasks . This is the easiest form of\nrequirements elicitation, but it suffers from all of the dra wbacks mentioned before.\nIn a structured interview, the analyst tries to overcome the se by leading the user, for\nexample through closed or probing questions.\nIn discussion sessions with a group of users, we often ﬁnd tha t some users are\nfar more", "token_count": 512, "start_token": 128898, "end_token": 129410, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 280, "text": "In a structured interview, the analyst tries to overcome the se by leading the user, for\nexample through closed or probing questions.\nIn discussion sessions with a group of users, we often ﬁnd tha t some users are\nfar more articulate than others, and thus have a greater inﬂu ence on the outcome.\nThe consensus thus reached need not be well-balanced. To ove rcome this problem, a\nDelphi technique may be employed. The Delphi technique is an iterative technique\nin which information is exchanged in a written form until a co nsensus is reached.\nFor example, participants may write down their requirement s, sorted in order of\nimportance. The sets of requirements thus obtained are dist ributed to all participants,\n216 REQUIREMENTS ENGINEERING\nwho reﬂect on them to obtain a revised set of requirements. Th is procedure is repeated\nseveral times until sufﬁcient consensus is reached.\nFor consumer products, such as word processing packages, an tivirus software\nor software for your personal administration, users often h ave the option to give\nfeedback, raise questions, report bugs, and the like, elect ronically. This type of\ninformation is also regularly gathered and stored by sales a nd marketing people in\nthe course of their contacts with customers. These logs can b e mined and in this way\nprovide a valuable source of information when looking for re quirements for the next\nrelease of that software.\nTask analysis Employees working in some domain perform a number of tasks, s uch\nas handling requests to borrow a book, cataloging new books, ordering books, etc.\nHigher-level tasks may be decomposed into subtasks. For exa mple, the task ‘handle\nrequest to borrow a book’ may lead to the following subtasks:\n– check member identiﬁcation,\n– check for limit on the number of books that may be borrowed,\n– register book as being borrowed by the library member,\n– issue a slip indicating the due back date.\nTask analysis is a technique to obtain a hierarchy of tasks an d subtasks to be carried\nout by people working in the domain. Any of the other techniqu es discussed may be\nused to get the necessary information to draw this hierarchy . There are no clear-cut\nrules as to when to stop decomposing tasks. A major", "token_count": 512, "start_token": 129360, "end_token": 129872, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 281, "text": "\nout by people working in the domain. Any of the other techniqu es discussed may be\nused to get the necessary information to draw this hierarchy . There are no clear-cut\nrules as to when to stop decomposing tasks. A major heuristic is that at some point\nusers tend to ‘refuse’ to decompose tasks any further. For in stance, when being asked\nhow the member identiﬁcation is checked, the library employ ee may say ‘Well, I\nsimply check his id.’ At this point, further decomposition i s meaningless.\nTask analysis is often applied at the stage when (details abo ut) the human--\ncomputer interaction component are being decided upon. Thi s underestimates its\npotency as a general requirements elicitation technique. I t also gives the (wrong)\nimpression that users are only concerned with the ‘look and f eel’ of the interface.\nScenario-based analysis Instead of looking for generic plans as in interviews or task\nanalysis, the analyst may study instances of tasks. A scenario is a story which tells\nus how a speciﬁc task instance is executed. The scenario can b e real or artiﬁcial. An\nexample of a real scenario is that the analyst observes how a l ibrary employee handles\nan actual user request. We may ask the library employee to ver balize what he is doing\nand make an audio or video recording thereof. This think aloud method is a fairly\nunobtrusive technique to study people at work. It is often us ed to assess prototypes\nor existing information systems.\nAlternatively, we may construct artiﬁcial scenarios and di scuss these with the user.\nAs a ﬁrst shot, we may for example draw up the following scenar io for returning a\nbook:\n9.1. REQUIREMENTS ELICITATION 217\n1. The due back date for the book is checked. If the book is over due, the member\nis asked to pay the appropriate ﬁne.\n2. The book is recorded as again being eligible for checking- out.\n3. The book is put back in its proper place.\nWhen this scenario is discussed with the library employee, a number of related issues\nmay crop up, either through probing questions from the analy st, or because the user\ncontrasts the", "token_count": 512, "start_token": 129822, "end_token": 130334, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 282, "text": ". The book is put back in its proper place.\nWhen this scenario is discussed with the library employee, a number of related issues\nmay crop up, either through probing questions from the analy st, or because the user\ncontrasts the scenario with daily practice. Example questi ons that could be raised\ninclude such things as:\n– What happens when the person returning the book is not a regi stered member\nof the library?\n– What happens when the book returned is damaged?\n– What happens if the member returning this book has other boo ks that are\noverdue or an outstanding reservation for another book?\nIn essence, this type of story-telling provides the user wit h an artiﬁcial mock-up version\nof the software eventually to be delivered. It serves as a pap er-based prototype to\ngain a better understanding of the requirements. If tied to a UML-type of modeling,\nscenario-based analysis is often called use-case analysis ; see section 10.3.6. Scenarios\nand use cases are the elicitation methods most often used.\nScenario-based analysis is often done in a somewhat haphaza rd way. In that case,\nthere is no way of telling whether enough scenarios have been drawn up and a\nsufﬁciently accurate and complete picture of the requireme nts is obtained. Writing\ngood scenarios is by no means easy. Though it may look trivial to ‘just record user\nepisodes’, a fair mount of domain expertise is needed to get a good and reliable set of\nscenarios.\nScenarios can be looked at from different perspectives. In t he above example\nscenario for returning a book, the scenario lists a series of actions or events that\ntogether make up some episode. The focus then is on the proces s aspect, showing\nhow the system proceeds through successive states. Alterna tively, the same scenario\nmay be looked at from a user perspective: how will the user int eract with the system,\nwhat functionalities will she be offered? Yet another persp ective is that the scenario\nleads to discussions about alternatives from which a certai n choice has to be made, as\nin the questions that the example scenario above raised.\nEthnography A major disadvantage of eliciting requirements through, fo r example,\ninterviews is that the analyst imposes his view", "token_count": 512, "start_token": 130284, "end_token": 130796, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 283, "text": " which a certai n choice has to be made, as\nin the questions that the example scenario above raised.\nEthnography A major disadvantage of eliciting requirements through, fo r example,\ninterviews is that the analyst imposes his view of how the wor ld is ordered onto the\nuser. Such methods may fail if the analyst and user do not shar e a category system.\nThe analyst may, for example, ask the following:\n‘If a member wants to borrow a book while he or she still has an o utstanding ﬁne, will\nyou:\n218 REQUIREMENTS ENGINEERING\na) Refuse the request, or\nb) Handle the request anyway’\nThis binary choice need not map actual practice. The library employee may, for\nexample, grant the request provided part of the outstanding ﬁne is settled or if he\nknows the member to be trustworthy.\nThinking aloud protocols are based on the idea that users hav e well-deﬁned\ngoals and subgoals, and that they traverse such goal trees in a neat top-down\nmanner. People however often do not have preconceived plans , but rather proceed\nin somewhat opportunistic ways.\nA disadvantage of task analysis is that it considers individ ual tasks of individual\npersons, without taking into account the social and organiz ational environment in\nwhich these tasks are executed.\nEthnographic methods are claimed not to have such shortcomi ngs. In ethnog-\nraphy, groups of people are studied in their natural setting s. It is well-known from\nsociology, where for example Polynesian tribes are studied by living with them for an\nextended period of time. Likewise, user requirements can be studied by participating\nin their daily work for a period of time, for example by becomi ng a library employee.\nThe analyst becomes an apprentice, recognizing that the fut ure users of the system\nare the real experts in their work. Ethnographic methods are more likely to uncover\ntacit knowledge than most other elicitation techniques.\nForm analysis A lot of information about the domain being modeled can often\nbe found in various forms being used. For example, to request some conference\nproceedings from another library, the user might have to ﬁll in a form such as given\nin ﬁgure 9.4.", "token_count": 512, "start_token": 130746, "end_token": 131258, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 284, "text": "\nbe found in various forms being used. For example, to request some conference\nproceedings from another library, the user might have to ﬁll in a form such as given\nin ﬁgure 9.4.\nFigure 9.4 A sample form\n9.1. REQUIREMENTS ELICITATION 219\nForms provide us with information about the data objects of t he domain, their\nproperties, and their interrelations. They are particular ly useful as an input to modeling\nthe data aspect of the system; see also section 10.1.1.\nLibrary users often have incomplete knowledge of the inform ation sources they\nare interested in. For example, someone might be looking for the proceedings of\nthe International Conference on Software Engineering that took place in Berlin. Only if the\nvarious entries from the above form are used as entities in th e underlying data model,\ncan such a query be answered easily. In this case, the form dir ectly points at a useful\nrequirement which might otherwise go unnoticed.\nNatural language descriptions Like forms, natural language descriptions provide a\nlot of useful information about the domain to be modeled. The operating instructions\nfor library employees might for instance contain a paragrap h like the one given in\nﬁgure 9.5. This text gives us such information as:\n– There are (at least) two accounts that orders can be charged to;\n– There is a list of staff members authorized to sign off such r equests;\n– There is the possibility of ordering multiple copies of tit les, such as this book\non Software Engineering , on behalf of students.\nTitle acquisition\nBefore a request to acquire a title can be complied with, form B has to be ﬁlled in\ncompletely. A request can not be handled if it is not signed by an authorized staff\nmember or the account to be charged (‘Student’ or ‘Staff’) is not indicated. A request\nis not to be granted if the title requested is already present in the title catalog, unless\nit is marked ‘Stolen’ or ‘Lost’, or the account is ‘Student’.\nFigure 9.5 A sample instruction for library employees\nOften, natural language descriptions (and forms) provide t he analyst with background\ninformation to be used in conjunction with other elicitatio n techniques such as\ninterviews. Natural language descriptions in", "token_count": 512, "start_token": 131208, "end_token": 131720, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 285, "text": "\nFigure 9.5 A sample instruction for library employees\nOften, natural language descriptions (and forms) provide t he analyst with background\ninformation to be used in conjunction with other elicitatio n techniques such as\ninterviews. Natural language descriptions in particular t end to assume a lot of tacit\nknowledge by the reader. For example, if form B contains an IS BN, this saves the\nlibrary employee some work, but the request will probably st ill be handled if this\ninformation is not provided. A practical problem with natur al language descriptions\nis that they are often not kept up-to-date. Like software doc umentation, their validity\ntends to deteriorate with time.\nNatural language descriptions are often taken as a starting point in object-oriented\nanalysis techniques. This is further discussed in section 1 2.3.\n220 REQUIREMENTS ENGINEERING\nDerivation from an existing system Starting from an existing system, for instance a\nsimilar system in some other organization or a description i n a text book, we may\nformulate the requirements of the new system. Obviously, we have to be careful and\ntake the peculiar circumstances of the present situation in to account.\nRather than looking at one particular system, we may also stu dy a number of\nsystems in some application domain. This meta-requirement s analysis process is\nknown as domain analysis . Its goal generally is to identify reusable components,\nconcepts, structures, and the like. It is dangerous to look f or reusable requirements\nin immature domains. Requirements may then be reused simply because they are\navailable, not because they ﬁt the situation at hand. They be come ‘dead wood’. In\nthe context of requirements analysis, domain analysis can b e viewed as a technique\nfor deriving a ‘reference’ model for systems within a given d omain. Such a reference\nmodel provides a skeleton (architecture) that can be augmen ted and adapted to ﬁt\nthe speciﬁc situation at hand.\nDomain analysis is further discussed in chapter ??, in the context of software reuse\nand software product line development.\nBusiness Process Redesign (BPR). In many software development projects, the\npeople involved jump to conclusions rather quickly: automa tion is the answer.\nEven worse, their conclusion might be that automating the cu rrent situation is the\nanswer. In Business Process Redes", "token_count": 512, "start_token": 131670, "end_token": 132182, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 286, "text": "). In many software development projects, the\npeople involved jump to conclusions rather quickly: automa tion is the answer.\nEven worse, their conclusion might be that automating the cu rrent situation is the\nanswer. In Business Process Redesign (or Business Process R eengineering), a rather\ndifferent strategy is followed. It is an organizational act ivity to radically redesign\nbusiness processes to achieve competitive breakthroughs i n, e.g. quality, cost, or user\nsatisfaction. In BPR, we depart completely from the existin g ways of doing things. In\nBPR, the following steps are distinguished:\n1. Identify processes for innovation. Two major approaches for doing so are the\nexhaustive and high-impact approach. In the exhaustive app roach, an attempt\nis made to identify all processes, which are then prioritize d for their redesign\nurgency. The high-impact approach attempts to identify the most important\nprocesses only, or the ones that conﬂict with the business vi sion.\n2. Identify change levers. In this step, opportunities faci litating process improve-\nment are identiﬁed. Three types of lever can be recognized: o rganizational\nenablers (such as empowering teams), human resource enable rs (such as task\nenrichment) and information technology enablers.\n3. Develop process visions. For redesign to be successful, t he organization needs\nto know which goals it wants to reach. This is described in the process vision.\nThe main components of a process vision are: process objecti ves (measurable\ntargets of the future performance of the system), process at tributes (qualitative\nand descriptive properties of the future process), critica l success factors and\nconstraints (organizational, cultural, and technologica l).\n9.1. REQUIREMENTS ELICITATION 221\n4. Understand the existing process. This includes document ing the existing\nprocess, measuring it, and identifying problematic aspect s. It allows us to assess\nthe health of the existing process, and brings problems to th e surface.\n5. Design and prototype the new process. This is the ﬁnal step . Prototyping makes\nit possible to try out new structures, thereby reducing the r isk of failure.\nBPR is not really a requirements elicitation technique prop er. It", "token_count": 512, "start_token": 132132, "end_token": 132644, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 287, "text": " new process. This is the ﬁnal step . Prototyping makes\nit possible to try out new structures, thereby reducing the r isk of failure.\nBPR is not really a requirements elicitation technique prop er. It is mentioned here\nbecause it emphasizes an essential issue to be addressed dur ing the requirements\nengineering phase. Business processes should not be driven by information technol-\nogy. Rather, information technology should enable them. Th ough a complete BPR\neffort is not necessary or feasible in many situations, reth inking the existing processes\nand procedures is a step which is all too often thoughtlessly skipped in software\ndevelopment projects.\nAs an example, consider our library automation project once again. Careful\ninspection of the current situation might reveal that thing s aren’t all that bad.\nHowever, the impression is that the number of requests that c ould not be granted has\nsteadily risen in the past years. This is perceived to be the m ain cause of the increasing\nnumber of dissatisﬁed users. Since service to its customers has high priority, one of\nthe objectives is to decrease the number of requests that can not be satisﬁed by 50%\nwithin two years. For this to be possible, the library should be allowed to spend the\navailable budget at its own discretion, rather than being tr iggered by signals from\nresearchers only (this sounds radical, doesn’t it). It is th erefore decided to augment\nthe existing automated system with modules to keep track of b oth successful and\nunsuccessful requests. Based on the insights gained from th is measurement process\nduring a period of three months, a decision will be taken as to how large a percentage\nof the annual budget will be reallocated.\nPrototyping Given the fact that it is difﬁcult, if not impossible, to buil d the right\nsystem from the start, we may decide to use prototypes. Start ing from a ﬁrst set of\nrequirements, a prototype of the system is constructed. Thi s prototype is used for\nexperiments, which lead to new requirements and more insigh t into the possible uses\nof the system. In one or more ensuing steps, a more deﬁnite set of requirements is\ndeveloped. Prototyping is discussed in section 3.2.1. Othe", "token_count": 512, "start_token": 132594, "end_token": 133106, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 288, "text": " more insigh t into the possible uses\nof the system. In one or more ensuing steps, a more deﬁnite set of requirements is\ndeveloped. Prototyping is discussed in section 3.2.1. Othe r agile processes follow a\nsimilar strategy in which requirements are quickly transla ted into a running system to\nbe assessed by its users.\nOf these requirements elicitation techniques, asking is th e least certain strategy,\nwhile prototyping is the least uncertain. Besides the exper ience of both users and\nanalysts, the uncertainty of the process is also inﬂuenced b y the stability of the\nenvironment, the complexity of the product to be developed a nd the familiarity with\nthe problem area in question. We may try to estimate the impac t of those factors\non the vulnerability of the resulting requirements speciﬁc ation, and then decide on a\ncertain primary method for requirements elicitation based on this estimate.\n222 REQUIREMENTS ENGINEERING\nFor a well-understood problem, with very experienced analy sts, interviewing the\nprospective users may sufﬁce. However, if it concerns an adv anced and ill-understood\nproblem from within a rapidly changing environment and the a nalysts have little or\nno experience in the domain in question, it seems wise to foll ow an agile process.\nRequirements uncertainty is not the only problem project ma nagers have to\ncope with, and a different process is not the only solution th ey opt for. Political\naspects (such as hidden agendas and conﬂicts between stakeh olders) are often seen as\nlarger risks than mere requirements uncertainty (Moynihan , 2000). Of course, these\nare related. In both cases chances are high that requirement s will change. Project\nmanagers often follow a formal route to handle disagreement s between stakeholders,\nand let the customers sign off the requirements document. Wh ether this is the answer\nin the long run is questionable, though.\nAs the uncertainty decreases, the beneﬁcial effects of user participation in\nrequirements engineering diminish. If the uncertainty inc reases, however, greater user\nparticipation does have a positive effect on the quality of r equirements engineering.\nIt is generally wise to have multiple customer--developer l inks in a software\ndevelopment project, and during requirements engineering in particular. Ke", "token_count": 512, "start_token": 133056, "end_token": 133568, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 289, "text": ", greater user\nparticipation does have a positive effect on the quality of r equirements engineering.\nIt is generally wise to have multiple customer--developer l inks in a software\ndevelopment project, and during requirements engineering in particular. Keil and\nCarmel (1995) studied the relation between project success and the number and\ntype of such customer--developer links. The authors observ ed a strong correlation\nbetween the number of links and project success: more links i mplied more successful\nprojects. The relative contribution to project success dim inishes as the number of\nlinks grows; there is no need to have more than, say, half a doz en links. A further\ninteresting observation from this study is that links with direct users have more impact\non project success than links with indirect users such as user representatives or sales\npeople. Finally, it was noted that customer-driven develop ment projects tend to\nuse and prefer different types of link to market-driven deve lopment projects. For\nexample, the favorite link for custom development -- facili tated teams -- was not used\nby package developers, while the favorite link for package d evelopers -- support lines\n-- was seldom used for custom projects.\nWe should be very careful in our assessment of which requirem ents elicitation\ntechnique to choose. It is all too common to be too optimistic about our ability to\nproperly assess software requirements.\nAs an example, consider the following anecdote from a Dutch n ewspaper. A ﬁrm\nin the business of farm automation had developed a system in w hich microchips were\nput in cows’ ears. Subsequently, each individual cow could b e tracked: food and water\nsupply was regulated and adjusted, the amount and quality of the milk automatically\nrecorded and analyzed, etc. Quite naturally, this same tech nique was next successfully\napplied to pigs. Thereafter, it was tried on goats. A million -dollar, fully automated\ngoat farm was built. But alas, things did not work out that wel l for goats. Contrary to\ncows and pigs, goats eat everything, including their compan ions’ chips.\n9.1. REQUIREMENTS ELICITATION 223\n9.1.3 Goals and Viewpoints\nIn this section we discuss two ways to structure a set of requi rements. One way to do\nso is in a", "token_count": 512, "start_token": 133518, "end_token": 134030, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 290, "text": "\n9.1. REQUIREMENTS ELICITATION 223\n9.1.3 Goals and Viewpoints\nIn this section we discuss two ways to structure a set of requi rements. One way to do\nso is in a hierarchical structure: higher-level requiremen ts are decomposed into lower-\nlevel ones. The high-level requirements are often termed go als. The other structuring\nmethod links requirements to speciﬁc stakeholders. For exa mple, management may\nhave a set of requirements, and the end-users may have (anoth er) set of requirements.\nThese different sets of requirements are called viewpoints . In both cases, elicitation\nand structuring go hand in hand.\nFor example, one of the requirements elicited for our librar y system could be\nthat the system should allow users to search the database for a particular book. By\nasking ourselves or the stakeholders why this requirement is needed, a higher level\nrequirement is detected, viz. the necessity for having sear ch facilities. Again asking\nwhy, a high-level goal of serving the customers is arrived at . Going the other way, by\nasking how the library system may help serve the customers, a requireme nt to learn\nabout user preferences and use this knowledge while interac ting with the user, might\nemerge. In this way, by asking why and how questions, a hierarchical structure of goals\nand requirements develops. Figure 9.6 contains an example o f such a hierarchical\nstructure.\nlearn user\npreferences\nsearch\nfacilities\nsearch news itemsearch book\nserve customers\nFigure 9.6 Hierarchy of requirements\n224 REQUIREMENTS ENGINEERING\nFigure 9.6 depicts a reﬁnement structure, in which each requ irement is reﬁned\n(decomposed) into a set of subrequirements that together sa tisfy the parent require-\nment. The subrequirements are AND-related: ‘search book’ a nd ‘search news item’\ntogether make up the ‘search facilities’ requirement.\nWe may also include other types of relationships. For instan ce, we may have\ncertain options for a particular requirement, and to that en d have OR-relations next to\nAND-relations. We may also include other types of link. If we have a requirement to\n", "token_count": 512, "start_token": 133980, "end_token": 134492, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 291, "text": " relationships. For instan ce, we may have\ncertain options for a particular requirement, and to that en d have OR-relations next to\nAND-relations. We may also include other types of link. If we have a requirement to\nimpose ﬁnes on customers who return items late, we may concei ve this as conﬂicting\nwith our goal of serving customers, and connect these two req uirements by a link of\ntype ‘conﬂicts with’.\nThis so-called goal-driven requirements engineering results in a graph connecting\nhigh-level goals to lower-level requirements. This graph c an be reasoned about, e.g.\nto validate that certain goals are indeed reached, or to dete ct conﬂicts (Lamsweerde,\n2001).\nIt is often useful to collect and organize requirements from different perspectives,\nor viewpoints. Different stakeholders may have different sets of require ments.\nDifferent quality concerns may also lead to different sets o f requirements, leading\nfor instance to a security viewpoint. The latter type of pers pective is usually dealt\nwith during software architecture design, and will be discu ssed in chapter 11. The\ntechniques discussed in section 9.3 implicitly denote diff erent viewpoints as well, such\nas a data viewpoint in the entity-relationship models. Here , we focus on different\nviewpoints caused by different stakeholders. These differ ent viewpoints may be in\nconﬂict, and these conﬂicts need to be recognized and dealt w ith during requirements\nengineering.\nThe Computer Aided Dispatch System for The London Ambulance Service\nagain provides a clear case of conﬂicting viewpoints: manag ement wants an effective\nsystem, crew members want to get home within a reasonable tim e after their shift has\nended (see also sections 1.4.3 and 9.1.1). For our library sy stem, conﬂicts between\nstakeholders may likewise occur.\nConsider, for example, the following issue which may crop up during the\nrequirements elicitation phase for our library system. The system has to offer certain\nfeatures to register and handle ﬁnes. An item not returned in time incurs a ﬁne of,\nsay, $0.25 per day. John, one of the library employees involv ed in the speci", "token_count": 512, "start_token": 134442, "end_token": 134954, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 292, "text": "\nfeatures to register and handle ﬁnes. An item not returned in time incurs a ﬁne of,\nsay, $0.25 per day. John, one of the library employees involv ed in the speciﬁcation\nprocess, takes the following position (denoted ‘Pos A’ in ﬁg ure 9.7): members should\nbe warned about outstanding ﬁnes at the earliest possible mo ment. His argument (‘Arg\nA’) is that service is degraded if a member cannot borrow an it em because some other\nmember has not returned that item on time. Mary, the library m anager, takes a rather\ndifferent position (‘Pos B’): members should not be warned about outstanding ﬁnes\nuntil the due-back date has expired one month. Her argument ( ‘Arg B’) is that ﬁnes\nare a most welcome addition to the library budget, which is un der severe pressure\nbecause of the continuing price increase of journal subscri ptions.\nThis situation is graphically depicted in the graph in ﬁgure 9.7. The graph contains\nnodes of types ‘issue’, ‘position’ and ‘argument’, and dire cted links of type ‘response-to’,\n9.1. REQUIREMENTS ELICITATION 225\nFigure 9.7 Graph representation of conﬂicting viewpoints\n‘taken-by’ and ‘supports’. Capturing this type of informat ion in an automated system\noffers possibilities to store, trace and manipulate the ver y diverse types of information\nbeing gathered during the requirements engineering phase. An early system along\nthese lines is gIBIS, a system designed to capture early desi gn decisions.\nTwo viewpoints in particular are important during requirem ents engineering: the\nbusiness viewpoint and the personal viewpoint. The busines s viewpoint is usually\npropagated by management stakeholders, while the personal viewpoint is usually\npropagated by end users. However, end users tend to also ascr ibe to business\nrequirements, at least at an early stage. For instance, when John is asked whether\nﬁnes are a welcome addition to the subsidy the library gets fr om the government, a\nlikely answer is ‘yes’. This requirement", "token_count": 512, "start_token": 134904, "end_token": 135416, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 293, "text": "irements, at least at an early stage. For instance, when John is asked whether\nﬁnes are a welcome addition to the subsidy the library gets fr om the government, a\nlikely answer is ‘yes’. This requirement is viewed as a requi rement of the business, not\na personal requirement of John. Only when he is confronted wi th the consequences,\nwill he realize that this is after all not what he wants. And a r equest to change the\nsystem will follow.\n9.1.4 Prioritizing Requirements\nOur task is not to provide every button and pull-down menu enh ancement that our\ncustomers ask for, but to invent a completely new way of worki ng -- one that will thrill\n226 REQUIREMENTS ENGINEERING\nand amaze them.\n(Robertson, 2002)\nIn most cases, not all requirements can be realized, so we hav e to make a selection.\nIn section 3.2.3 we mentioned a very simple form of requireme nts prioritization called\ntriage. A variant often used is known as MoSCoW (the o’s are just ther e to be able to\npronounce the word). Usinig MoSCoW, we distinguish four typ es of requirement:\n/AF Must haves : these are the top priority requirements, the ones that deﬁn itely\nhave to be realized in order to make the system acceptable to t he customer.\n/AF Should haves : these requirements are not strictly mandatory, but they ar e\nhighly desirable.\n/AF Could haves : if time allows, these requirements will be realized as well . In\npractice, they usually won’t.\n/AF Won’t haves : these requirements will not be realized in the present vers ion.\nThey are recorded though. They will be considered again for a next version of\nthe system.\nThe MoSCoW scheme assumes that requirements can be ordered a long a single axis,\nand that realizing more requirements yields more satisﬁed c ustomers. Reality often\nis more complex. In the Kano model (Kano, 1993), user preferences are classiﬁed\ninto ﬁve categories, as listed in ﬁgure 9.8. The way customer s value the Attractive,\nMust-be and One", "token_count": 512, "start_token": 135366, "end_token": 135878, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 294, "text": " (Kano, 1993), user preferences are classiﬁed\ninto ﬁve categories, as listed in ﬁgure 9.8. The way customer s value the Attractive,\nMust-be and One-dimensional categories of requirements is depicted in ﬁgure 9.9.\nThis ﬁgure shows that offering attractive, so called killer features, is what will really\nexcite your customers. The above quote from Robertson (2002 ) points in the same\ndirection: amaze your customer by giving him something he ne ver even dreamt of.\nIn market-driven software development, the product often h as a series of releases.\nThe list of requirements for such products is usually derive d from sales information,\nuser logs from earlier versions of the system, and other sour ces of indirect information.\nOne then has to decide which requirements to include in the cu rrent version, and\nwhich ones to postpone to a next one. Business case analysis, return on investment\nestimations, and similar economics-driven argumentation s then are used to set\npriorities. This priority setting is to be repeated for each version, since user preferences\nmay change, the market reacts, and the like.\nFinally, the prioritization of requirements is related to t he notion of scoping in\nsoftware product lines. If we want to develop a series of simi lar library systems, we\nhave to delimit the domain we intend to handle. A smaller doma in, say only scientiﬁc\nlibraries, is easier to realize, but has a smaller market. A s et of products covering\na larger domain is more difﬁcult to realize, yet has the promi se of larger sales and\nproﬁts. Scoping is further discussed in chapter ??, in the context of our discussion of\nsoftware product lines.\n9.1. REQUIREMENTS ELICITATION 227\nAttractive The customer will be more satisﬁed if these requi re-\nments are met, but not les satisﬁed if they are not. For\nexample, an automatic alert if new books of a beloved\nauthor arrive.\nMust-be The customer will be dissatisﬁed if these requireme nts\nare not met, but his satisfaction will never raise above\nneutral. An example is the ability to search the", "token_count": 512, "start_token": 135828, "end_token": 136340, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 295, "text": " of a beloved\nauthor arrive.\nMust-be The customer will be dissatisﬁed if these requireme nts\nare not met, but his satisfaction will never raise above\nneutral. An example is the ability to search the library\ncatalog.\nOne-dimensional For requirements of this category, satisf action is pro-\nportional to how many of these requirements are being\nmet. Alternative ways to search the library catalog could\nfall into this category.\nIndifferent The customer does not really care about these re quire-\nments. For example, the customer might not care\nwhether different categories of library items are dis-\nplayed in a different color on the screen.\nReverse The customer’s judgement of the requirements is the\nopposite of what the analyst thought a priori. For\nexample, the analyst may have thought the library\ncustomer would want the system to remember her\nsearch patterns so as to be able to serve her better next\ntime, while the customer wants to start afresh each time.\nQuestionable The customer’s preferences are not clear. She both\nseems to like and dislike a certain feature.\nFigure 9.8 Kano’s requirements categories\n9.1.5 COTS selection\nUp till now, we dealt with a situation where the customer phra ses her requirements,\nafter which a system that satisﬁes these requirements is dev eloped. With Commercial\nOff The Shelf (COTS) software, the customer has to choose fro m what is available.\nIn practice, the situation is not always that clear cut, and t he COTS system may be\nextended or adapted to suit the customer’s needs. For our dis cussion, we assume it is\na pure selection process.\nCOTS selection is an iterative process comprising the follo wing steps:\n1. Deﬁne requirements. As in ordinary requirements elicita tion processes, a list\nof requirements for the product is derived. Any of the elicit ation techniques\ndiscussed above may be used in this process.\n228 REQUIREMENTS ENGINEERING\nfunctional\none-dimensional\nmust-be\ndysfunctional\nsatisfied\ndissatisfied\nattractive\nFigure 9.9 The Kano diagram\n2. Select components. A set of components that can possibly h andle the require-\nments posed is determined", "token_count": 512, "start_token": 136290, "end_token": 136802, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 296, "text": "be\ndysfunctional\nsatisfied\ndissatisfied\nattractive\nFigure 9.9 The Kano diagram\n2. Select components. A set of components that can possibly h andle the require-\nments posed is determined. This selection process may invol ve market research,\ninternet browsing, and a variety of other techniques.\n3. Rank the components. The components are ranked in the orde r in which they\nsatisfy the requirements.\n4. Select the most appropriate component, or iterate.\nOften, the set of components and requirements are too large t o make a complete\nanalysis and ranking in one step feasible. An iterative proc ess is then followed,\nwhereby the most important requirements are used to make a ﬁr st selection from the\nset of available components. In a next step, a larger list of r equirements is assessed\nagainst a smaller set of components. And so on.\nThere are different ways to rank components. A straightforw ard method is the\nWeighted Scoring Method (WSM). Each requirement is given a w eight, and the\nalternatives are given a score for each requirement, say on a scale from 1 to 5.\nIn table 9.1, three components labeled A, B, and C are scored o n three criteria:\nperformance, supplier reputation, and functionality. In t he example, components B\nand C score highest, and these might next be scrutinized furt her.\n9.2. REQUIREMENTS DOCUMENTATION AND MANAGEMENT 229\nTable 9.1 WSM example\nCriteria Weight A B C\nPerformance 2 1 3 5\nSupplier 1 2 2 5\nFunctionality 3 4 5 1\nTotal 16 23 18\nA major drawback of WSM is that every criterion can be compens ated for by\nany other criterion. In the example from table 9.1, componen t C makes it to the\nnext round even though it scores very low on functionality. M ore complex ranking\nschemes, such as the Analytic Hierarchy Process (AHP) overc ome this drawback\n((Saaty, 1990)).\n9.2 Requirements Documentation and Management\nThe end-product of the requirements engineering phase in a d ocument-driven\ndevelopment project is a requirements speciﬁcation. The re quirements speciﬁcation\nis an a posteriori reconstruction of the results", "token_count": 512, "start_token": 136752, "end_token": 137264, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 297, "text": "The end-product of the requirements engineering phase in a d ocument-driven\ndevelopment project is a requirements speciﬁcation. The re quirements speciﬁcation\nis an a posteriori reconstruction of the results of this anal ysis phase. Its purpose is\nto communicate these results to others. It serves as an ancho r point against which\nsubsequent steps can be justiﬁed.\nThe requirements speciﬁcation is the starting point for the next phase: design.\nConsequently, a very precise, even mathematical descripti on is preferable. On the\nother hand, the speciﬁcation must also be understandable to the user. This often\nmeans a readable document, using natural language and pictu res. In practice, one\nhas to look for a compromise. Alternatively, the requiremen ts speciﬁcation may be\npresented in different, but consistent, forms to the differ ent audiences involved.\nBesides readability and understandability, various other requirements for this\ndocument can be stated (IEEE830, 1993):\n/AF A requirements speciﬁcation should be correct. There is no procedure to\nguarantee correctness. The requirements speciﬁcation sho uld be validated\nagainst other (superior) documents and the actual needs of t he users to assess\nits correctness.\n/AF A requirements speciﬁcation should be unambiguous, both to those who create it\nand to those who use it. We must be able to uniquely interpret r equirements.\nBecause of its very nature, this is difﬁcult to realize in a na tural language.\n/AF A requirements speciﬁcation should be complete. All signiﬁcant matters relating\nto functionality, performance, constraints, and the like, should be documented.\nThe responses to both correct and incorrect input should be s peciﬁed; phrases\n230 REQUIREMENTS ENGINEERING\nlike ‘to be determined’ are particularly insidious. Unfort unately, it is not always\nfeasible to complete the speciﬁcation at an early stage. If c ertain requirements\ncan only be made speciﬁc at a later stage, the requirements sp eciﬁcation\nshould at least document the ultimate point in time at which", "token_count": 512, "start_token": 137214, "end_token": 137726, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 298, "text": "��cation at an early stage. If c ertain requirements\ncan only be made speciﬁc at a later stage, the requirements sp eciﬁcation\nshould at least document the ultimate point in time at which t his should have\nhappened.\n/AF A requirements speciﬁcation should be (internally) consistent, i.e. different parts\nof it should not be in conﬂict with each other. Conﬂicting req uirements can be\nboth logical and temporal. Using different terms for one and the same object\nmay also lead to conﬂicts.\n/AF Requirements should be ranked for importance or stability. Typically, some\nrequirements are more important than others. In some cases, a simple ranking\nscheme like ‘essential’, ‘worthwhile’, and ‘optional’ wil l sufﬁce; in other cases, a\nmore sophisticated classiﬁcation scheme may be needed (see also section 9.1.4).\nWe may indicate the stability of requirements by indicating the likelihood,\nor the expected number, of changes. Through the explicit inc orporation of\nthis type of information in the requirements document, user s are stimulated\nto give more consideration to each requirement. It also give s developers the\nopportunity to better direct their attention.\n/AF A requirements speciﬁcation should be veriﬁable . This means that there must be\na ﬁnite process to determine whether or not the requirements have been met.\nPhrases like ‘the system should be user-friendly’ are not ve riﬁable. Likewise,\nthe use of quantities that cannot be measured, as in ‘the syst em’s response time\nshould usually be less than two seconds’, should be avoided. A requirement like\n‘for requests of type X, the system’s response time is less th an two seconds in\n80% of cases, with a maximum machine load of Y’, is veriﬁable.\n/AF A requirements speciﬁcation should be modiﬁable . Software models part of\nreality. Therefore it changes. The corresponding requirem ents speciﬁcation\nhas to evolve together with the reality being modeled.", "token_count": 512, "start_token": 137676, "end_token": 138188, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 299, "text": " requirements speciﬁcation should be modiﬁable . Software models part of\nreality. Therefore it changes. The corresponding requirem ents speciﬁcation\nhas to evolve together with the reality being modeled. Thus, the document\nmust be organized in such a way that changes can be accommodat ed readily\n(a tabular or database format, for example). Redundancy mus t be prevented\nas much as possible, for otherwise there is the danger that ch anges lead to\ninconsistencies.\n/AF A requirements speciﬁcation should be traceable. The origin and rationale of each\nand every requirement must be traceable. A clear and consist ent numbering\nscheme makes it possible that other documents can uniquely r efer to parts of\nthe requirements speciﬁcation.\nAs a guideline for the contents of a requirements speciﬁcati on we will follow\nIEEE Standard 830. This standard does not give a rigid form fo r the requirements\nspeciﬁcation. In our opinion, the precise ordering and cont ents of the elements of this\n9.2. REQUIREMENTS DOCUMENTATION AND MANAGEMENT 231\ndocument also is less essential. The important point is to ch oose a structure which\nadheres to the above constraints. In IEEE Standard 830, a glo bal structure such as\ndepicted in ﬁgure 9.10, is used.\n1. Introduction\n1.1 Purpose\n1.2 Scope\n1.3 Deﬁnitions, acronyms and abbreviations\n1.4 References\n1.5 Overview\n2. Overall description\n2.1 Product perspective\n2.2 Product functions\n2.3 User characteristics\n2.4 Constraints\n2.5 Assumptions and dependencies\n2.6 Requirements subsets\n3. Speciﬁc requirements\nFigure 9.10 Global structure of the requirements speciﬁcat ion ( Source: IEEE Recommended\nPractice for Software Requirements Speciﬁcations , IEEE Std 830, 1993. Reproduced by permission\nof IEEE .)\nFor any nontrivial system, the detailed requirements will c onstitute by far the\nlargest part of the requirements document. It is therefore h elpful to somehow\ncategorize these detailed requirements. This can be done al on", "token_count": 512, "start_token": 138138, "end_token": 138650, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 300, "text": "\nFor any nontrivial system, the detailed requirements will c onstitute by far the\nlargest part of the requirements document. It is therefore h elpful to somehow\ncategorize these detailed requirements. This can be done al ong different dimensions,\nsuch as:\n/AF Mode. Systems may behave differently depending on the mode of ope ra-\ntion, such as training or operational. For example, perform ance or interface\nrequirements may differ between modes.\n/AF User class . Different functionality may be offered to different class es of users,\nsuch as library members and library personnel.\n/AF Objects. Requirements may be classiﬁed according to the objects (re al-world\nentities) concerned. This classiﬁcation scheme is a natura l one when used in\nconjunction with an object-oriented analysis technique (s ee section 12.3).\n/AF Response. Some systems are best described by placing together functi ons in\nsupport of the generation of a response, for example functio ns associated with\ncatalog queries or library member status information.\n232 REQUIREMENTS ENGINEERING\n/AF Functional hierarchy . When no other classiﬁcation ﬁts, some functional hier-\narchy, for example organized by common inputs, may be used.\nAs an example, ﬁgure 9.11 gives a reﬁnement\nof the section on speciﬁc requirements along the dimension o f user classes,\n3. Speciﬁc requirements\n3.1 External interface requirements\n3.1.1 User interfaces\n3.1.2 Hardware interfaces\n3.1.3 Software interfaces\n3.1.4 Communications interfaces\n3.2 Functional requirements\n3.2.1 User class 1\n3.2.1.1 Functional requirement 1.1\n3.2.1.2 Functional requirement 1.2\n. . .\n3.2.2 User class 2\n. . .\n3.3 Performance requirements\n3.4 Design constraints\n3.5 Software system attributes\n3.6 Other requirements\nFigure 9.11 Prototype outline of the section on Speciﬁc Requ irements ( Source: IEEE\nRecommended Practice for Software Requirements Speciﬁcat ions, IEEE Std 830-1993. Reproduced\nby permission", "token_count": 512, "start_token": 138600, "end_token": 139112, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 301, "text": "Figure 9.11 Prototype outline of the section on Speciﬁc Requ irements ( Source: IEEE\nRecommended Practice for Software Requirements Speciﬁcat ions, IEEE Std 830-1993. Reproduced\nby permission of IEEE .)\nA further clariﬁcation of the various components is given in Appendix ??. As an\nexample, ﬁgure 9.12 contains (part of) a possible requireme nts speciﬁcation for the\nlibrary example mentioned earlier, following the IEEE guid elines.\nStart of ﬁgure 9.12\n1. Introduction.\n1.1 Purpose. This document states the requirements of an automated libr ary\nsystem for a medium-sized library of a research institute. T he requirements\nstated serve as a basis for the acceptance procedure of this s ystem. The\ndocument is also intended as a starting point for the design p hase.\n9.2. REQUIREMENTS DOCUMENTATION AND MANAGEMENT 233\n1.2 Scope. The intended product automates the library functions desc ribed in\nDOC1. Its purpose is to provide a more effective service to th e library\nusers, in particular through the online search facilities o ffered. More details\nof the performance requirements are given in section 3.3 of t his document.\nOnce this system is installed, the incorporation of new titl es will go from\nan average of 15 minutes down to an average of 5 minutes.\n1.3 Deﬁnitions, acronyms and abbreviations . Library member: . . . , Library personnel:\n. . . , User: The term user may refer to both library members and library\npersonnel, and is used to denote either class of users. Title catalog: . . . ,\nPICA: . . . , etc.\n1.4 References. DOC1: . . . , DOC2: . . . , etc.\n1.5 Overview. Section 2 of this document gives a general overview of the sy stem.\nSection 3 gives more speciﬁc requirements for functions off ered. These\nfunctions are categorized according to the class of users th ey support:\n(external) members of the library and library personnel, re spectively.\n2. Overall description .\n2.1 Product perspective . The already installed database system X will be used to\nstore the various", "token_count": 512, "start_token": 139062, "end_token": 139574, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 302, "text": " class of users th ey support:\n(external) members of the library and library personnel, re spectively.\n2. Overall description .\n2.1 Product perspective . The already installed database system X will be used to\nstore the various catalogs as well as the library member admi nistration.\nThere are no interfaces to other systems. The system will be r ealized on the\nY conﬁguration. The maximum external storage capacity for t he catalogs\nof the system is 1500 MB. Library personnel will use a barcode reader to\nenter member, book and journal identiﬁcations. The interfa ce protocol to\nthe barcode reader is described in DOC4.\n2.2 Product functions . The system provides two types of function:\n– Functions by which users may search the catalogs of books an d journal\narticles. A list of these functions is given in DOC1. A more de tailed\ndescription is given in section 3.2.1.\n– Functions by which library personnel may update the admini stration\nof borrowed titles and the system’s catalogs; see section 3. 2.2.\nThe user of the system selects one of the functions offered th rough the\nmain menu (section 3.2.1.1 and 3.2.2.1).\n2.3 User characteristics . The library members are incidental users of the system\nand have little knowledge of automated systems of this kind. The system\ntherefore has to be self-instructing. Speciﬁc requirement s are formulated\nin sections 3.1.1 and 3.3. The library personnel will be trai ned in the use\nof the system; see section 3.1.1.\n2.4 Constraints. Library members may only search the catalogs of books and\njournal articles; they are not allowed to update a catalog or the user\nadministration. The latter functionality is to be offered t hrough a dedicated,\npassword-protected interface only.\n234 REQUIREMENTS ENGINEERING\n2.5 Assumptions and dependencies . . . .\n2.6 Requirements subsets . . . .\n3. Speciﬁc requirements .\n3.1 External interface requirements .\n3.1.1 User interfaces . The screen formats for the different features are\nspeciﬁed in Appendix A. Appendix", "token_count": 512, "start_token": 139524, "end_token": 140036, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 303, "text": " . .\n3. Speciﬁc requirements .\n3.1 External interface requirements .\n3.1.1 User interfaces . The screen formats for the different features are\nspeciﬁed in Appendix A. Appendix B lists the mapping of comma nds\nto function keys. The user can get online help at any point by g iving\nthe appropriate command. Appendix C contains a list of typic al\nusage scenarios. These usage scenarios will be used as accep tance\ncriteria: 80% of the users must be able to go through them with in\nten minutes. An instruction session for library personnel s hould take\nat most two hours.\n3.1.2 Hardware interfaces . The user interface is screen-oriented. The system\nuses up to ten function keys.\n3.1.3 Software interfaces . The interface with database system X is described\nin DOC2.\n3.1.4 Communications interfaces . Not applicable.\n3.2 Functional requirements .\n3.2.1 Library member functions .\n3.2.1.1 Select member feature . The user selects one of the options from\nthe main menu. Subsequent actions are described in sections\n3.2.1.2 and 3.2.1.3.\nAt any point, the user has an option to return to the main\nmenu (see Appendix B).\n3.2.1.2 Search book catalog . Given (part of) a book title or author\nname, the user may search the book catalog for titles that\nmatch the input given. The user is offered a screen with\ntwo ﬁll-in-the-blank areas (one for the title and one for the\nauthor), one of which is to be ﬁlled in.\nInput. The input may contain both upper and lower case\nletters. Special symbols allowed are listed in DOC1. Any\nother glyphs entered are discarded and are not shown on\nthe screen. The input is considered complete when the\nprocessing command is issued.\nProcessing. All lower case letters are turned into upper case\nletters. The string thus obtained is used when querying the\ndatabase. A database entry matches the title string given if\nthe transformed input is a substring of the title ﬁeld of the\nentry. The same holds for the author ﬁeld if (part of) an\nauthor name is", "token_count": 512, "start_token": 139986, "end_token": 140498, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 304, "text": " database entry matches the title string given if\nthe transformed input is a substring of the title ﬁeld of the\nentry. The same holds for the author ﬁeld if (part of) an\nauthor name is input.\n9.2. REQUIREMENTS DOCUMENTATION AND MANAGEMENT 235\nOutput. A list of titles that match the input is displayed. Up\nto four titles are shown on the screen. The user may traverse\nthe list of titles found using the screen scrolling commands\nprovided. A warning is issued if no title matches the input\ngiven.\n3.2.1.3 Search article catalog . . . .\n3.2.2 Library personnel functions .\n3.2.2.1 Select personnel feature . Through a dedicated, password-protected\ninterface, library personnel are offered an extended main\nmenu, listing the options available to all users, as well as t he\noptions available to library personnel only. The latter are\ndescribed in sections 3.2.2.2 and 3.2.2.3.\n3.2.2.2 Borrow title . . . .\n3.2.2.3 Modify catalog . . . .\n3.3 Performance requirements . The system will initially support 32 concurrent access\npoints. Its maximum capacity is 128 concurrent access point s.\nThe present database holds 25 000 book titles and 500 journal subscriptions.\nThe storage capacity needed for these data is 300 MB. On avera ge 1000\nbooks and 2000 journal issues enter the library per year. The average\njournal issue has six articles. This requires a storage capa city of 15 MB per\nyear.\nThe system must be able to serve 20 users simultaneously. Wit h this\nmaximum load and a database size of 450 MB, user queries as lis ted in\nsections 3.2.1 and 3.2.2 must be answered within ﬁve seconds in 80% of\nthe cases.\n3.4 Design constraints .\n3.4.1 Standards compliance . Title descriptions must be stored in PICA-format.\nThis format is described in DOC3.\n3.4.2 Hardware limitations . See section 2.1.\n3.5 Software system attributes .\n3.5.1 Availability. During normal ofﬁce hours (9 am--5 pm) the system\nmust be available 95% of the time. A backup of the system", "token_count": 512, "start_token": 140448, "end_token": 140960, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 305, "text": "1.\n3.5 Software system attributes .\n3.5.1 Availability. During normal ofﬁce hours (9 am--5 pm) the system\nmust be available 95% of the time. A backup of the system is mad e\nevery day at 5 pm.\n3.5.2 Security. The functions described in section 3.2.2 are restricted to\nlibrary employees and password-protected. . . .\n3.5.3 Maintainability. . . .\n3.6 Other requirements . . . .\nThe IEEE framework for the requirements speciﬁcation is esp ecially appropriate in\ndocument-driven models for the software development proce ss: the waterfall model\n236 REQUIREMENTS ENGINEERING\nFigure 9.12 Partly worked-out requirements speciﬁcation f or the library example\nEnd ﬁgure 9.12\nand its variants. When a prototyping technique is used to det ermine the user interface,\nthe IEEE framework can be used to describe the outcome of that prototyping process.\nThe framework assumes a model in which the result of the requi rements engineering\nprocess is unambiguous and complete. Though it is stated tha t requirements should\nbe ranked for importance, and requirements that may be delay ed until future versions\nmay be included as subsets, this does not imply that a layered view of the system can\nbe readily derived from a requirements document drawn up thi s way.\nIrrespective of the format chosen for representing require ments, the success of a\nproduct strongly depends upon the degree to which the desire d system is properly\ndescribed during the requirements engineering phase. Smal l slips in the requirements\nspeciﬁcation may necessitate large changes in the ﬁnal soft ware. Software is not\ncontinuous, as we noted earlier.\nThe importance of a solid requirements speciﬁcation cannot be stressed often\nenough. In some cases, up to 95% of the code of large systems ha s had to be rewritten\nin order to adhere to the ultimate user requirements.\n9.2.1 Requirements Management\nA fundamental problem with the IEEE framework discussed abo ve is that it describes\nthe end product only. Before this ﬁnal stage is reached, the ‘ current’ set of requirements\nis in a constant state of ﬂux. And even after the requirements phase", "token_count": 512, "start_token": 140910, "end_token": 141422, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 306, "text": "o ve is that it describes\nthe end product only. Before this ﬁnal stage is reached, the ‘ current’ set of requirements\nis in a constant state of ﬂux. And even after the requirements phase is ended, require-\nments will change and new requirements will be put forth. The latter phenomenon is\nknown as requirements creep , and is the cause for many run-away projects.\nChanges in requirements cannot be circumvented. In many cas es, it is not wise to\naim for an early freeze of the requirements either. In genera l, the preferred situation\nis as depicted in ﬁgure 9.13: in the course of time, the set of r equirements becomes\nmore and more stable.\nObviously, this evolving set of requirements has to be manag ed. Requirements\nmanagement involves three activities:\n– requirements identiﬁcation,\n– requirements change management, and\n– requirements traceability.\nEach requirement has to have a unique identiﬁcation. The sim plest form is to just\nnumber them. If there is a hierarchical organization, as in a goal-hierarchy, such can\nbe reﬂected in the numbering scheme. Since requirements are often changed and\nupdated, it is expedient to include versioning information as well. Finally, we may\n9.2. REQUIREMENTS DOCUMENTATION AND MANAGEMENT 237\ntime\nrequirements stability\nrequirements\ncreep\ntoo early\nfreeze\nFigure 9.13 Requirements stability over time\nadd some attributes to each requirement, such as its status, priority, main stakeholder\ninvolved, and the like. Requirements engineering tools usu ally have means to store\nrequirements in a structured repository.\nChanges to requirements have to be properly managed. By view ing each require-\nment as a conﬁguration item, the rules and procedures from co nﬁguration management\n(chapter 4) can be applied.\nWe may connect requirements to solution elements such as des ign elements or\neven software components that realize those requirements. In this way, we establish\ntraceability from requirements to code and vice versa. This allows us to tr ace where\nrequirements are realized (forward traceability), and why certain solutions are chosen\n(backward traceability). Traceability information is imp ortant in all development\nphases. It can be used to", "token_count": 512, "start_token": 141372, "end_token": 141884, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 307, "text": " This allows us to tr ace where\nrequirements are realized (forward traceability), and why certain solutions are chosen\n(backward traceability). Traceability information is imp ortant in all development\nphases. It can be used to answer a variety of questions, such a s:\n– where is this requirement implemented?\n– do we need this requirement?\n– are all requirements linked to solution elements?\n– which requirement does this test case cover?\n– what is the impact of this requirement?\n238 REQUIREMENTS ENGINEERING\n– do we need this design element (piece of code)?\nThis way of making the relation between requirements and sol utions explicit\nis closely related to design space analysis . In design space analysis, the aim is to\nexplicitly model all possible combinations of requirement s and solutions. Design\nspace analysis originated in the ﬁeld of human-computer int eraction. A well-known\nnotation for Design Space Analysis is known as QOC (Question s, Options and\nCriteria). Questions correspond to requirements, Options are the possible answers\nto those requirements, and Criteria refer to the reasoning f or choosing a particular\noption. For instance, we may display the result of a news quer y of a library customer\n(the question) either sorted by date of publication, or by au thor name (the options).\nThe criterion for using either order could be the source of th e news item: sort\nnewspaper articles by date, and journal articles by author n ame.\nOn one hand, design space analysis results in a rich structur e in which an extensive\nrecord is built up of the rationale for a speciﬁc solution. Wh y is this system built the\nway it is? Which alternatives did we consider but reject? Whi ch requirements survived\nthe tradeoffs we had to make? On the other hand, capturing all this information is\nexpensive, and the immediate beneﬁts are difﬁcult to prove, if at all. This is a main\nreason why design rationale by and large failed to transfer t o practice.\n9.3 Requirements Speciﬁcation Techniques\nThe document that is produced during requirements engineer ing -- the requirements\nspeciﬁcation -- serves two groups of people. For the user, th e requirements speciﬁca-\ntion is a clear and precise description of the functionality that", "token_count": 512, "start_token": 141834, "end_token": 142346, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 308, "text": " that is produced during requirements engineer ing -- the requirements\nspeciﬁcation -- serves two groups of people. For the user, th e requirements speciﬁca-\ntion is a clear and precise description of the functionality that the system has to offer.\nFor the designer, it is the starting point for the design. It i s not easy to serve both\ngroups with one and the same document.\nThe user is in general best served by a document which speaks h is language, the\nlanguage that is used within the application domain. In the e xample used before, this\nwould result in using terms like ‘title description’ and ‘ca talog’.\nThe designer on the other hand, is best served with a language in which concepts\nfrom his world are used. In terms of the library example, he ma y prefer concepts\nlike records (an instance of which might be termed ‘title des cription’) or ﬁles. In one\nsense, this boils down to a difference in language. However, this difference is of\nfundamental importance with respect to the later use of the s ystem’s description.\nIf the system is described in the user’s language, the requir ements speciﬁcation\nis mostly phrased in some natural language. If we try to somew hat formalize this\ndescription, we may end up with a technique in which certain f orms have to be ﬁlled\nin or certain drawing techniques have to be applied.\nIf, on the other hand, the expert language of the software eng ineer plays a central\nrole, we often use some formal language. A requirements spec iﬁcation phrased in such\na formal language may be checked using formal techniques, fo r instance with regard\nto consistency and completeness.\n9.3. REQUIREMENTS SPECIFICATION TECHNIQUES 239\nIn practice, an outspoken prevalence for the user’s expert l anguage shows itself.\nWe may then use existing concepts from the environment in whi ch the system is\ngoing to be used. Admittedly, these concepts are not sharply deﬁned, but in general\nthere are no misconceptions between the experts in the appli cation domain as regards\nthe meaning of those concepts. A description in terms of thos e concepts can thus still\nbe very precise. Since the �", "token_count": 512, "start_token": 142296, "end_token": 142808, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 309, "text": "�ned, but in general\nthere are no misconceptions between the experts in the appli cation domain as regards\nthe meaning of those concepts. A description in terms of thos e concepts can thus still\nbe very precise. Since the ﬁrst goal of the requirements speciﬁcation is to g et a complete\ndescription of the problem to be solved, the user’s expert la nguage then would be the\nbest language for the requirements speciﬁcation.\nHowever, there are certain drawbacks attached to the use of n atural language.\nMeyer (1985) gives an example which illustrates very well wh at may go wrong when\nnatural language is used in a requirements speciﬁcation. Me yer lists seven sins which\nmay beset the analyst when using natural language:\n/AF Noise This refers to the presence of text elements that do not conta in\ninformation relevant to the problem. Variants hereof are re dundancy and\nregret. Redundancy occurs when things are repeated. Since n atural language\nis very ﬂexible, related matters can easily be phrased in com pletely different\nways. When this happens the cohesion between matters gets bl urred. Regret\noccurs when statements are reversed or shaded. In the librar y example, for\ninstance, we could have used the phrase ‘a list of all books wr itten by author\nD’ several times and only then realize that this list may be em pty, necessitating\nsome special reaction from the system.\n/AF Silence Silence occurs when aspects that are of importance for a prop er solution\nof the problem, are not mentioned. An example of this was that the need for\ntwo variants on an author’s name was not stated explicitly.\n/AF Over-speciﬁcation This occurs when elements of a requirements speciﬁcation\ncorrespond to aspects of a possible solution, rather than to aspects of the\nproblem. As an example, we could have speciﬁed that books be k ept sorted\nby the ﬁrst author’s name. Over-speciﬁcation limits the sol ution space for the\ndesigner.\n/AF Contradictions If the description of one and the same aspect is given more\nthan once, in different words, contradictions", "token_count": 512, "start_token": 142758, "end_token": 143270, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 310, "text": "s name. Over-speciﬁcation limits the sol ution space for the\ndesigner.\n/AF Contradictions If the description of one and the same aspect is given more\nthan once, in different words, contradictions may occur. Th is risk is especially\nthreatening when one tries to be too literary. A requirement s speciﬁcation is\nnot meant to be a novel.\n/AF Ambiguity Natural language allows for more than one meaning for one and the\nsame phrase. Ambiguity can easily occur when terms are used t hat belong to\nthe jargon of one or both parties. A ‘book’ may both denote a ph ysical object\nand a more abstract entity of which several instantiations ( copies) may exist.\n/AF Forward references References to aspects of the problem that are only deﬁned\nlater on in the text. This especially occurs in large documen ts that lack a clear\nstructure. Natural language in itself does not enforce a cle ar structure.\n240 REQUIREMENTS ENGINEERING\n/AF Wishful thinking A description of aspects of the system such that a realistic\nsolution will be hard to ﬁnd.\nA possible alternative given by Meyer is to ﬁrst describe and analyze the problem\nusing some formal notation and then translate it back into na tural language. The\nnatural language description thus obtained will in general represent a more precise\nnotion of the problem. And it is readable to the user. Obvious ly, both these models\nmust now be kept up-to-date.\nQuite a number of techniques and accompanying notations hav e evolved to sup-\nport the requirements engineering process. Most often, the representation generated\nis a set of semantic networks. Each such representation has v arious types of nodes\nand links between nodes, distinguished by visual clues such as their shape or natural\nlanguage labels. Nodes typically represent things like pro cesses, stores, objects, and\nattributes. Nodes are joined by arrows representing relati onships such as data ﬂow,\ncontrol ﬂow, abstraction, part-whole, or is-part-of.\nTypical examples of such techniques and their representati ons are discussed\nin chapter 10. Entity--Relationship Modeling (section 10. 1.1) is a widely-known\ntechnique to model the data aspect of", "token_count": 512, "start_token": 143220, "end_token": 143732, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 311, "text": "of.\nTypical examples of such techniques and their representati ons are discussed\nin chapter 10. Entity--Relationship Modeling (section 10. 1.1) is a widely-known\ntechnique to model the data aspect of an information system. Finite State Machines\n(section 10.1.2) can be viewed as a technique to model the fun ctional aspect. They\nhave a much wider applicability though, and constitute a bas ic underlying mechanism\nfor many modeling techniques. In particular, the Uniﬁed Mod eling Language (UML)\nowes tribute to them. UML diagrams (section 10.3) are widely used to model the\nresult of both requirements engineering and design. Sectio n 9.3.1 touches upon the\nissue of how to specify non-functional requirements.\n9.3.1 Specifying Non-Functional Requirements\nThe IEEE framework depicted in ﬁgure 9.11 lists four types of non-functional\nrequirements: external interface requirements, performa nce requirements, design\nconstraints and software system attributes. These non-fun ctional requirements can\nbe viewed as constraints placed upon the development proces s or the products to be\ndelivered.\nExternal interface requirements and design constraints ar e generally phrased in\nterms of (non-negotiable) obligations to be met. They are di ctated at the start of the\nproject and often concern matters which surpass an individu al development project.\nExamples of such requirements include:\n– hardware, software and communications interfaces to be co mplied with;\n– user interfaces that have to obey company standards;\n– report formats to be adhered to;\n– process constraints such as ISO 9000 compliance or a prescr ibed development\nmethod;\n9.4. VERIFICATION AND VALIDATION 241\n– hardware limitations caused by the available infrastruct ure.\nThe remaining non-functional requirements are also known a s quality requirements.\nQuality requirements are notoriously difﬁcult to specify a nd verify. This topic is dealt\nwith extensively in chapter 6. At this point, we merely wish t o re-emphasize two\nessential issues: quality requirements should be expresse d in objective, measurable\nterms and perfection incurs inﬁnite cost.\nLike all other requirements, quality requirements should b e veri�", "token_count": 512, "start_token": 143682, "end_token": 144194, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 312, "text": "-emphasize two\nessential issues: quality requirements should be expresse d in objective, measurable\nterms and perfection incurs inﬁnite cost.\nLike all other requirements, quality requirements should b e veriﬁable. Require-\nments such as ‘the system should be ﬂexible’, ‘the system sho uld be user-friendly’,\nor ‘response times should be fast’, can never be veriﬁed and s hould not therefore\nappear in the requirements speciﬁcation. Other phraseolog y can be used such as ‘for\nactivities of type A the system should have a maximum respons e time of one second\nin 80% of the cases, while a maximum response time of three sec onds is allowed in\nthe remaining 20% of the cases’.\nConversely, extreme levels of quality requirements, such a s zero defects or\nresponse times of less than 1 second in 100% of the cases, gene rally incur extremely\nhigh costs, or are not feasible at all. Given the fact that use rs ﬁnd it difﬁcult to\nexpress their true requirements, they may be inclined to ask for too much where\nquality requirements are concerned, just ‘to be on the safe s ide’. To the analyst and\ndevelopers, it is likewise difﬁcult to assess the feasibili ty of those requirements. How\ncan we be sure about response times before even one line of cod e has been written?\nConsider the following example of what may and may not be tech nically feasible.\nSuppose we have an application in which two kinds of transact ions may occur.\nThose transactions are characterized by their frequency, C PU-time needed and the\nnumber of physical I/O transports. The average I/O access ti me is also given. Using a\nstatistical distribution describing the dynamics of these systems, one may then answer\nquestions such as: ‘how much capacity should the CPU have in o rder to achieve a\nresponse time of at most 2 seconds in X% of cases?’ Some given c onﬁguration may\nsatisfy the constraints for the case X = 80. A somewhat more st ringent requirement\n(X = 90) may require doubling the CPU-capacity. An even more s e", "token_count": 512, "start_token": 144144, "end_token": 144656, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 313, "text": "� Some given c onﬁguration may\nsatisfy the constraints for the case X = 80. A somewhat more st ringent requirement\n(X = 90) may require doubling the CPU-capacity. An even more s evere requirement\n(X = 95) might well not be achievable by the range of machines a vailable.\nAt ﬁrst sight, the differences between these requirements s eem marginal. They\nturn out to have a tremendous effect, though. An early and car eful analysis of the\ntechnical feasibility may yield surprising answers to a num ber of important questions.\nUsually, this type of analysis is done at software architect ure time. There are many\nexamples of projects in which lots of money was spent on softw are development\nefforts which turned out to be not practically feasible (Bab er, 1982).\n9.4 Veriﬁcation and Validation\nIn chapter 1, we argued that a careful study of the correctnes s of the decisions\nmade at each stage is a critical success factor. This means th at during requirements\n242 REQUIREMENTS ENGINEERING\nengineering we should already start verifying and validati ng the decisions laid down\nin the requirements speciﬁcation.\nThe requirements speciﬁcation should reﬂect the mutual und erstanding of the\nproblem to be solved by the prospective users and the develop ment organization:\nhas everything been described, and has it been described pro perly. Validating the\nrequirements thus means checking them for properties like c orrectness, completeness,\nambiguity, and internal and external consistency. Of neces sity, this involves user\nparticipation in the validation process. They are the owner s of the problem and\nthey are the only ones to decide whether the requirements spe ciﬁcation adequately\ndescribes their problem.\nIf the requirements speciﬁcation itself is expressed in a fo rmal language, the syntax\nand semantics of that representation can be veriﬁed through formal means. However,\nthe requirements speciﬁcation can never be completely vali dated in a formal way,\nsimply because the point of departure of requirements engin eering is informal. Most\nof the testing techniques applied at this stage are therefor e informal as well. They are\nmeant to ascertain that the parties involved have the same", "token_count": 512, "start_token": 144606, "end_token": 145118, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 314, "text": ",\nsimply because the point of departure of requirements engin eering is informal. Most\nof the testing techniques applied at this stage are therefor e informal as well. They are\nmeant to ascertain that the parties involved have the same, p roper understanding of\nthe problem. A major stumbling block to this stage is ensurin g the user understands\nthe contents of the requirements speciﬁcation. The techniq ues applied at this stage\noften resolve to a translation of the requirements into a for m palatable to user\ninspection: natural-language paraphrasing, the discussi on of possible usage scenarios,\nprototyping, and animation.\nBesides testing the requirements speciﬁcation itself, we a lso generate at this stage\nthe test plan to be used during system or acceptance testing. A test plan is a document\nprescribing the scope, approach, resources, and schedule o f the testing activities. It\nidentiﬁes the items and features to be tested, the testing ta sks to be performed, and\nthe personnel responsible for these tasks. We may at this poi nt develop such a plan\nfor the system testing stage, i.e. the stage at which the deve lopment organization\ntests the complete system against its requirements. Accept ance testing is similar, but\nis performed under supervision of the user organization. Ac ceptance testing is meant\nto determine whether or not the users accept the system.\nA more elaborate treatment of the various veriﬁcation and va lidation techniques\nwill be given in chapter 13.\n9.5 Summary\nDuring requirements engineering we try to get a complete and clear description of the\nproblem to be solved and the constraints that must be satisﬁe d by any solution to that\nproblem. During this phase, we do not only consider the funct ions to be delivered, but\nwe also pay attention to requirements imposed by the environ ment. The requirements\nengineering phase results in a series of models concentrati ng on different aspects of\nthe system (such as its functionality, user interface and co mmunication structure)\nand different perspectives (audiences). The result of this process is documented in a\nrequirements speciﬁcation. A good framework for the conten ts of the requirements\n9.5. SUMMARY 243\nspeciﬁcation is", "token_count": 512, "start_token": 145068, "end_token": 145580, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 315, "text": "audiences). The result of this process is documented in a\nrequirements speciﬁcation. A good framework for the conten ts of the requirements\n9.5. SUMMARY 243\nspeciﬁcation is given in (IEEE830, 1993). It should be kept i n mind that this document\ncontains an a posteriori reconstruction of an as yet ill-und erstood iterative process.\nThis iterative process involves four types of activity:\n– requirements elicitation, which is about understanding the problem,\n– requirements speciﬁcation, which is about describing the problem,\n– requirements validation, which is about agreeing upon the problem, and\n– requirements negotiation, which is about ﬁtting the problem to the situation at\nhand.\nIn many cases, fully completing requirements engineering b efore design and construc-\ntion start is not feasible. In agile development processes, requirements engineering is\nintertwined with design and construction.\nDuring requirements engineering we are modeling part of rea lity. The part of\nreality we are interested in is referred to as the universe of discourse (UoD). The\nmodeling process is termed conceptual modeling.\nPeople involved in a UoD have an implicit conceptual model of that UoD.\nDuring conceptual modeling, an implicit model is turned int o an explicit one. The\nexplicit conceptual model is used to communicate with other people, such as users\nand designers, and to assess the validity of the system under development during all\nsubsequent phases. During the modeling process, the analys t is confronted with two\ntypes of problem: analysis problems and negotiation proble ms. Analysis problems\nhave to do with getting the requirements right. Negotiation problems arise because\ndifferent people involved may have different views on the Uo D to be modeled,\nopposing interests, and so on.\nExisting approaches to requirements engineering are large ly Taylorian in nature.\nThey ﬁt a functional view of software development in which th e requirements\nengineering phase serves to elicit the ‘real’ user requirem ents. It is increasingly being\nrecognized that the Taylorian approach need not be the most a ppropriate approach\nto requirements engineering. Many UoDs under consideratio n involve people whose\nworld model is incomplete, irrational, or in conﬂict with th e world view of others.\nIn such cases,", "token_count": 512, "start_token": 145530, "end_token": 146042, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 316, "text": " a ppropriate approach\nto requirements engineering. Many UoDs under consideratio n involve people whose\nworld model is incomplete, irrational, or in conﬂict with th e world view of others.\nIn such cases, the analyst is not a passive outside observer o f the UoD, but actively\nparticipates in shaping the UoD. The analyst gets involved i n negotiation problems\nand has to choose the view of some party involved, or assist in obtaining some\ncompromise.\nThe following description techniques are often used for the requirements speciﬁ-\ncation:\n– natural language,\n– pictures, and\n– formal language.\n244 REQUIREMENTS ENGINEERING\nAn advantage of using natural language is that the speciﬁcat ion is very readable and\nunderstandable to the user and other non-professionals inv olved. Pictures may be put\nto advantage in bringing across the functional architectur e of the system. A formal\nlanguage allows us to use tools in analyzing the requirement s. Because of its precision,\nit is a good starting point for the design phase. We may also ar gue that both formal\nand informal notations be used, since they augment and compl ement each other. For\neach of the parties involved, a notation should be chosen tha t is appropriate to the\ntask at hand.\n9.6 Further Reading\nThere are many text books fully devoted to requirements engi neering. Davis (1993)\nprovides a fairly complete coverage of ‘classic’ requireme nts speciﬁcation techniques.\nDavis (2005) focuses on requirements engineering in the fac e of tight schedule con-\nstraints. Wieringa (1996) discusses a number of requiremen ts speciﬁcation techniques\nin quite some depth. The distinction between implicit and ex plicit conceptual models\nis made there too. Loucopoulos and Karakostas (1995) and Kot onya and Sommerville\n(1997) have a stronger emphasis on the full requirements eng ineering process. Juristo\net al. (2002) discuss the state of the practice in requiremen ts engineering. Hofman\nand Lehner (2001) focus on successful requirements practic es. Sommerville (2005)\ndiscusses recent developments in the ﬁeld.\nPohl (1993) and Gogu", "token_count": 512, "start_token": 145992, "end_token": 146504, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 317, "text": " ts engineering. Hofman\nand Lehner (2001) focus on successful requirements practic es. Sommerville (2005)\ndiscusses recent developments in the ﬁeld.\nPohl (1993) and Goguen and Jirotka (1994) emphasize the role of social and\ncognitive issues in requirements engineering. Ramos et al. (2005) argue that emotion\nis relevant in requirements engineering. The thin spread of application knowledge\namongst the specialists involved is discussed in (Curtis et al., 1988). Difﬁculties of\nrequirements engineering for market-driven software deve lopment are addressed in\n(Potts, 1993). Moynihan (2000) discusses how managers cope with requirements\nuncertainty.\nThe objectivist--subjectivist and order--conﬂict dimens ions and the resulting four\nparadigms for requirements engineering are discussed in (H irschheim and Klein,\n1989). Various socio-technical, subjectivist, approache s to requirements elicitation\nare discussed in (Atkinson, 2000).\nTask analysis is discussed in (Sebillotte, 1988). Scenario -based requirements\nengineering techniques are discussed in (Weidenhaupt et al ., 1998) and (TrSE,\n1998). Sutcliffe et al. (1998) describe how to create and doc ument scenarios during\nrequirements engineering. Business Process Redesign is de scribed in (Keen, 1991) and\n(Tapscott and Caston, 1993). A framework for BPR is given in ( Davenport, 1993).\nResearch in requirements elicitation is aimed at developin g techniques which\novercome our limitations as humans in conveying informatio n. An early overview\nof this type of problem is given in (Davis, 1982). A more recen t survey and\nevaluation of elicitation techniques is given in (Goguen an d Linde, 1993). Example\nexperience reports are given in (Sommerville et al., 1994) a nd (Coakes and Coakes,\n9.6. FURTHER READING 245\n2000) (ethnographic approach) and (Beyer and Holtzblatt, 1 995) (the analyst as an\napprentice to the user).\nLamsweerde (2001) gives a very good overview of goal-orient ed requirements\n", "token_count": 512, "start_token": 146454, "end_token": 146966, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 318, "text": "ographic approach) and (Beyer and Holtzblatt, 1 995) (the analyst as an\napprentice to the user).\nLamsweerde (2001) gives a very good overview of goal-orient ed requirements\nengineering. Mylopoulos et al. (2001) is another article by pioneers in this area. Darke\nand Shanks (1996) and Sommerville and Sawyer (1997) provide a good overview of\nviewpoints in the context of requirements engineering.\nLefﬁngwell and Widrig (2000) is fully devoted to requiremen ts management. One\nof the ﬁrst discussions of requirements traceability is (Go tel and Finkelstein, 1994).\nDesign space analysis is discussed in (Moran and Carroll, 19 94). Questions, Options,\nCriteria (QOC) stem from (MacLean et al., 1991). gIBIS, a hyp ertext system designed\nto capture early design decisions, is described in (Conklin and Begeman, 1988).\nKano’s model is discussed in (Kano, 1993). The quest for crea tivity in requirements\nengineering is further stressed in (Robertson, 2002), Aust in and Devin (2003) and\n(Maiden et al., 2004).\nMorisio et al. (2002) gives a taxonomy of COTS products. COTS selection\nprocedures are discussed in (Maiden and Ncube, 1998).\nExercises\n1. What are the four major types of activity in requirements e ngineering?\n2. What is requirements elicitation?\n3. What is the difference between an implicit and an explicit conceptual model?\n4. In what sense are most requirements engineering techniqu es Taylorian in\nnature?\n5. Describe the requirements elicitation technique called task analysis.\n6. Describe the requirements elicitation technique called scenario-based analy-\nsis.\n7. In which circumstances is ethnography a viable requireme nts elicitation\ntechnique?\n8. What is goal-oriented requirements engineering?\n9. How can conﬂicting requirements be represented in viewpo ints?\n10. What does MoSCoW stand for?\n11. Why is the distinction between ‘Attractive’, ‘Must-be’ and ‘One-dimensional’\ncategories of requirements in Kano�", "token_count": 512, "start_token": 146916, "end_token": 147428, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 319, "text": "10. What does MoSCoW stand for?\n11. Why is the distinction between ‘Attractive’, ‘Must-be’ and ‘One-dimensional’\ncategories of requirements in Kano’s model relevant?\n246 REQUIREMENTS ENGINEERING\n12. How does the presence of COTS components affect requirem ents engineer-\ning?\n13. Why is requirements traceability important?\n14. List and discuss the major quality requirements for a req uirements document.\n15. List and discuss major drawbacks of using natural langua ge for specifying\nrequirements.\n16. /DJ Draw up a requirements speciﬁcation for a system whose devel opment you\nhave been involved with, following IEEE 830. Discuss the maj or differences\nbetween the original speciﬁcation and the one you wrote.\n17. /DI What are major differences in the external environment of an ofﬁce\nautomation system and that of an embedded system, like an ele vator con-\ntrol system. What impact will these differences have on the r equirements\nelicitation techniques to be employed?\n18. /DI For an ofﬁce information system, identify different types o f stakeholders.\nCan you think of ways in which the requirements of these stake holders might\nconﬂict?\n19. /DI Reﬁne the framework in ﬁgure 9.1 such that it reﬂects the situ ation in which\nwe have to explicitly model both the current and the new work s ituation.\n20. /DI Discuss pros and cons of the following descriptive means for a requirements\nspeciﬁcation: full natural language, constrained natural language, a pictorial\nlanguage like UML.\n21. /DI Which of the descriptive means mentioned in the previous exe rcise would\nyou favor for describing the requirements of an ofﬁce automa tion system?\nAnd which one for an elevator control system?\n22. /DJ Take the requirements speciﬁcation document from a project you have\nbeen involved in and assess it with respect to the requiremen ts for such a\ndocument as listed in section 9.2 (unambiguity, completene ss, etc.).\n23. /DI How would you test the requirements stated in the", "token_count": 512, "start_token": 147378, "end_token": 147890, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 320, "text": " in and assess it with respect to the requiremen ts for such a\ndocument as listed in section 9.2 (unambiguity, completene ss, etc.).\n23. /DI How would you test the requirements stated in the document fr om the\nprevious exercise? Are the requirements testable to start w ith?\n24. /DJ How would you go about determining the requirements for a hyp ertext-like\nbrowsing system for a technical library. Both users and staf f of the library\nonly have experience with keyword-based retrieval systems .\n25. /DI As an analyst involved in the development of this hypertext b rowsing\n9.6. FURTHER READING 247\nsystem, discuss possible stands in the subjectivist--obje ctivist and order--\nconﬂict dimensions. What are the arguments for and against t hese stands?\n26. /DJ Write a requirements speciﬁcation for a hypertext browsing system.\n27. /DI Study the following speciﬁcation for a simple line formatte r:\nThe program’s input is a stream of characters whose end is sig naled with a\nspecial end-of-text character, ET. There is exactly one ET c haracter in each\ninput stream. Characters are classiﬁed as:\n– break characters -- BL (blank) and NL (new line);\n– nonbreak characters -- all others except ET;\n– the end-of-text indicator - ET.\nA word is a non-empty sequence of nonbreak characters. A break is a sequence\nof one or more break characters. Thus, the input can be viewed as a sequence\nof words separated by breaks, with possible leading and trai ling breaks, and\nending with ET.\nThe program’s output should be the same sequence of words as i n the input,\nwith the exception that an oversize word (i.e. a word contain ing more than\nMAXPOS characters, where MAXPOS is a positive integer) shou ld cause an\nerror exit from the program (i.e. a variable, Alarm, should h ave the value\nTRUE). Up to the point of an error, the program’s output shoul d have the\nfollowing properties:\n1 A new line should start only between words and at the beginni ng of the", "token_count": 512, "start_token": 147840, "end_token": 148352, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 321, "text": " ave the value\nTRUE). Up to the point of an error, the program’s output shoul d have the\nfollowing properties:\n1 A new line should start only between words and at the beginni ng of the\noutput text, if any.\n2 A break in the input is reduced to a single break character in the output.\n3 As many words as possible should be placed on each line (i.e. between\nsuccessive NL characters).\n4 No line may contain more than MAXPOS characters (words and B Ls).\nIdentify as many trouble spots as you can in this speciﬁcatio n. Compare your\nﬁndings with those in (Meyer, 1985).\n28. /DI What are the major uses of a requirements speciﬁcation. In wh at ways do\nthese different uses affect the style and contents of a requi rements document?\n10\nModeling\nLEARNING OBJECTIVES\n/AF To know about various classic modeling techniques\n/AF To know about UML, the Uniﬁed Modeling Language, and its main diagram\ntypes\n/AF To know the terminology of object orientation\n249\nIn the course of a software development project, and most not ably during\nrequirements engineering and design, many modeling notati ons are used.\nThese range from very informal sketches of system functions or screen layout,\nto highly formal descriptions of system behaviour. The most common notations\nused are box-and-line diagrams with semi-formal semantics . In this chapter we\ndiscuss a number of these diagrammatic notations.\nDuring software development, a lot of communication takes p lace. This commu-\nnication is supported by all kinds of notations to convey its message. A sketch of\nsome screen layout may support the communication between a u ser and a require-\nments engineer. A much more formal description of class inte rfaces may support the\ncommunication between a designer and a developer.\nThe most common notations used to support communication bet ween the\nvarious stakeholders involved in software development use some sort of box-and-line\ndiagrams. Sometimes, these diagrams have very informal sem antics. For instance, the\nboxes may denote parts of the system, where it is not clear wha t exactly a part is.\nOne box may denote a major subsystem, another box", "token_count": 512, "start_token": 148302, "end_token": 148814, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 322, "text": "agrams. Sometimes, these diagrams have very informal sem antics. For instance, the\nboxes may denote parts of the system, where it is not clear wha t exactly a part is.\nOne box may denote a major subsystem, another box may denote t he set of security\nmeasures taken. Likewise, lines may denote a parts-of relat ion, a calling relation, a\nuses relation, and so on. While being drawn, these loose sema ntics may not be a\nproblem. But the next day, confusion will arise.\nAn alternative is to use diagrams that do have a more precise s emantics. If the\nreaders know these semantics, there need not be any confusio n of what exactly is\nmeant. If the semantics are precise enough, the diagrams can be subjected to all kinds\nof consistency checks. Tools may generate the diagrams, rea d them, and possibly\neven generate executable code from the diagrams. And ﬁnally , we may link the\ndiagrams to the methods that generate them, thereby giving s ome operationalization\nto their construction process. For instance, the steps in a d esign method can be linked\nto the steps for generating the corresponding diagram. The l atter kinds of diagrams\nare discussed in chapter 12, together with a discussion of th e corresponding design\nmethods.\nIn this chapter, we discuss a number of semi-formal modeling notations. Most of\nthem use some sort of box-and-line diagram. Some use a more te xtual layout. The\ndiagrams and schema are usually drawn during requirements e ngineering and design.\nSome primarily serve requirements engineering. For instan ce, use case diagrams are\nusually drawn during requirements engineering. Jackson st ructure diagrams on the\nother hand are mostly used during design. Many modeling nota tions serve both.\nCurrently, the mainstream modeling notations stem from UML -- the Uniﬁed\nModeling Language. Many diagrams from UML, though, are base d on or derived\nfrom earlier ones. And, certainly in legacy applications, y ou may come across many\nof these older notations. Therefore, a sample of both is prov ided in this chapter.\nUML evolved from some of the mainstream object-oriented ana lysis and design\nmethods. The concept of object orientation in turn has its ro ots in the development\n250 MODEL", "token_count": 512, "start_token": 148764, "end_token": 149276, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 323, "text": " of both is prov ided in this chapter.\nUML evolved from some of the mainstream object-oriented ana lysis and design\nmethods. The concept of object orientation in turn has its ro ots in the development\n250 MODELING\nof programming languages, most notably SIMULA-67 and Small talk. With respect\nto analysis and design (and requirements analysis), object orientation is best viewed\nby highlighting the differences with more traditional desi gn methods such as func-\ntional decomposition and dataﬂow design. Whereas traditio nal techniques focus on\nidentifying the functions that the system is to perform, object-oriented methods focu s\non identifying and interrelating the objects that play a role in the system. Section 10.2\nintroduces a number of relevant concepts, such as object, at tribute, class, relationship.\nIn one way or another, these concepts show up in many UML diagr am types.\n10.1 Classic Modeling Techniques\nWe discuss four classic modeling techniques that have been a round for quite a while:\n/AF Entity--Relationship Modeling (ERM) is a data modeling tec hnique, pioneered\nby Chen in the seventies. UML class diagrams are based on ERM.\n/AF Finite State Machines (FSM) are used to model states and stat e transitions.\nIn the early days, certain types of formal languages, as for i nstance used in\ncompilers, were modeled as ﬁnite state machines. UML state m achine diagrams\nare based on ﬁnite state machines.\n/AF Data Flow Diagrams (DFD) model a system as a set of processes a nd data ﬂows\nthat connect these processes. It is the notation used in data ﬂow design. DFDs\nresemble the UML sequence diagram.\n/AF CRC cards are a simple requirements elicitation tool. Much o f the information\ncollected on CRC cards can also be represented in UML communi cation\ndiagrams.\nMany other classic modeling notations exist. Many of these a re tied to a certain\nanalysis or design method. We will discuss some of them in cha pter 12 in the\ncontext of a discussion of design methods. The ones discusse d here are relatively\nmethod-independent.\n10.1.1 Entity", "token_count": 512, "start_token": 149226, "end_token": 149738, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 324, "text": " certain\nanalysis or design method. We will discuss some of them in cha pter 12 in the\ncontext of a discussion of design methods. The ones discusse d here are relatively\nmethod-independent.\n10.1.1 Entity--Relationship Modeling\nIn data-intensive systems, modeling the (structure of) the data is an important concern.\nUntil the 1970s, data modeling techniques very much mixed up implementation\nconcerns with concerns arising from the logical structure o f the UoD. For example,\nthe book catalog would be modeled as a ‘table’ containing ‘tu ples’ (‘records’) with\nalphanumeric ﬁelds containing the title and author, and num eric ﬁelds containing the\npublication year and number of pages.\nEntity--relationship modeling (ERM), as pioneered by Chen, is directed at\nmodeling the logical, semantic structure of the UoD, rather than its realization in\nsome database system. Entity relationship models are depic ted in entity--relationship\n10.1. CLASSIC MODELING TECHNIQUES 251\ndiagrams (ERDs). There are many variants of ERM, which differ in their graphical\nnotations and extensions to Chen’s original approach. The b asic ingredients of ERM\nare given in ﬁgure 10.1.\nentity distinguishable object of some type\nentity type type of a set of entities\nattribute value piece of information (partially) describi ng an entity\nattribute type of a set of attribute values\nrelationship association between two or more entities\nFigure 10.1 ERM concepts and their meaning\nAn entity is a ‘thing’ that can be uniquely identiﬁed. Entiti es are usually depicted\nin an ERD as rectangles. Example entities are:\n– tangible objects, such as copies of a book, identiﬁed by som e number;\n– intangible objects, such as books identiﬁed by their ISBN, or members of\nsome organizational construct, such as library employees i dentiﬁed by their\nemployee number.\nEntities have properties known as attributes. For example, some library employee\nmay have the name ‘Jones’. Here, ‘Jones’ is the value of the at tribute called �", "token_count": 512, "start_token": 149688, "end_token": 150200, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 325, "text": "ed by their\nemployee number.\nEntities have properties known as attributes. For example, some library employee\nmay have the name ‘Jones’. Here, ‘Jones’ is the value of the at tribute called ‘name’.\nAttributes are usually depicted as circles or ellipses.\nBoth entities and attribute values have a type. As modelers, we tend to view a type\nas a set of properties shared by its instances. As implemento rs, we tend to view a type\nas a set of values with a number of associated operations. For the attribute ‘number\nof books on loan’, the set of values could be the set 0 .. 10 with operations such\nas increment and decrement. For the entity type ‘book copy’, candidate operations\nwould be ‘borrow’, ‘return’, and so on.\nEntities are linked through relationships. For example, th e relationship ‘borrow’\ninvolves the entities ‘book copy’ and ‘library member’. Mos t often, a relationship is\nbinary, i.e. it links two entities. A relationship is denote d by a diamond linked to the\nentities involved.\nEntity--relationship models impose restrictions on the ca rdinality of relationships.\nIn its simplest form, the relationships are 1--1, 1--N, or N- -M. The relationship\n‘borrow’ is 1--N: a copy of a book can be borrowed by one member only, while a\nmember may have borrowed more than one book copy. In an ERD, th ese cardinality\nconstraints are often indicated by small adornments of the a rrows linking the entities.\nAn example entity--relationship diagram is given in ﬁgure 1 0.2. Cardinality\nconstraints have been indicated by explicitly indicating t he set of possibilities. Thus,\n252 MODELING\nthis ERD states that a book copy can be borrowed by at most one m ember, and a\nmember may borrow up to 10 book copies.\nFigure 10.2 An entity--relationship diagram\nAn entity--relationship model can be obtained using any of t he elicitation\ntechniques discussed before. In particular, form analysis and analysis of natural\nlanguage descriptions are often used. Since ERMs tell only p art of", "token_count": 512, "start_token": 150150, "end_token": 150662, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 326, "text": "relationship diagram\nAn entity--relationship model can be obtained using any of t he elicitation\ntechniques discussed before. In particular, form analysis and analysis of natural\nlanguage descriptions are often used. Since ERMs tell only p art of the story,\nadditional techniques have to be employed to model other asp ects. Many Structured\nAnalysis techniques, for example, incorporate ERM to model the data aspect.\nEntity--relationship modeling is a natural outgrowth of da tabase modeling.\nOriginally, ERM was intended to model the logical structure of data, rather than\nthe logical structure of the UoD. In heuristics on how to obta in a ‘good’ entity--\nrelationship model, these roots are still visible. For exam ple, some of these heuristics\nresemble normalization constraints from database theory. This may explain why\nsome do not commend entity--relationship modeling as a requ irements speciﬁcation\ntechnique (see, e.g. (Davis, 1993)).\nPresent-day ERM has a lot in common with object-oriented ana lysis techniques.\nFor example, subtype--supertype relations between entity types are included in many\nERM-techniques. Conversely, the class diagram of UML (see s ection 10.3.1) includes\nmany elements from ERM.\n10.1.2 Finite State Machines\nAt any one point in time, our library is in one of a (vast) numbe r of possible states.\nThe state of the library can be expressed in terms of things li ke:\n– the collection of titles available,\n10.1. CLASSIC MODELING TECHNIQUES 253\n– the collection of titles ordered but not yet received,\n– the collection of library members,\n– the balance of the account from which acquisitions are paid .\nAny action occurring in the library, be it the return of a book or the appointment of\na new employee, transforms the current state\n/D7 into a new state /D7\n/BC\n.\nRequirements speciﬁcation techniques which model a system in terms of states\nand transitions between states are called state-based modeling techniques. A simple\nyet powerful formalism for specifying states and state tran sitions is the Finite State\nMachine (FSM). An FSM consists of a ﬁnite", "token_count": 512, "start_token": 150612, "end_token": 151124, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 327, "text": "and transitions between states are called state-based modeling techniques. A simple\nyet powerful formalism for specifying states and state tran sitions is the Finite State\nMachine (FSM). An FSM consists of a ﬁnite number of states and a set of t ransitions\nfrom one state to another that occur on input signals from a ﬁn ite set of possible\nstimuli. The initial state is a specially designated state f rom which the machine\nstarts. Usually, one or more states are designated as ﬁnal st ates. Pictorially, FSMs\nare represented as state transition diagrams (STD). In a state transition diagram,\nstates are represented as bubbles with a label identifying t he state, and transitions\nare indicated as labeled arcs from one state to another, wher e the label denotes the\nstimulus which triggers the transition. Figure 10.3 gives a n FSM depicting the possible\nstates of a book copy and the transitions between those state s. The ﬁnal state is the\none labeled ‘written off’. Any of the others could be designa ted as the initial state.\nFigure 10.3 A state transition diagram\nFigure 10.3 models only a tiny part of the library system. It d oes not describe\nthe complete state of the system in any one bubble, nor does it depict all possible\n254 MODELING\nstate transitions. Modeling a system in one, large and monol ithic, STD is not to be\nrecommended. Such a structure soon becomes unwieldy and dif ﬁcult to understand.\nThough we could model the system in a series of FSMs, we would s till have the\nproblem of how to integrate these into one model.\nA possible way out is to allow for a hierarchical decompositi on of FSMs. This is\nthe essence of a notation known as statecharts. In statecharts, groups of states can be\nviewed as a single entity at one level, to be reﬁned at the next level of abstraction. In\nUML, FSMs are modeled in the state machine diagram (section 1 0.3.2).\n10.1.3 Data Flow Diagrams (DFD)\nThe data ﬂow design method originated in the early 1970s with Yourdon and\nConstantine. In its simplest form, data", "token_count": 512, "start_token": 151074, "end_token": 151586, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 328, "text": ".3.2).\n10.1.3 Data Flow Diagrams (DFD)\nThe data ﬂow design method originated in the early 1970s with Yourdon and\nConstantine. In its simplest form, data ﬂow design is but a fu nctional decomposition\nwith respect to the ﬂow of data. A component (module) is a blac k box which\ntransforms some input stream into some output stream. The ma in notation used is\nthat of Data Flow Diagrams (DFD).\nFour types of data entity are distinguished in a data ﬂow diag ram:\nExternal entities are the source or destination of a transaction. These entiti es are\nlocated outside the domain considered in the data ﬂow diagra m. External entities are\nindicated as squares.\nProcesses transform data. Processes are denoted by circles.\nData ﬂows between processes, external entities and data stores. A dat a ﬂow is\nindicated by an arrow. Data ﬂows are paths along which data st ructures travel.\nData stores lie between two processes. This is indicated by the name of th e data store\nbetween two parallel lines. Data stores are places where dat a structures are stored\nuntil needed.\nData ﬂow diagrams result from a top-down decomposition proc ess. The process\nat the highest level has one process only, denoting ‘the syst em’. Next, this top-level\ndiagram is further decomposed. For our library example, thi s could lead to the data\nﬂow diagram of ﬁgure 10.4. A client request is ﬁrst analyzed i n a process labeled\n‘preliminary processing’. As a result, one of ‘borrow title ’ or ‘return title’ is activated.\nBoth these processes update a data store labeled ‘catalog ad ministration’. Client\nrequests are logged in a data store ‘log ﬁle’. This data store is used to produce\nmanagement reports.\nThe design method mostly used in conjunction with data ﬂow di agrams is\ndiscussed in section 12.2.2. There, we will also give more ex ample data ﬂow diagrams.\n10.1.4", "token_count": 512, "start_token": 151536, "end_token": 152048, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 329, "text": "The design method mostly used in conjunction with data ﬂow di agrams is\ndiscussed in section 12.2.2. There, we will also give more ex ample data ﬂow diagrams.\n10.1.4 CRC Cards\nCRC stands for Class -- Responsibility -- Collaborators. A C RC card is simply\na 4”\n/A2 6” or 5” /A2 7” index card with three ﬁelds labeled Class, Responsibilit y and\n10.1. CLASSIC MODELING TECHNIQUES 255\nFigure 10.4 Data ﬂow diagram for library automation\nCollaborators. CRC cards were developed in response to a nee d to document\ncollaborative design decisions. CRC cards are especially h elpful in the early phases\nof software development, to help identify components, disc uss design issues in multi-\ndisciplinary teams, and specify components informally. CR C cards may be termed\na low-tech tool, as opposed to the high-tech tools we commonl y use. Yet they are\nhighly useful. They are also fun to work with in our all-too-s erious business meetings.\nCRC cards are not only used in collaborative design sessions . Within the design\npattern community, for instance, they are used to document t he elements that\nparticipate in a pattern.\nThe word ‘class’ in CRC is a historical relic. CRC cards can be used to describe\nany design element. We will stick to the original terminolog y, however. The class\nname appears in the upper-left corner of the card. A bullet-l ist of responsibilities\n256 MODELING\nappears under the class name and a list of collaborators appe ars on the right part of\nthe card.\nFigure 10.5 A CRC card\nFigure 10.5 gives an example of a CRC card for a component Reservations in our\nlibrary system. The main responsibilities of this componen t are to keep an up-to-date\nlist of reservations and to handle reservations on a FIFO bas is. Its collaborators are the\ncatalog component and the user session component. The types of interaction with\nthese components is shown in ﬁgure 10.16.\n10.2 On Objects and Related Stuff\nWhat matters is not how closely we model today’s reality but h ow ext", "token_count": 512, "start_token": 151998, "end_token": 152510, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 330, "text": " session component. The types of interaction with\nthese components is shown in ﬁgure 10.16.\n10.2 On Objects and Related Stuff\nWhat matters is not how closely we model today’s reality but h ow extensible and\nreusable our software is.\n(Meyer, 1996)\nThe world around us is full of objects, animate and inanimate , concrete and abstract:\ntrees and tables, cars and legal cases. According to some, an alysis and design is about\nmodeling those real-world objects. By and large, this view h as its origins in the\nScandinavian school of programming language design (SIMUL A-67) and software\ndevelopment. It may be termed the European view. According t o others, analysis\nand design is about identifying reusable components and bui lding their inheritance\nhierarchy. This latter view, which may be termed the America n view, clearly shows\nitself in the above citation.\nWhat then is an object? As might be expected, there are different views of what\nthe notion of object entails. We may distinguish the followi ng viewpoints:\n10.2. ON OBJECTS AND RELATED STUFF 257\n/AF The modeling viewpoint: an object is a conceptual model of so me part of a real\nor imaginary world. This is termed the European view. From th is point of view,\nimportant characteristics are:\n– each object has an identity, which distinguishes it from all other objects;\n– objects have substance: properties that hold and can be disc overed by\ninvestigating an object.\nFrom a practical point of view, object identity is an immutab le tag, or an address,\nwhich uniquely identiﬁes that object. Different objects oc cupy different regions\nof memory. Pragmatically also, objects may be regarded as im plementations\nof abstract data types (ADTs). An object then consists of a mu table state, i.e.\nthe set of variables of the ADT, and operations to modify or in spect the state.\nTypically, the only way to access an object is through these o perations. These\noperations thus act as an interface to the object. An object t hen is a collection\nof three aspects:\nobject = identity /B7 variables /B7 operations\nor\nobject = identity /B7 state /B7 behavior", "token_count": 512, "start_token": 152460, "end_token": 152972, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 331, "text": "\noperations thus act as an interface to the object. An object t hen is a collection\nof three aspects:\nobject = identity /B7 variables /B7 operations\nor\nobject = identity /B7 state /B7 behavior\n/AF The philosophical viewpoint: objects are existential abst ractions, as opposed\nto universal abstractions. In some circles (notably Smallt alk), ‘everything\nis an object’. In this view, objects act as a unifying notion u nderlying all\ncomputation. However, one may also argue that there are two r ather distinct\ntypes of abstraction. Some kinds of entity have a natural beg inning and end.\nThey are created at some point in time, exist for a while, and a re ultimately\ndestroyed. The kinds of entities modeled as objects during a nalysis and design\ntypically belong to this class. Other kinds of entities, suc h as numbers, dates\nand colors, have ‘eternal’ existence. They are not instanti ated; they cannot be\nchanged; they ‘live’ forever. These entities are usually re ferred to as values.\n/AF The software engineering viewpoint: objects are data abstr actions, encapsulat-\ning data as well as operations on those data. This viewpoint s tresses locality\nof information and representation independence; see also s ections 12.1.1\nand 12.1.3. However, not all programming languages enforce data abstrac-\ntion, and objects need not always encapsulate an abstract da ta type. We might\nclaim that data abstraction and objects are somewhat orthog onal, independent\ndimensions.\nA programming language that merely allows us to encapsulate abstract data\ntypes in modules is often termed object-based. The adjective object-oriented\nthen is reserved for languages that also support inheritance. Inheritance is\ndiscussed below.\n258 MODELING\n/AF The implementation viewpoint: an object is a contiguous str ucture in memory.\nTechnically, an object may be regarded as a record of data and code elements.\nAn object may be composite or aggregate, in which case it poss esses other\nobjects. These sub-objects in turn may possess even ‘smalle r’ sub-objects,\netcetera. The lowest-level objects in this hierarchy are at omic objects, typically\ndenoting things like integers, real numbers", "token_count": 512, "start_token": 152922, "end_token": 153434, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 332, "text": ". These sub-objects in turn may possess even ‘smalle r’ sub-objects,\netcetera. The lowest-level objects in this hierarchy are at omic objects, typically\ndenoting things like integers, real numbers or Booleans.\nThe implementation of this ‘possessed-by’ relation appear s to be intricate. On\nthe one hand, objects may be contained in other objects. In th is representation,\nall references are dispensed with. There is no concept of sha ring. This scheme\nis known as value semantics . Value semantics is inadequate for object-oriented\nsystems, since such systems require sharable objects. The o pposite scheme is\nreference semantics : data is represented as either an atomic object or as an\naggregate of references to other objects. Pure reference se mantics is inefﬁcient\nin the case of primitive objects like integers or characters . A combination in\nwhich aggregate objects may contain other objects, refer to other objects, or\ndo both at the same time, is commonly used as a storage scheme. The choice of\na particular storage model is to some extent reﬂected in the h igh-level language\nsemantics (for example, where it concerns copying or compar ing objects).\n/AF The formal viewpoint: an object is a state machine with a ﬁnit e set of states and\na ﬁnite set of state functions. These state functions map old states and inputs to\nnew states and outputs.\nFormalization of the concepts and constructions of object- oriented languages is\ndifﬁcult. Mathematical formalisms tend to be value-based. Imperative concepts,\nsuch as state and sharing, that are central to object-orient ed languages do not\nﬁt easily within such schemes.\nDuring analysis, the conceptual viewpoint is usually stres sed. Those who are of the\nopinion that analysis and design smoothly shade off into one another tend to keep\nthis view during design. Others however are of the opinion th at analysis and design\nare different, irrespective of whether they are object-ori ented or not. They are likely\nto stress other viewpoints during design. The deﬁnition of a n object as given in (Coad\nand Yourdon, 1991) also reﬂects the tension between a proble m-oriented and a\nsolution-", "token_count": 512, "start_token": 153384, "end_token": 153896, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 333, "text": " other viewpoints during design. The deﬁnition of a n object as given in (Coad\nand Yourdon, 1991) also reﬂects the tension between a proble m-oriented and a\nsolution-oriented viewpoint: an object is ‘an abstraction of something in a problem\ndomain, reﬂecting the capabilities of a system to keep infor mation about it, interact\nwith it, or both; an encapsulation of Attribute values and their exclusive Services.’\nWe will come back to this dichotomy when discussing object-o riented methods in\nsection 12.3.\nAs noted above, objects are characterized by a set of attribu tes (properties).\nA table has legs, a table top, size, color, etc. The attribute concept originates\nwith Entity--Relationship Modeling; see section 10.1.1. I n ERM, attributes represent\nintrinsic properties of entities, properties whose value does not depend on other entities.\nAttributes denote identifying and descriptive properties , such as name or weight.\n10.2. ON OBJECTS AND RELATED STUFF 259\nRelationships on the other hand denote mutual properties, such as an employee being\nassigned to a project or a book being borrowed by a member. In U ML, these\nrelationships are called associations. In UML, the distinc tion between attributes and\nrelationships formally does not exist. Both are properties of a class. It is considered\ngood practice in UML though to model simple properties as att ributes, and more\ncomplex properties as associations.\nIn the context of object-oriented modeling, the term attrib ute is sometimes used\nto denote any ﬁeld in the underlying data structure. In that c ase, the object’s identity\nis an attribute, the state denotes the set of ‘structural’ at tributes, and the operations\ndenote the ‘behavioral’ attributes. We will use the term att ribute to denote a structural\nattribute. Collectively, this set of attributes of an objec t thus constitutes its state. It\nincludes the intrinsic properties, usually represented as values, as well as the mutual\nproperties, usually represented as references to other obj ects.\nAt the programming-language level, objects that have the sa me set of attributes\nare said to belong to", "token_count": 512, "start_token": 153846, "end_token": 154358, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 334, "text": " the intrinsic properties, usually represented as values, as well as the mutual\nproperties, usually represented as references to other obj ects.\nAt the programming-language level, objects that have the sa me set of attributes\nare said to belong to the same class. Individual objects of a class are called instances of\nthat class. So we may have a class Table, with instances MyTable and YourTable.\nThese instances have the same attributes, with possibly dif ferent values.\nAn object not only encapsulates its state, but also its behavior, i.e. the way in which\nit acts upon other objects and is acted upon by other objects. The behavior of an\nobject is described in terms of services provided by that object. These services are\ninvoked by sending messages from the object that requests the service to the object that\nis acted upon.\nIn order for a collection of objects to operate together as in tended, each of the\nobjects must be able to rely on the proper operation of the obj ects with which it\ninteracts. In a client-server view, one object, the client, requests some service from\nanother object, the server. This mutual dependency may be vi ewed as a contract\nbetween the objects involved. The client will not ask more th an what is stated in the\ncontract, while the server promises to deliver what is state d in the contract. In this\nperspective, services are also referred to as responsibilities.\nThe major behavioral aspect of an object concerns state chan ges. The state of an\nobject instance is not static, but changes over time: the obj ect instance is created,\nupdated, and eventually destroyed. Also, certain informat ion may be requested from\nan object. This information may concern the state of the obje ct instance, but it may\nalso involve a computation of some sort.\nFor example, a customer of a library may have attributes like Name, Address,\nand BooksOnLoan. It must be possible to create an instance of the object type\nCustomer. When doing so, suitable values for its attributes must be pr ovided. Once\nthe instance has been created, state changes are possible: b ooks are loaned and\nreturned, the customer changes address, etc. Finally, the i nstance is destroyed when\nthe customer ceases to be a member. Information requested ma y concern such things\nas a list of books on loan or the number", "token_count": 512, "start_token": 154308, "end_token": 154820, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 335, "text": "ed and\nreturned, the customer changes address, etc. Finally, the i nstance is destroyed when\nthe customer ceases to be a member. Information requested ma y concern such things\nas a list of books on loan or the number of books on loan. The for mer is part of the\nstate that describes a particular customer and can be retrie ved directly from that state.\nNumberOfBooksOnLoan is a service that requires a computation of some sort, for\n260 MODELING\nexample counting the number of elements in BooksOnLoan.\nWe will generally not be concerned with individual objects. Our goal is to identify\nand relate the object types (i.e. classes). We will often use the term object to denote\nan object type. One of our major concerns during analysis and design is to identify\nthis set of objects, together with their attributes (state) and services (behavior).\nRelations between objects can be expressed in a classiﬁcati on structure. The major\ntypes of relation depicted in such structures are listed in ﬁ gure 10.6.\nRelation Example\nSpecialization/Generalization, is-a Table is-a Furniture\nWhole-part, has Table has TableTop\nMember-of, has Library has Member\nFigure 10.6 Major types of relations between objects\nIf we have objects Table and Chair, we may also deﬁne a more general object\nFurniture. Table and Chair are said to be specializations of Furniture, while Furniture\nis a generalization of Table and Chair. These relations are also known as ‘is-a’ relations.\nThe is-a relation is a well-known concept from Entity--Rela tionship Modeling.\nThe generalization/specialization relations can be expre ssed in a hierarchical\nstructure like the one in ﬁgure 10.7. In its most general form the classiﬁcation\nstructure is a directed acyclic graph (DAG). Many classiﬁca tion structures can be\ndepicted as a tree though, in which case each object is a direc t descendant of exactly\none other object. At the programming-language level, single inheritance corresponds\nto a tree structure, while multiple inheritance corresponds to a DAG.\nDifferent objects may share some of their attributes. Both t ables and chairs have\n", "token_count": 512, "start_token": 154770, "end_token": 155282, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 336, "text": " of exactly\none other object. At the programming-language level, single inheritance corresponds\nto a tree structure, while multiple inheritance corresponds to a DAG.\nDifferent objects may share some of their attributes. Both t ables and chairs have\na height, for instance. Rather than deﬁning the full set of at tributes for each object,\nwe may deﬁne common attributes at a higher level in the object hierarchy and let\ndescendants inherit those attributes. We may therefore deﬁne the attribute Height at\nthe level of Furniture rather than at the level of each of its descendants. Obviousl y,\nthis is just another way of looking at the object hierarchy. T he fact that Chair and\nTable are both descendants of Furniture already suggests that they share certain\nproperties, properties that are common to the various types of furniture. The fact that\nthey are different descendants of Furniture also suggests that they each have unique\nproperties.\nAlternatively, we may view the object hierarchy as a type hierarchy . Chair and\nTable are subtypes of Furniture, just like Cardinal is a subtype of Integer. In this\nview, an object is a restriction of the objects of which it is a specialization. Each chair\nis a piece of furniture, but the reverse is not generally true .\n10.2. ON OBJECTS AND RELATED STUFF 261\nFigure 10.7 Object hierarchy\nBy explicitly relating objects in the object hierarchy, a mu ch tighter semantic\nbinding between related objects is realized than is possibl e in more traditional design\napproaches. In a functional decomposition of our library au tomation problem for\nexample, there is virtually no way to make the similarities b etween books and journals\nexplicit in the design. In an object-oriented design, objec ts Book and Journal can\nbe made descendants of a more general object Publication, and attributes like\nPublisher can be inherited from this more general type of object.\nThe is-a relation is one way to organize (object) types into a hierarchy. The\npart-of relation is another major organizational property of object types. A Table\n‘has’ a TableTop and Legs. A Publication ‘has’ a TitleDescription and a Publisher.\nThis part-of relation aggregates components into a ‘whole’. It describes how compound\nthings are made up of simpler things. By deﬁnition", "token_count": 512, "start_token": 155232, "end_token": 155744, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 337, "text": " ‘has’ a TitleDescription and a Publisher.\nThis part-of relation aggregates components into a ‘whole’. It describes how compound\nthings are made up of simpler things. By deﬁnition, the compo und is at a higher level\nof abstraction than its components.\nAn object like TableTop is made up of attributes, for example Color, Width and\nLength. At the next level, objects like TableTop and Legs are assembled into a\nhigher-level object, viz. Table. At that level, we may introduce additional attributes,\n262 MODELING\nsuch as Size, so that Table may also be seen as an aggregate of the ﬁrst kind. In\ngeneral, a compound object consists of a number of (referenc es to) other objects and\na number of ‘simple’ attributes, i.e. values.\nIn the case of Table, the part-of relation is a real-world part-of relation. In t he\ncase of Publication, Publisher does not correspond to some part of the underlying\nreal-world object. It merely is part of the representation of the object Publication.\nSometimes, an explicit distinction is made between the real -world part-of relation\nand the representational part-of (or component-of) relati on. In UML they are called\ncomposition and aggregation, respectively.\nIn many modeling methods, the part-of relation subsumes the member-of relation.\nThe member-of relation is used to model the relationship bet ween a set and its\nmembers. It is, however, sometimes useful to be able to disti nguish between these\norganizational properties. For example, the part-of relat ion is generally considered to\nbe transitive, whereas the member-of relation is not. If Book is a member of Library,\nand Library is a member of PublicInstitutions, we do not want to infer that Book\nis a member of PublicInstitutions.\n10.3 The Uniﬁed Modeling Language\nThe Uniﬁed Modeling Language has its roots in the object-ori ented analysis and\ndesign methods of the 1980s. Several key players in this ﬁeld (Grady Booch, John\nRumbaugh and Ivar Jacobson) came to work for Rational, and st arted to unify their\n", "token_count": 512, "start_token": 155694, "end_token": 156206, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 338, "text": "\ndesign methods of the 1980s. Several key players in this ﬁeld (Grady Booch, John\nRumbaugh and Ivar Jacobson) came to work for Rational, and st arted to unify their\nmethods and notations. This resulted in the ﬁrst versions of UML. At a later stage,\nOMG --- the Object Management Group, an open consortium of co mpanies --- took\nover. They now control the activities around UML, and adopte d it as one of their\nstandards. The current version is known as UML 2. UML is by far the most widely\nused notation for both requirements engineering and design .\nThe 13 diagrams of UML 2 are listed in ﬁgure 10.8. Some diagram s, such as the\nclass diagram and the state machine diagram, have been there since the beginning\nof object orientation. Others are more recent. For example, the composite structure\ndiagram and the timing diagram were introduced in UML 2. Some of the diagrams\ngive a static view. For instance, a class diagram shows the st atic structure of a system.\nOther diagrams give a dynamic, or behavioral view, i.e. they show what happens\nwhen the system is executed. For instance, a sequence diagra m shows which messages\nare exchanged between instances of classes. In ﬁgure 10.8, s tatic diagrams are marked\nwith an S, and dynamic diagrams are marked with a D. In the next subsections, we\ndiscuss the most important UML diagrams.\n10.3.1 The Class Diagram\nClass diagrams depict the static structure of a system. A cla ss diagram is a graph\nin which the nodes are objects (classes) and the edges are rel ationships between\n10.3. THE UNIFIED MODELING LANGUAGE 263\nDiagram Description\nActivity (D) To model business processes, workﬂow, procedu ral\nlogic. Similar to ﬂowcharts, but activity diagrams\nsupport parallelism, like in Petri nets\nClass (S) To model classes, their features and relationship s.\nSee section 10.3.1\nCommunication (D) To model the ﬂow of messages between insta nces\nof classes. Very similar to the sequence diagram.\nSee section 10.3.4\n", "token_count": 512, "start_token": 156156, "end_token": 156668, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 339, "text": " s.\nSee section 10.3.1\nCommunication (D) To model the ﬂow of messages between insta nces\nof classes. Very similar to the sequence diagram.\nSee section 10.3.4\nComponent (S) To model a set of components and their interrel a-\ntionships (through interfaces). See section 10.3.5\nComposite structure To model the internal dynamic structur e of a class\nDeployment To model the physical layout, i.e. the assignmen t\nof system elements to hardware elements\nInteraction overview (S) Combines activity diagrams and se quence diagrams\nObject (S) To model objects and their relationships at some\npoint in time; also known as instance diagram\nPackage (S) To model the grouping of elements into packages\nSequence (D) To model the order in which messages are\nexchanged between instances of classes. See\nsection 10.3.3\nState machine (D) To model the states in which an object can be , and\nthe transition between states. See section 10.3.2\nTiming (D) To model state changes of an object over time\nUse case (D) To model use cases. See section 10.3.6\nFigure 10.8 UML 2 diagram types\nobjects. By decorating the edges, many kinds of relationshi ps can be modeled. These\nrelationships fall into two classes: generalizations and associations.\nThe most common example of a generalization-type class diag ram is a diagram\ndepicting the subclass--superclass hierarchy. Figure 10. 7 is an example of such a class\ndiagram. The classes are denoted by rectangles that have thr ee compartments. These\ncompartments contain, from top to bottom:\n– the name of the class,\n– the list of attributes of the class, and\n– the list of operations of the class.\n264 MODELING\nUML allows for quite some variety in its notation. We may for i nstance depict\na class as a rectangle with one compartment only, just giving the name of the\nclass. Adding slightly more detail, we may depict a class as a rectangle having two\ncompartments, where the second one characterizes the respo nsibilities of that class,\ni.e., what it is supposed to do, as kind of an inline comment. F igure", "token_count": 512, "start_token": 156618, "end_token": 157130, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 340, "text": " depict a class as a rectangle having two\ncompartments, where the second one characterizes the respo nsibilities of that class,\ni.e., what it is supposed to do, as kind of an inline comment. F igure 10.9 gives the\nthree-compartment representation in which a number of anal ysis-level details have\nbeen added. We may even extend the notation further and add im plementation-level\ndetails, such as whether attributes and operations are publ ic or private. We may think\nof these different representations as different views of th e same model element. We\nmay envision tool support that allows the user to switch from one representation to\nanother, suppressing or adding detail as the need arises.\narchive()\npublisher: String\nisbn: String\nname: String\nreturn()\nborrow(Client)\ntitle: String\nauthor: String\nPublication\nJournalBook\nFigure 10.9 UML class diagram: generalization\nThe hollow triangle in ﬁgure 10.9 indicates that the structu re is a generaliza-\ntion/specialization structure. Generalization is shown a s a solid path from the more\nspeciﬁc element (such as Book) to the more general element ( Publication), with a\nlarge hollow triangle at the end of the path. A group of genera lization paths may be\nshown as a tree with a shared segment, as in ﬁgure 10.9.\n10.3. THE UNIFIED MODELING LANGUAGE 265\nThe attributes of a class denote properties of that class. E.g., publisher is a property\nof Publication. Next to attributes, UML has another way of denoting propert ies of\na class, viz. associations. A UML association is depicted as a solid line connecting two\nclasses. This line may be adorned with a variety of glyphs and textual information to\nprovide further speciﬁcs of the relationship. A simple asso ciation between a library\nand its clients is depicted in ﬁgure 10.10a. The (optional) n ame of the association is\nprinted near the path. The solid triangle indicates the dire ction in which the verb is\nto be read. Note that associations are bi-directional: a cli ent is a member of a library,\nand a library has members. Further", "token_count": 512, "start_token": 157080, "end_token": 157592, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 341, "text": " near the path. The solid triangle indicates the dire ction in which the verb is\nto be read. Note that associations are bi-directional: a cli ent is a member of a library,\nand a library has members. Further adornments can be added to indicate properties of\nthe association. In ﬁgure 10.10a we have added multiplicity information: a client can\nbe a member of one or more libraries, while a library may have z ero or more clients.\nStrictly speaking, there is no difference between an attrib ute and an association.\nIn ﬁgure 10.10b, we have depicted Client as an attribute of Library. Usually, simple\nproperties such as numbers and dates are modeled as attribut es, while more signiﬁcant\nconcepts are modeled as associations.\nAn association such as Member-of also has class properties. For example, this\nassociation has attributes, e.g. MemberId, and operations, such as BecomeMember\nand CeaseToBeMember. Alternatively, we may say that class Membership has\nassociation properties. In UML, this model element is terme d association class . It\ncan be depicted as a class symbol attached by a dashed line to a n association path,\nas in ﬁgure 10.10c. We may even promote an association clas to a full class, as\nin ﬁguUML10.10d. Notice that the multiplicities have moved . A membership (of\na client) can be to one or more libraries, whereas the members hip (of the library)\nrelates to zero or more clients.\nThe part-of relation is called aggregation or composition in UML. In an aggre-\ngation, objects can be part of more than one other object. For example, if our library\nmaintains lists of required readings for certain courses, t hen a given book may be a\npart of more than one required reading list. Aggregation is d enoted with an open\nﬁled diamond as association role adornment. Composition is a strong notion of\naggregation, in which the part object may belong to only one w hole object. With\ncomposition, the parts are expected to live and die with the w hole. If a table is\ncomposed of four legs and a tabletop, the table owns these parts", "token_count": 512, "start_token": 157542, "end_token": 158054, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 342, "text": " which the part object may belong to only one w hole object. With\ncomposition, the parts are expected to live and die with the w hole. If a table is\ncomposed of four legs and a tabletop, the table owns these parts. They cannot be part\nof another table at the same time. Composition is denoted by a solid ﬁlled diamond as\nan association role adornment, as in ﬁgure 10.11a. Figure 10 .11a shows a Book with\nparts title, author, and isbn. A book has one title and one ISBN, so these parts have\nmultiplicity 1. We assume here that a book may have up to three authors, so that part\nhas multiplicity of 1..3. At the whole end of composition, th e multiplicity is either 1\nor 0..1. This part-of relationship is a relationship betwee n a class and the classes of\nits attributes. An alternative notation for this part-of re lation therefore consists of the\ntop two compartments of the diagram for a class, as in ﬁgure 10 .11b.\nNext to generalization and association, there are many othe r ways in which\nelements of a class diagram may depend on each other. For exam ple, one class may\ncall operations from another class, create instances of ano ther class, and so on. Such\n266 MODELING\nLibrary\nClient: Clientinfo [*]\nb)\nClient\n1..** Is-member-of\nLibrary\nMemberId\nMembership\nd)\na)\nIs-member-of\nc)\nLibrary\nMembership\nMemberId\nClient\n1..* *\nClient\nLibrary\n* 1..*\nFigure 10.10 UML class diagram: (a) association, (b) associ ation as attribute, (c)\nassociation class, (d) association class as a full class\ndependencies are depicted with a dashed arrow, labeled with the type of dependency.\nIf all dependencies are included in a class diagram, it soon b ecomes very cluttered.\nSo it is wise to only include important dependencies. Many ty pes of dependencies\nneed not be modeled by hand, but can be derived from the source code, and tools\nexist that do so.\nAn abstract class is a class that cannot be instantiated directly. Only its (co ncrete)", "token_count": 512, "start_token": 158004, "end_token": 158516, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 343, "text": " ty pes of dependencies\nneed not be modeled by hand, but can be derived from the source code, and tools\nexist that do so.\nAn abstract class is a class that cannot be instantiated directly. Only its (co ncrete)\nclients can. Abstract classes typically occur in hierarchi es of data types. For instance,\nwe may have an abstract class List, with subclasses like LinkedList and ArrayList.\n10.3. THE UNIFIED MODELING LANGUAGE 267\nFigure 10.11 UML class diagram: composition as (a) associat ion role adornment and\n(b) a simple class diagram\nThe abstract class List may have abstract operations as well, such as get, that can\nonly be made concrete at the subclass level. At the level of List, we then merely\nstate that each of its subclasses will provide an implementa tion of get. In our library\nexample, we could have designated Publication as an abstract class. Abstract classes\nare indicated by printing their name in italics.\nAn interface is a class all of whose features are abstract. It has no implem entation.\nInterfaces are a useful means to split the set of properties o f a class into subsets, in\ncase other classes only need access to subsets of those prope rties. For instance, class\nPublication may have properties that are accessible to customers of the l ibrary, as\nwell as properties that are for internal use only, such as its price, who authorized\nacquisition, and so on. We may then deﬁne two interfaces to Publication that\nare made available to different other classes in the system. Publication then provides\ndifferent interfaces to different client classes, who in tu rn require the interface. Interfaces\nare marked with the keyword\n/AS interface/AT , as in ﬁgure 10.12. Interfaces are often\nused to increase the robustness of a model, by restricting ac cess to properties really\nneeded.\n10.3.2 The State Machine Diagram\nA major class of services provided by an object relates to the object’s life cycle: an\nobject instance is created, updated zero or more times, and ﬁ nally destroyed. State\ntransition diagrams, which depict the possible states of an object and the transitions\nbetween those states, are a good help in modeling this life cy cle.\n268 MODEL", "token_count": 512, "start_token": 158466, "end_token": 158978, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 344, "text": " zero or more times, and ﬁ nally destroyed. State\ntransition diagrams, which depict the possible states of an object and the transitions\nbetween those states, are a good help in modeling this life cy cle.\n268 MODELING\nPublication\nBorrow\nClientData\n<<interface>>\nPrice\n<<interface>>\nFinancialData\nAcquisition\nEmployee\nClient\nFigure 10.12 UML class diagram: interfaces\nUsually, the ﬁnite state machine model and its associated st ate transition diagram\n(see section 10.1.2) are extended in several ways when used i n modeling the behavior\nof objects over time:\n/AF In the classical ﬁnite state machine model, states do not hav e local variables.\nAll necessary information is coded in the state. This easily leads to unwieldy\nmodels. For instance, suppose we want to model an object LibraryMember\nas follows: a person may become a member of the library, borro w up to 10\nbooks, and cease to be a member of the library. This leads to a ﬁ nite state\nmachine with states like has-borrowed-0-books, has-borrowed-1-book,\nhas-borrowed-2-books, . . . , has-borrowed-10-books. If the number of\nbooks on loan could be modeled as a local variable, the number of states in the\nmodel would be reduced from 12 to 2.\nFor this reason, the ﬁnite state machine is usually extended by adding local\nvariables to the model. A state in this extended ﬁnite state m achine then\ncomprises both the explicit state represented by a node in th e state transition\ndiagram and the value of the model’s variables.\nThese local variables are not only used to decrease the numbe r of states. State\ntransitions may now also change the values of variables; the variables may be\ntested to determine the next state and transitions may be gua rded by the value\nof the variables. In ﬁgure 10.13, the number of books on loan i s kept in the\nlocal variable\n/C6 . This variable is initialized to zero, updated when a book is\nborrowed or returned, and tested when a person terminates hi s membership.\n/", "token_count": 512, "start_token": 158928, "end_token": 159440, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 345, "text": " number of books on loan i s kept in the\nlocal variable\n/C6 . This variable is initialized to zero, updated when a book is\nborrowed or returned, and tested when a person terminates hi s membership.\n/AF The components being modeled interact with the environment : there are input\nevents and output actions. In all modeling methods that we kn ow of, input\n10.3. THE UNIFIED MODELING LANGUAGE 269\nevents trigger transitions. When a person becomes a member o f the library, this\ntriggers the initial transition; when she borrows a book, it triggers a transition\nfrom a state, say, has-borrowed-7-books to a state has-borrowed-8-books.\nIf the model has local variables, the latter state transitio n may result in a change\nin the value of such a local variable. In ﬁgure 10.13, the inpu t events are denoted\nas strings that label state transitions (like Start and Borrow).\nDifferent modeling methods have different ways to handle ou tput actions.\nSometimes, output actions are associated with a transition (this is known as a\nMealy machine), sometimes output actions are associated wi th a state (a Moore\nmachine). In the latter case, the output action is carried ou t as soon as the state\nis entered. In a formal sense, Mealy machines and Moore machi nes have the\nsame expressive power.\n/AF Finite state diagrams may become unwieldy. Therefore, one m ay add some\nstructure, through a hierarchy. Part of the model may be comp ressed into one\nstate. If we are interested in the details of a state, we may ‘z oom in’ on that\nstate.\nMany modeling methods, including UML, depict the sequence o f states that an\nobject goes through in a variant of the statechart. Statecharts are extended ﬁnite state\nmachines (i.e. they have local variables) in which output ac tions may be associated\nwith both transitions and states and in which states can be ar ranged hierarchically. In\nUML, this type of diagram is called state machine diagram .\nFigure 10.13 UML state machine diagram: object Member\n270 MODELING\nAs with class diagrams, UML has a rich notation for state", "token_count": 512, "start_token": 159390, "end_token": 159902, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 346, "text": " hierarchically. In\nUML, this type of diagram is called state machine diagram .\nFigure 10.13 UML state machine diagram: object Member\n270 MODELING\nAs with class diagrams, UML has a rich notation for state diag rams. We will\nillustrate the major ingredients through a few examples; se e also ﬁgures 10.13\nand 10.14.\nA state is some condition in the life of an object. It is shown a s a rectangle with\nrounded corners. An initial (pseudo) state is shown as a smal l ﬁlled circle. This initial\nstate is a mere notational device; an object can not be in such a state. It indicates\nthe transition to the ﬁrst ‘real’ state. A ﬁnal (pseudo) stat e is shown as a small circle\nsurrounding a small ﬁlled circle. This ﬁnal state is also a no tational device. A transition\nis shown as a solid arrow from one state to another. When a chan ge of state occurs,\nthat transition is said to ‘ﬁre’. A transition has a label tha t comes in three parts. The\ngeneral form is trigger-signature [guard]/activity . All three parts are optional. The trigger-\nsignature denotes the event which triggers the transaction , such as the borrowing of a\nbook. The event may be guarded by a Boolean expression. For ex ample, the transition\nfrom state is-member to cleaning-up in ﬁgure 10.13 is guarded by the expression\n‘/C6 /BP /BC ’; it can only occur if the number of books on loan is zero. When an event\noccurs, only one transition can be taken. So if multiple tran sitions occur with the\nsame event, the guards must be mutually exclusive. The trans ition label may include\na procedural expression after the symbol ‘/’. This procedur al expression is executed\nwhen the transition ﬁres.\nFigure 10.14 gives an example of nested states. Figure 10.14 a gives a global view\nof the life cycle of an object Book: a book is ordered, stays alive for a while, and is\neventually either disposed of or archived. In ﬁgure 10.14b", "token_count": 512, "start_token": 159852, "end_token": 160364, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 347, "text": " 10.14 a gives a global view\nof the life cycle of an object Book: a book is ordered, stays alive for a while, and is\neventually either disposed of or archived. In ﬁgure 10.14b, state alive is expanded to\nshow its ﬁner structure. In this example, the state is reﬁned into mutually exclusive\ndisjoint substates: a book is either available or borrowed1. The transition from state\nordered to state alive is drawn to the boundary of state alive. This is equivalent\nto a transition to the initial state within the graphics regi on of alive. The transition\nfrom the nested state available to states disposed and archived is made directly.\nTo indicate this transition from a suppressed internal stat e of alive to disposed and\narchived in ﬁgure 10.14a, the transitions are not drawn from the bound ary of alive,\nbut from a so-called stub, shown as a small vertical line drawn inside its boundary.\n10.3.3 The Sequence Diagram\nObjects communicate by sending messages. To carry out a cert ain task, a particular\nsequence of messages may have to be exchanged between two or m ore objects. The\ntime ordering in which this sequence of messages has to occur may be depicted\nin a sequence diagram . A sequence diagram is on type of interaction diagram .\nA second type of interaction diagram is the communication diagram , discussed in\n1 UML also allows you to reﬁne a state into concurrent substate s. For example, when a book is returned,\nseveral things have to be done. It has to be checked whether th e book is returned within the ﬁxed time.\nIf not, some ﬁne may be due. Possible outstanding reservatio ns need to be checked as well and, if so, one\nof these reservations must be handled. These subprocesses c an be handled concurrently. There can be a\nstate returning book which, when reﬁned, results in two or more concurrent, and-r elated substates. This\nis shown by tiling the graphics region of the state using dash ed lines to separate subregions.\n10.3. THE UNIFIED MODELING LANGUAGE 271\nFigure 10.14 UML state diagram: object Book, (a) global view and (b) expanded\nview\nsection 10.3", "token_count": 512, "start_token": 160314, "end_token": 160826, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 348, "text": " subregions.\n10.3. THE UNIFIED MODELING LANGUAGE 271\nFigure 10.14 UML state diagram: object Book, (a) global view and (b) expanded\nview\nsection 10.3.4. In the telecommunications domain, sequenc e diagrams are known\nas Message Sequence Charts and provide a standard notation f or designing and\nspecifying protocols. The sequence diagram is also used in t he design pattern\ncommunity, to graphically depict the interaction between t wo or more objects\nparticipating in a design pattern.\nIn a sequence diagram, the horizontal dimension shows the va rious objects that\nparticipate in the interaction. An object is shown as a verti cal dashed line, its ‘lifeline’.\nThe period in which the object is active (within the particul ar sequence of messages\ndepicted) is shown as a thin rectangle. If the distinction be tween active and inactive\nis not important, the entire lifeline may be shown as an activ ation, as in ﬁgure 10.15.\nThe ordering in which the objects are shown carries no meanin g.\nThe vertical dimension denotes the time sequencing of messa ges. Usually, only\nthe order in which messages are displayed carries meaning. For real-t ime applications,\nthe time axis may show actual numerical values.\nMessages are shown as labeled arcs from one object to another . The vertical\n272 MODELING\narrangement of messages indicates their order. The labels m ay also contain sequence\nnumbers, which are particularly useful to indicate concurr ency. A message may also\nbe labeled with a guard, a boolean expression that states the condition which must\nhold for the message to be sent.\nstart\nuser\n6: remove reservation\n6: borrow title\n5: title available\n5: hold title\n4: title returned\n3: [not available] reserve title\n2: title data\n1: look up\nreservationscatalog\nFigure 10.15 UML sequence diagram: reserving a title\nFigure 10.15 shows a possible sequence of interactions betw een a user, a catalog\nof available books, and an object which handles reservation s. The ﬁrst message comes\n10.3. THE UNIFIED MODELING LANGUAGE 273\nfrom an outside, unknown source. This message is called the found message", "token_count": 512, "start_token": 160776, "end_token": 161288, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 349, "text": " available books, and an object which handles reservation s. The ﬁrst message comes\n10.3. THE UNIFIED MODELING LANGUAGE 273\nfrom an outside, unknown source. This message is called the found message . The\nuser then sends a request to the catalog to look up a certain ti tle. The catalog reacts\nby sending data about that title to the user. If the title is no t available (this is indicated\nby a boolean expression, the guard, within square brackets) , a request to reserve that\ntitle is sent to the object that handles reservations. Some t ime later, that title will\nbecome available again and reservations will be notiﬁed. The object reservations\nwill then send a message to the catalog to hold that book and wi ll notify the user\nthat the title is now available. The ordering of those two mes sages is irrelevant, so\nthey carry the same sequence number. The user may now borrow t he title and the\ncorresponding reservation will be removed.\nAgain, UML has a rich notational vocabulary for sequence dia grams. It is possible\nto distinguish asynchronous message-passing from synchro nous message-passing, to\nindicate iteration, to show the creation and destruction of objects, and so on. The\nmain purpose of the sequence diagram however remains the sam e: an easy-to-read\noverview of the passing of messages in a particular interact ion sequence.\n10.3.4 The Communication Diagram\nThe communication diagram is another way to show one possibl e scenario for the\ninteraction between a number of related objects. A communic ation diagram is a\ndirected graph where the nodes denote entities and the edges denote communication\nbetween those entities.\n3: [not available] reserve title\n5: title available\nlook up\n1:\ntitle data\n2:\nuser\nborrow\n6:\ntitle\ncatalog\nstart\n6: remove reservation\nreservations\n4: title returned\n5: hold title\nFigure 10.16 UML communication diagram: reserving a title\n274 MODELING\nFigure 10.16 shows the same sequence of interactions as the s cenario depicted\nin the sequence diagram in ﬁgure 10.15. Communication diagr ams emphasize the\nobjects and their relationships relevant to a particular in teraction. To provide more\ndetail about", "token_count": 512, "start_token": 161238, "end_token": 161750, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 350, "text": " of interactions as the s cenario depicted\nin the sequence diagram in ﬁgure 10.15. Communication diagr ams emphasize the\nobjects and their relationships relevant to a particular in teraction. To provide more\ndetail about the interaction, relevant attributes may be sh own inside the nodes (by\nadding another compartment as in a class diagram) and these a ttributes may be\nincorporated in the labels of the edges as well.\nSequence diagrams emphasize the ordering of messages. In a s equence diagram,\nsequence numbers are optional; in a communication diagram, they are mandatory\nsince the ordering does not show itself graphically.\n10.3.5 The Component Diagram\nWhen designing larger systems, it may be useful to be able to i dentify entities larger\nthan a single class. Such can be done in a component diagram . In software architecture\ndescriptions, for instance, the component diagram is a good way to depict a module\nview of a system (see section 11.3).\nIn essence, a component diagram is a class diagram with the st ereotype\n/AS component/AT . In UML 1, the component diagram had a special form. In UML 2,\nthis form is often depicted as a small component icon inside t he component, as is done\nin ﬁgure 10.17. Other than this icon, the component diagram d oes not introduce any\nnew notation.\nFinancialData\nClientData\n<<component>>\nPublication\nSearching\nStorage\nEmployee\nClient\nFigure 10.17 UML component diagram\nComponents contain classes, or other components. In ﬁgure 1 0.17 we have\nmodeled Publication as a component containing two classes, called Searching and\nStorage. Components are connected by interfaces. Figure 10.12 uses the so-called\nball-and-socket notation to depict interfaces. Both this n otation and the one used in\nﬁgure 10.17 are allowed in both class diagrams and component diagrams.\n10.3. THE UNIFIED MODELING LANGUAGE 275\n10.3.6 The Use Case\nOne possible requirements elicitation technique is scenar io-based analysis; see also\nchapter 9. A scenario is a story which tells how a speciﬁc task instance is executed.\nOften, different scenarios are variations on the same theme . For instance,", "token_count": 512, "start_token": 161700, "end_token": 162212, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 351, "text": " technique is scenar io-based analysis; see also\nchapter 9. A scenario is a story which tells how a speciﬁc task instance is executed.\nOften, different scenarios are variations on the same theme . For instance, one scenario\nmay describe the ordinary borrowing of a book, another one ma y describe borrowing\na book when there are still outstanding ﬁnes, and so on. A set o f scenarios having the\nsame user goal, in this case borrowing, is called a use case .\nA use case can be documented in various ways: as narrative tex t, formally using\npre- and postconditions, for example, or graphically as in a state transition diagram.\nThe use case diagram provides an overview of a set of use cases. Each use case is\nshown as an ellipse with the name of the use case. The use cases are enclosed by a\nrectangle denoting the system boundary. An actor that initi ates or participates in a\nscenario is shown as a stick ﬁgure with the name of the actor be low. Figure 10.18\nshows part of the use case diagram for our library system. Bor rowing a book involves\ntwo actors: a client and an employee of the library. Many othe r use cases will involve\nthose two actors as well. The ordering of a new book needs appr oval of a supervisor,\nas does the remittance of a ﬁne.\nFigure 10.18 UML use case diagram\n276 MODELING\n10.4 Summary\nDuring requirements engineering and design, a variety of mo deling notations are\nbeing applied. Most of these use some sort of box-and-line di agram. The mainstream\nmodeling notations of today stem from UML --- the Uniﬁed Mode ling Language.\nMany UML diagrams in turn are based on or derived from earlier types of diagram. In\nthis chapter, we discuss a selection of classic modeling not ations as well as the major\nUML diagram types.\nThe classic modeling notations discussed are:\n/AF Entity-Relationship Modeling (ERM), used to model the stru cture of data.\n/AF Finite State Machines (FSM), to model states and state trans itions of a system.\n/AF Data Flow Diagrams (DFD) to model functional decomposition with respect\nto data.\n/", "token_count": 512, "start_token": 162162, "end_token": 162674, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 352, "text": " data.\n/AF Finite State Machines (FSM), to model states and state trans itions of a system.\n/AF Data Flow Diagrams (DFD) to model functional decomposition with respect\nto data.\n/AF CRC Cards, a simple notation to document collaborative desi gn decisions.\nUML evolved from earlier object-oriented analysis and desi gn methods. Concepts\nused in UML, such as object, attribute, class, relationship , originate in the ﬁeld of\nobject orientation. UML 2 offers 13 diagram types. These fal l into two classes. Some\ndiagrams give a static view of the system. For instance, a cla ss diagram shows how a\nsystem is statically organized into classes. Other diagram s give a dynamic view. For\ninstance, a sequence diagram shows the time ordering of mess age exchanges between\ninstance of classes.\n10.5 Further Reading\nEntity--relationship modeling was pioneered by Chen (Chen , 1976). Many texts on\ndatabase modeling include an elaborate discussion of ERM; s ee for example (Batini\net al., 1992). Statecharts are described in (Harel, 1988). C RC cards are described\nin (Beck and Cunningham, 1989).\nThe different views of the notion of object are discussed in ( Taivalsaari, 1993).\nThe various meanings of attribute and related notions such a s aggregate, part and\nmember are discussed in (Motschnig-Pitrik, 1996). (Wegner , 1992) is a classic paper\non the various dimensions of object-oriented modeling.\nFowler (2004) provides a good introduction to UML. UML is ext ensively discussed\nin two books by its creators: (Booch et al., 1999) and (Rumbau gh et al., 1999).\nExercises\n1. Explain the following concepts from entity--relationsh ip modeling: entity,\nentity type, attribute value, attribute, relationship.\n10.5. FURTHER READING 277\n2. Deﬁne the following terms: object, state, attribute, mes sage, and inheritance.\n3. Explain the difference between the specialization--gen eralization relation and\nthe whole--part relation.\n4. Explain the difference between a class diagram and a state machine diagram.\n5. Explain the difference between a sequence diagram and a co mmunication\ndiagram.\n", "token_count": 512, "start_token": 162624, "end_token": 163136, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 353, "text": "gen eralization relation and\nthe whole--part relation.\n4. Explain the difference between a class diagram and a state machine diagram.\n5. Explain the difference between a sequence diagram and a co mmunication\ndiagram.\n6. Explain the difference between a class diagram and a compo nent diagram.\n7. What are CRC cards and use-case scenarios used for in objec t-oriented\nanalysis and design?\n8. In what respects does a UML state diagram differ from a stat e transition\ndiagram?\n9. /DI In what sense can the interface to a class be considered a cont ract? What\nare the repercussions of this for subtyping relations? (See (Meyer, 1992)).\n11\nSoftware Architecture\nLEARNING OBJECTIVES\n/AF To appreciate the role of software architecture in software development\n/AF To understand the relation between software architecture a nd design decisions\n/AF To be able to document a software architecture in different v iews\n/AF To be able to characterize some important software architec tural styles\n/AF To understand the role and purpose of software architecture assessments\n279\nSoftware architecture concerns the large-scale structure of software systems.\nThis large-scale structure reﬂects the early, essential de sign decisions. This\ndecision process involves negotiating and balancing of fun ctional and quality\nrequirements on one hand, and possible solutions on the othe r hand. Software\narchitecture is not a phase strictly following requirement s engineering, but\nthe two are intertwined. In this chapter, we discuss how to de sign, document\nand evaluate software architectures.\nA good design is the key to a successful product. Almost 2000 y ears ago, the\nRoman architect Vitruvius recorded what makes a design good : durability ( ﬁrmitas ),\nutility ( utilitas), and charm ( venustas). These quality requirements still hold, for\nbuildings as well as software systems. A well-designed syst em is easy to implement, is\nunderstandable and reliable, and allows for smooth evoluti on. Badly-designed systems\nmay work at ﬁrst, but they are hard to maintain, difﬁcult to te st, and unreliable.\nDuring the design phase, the system is decomposed into a numb er of interacting\ncomponents. The top", "token_count": 512, "start_token": 163086, "end_token": 163598, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 354, "text": " at ﬁrst, but they are hard to maintain, difﬁcult to te st, and unreliable.\nDuring the design phase, the system is decomposed into a numb er of interacting\ncomponents. The top-level decomposition of a system into ma jor components\ntogether with a characterization of how these components in teract, is called its\nsoftware architecture . Viewed this way, software architecture is synonymous with\nglobal design. There is, however, more to software architec ture than mere global\ndesign.\nSoftware architecture serves three main purposes:\n/AF It is a vehicle for communication among stakeholders. A soft ware architecture\nis a global, often graphic, description that can be communic ated with the\ncustomers, end users, designers, and so on. By developing sc enarios of antici-\npated use, relevant quality aspects can be analyzed and disc ussed with various\nstakeholders. The software architecture also supports com munication during\ndevelopment. It can be used to develop a skeletal version of the system. This\nskeletal version contains all of the architecture’s compon ents in a rudimentary\nform. The skeletal system can be used as an environment for th e incremental\nimplementation of the system. It can also be used as an enviro nment (test\nharness) for testing the system.\n/AF It captures early design decisions. In a software architect ure, the global\nstructure of the system has been decided upon, through the ex plicit assignment\nof functionality to components of the architecture. These e arly design decisions\nare important since their ramiﬁcations are felt in all subse quent phases. It is\ntherefore paramount to assess their quality at the earliest possible moment.\nBy evaluating the architecture, a ﬁrst and global insight in to important quality\naspects can be obtained. The global structure decided upon a t this stage also\nstructures development: the work-breakdown structure may be based on the\ndecomposition chosen at this stage, testing may be organize d around this same\ndecomposition, and so on.\n280 SOFTWARE ARCHITECTURE\n/AF It is a transferable abstraction of a system. The architectu re is a basis for\nreuse. Design decisions are often ordered, from essential t o nice features. The\nessential decisions are captured in the", "token_count": 512, "start_token": 163548, "end_token": 164060, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 355, "text": "CHITECTURE\n/AF It is a transferable abstraction of a system. The architectu re is a basis for\nreuse. Design decisions are often ordered, from essential t o nice features. The\nessential decisions are captured in the architecture, whil e the nice features can\nbe decided upon at a later stage. The software architecture t hus provides a basis\nfor a family of similar systems, a so-called product line ; see also chapter ??.\nThe global description captured in the architecture may als o serve as a basis\nfor training, e.g. to introduce new team members.\nThe traditional view holds that the requirements fully dete rmine the structure of a\nsystem. Traditional design methods as discussed in chapter 12 work that way. Their\naim is to systematically bridge the gap between the requirem ents and some blueprint\nof an operational system in which all of the requirements are met. It is increasingly\nbeing recognized that other forces inﬂuence the architectu re (and, for that matter,\nthe design) as well:\n/AF Architecture is inﬂuenced by the development organization . In our library\nexample, for example, the hardware and software for reading bar codes\nmight be subcontracted to some organization having special expertise in that\narea. There will then be one or more system components with ex ternally-\ndictated functionality and interfaces to deal with this par t of the problem.\nIf an organization deploys one or more systems with a certain architecture,\n(maintenance) expertise will be structured according to th e decomposition\nchosen in that architecture and there will be a pressure to ha ve future systems\nfollow that same architecture.\n/AF Architecture is inﬂuenced by the background and expertise o f the architect.\nIf an architect has positive experience with, say, a layered architecture, he is\nlikely to use that same approach on his next project.\n/AF Architecture is inﬂuenced by its technical and organizatio nal environment.\nIn ﬁnancial applications, for instance, government rules m ay require a certain\ndivision of functionality between system components. In em bedded systems,\nthe functionality of hardware components may inﬂuence the f unctionality of\nand interaction between software components. Finally, the software engineering\ntechniques prevalent in the development organization will exert inﬂuence on\nthe", "token_count": 512, "start_token": 164010, "end_token": 164522, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 356, "text": "\nthe functionality of hardware components may inﬂuence the f unctionality of\nand interaction between software components. Finally, the software engineering\ntechniques prevalent in the development organization will exert inﬂuence on\nthe architecture.\nThis mutual inﬂuencing between an architecture and its envi ronment is a cyclical\nprocess, known as the Architecture Business Cycle (ABC) (Ba ss et al., 2003). For\nexample, an architecture yields certain units of work, corr esponding to the compo-\nnents distinguished in the architecture. If the same compon ents occur over and over\nagain, expertise will be organized according to the functio nality embedded in these\ncomponents. The development organization may then become e xpert in certain areas.\nThis expertise then becomes an asset which may affect the goa ls of the development\norganization. The organization may try to develop and marke t a series of similar\nproducts in which this expertise is exploited.\n281\nTraditional design is inward-looking: given a set of requir ements, how can we\nderive a system that meets those requirements. Software arc hitecture has an outward\nfocus as well: it takes into account how the system ﬁts into it s environment. Software\narchitecting includes negotiating and balancing of functi onal and quality requirements\non one hand, and possible solutions on the other hand. This is further elaborated\nin section 11.1. Balancing requirements also requires that the candidate software\narchitecture is assessed. This is a form of testing, discuss ed in section 11.5.\nOne of the early deﬁnitions of software architecture is (Sha w et al., 1995):\nThe architecture of a software system deﬁnes that system in t erms of\ncomputational components and interactions among those com ponents.\nA more recent deﬁnition is (Bass et al., 2003):\nThe software architecture of a program or computing system i s the\nstructure or structures of the system, which comprise softw are elements,\nthe externally visible properties of those elements, and th e relationships\namong them.\nThe latter deﬁnition reﬂects, among others, the insight tha t there may be more than\none structure that is of interest. In house construction, we also use", "token_count": 512, "start_token": 164472, "end_token": 164984, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 357, "text": " th e relationships\namong them.\nThe latter deﬁnition reﬂects, among others, the insight tha t there may be more than\none structure that is of interest. In house construction, we also use different drawings:\none for the electrical wiring, one for the water supply, etc. These drawings reﬂect\ndifferent structures which are all part of the same overall a rchitecture. We generally\nobserve the architecture through one of these more speciﬁc v iews. The same holds\nfor the software architecture. This is further elaborated i n section 11.3.\nIn the software architecture, the global structure of the sy stem has been decided\nupon. This global structure captures the early, major desig n decisions. Whether a\ndesign decision is major or not really can only be ascertaine d with hindsight, when\nwe try to change the system. Only then will it show which decis ions were really\nimportant. A priori, it is often not at all clear if and why one design decision is more\nimportant than another (Fowler, 2003). For instance, we may decide to separate the\nuser interface from the processing part and store data about books in a ﬂat ﬁle in our\nlibrary system. Both decisions could be important, but need not be. Separating the\nuser interface from the processing part is generally consid ered good design. If, at a\nlater stage, changes occur in either part, we will be glad to h ave made this decision. If\nno such changes occur, the decision was not all that importan t, after all. Deciding to\nuse ﬂat ﬁles to store data in our library system may turn out to have been important if\nour library grows and we are forced to switch to database stor age of data. But again,\nif no such change occurs, the decision wasn’t that important either.\nViewed this way, the architectural design process is about m aking the important\ndesign decisions. Next, these important design decisions n eed to be documented.\nBoth the process of making architectural decisions and thei r documentation for later\nuse are discussed in section 11.2.\nA very active ﬁeld of research these days is aimed at identify ing and describing\ncomponents at a higher level of abstraction, i.e.", "token_count": 512, "start_token": 164934, "end_token": 165446, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 358, "text": " thei r documentation for later\nuse are discussed in section 11.2.\nA very active ﬁeld of research these days is aimed at identify ing and describing\ncomponents at a higher level of abstraction, i.e. above the l evel of a module or\n282 SOFTWARE ARCHITECTURE\nabstract data type. These higher-level abstractions are kn own as design patterns and\nsoftware architectural styles (or architectural patterns ).\nPart of the work in software architecture is aimed at charact erizing and classifying\nthese software architectural styles, as well as developing appropriate notations and\nsupporting tools. The ultimate goal is that the resulting ab stractions become part of\nthe vocabulary of software engineers, much like abstract da ta types are already part\nof that vocabulary. Section 11.4 gives an overview of the maj or issues involved in\nsoftware architectural styles. Design patterns are furthe r discussed in Chapter 12.\nToday’s work in software architecture is broad in scope. Alm ost any topic in\nsoftware engineering is being rethought in architectural t erms. The discussion in\nthis chapter is focused on how to design, name, Document, and assess software\narchitectures.\n11.1 Software Architecture and the Software Life Cycle\nIf software architecture is just global design, we would be s elling old wine in new\nbottles. The design phase then is simply split into two subph ases: architectural, global\ndesign, and detailed design. The methods used in these two su bphases might be\ndifferent, but both essentially boil down to a decompositio n process, taking a set\nof requirements as their starting point. Both design phases then are inward-looking:\nstarting from a set of requirements, derive a system that mee ts those requirements.\nA ‘proper’ software architecture phase however has an outwa rd focus as well. It\nincludes negotiating and balancing of functional and quali ty requirements on one\nhand, and possible solutions on the other hand. This means re quirements engineering\nand software architecture are not subsequent phases that ar e more or less strictly\nseparated, but instead they are heavily intertwined. An ini tial set of functional and\nquality requirements is the starting point for developing a n initial architecture. This\ninitial architecture results in a number of issues that requ ire further discussion with\nstakeholders. For instance, the envisaged solution may be t oo", "token_count": 512, "start_token": 165396, "end_token": 165908, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 359, "text": " of functional and\nquality requirements is the starting point for developing a n initial architecture. This\ninitial architecture results in a number of issues that requ ire further discussion with\nstakeholders. For instance, the envisaged solution may be t oo costly, integration with\nalready existing systems may be complex, maintenance may be an issue because of a\nlack of staff with certain expertise, or performance requir ements cannot be met. These\ninsights lead to further discussions with stakeholders, a r evised set of requirements,\nand a revised architecture. This iterative process continu es until an agreement is\nreached. Only then will detailed design and implementation proceed. The difference\nbetween these two paradigms is illustrated in ﬁgure 11.1.\nWe thus see important differences between the traditional p rocess models without\nspeciﬁc attention to software architecture, and process mo dels which do pay attention\nto software architecture:\n/AF In traditional models, iteration only concerns functional requirements. Once\nthe functional requirements are agreed upon, design starts . In process models\nthat include a software architecture phase, iteration invo lves both functional\n11.2. ARCHITECTURE DESIGN 283\nagreement\nstakeholders\n(few) (many)\nstakeholders\nrequirements quality requirements quality\ndevelopment\narchitecture\nagreement\ndevelopment)\n(b)(a)\nFigure 11.1 Software life cycle without (a) and with (b) expl icit attention to software\narchitecture\nand quality requirements. Only when the combined set of func tional and\nquality requirements is agreed upon, will development proc eed.\n/AF Traditional models involve negotiation with a few stakehol ders only. Usually,\nonly the client and end users are involved. Negotiations abo ut architectural\nsolutions may involve a much larger variety of stakeholders , and include for\ninstance the future maintenance organization for the syste m to be developed,\nor owners of other systems that this system has to interact wi th.\n/AF In traditional models there is no balancing of functional an d quality require-\nments. Once the functional requirements are agreed upon, de velopment\nproceeds and it is assumed that quality requirements can be m et. If it turns\nout that the quality requirements cannot be met, the project gets into trouble.\nDeadlines slip, functionality is skipped, more hardware is bought", "token_count": 512, "start_token": 165858, "end_token": 166370, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 360, "text": "velopment\nproceeds and it is assumed that quality requirements can be m et. If it turns\nout that the quality requirements cannot be met, the project gets into trouble.\nDeadlines slip, functionality is skipped, more hardware is bought, etc. In pro-\ncess models that include a software architecture phase, the re is a balancing of\nfunctional and quality requirements at an early stage.\n11.2 Architecture design\nDesign is a problem-solving activity, and as such very much a matter of trial and\nerror. In the presentation of a mathematical proof, subsequ ent steps dovetail well into\neach other and everything drops into place at the end. The act ual discovery of the\n284 SOFTWARE ARCHITECTURE\nproof was probably quite different. The same holds for the de sign of software. We\nshould not confuse the outcome of the design process with the process itself. The\noutcome of the design process is a ‘rational reconstruction ’ of that process. (Note that\nwe made precisely the same remark with respect to the outcome of the requirements\nengineering process.)\nDuring design, the system is decomposed into parts that each have a lower\ncomplexity than the system as a whole, while the parts togeth er solve the user’s\nproblem. The design problem can now be formulated as follows : how to determine\nthis decomposition. There really is no universal method for this. The design process is\na creative one, and the quality and expertise of the designer s is a critical determinant\nfor its success. Yet, during the course of the years, a number of ideas and guidelines\nhave emerged which may serve us in designing software. These have resulted in a\nlarge number of design methods, which are the topic of chapte r 12.\nIn a similar vein, architectural design methods have been de veloped. A good\nexample hereof is Attribute Driven Design (ADD), described in (Bass et al., 2003).\nThe input to the ADD process are the requirements, formulate d as a set of prioritized\nquality attribute scenarios. A quality attribute scenario is a scenario as known\nfrom requirements engineering, but whose description expl icitly captures quality\ninformation; see also section 6.3.\nADD is described as a topdown decomposition process. In each iteration, one or\na few components are selected for further decomposition. In the ﬁrst iteration, there\nis", "token_count": 512, "start_token": 166320, "end_token": 166832, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 361, "text": "information; see also section 6.3.\nADD is described as a topdown decomposition process. In each iteration, one or\na few components are selected for further decomposition. In the ﬁrst iteration, there\nis only one component, ‘the system’. From the set of quality a ttribute scenarios, an\nimportant quality attribute is selected that will be handle d in the current reﬁnement\nstep. For instance, in our library system, we may have decide d on a ﬁrst decomposition\nof the system into three layers: a presentation layer, a busi ness logic layer, and a\ndata layer. In a next ADD step, we may decide to decompose the p resentation layer,\nand select usability as the quality attribute that drives th is decomposition. A pattern\nis then selected that satisﬁes the quality attribute. For in stance, a data validation\npattern (Folmer et al., 2003) may be applied to verify whethe r data items have been\nentered correctly. Finally, the set of quality attribute sc enarios is veriﬁed and reﬁned,\nto prepare for the next iteration.\nADD gives little guidance for the precise order and kind of re ﬁnement steps. This\nis very much a matter of the architect’s expertise. The same r ather global support is\ngiven by other architecture design methods, as discussed by Hofmeister et al. (2007).\nThe global workﬂow common to these methods is depicted in ﬁgu re 11.2. At the\ncentre, the backlog is depicted. The backlog contains a list of issues to be tackl ed,\nopen problems, ideas that still have to be investigated, and so on. The name derives\nfrom Scrum, an agile method (Schwaber and Beedle, 2002). The re, the backlog drives\nthe project. In (architecture) design projects, the notion of a backlog is usually not\nrepresented explicitly. Yet, it is always there, if only in t he head of the architect.\nThere are three inputs to the backlog: context, requirement s, and evaluation results.\nThe context refers to such things as upfront ideas the archit ect may have, available\nassets that can be used, constraints set, and the like. Obvio us", "token_count": 512, "start_token": 166782, "end_token": 167294, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 362, "text": " inputs to the backlog: context, requirement s, and evaluation results.\nThe context refers to such things as upfront ideas the archit ect may have, available\nassets that can be used, constraints set, and the like. Obvio usly, the requirements\n11.2. ARCHITECTURE DESIGN 285\nconstitute another important input. In each step of the arch itecting process, one or a\nfew items from the backlog are taken and used to transform the architecture developed\nso far. The result of this transformation is evaluated (usua lly rather informally), and\nthis evaluation may in turn change the contents of the backlo g. New items may be\nadded (for instance new problems), items may disappear or be come obsolete, and the\npriorities of backlog items may change.\nevaluation\nsynthesis\ncontext\nbacklog\nresults\nevaluation\nrequirements\narchitecture\nFigure 11.2 Global workﬂow in architecture design\nFigures 11.1(b) and 11.2 describe the same iterative proces s. Whereas the former\nemphasizes interactions with external parties, the latter emphasizes the architectural\ndesign process itself. The latter process model also is more ﬁnegrained. Many of the\niterations involving one or more items of the backlog, a synt hesis step, evaluation of\nthe result and updating the backlog will be done by the archit ect and not involve\ncommunication with other stakeholders. But once in a while, communication with\nother stakeholders takes place, and this is the level at whic h ﬁgure 11.1(b) applies.\nThe architecture design process is very much driven by the ar chitect’s experience,\nmuch more so than by any of the so-called architecture design methods. An\nexperienced architect knows how to handle a given issue, rather than that some\nmethod tells him how to perform a design iteration. This is al so true for the design\nmethods discussed in chapter 12, that are applied at the more detailed levels of design.\nTheir descriptions usually give much more guidance than tho se for architecture\ndesign methods. But this guidance is used by inexperienced d esigners mostly. Since\narchitecture design is usually done by experienced designe rs, the amount of guidance\ngiven, and needed, is less. Attention then shifts to techniq ues for documenting the\nresult of", "token_count": 512, "start_token": 167244, "end_token": 167756, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 363, "text": " by inexperienced d esigners mostly. Since\narchitecture design is usually done by experienced designe rs, the amount of guidance\ngiven, and needed, is less. Attention then shifts to techniq ues for documenting the\nresult of the design process: the decisions, their rationale, and t he resulting design.\n286 SOFTWARE ARCHITECTURE\n11.2.1 Architecture as a set of design decisions\nIf architecture is the set of design decisions, then documen ting the architecture boils\ndown to documenting the set of design decisions. This is usua lly not done, though.\nWe can usually get at the result of the design decisions, the solutions chosen, but not\nat the reasoning behind them. Much of the rationale behind the solutions is usually\nlost forever, or resides only in the head of the few people ass ociated with them, if\nthey are still around.\nSo the reasoning behind a design decision is not explicitly c aptured. This is tacit\nknowledge, essential for the solution chosen, but not docum ented. At a later stage, it\nthen becomes difﬁcult to trace the reasons of certain design decisions. In particular,\nduring evolution one may stumble upon these design decision s, try to undo them\nor work around them, and get into trouble when this turns out t o be costly if not\nimpossible.\nThere are different types of undocumented design decisions :\n/AF The design decision is implicit: the architect is unaware of the decision, or it\nconcerns ‘of course’ knowledge. Examples include earlier e xperience, implicit\ncompany policies to use certain approaches, standards, and the like.\n/AF The design decision is explicit but undocumented: the archi tect takes a decision\nfor a very speciﬁc reason (e.g. the decision to use a certain u ser-interface policy\nbecause of time constraints). The reasoning is not document ed, and thus is\nlikely to vaporize over time.\n/AF The design decision is explicit, and explicitly undocument ed: the reasoning is\nhidden. There may be tactical company reasons to do so, or the architect may\nhave personal reasons (e.g. to protext his position).\nIt is an illusion to want to document all design decisions. Th ere are far too many of\nthem, and not all of them are that important. And documenting design decisions takes", "token_count": 512, "start_token": 167706, "end_token": 168218, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 364, "text": " reasons (e.g. to protext his position).\nIt is an illusion to want to document all design decisions. Th ere are far too many of\nthem, and not all of them are that important. And documenting design decisions takes\ntime and effort from the architect, a very busy person. But we may try to document\nthe really important ones.\nA design decision addresses one or more issues that are relev ant for the problem\nat hand. There may be more than one way to resolve these issues , so that the decision\nis a choice from amongst a number of alternatives. The partic ular alternative selected\npreferably is chosen because it has some favorable characte ristics. That is, there is\na rationale for our particular choice. Finally, the particu lar choice made may have\nimplications for subsequent decision making. Figure 11.3 g ives a template for the type\nof information that is important to capture for each design d ecision.\nFigure 11.4 gives an example of a design decision for our libr ary application. It\nconcerns the choice for a 3-tier architecture, consisting o f a presentation layer, a\nbusiness logic layer, and a data management layer.\nDesign decisions are often related. A given design decision may constrain further\ndecisions, exclude or enable them, override them, be in conﬂ ict with them, and the\n11.3. ARCHITECTURAL VIEWS 287\nElement Description\nIssues Design issues being addressed by this decision\nDecision The decision taken\nStatus The status of the decision, e.g. pending, approved\nAssumptions The underlying assumptions about the environm ent\nin which the decision is taken\nAlternatives Alternatives considered for this decision\nRationale An explanation of why the decision was chosen\nImplications Implications of this decision, such as the nee d for\nfurther decisions or requirements\nNotes Any additional information one might want to\ncapture\nFigure 11.3 Elements of a design decision\nlike. These relationships between design decisions resemb le the kind of relationships\nthat may exist between requirements, as discussed in sectio n 9.1.3. And likewise, the\nnotations and tools used to capture this information are ver y similar as well. A simple\nway to structure design decisions hierarchically is in the f orm of a decision tree. An\nexample hereof is given in �", "token_count": 512, "start_token": 168168, "end_token": 168680, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 365, "text": " And likewise, the\nnotations and tools used to capture this information are ver y similar as well. A simple\nway to structure design decisions hierarchically is in the f orm of a decision tree. An\nexample hereof is given in ﬁgure 11.5.\n11.3 Architectural views\nA software architecture serves as a vehicle for communicati on among stakeholders.\nExample stakeholders are: end users of the anticipated syst em, security experts,\nrepresentatives from the maintenance department, owners o f other systems that\nthis system has to interface with, software developers, and of course the architect\nhimself. These stakeholders all have a stake, but the stakes may differ. End users\nwill be interested to see that the system will provide them wi th the functionality\nasked for. Software developers will be interested to know wh ere to implement\nthis functionality. Maintainers want to assure themselves that components are as\nindependent as possible.\nIn some cases, it may be possible to devise one single archite cture representation\nthat serves all these stakeholders. In general, this will no t work, though. A speciﬁc\nstakeholder is best served by a representation of the softwa re architecture that\nhighlights his concerns. Another stakeholder is likely to b e better served by another\nrepresentation. Just think of civil engineering, where one representation may highlight\nthe outer appearance, while another highlights constructi on aspects.\n288 SOFTWARE ARCHITECTURE\nElement Description\nIssues The system has to be structured such that it is\nmaintainable, reusable, and robust.\nDecision A 3-tier architecture, consisting of a presentati on\nlayer, a business logic layer, and a data management\nlayer.\nStatus Approved.\nAssumptions The system has no hard real-time requirements\nAlternatives Alternatives are a Service-Oriented Archite cture\n(SOA), or a different type of X-tier architecture (e.g.\none with a fat client including both presentation\nand business logic, and a data management tier).\nRationale Maintenance is supported and extensions are easy\nto realize because of the loose coupling between\nlayers. Both the presentation layer and the data\nmanagement layer can be reused as is in other\napplications. Robustness is supported because the\ndifferent layers can easily be split over different\nmedia, and well", "token_count": 512, "start_token": 168630, "end_token": 169142, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 366, "text": " loose coupling between\nlayers. Both the presentation layer and the data\nmanagement layer can be reused as is in other\napplications. Robustness is supported because the\ndifferent layers can easily be split over different\nmedia, and well-deﬁned layer interfaces allow for\nsmoother testing.\nImplications Performance is hampered since all layers have to be\ngone through for most user actions.\nNotes None.\nFigure 11.4 Elements of a design decision\nIEEE standard 1471 (IEEE, 2000) gives a general structure fo r software architecture\nrepresentations. The main elements from this standard are:\n/AF Stakeholder: an individual, team, or organization (or classes hereof) w ith\ninterests in, or concerns relative to, a system.\n/AF View: a representation of a whole system from the perspective of a related set\nof concerns.\n/AF Viewpoint: A viewpoint establishes the purposes and audience for a vie w and\nthe techniques or methods employed in constructing a view.\nSo the stakeholder concerns determine which representatio ns, called views, are\nappropriate for a speciﬁc software architecture. Each view has a corresponding\n11.3. ARCHITECTURAL VIEWS 289\nMVC\nobserver\nX-tier\nSOA\n3-tier\nsystem structure\nFigure 11.5 Tree of design decisions\nviewpoint which gives the ‘syntax’ of the view, much like a co nstruction drawing has\nan accompanying description telling what all the glyphs in t he drawing mean.\nIEEE 1471 does not tell you which viewpoints to use. In essence, it suggests we\ndevelop an appropriate set of viewpoints for each separate s oftware architecture.\nIt does have the notion of a library viewpoint, though, a view point that might\nbe useful across different software architectures. Bass et al. (2003) give a collection\nof viewpoints that is useful across a wide variety of softwar e architectures. These\nviewpoints fall into three classes:\n/AF Module viewpoints give a static view of the system. They are usually depicted in\nthe form of box and line diagrams where the boxes denote syste m components\nand the lines denote some relation between those components . Figure 11.6\ndescribes typical module viewpoints.\n/AF Component and connector viewpoints give a dynamic view of the system, i.e.\nthey describe the system", "token_count": 512, "start_token": 169092, "end_token": 169604, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 367, "text": " syste m components\nand the lines denote some relation between those components . Figure 11.6\ndescribes typical module viewpoints.\n/AF Component and connector viewpoints give a dynamic view of the system, i.e.\nthey describe the system in execution. Again, they are usual ly depicted as\nbox and line diagrams. Figure 11.7 describes typical compon ent and connector\nviewpoints.\n/AF Allocation viewpoints give a relation the system and its environment, such as\nwho is responsible for which part of the system. Fig 11.8 give s typical allocation\nviewpoints.\n290 SOFTWARE ARCHITECTURE\nDecomposition. In a decomposition viewpoint, elements are related by the ‘ is\na submodule of’ relation. Larger elements are composed of sm aller ones. It is\nthe result of a topdown reﬁnement process. The decompositio n viewpoint often\nforms the basis for the project organization and the system’ s documentation.\nUses. In a uses viewpoint, the relation between elements is ‘uses ’ ( A calls B,\nA passes information to B, etc). The uses relation goes back t o Parnas (1972);\nsee also chapter 12. It is important when we want to assess mod iﬁability: if an\nelement is changed, all elements it is used by potentially ha ve to be changed as\nwell. It is also useful to determine incremental subsets of a system: if an element\nis in a given subset, all elements it uses must also be in that s ubset.\nLayered. The layered viewpoint is a special case of the uses viewpoin t. It is useful\nif we want to view the system as a series of layers, where eleme nts from layer /D2\ncan only use elements from layers /BO /D2 . Layers can often be interpreted as virtual\nmachines.\nClass. The class viewpoint describes how certain elements are a ge neralization of\nother elements. The relation between elements is ‘inherits from’. It is obviously\nmost applicable for object-oriented systems.\nFigure 11.6 Module viewpoints\nOf course, you are not going to use all these viewpoints for a s ingle software\narchitecture. Usually, one from each category will sufﬁce. You may for instance\nchoose the decomposition,", "token_count": 512, "start_token": 169554, "end_token": 170066, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 368, "text": " viewpoints\nOf course, you are not going to use all these viewpoints for a s ingle software\narchitecture. Usually, one from each category will sufﬁce. You may for instance\nchoose the decomposition, deployment, and work assignment viewpoints. It is also\npossible to combine viewpoints. In ﬁgure 11.9 we have combin ed the decomposition\nviewpoint and the client-server viewpoint to create a view f or our library system. In\nspeciﬁc cases, additional architectural views may be helpf ul or needed. In systems\nfor which the user interface is of critical importance, a sep arate user-interface view\nmay be developed. In electronic commerce applications, a vi ew highlighting security\naspects may come in handy. And so on.\nMany organizations have developed their own set of library v iewpoints. A well-\nknown set of library viewpoints is known as the ‘4 + 1 model’ (K ruchten, 1995). It\nconsists of the following viewpoints:\n– a conceptual, or logical viewpoint , which describes the system in terms of\nmajor design elements and their interactions;\n– an implementation viewpoint , which gives a view of the system in terms of\nmodules or packages and layers;\n11.3. ARCHITECTURAL VIEWS 291\nProcess. The process viewpoint describes the system as a series of pr ocesses,\nconnected by communication or synchronization links. It is useful if we want to\nreason about the performance or the availability of the syst em.\nConcurrency To determine opportunities for parallelism, a sequence of c ompu-\ntations that can be allocated to a separate physical thread l ater in the design\nprocess is collected in a ‘logical thread’. It is used to mana ge issues related to\nconcurrent execution.\nShared data This viewpoint shows how persistent data is produced, store d and\nconsumed. It is particularly useful if the system centers ar ound the manipulation\nof large amounts of data. It can be used to assess qualities su ch as performance\nand data integrity.\nClient-server To describe a system that consists of cooperating clients an d servers.\nThe connectors are the protocols and messages that clients a nd servers exchange.\nThis viewpoint expresses separation of concerns and physic al distribution of\nprocessing elements.\nFigure 11.7 Component and connector viewpoints", "token_count": 512, "start_token": 170016, "end_token": 170528, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 369, "text": " that consists of cooperating clients an d servers.\nThe connectors are the protocols and messages that clients a nd servers exchange.\nThis viewpoint expresses separation of concerns and physic al distribution of\nprocessing elements.\nFigure 11.7 Component and connector viewpoints\nDeployment This viewpoint shows how software is assigned to hardware el e-\nments, and which communication paths are used. This viewpoi nt allows one to\nreason about, e.g., performance, security, and availabili ty.\nImplementation This viewpoint indicates how software is mapped onto ﬁle\nstructures. It is used in the management of development acti vities and for build\nprocesses.\nWork assignment Shows who is doing what. This viewpoint is used to determine\nwhich knowledge is needed where. For instance, one may decid e to assign\nfunctional commonality to a single team.\nFigure 11.8 Allocation viewpoints\n– a process viewpoint which describes the dynamic structure of the system\nin terms of tasks, processes, their communication, and the a llocation of\n292 SOFTWARE ARCHITECTURE\nServer\nClientClient\ndatabase\ndatamanager\nbusiness logic\npresentation layerpresentation layer\nFigure 11.9 A 3-tier architecture\nfunctionality to run-time elements. This view is only neede d if the system has\na signiﬁcant degree of concurrency;\n– a deployment viewpoint , which contains the allocation of tasks to physical\nnodes. This view is only needed if the system is distributed.\nThe ‘+ 1’ viewpoint is a set of important use cases. This set of use cases drives the\narchitectural design, and serves as glue to connect the othe r four viewpoints. The ‘4\n+ 1 model’ now is part of the RUP development methodology (Kru chten, 2003).\nThe above viewpoints are all technical in nature. Often, it i s also useful to\nconstruct one or more viewpoints which emphasize business c oncerns. Figure 11.10\ngives a business oriented view of our library system. It addr esses three aspects of the\narchitecture: communication, storage, and layers. For eac h, several alternatives are\ngiven, and for each alternative the risk, time to market and c ost are indicated. One\nalternative for each aspect is chosen. These alternatives a re connected by curved\nlines. In this way, a quick", "token_count": 512, "start_token": 170478, "end_token": 170990, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 370, "text": " h, several alternatives are\ngiven, and for each alternative the risk, time to market and c ost are indicated. One\nalternative for each aspect is chosen. These alternatives a re connected by curved\nlines. In this way, a quick overview is obtained. The view is e asy to grasp, especially\nso for non-technical stakeholders 1 .\n1 This business view was created by Cuno de Boer, Raymond Backu s, Yoeri op ’t Roodt and Reinier\nL’ab ´ ee, students in my 2005 Software Architecture course.\n11.4. ARCHITECTURAL STYLES 293\nrisk: ++\nrisk: o\ntime-to-market:++\ncost: +\nrisk: --\ncost: +\ntime-to-market: +\ncost:++\ntime-to-market: +\ncost: --\nrisk: -\ntime-to-market: -\ncost: -\nrisk: --\ntime-to-market: +\ncost: +\nrisk: ++\ntime-to-market: +\ncost: +\nCommunication\nLayers\nStoragerisk: ++\nClient/Server Standalone\nFile MySQL Oracle\nX-tier non-layered MVC\ntime-to-market: o\nrisk: ++\ntime-to-market: o\ncost: o\nFigure 11.10 A business view\n11.4 Architectural Styles\nOne interesting theory of problem-solving in the programmi ng domain states that\nprogrammers solve such problems using programming plans , program fragments that\ncorrespond to stereotypical actions, and rules that descri be programming conventions.\nFor example, to compute the sum of a series of numbers, a progr ammer uses the\n‘running total loop plan’. In this plan, some counter is init ialized to zero and\nincremented with the next value of a series in the body of a loo p. Experts tend to\nrecall program fragments that correspond to plan structure s before they recall other\nelements of the program. This nicely maps onto the idea that k nowledge is stored in\nhuman memory in meaningful units (chunks).\nAn expert programmer has at his disposal a much larger number of knowledge\nchunks than a novice programmer. This concerns both program ming knowledge and\nknowledge about the application domain. Both during the sea rch for a solution", "token_count": 512, "start_token": 170940, "end_token": 171452, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 371, "text": " units (chunks).\nAn expert programmer has at his disposal a much larger number of knowledge\nchunks than a novice programmer. This concerns both program ming knowledge and\nknowledge about the application domain. Both during the sea rch for a solution and\nduring program comprehension, the programmer tries to link up with knowledge\nalready present. As a corollary, part of our education as pro grammer or software\nengineer should consist of acquiring a set of useful knowled ge chunks.\nAt the level of algorithms and abstract data types, such a bod y of knowledge has\nbeen accumulated over the years, and has been codiﬁed in text books and libraries\nof reusable components. As a result, abstractions, such as QuickSort, embodied in\nprocedures and abstract data types, such as Stack and BinaryTree, have become part\nof our vocabulary and are routinely used in our daily work.\n294 SOFTWARE ARCHITECTURE\nThe concepts embodied in these abstractions are useful duri ng the design,\nimplementation and maintenance of software for the followi ng reasons:\n/AF They can be used in a variety of settings and can be given uniqu e names.\nThe names are used in communicating the concepts and serve as labels when\nretrieving and storing them in human memory. The label QuickSort rings the\nsame bell for all people working in our ﬁeld.\n/AF We have notations and mechanisms to support their use and reu se, such as\nprocedure calls and the module concept.\n/AF We have organized related concepts into (semantic) network s that can be\nsearched for an item that ﬁts the problem at hand. For example , we know the\ntime and space tradeoffs between QuickSort and BubbleSort, or between a\nstandard binary search tree and an AVL-tree, and we know the g rounds on\nwhich to make a choice.\nDesign patterns are collections of a few modules (or, in obje ct-oriented circles,\nclasses) which are often used in combination, and which toge ther provide a useful\nabstraction. A design pattern is a recurring solution to a st andard problem. The\nprototypical example of a pattern is the MVC (Model--View-- Controller) pattern\nknown from Smalltalk. We may view design patterns as micro-a rchitectures. Design\npatterns are", "token_count": 512, "start_token": 171402, "end_token": 171914, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 372, "text": " andard problem. The\nprototypical example of a pattern is the MVC (Model--View-- Controller) pattern\nknown from Smalltalk. We may view design patterns as micro-a rchitectures. Design\npatterns are further discussed in section 12.5.\nTwo further notions often used in this context are ( application) framework\nand idiom. An application framework is a semi-ﬁnished system which ne eds to be\ninstantiated to obtain a complete system. It describes the a rchitecture of a family\nof similar systems. It is thus tied to a particular applicati on domain. The best\nknown examples are frameworks for building user interfaces . An idiom is a low-level\npattern, speciﬁc to some programming language. For example , the Counted Pointer\nidiom (Buschmann et al., 1996, pp 353--358) can be used to han dle references to\nobjects created dynamically in C++. It keeps a reference cou nter which is incremented\nor decremented when references to an object are added or remo ved. Memory occupied\nby an object is freed if no references to that object remain, i .e. when the counter\nbecomes zero. Frameworks and idioms thus offer solutions th at are more concrete and\nlanguage-speciﬁc than the architectural styles and design patterns we will discuss.\nThe work in the area of software architecture and design patt erns has been strongly\ninﬂuenced by the ideas of the architect Christopher Alexand er, as formulated in his\nbooks The Timeless Way of Building and A Pattern Language . The term ‘pattern’ derives\nfrom Alexander’s work, and the format used to describe softw are architectural styles\nand design patterns is shaped after the format Alexander use d to describe his patterns,\nlike ‘alcove’, ‘ofﬁce connection’ or ‘public outdoor room’ . In software engineering, we\noften draw a parallel with other engineering disciplines, i n particular civil engineering.\nThis comparison is made to highlight both similarities, suc h as the virtues of a phased\napproach, and differences, such as the observation that sof tware is logical rather than\nphysical, which hampers the control of progress. The compar ison with the ﬁeld of\n11", "token_count": 512, "start_token": 171864, "end_token": 172376, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 373, "text": " virtues of a phased\napproach, and differences, such as the observation that sof tware is logical rather than\nphysical, which hampers the control of progress. The compar ison with the ﬁeld of\n11.4. ARCHITECTURAL STYLES 295\narchitecture is often made to illustrate the role of differe nt views, as expressed in the\ndifferent types of blueprint produced. Each of these bluepr ints emphasizes a particular\naspect.\nThe classical ﬁeld of architecture provides some further in teresting insights for\nsoftware architecture. These insights concern:\n– the notion of architectural style,\n– the relationship between style and engineering, and\n– the relationship between style and materials.\nArchitecture is a (formal) arrangement of architectural el ements. An architectural\nstyle abstracts from the speciﬁcs of an architecture. The de composition of our library\nsystem might for instance result in an architecture consist ing of one main program\nand four subroutines, sharing three data stores. If we abstr act from these speciﬁcs, we\nobtain its architectural style, in which we concentrate on t he types of its elements\nand their interconnections.\nViewed in this way, an architectural style describes a certa in codiﬁcation of\nelements and their arrangement. Conversely, an architectu ral style constrains both\nthe elements and their interrelationships. For example, th e Tudor style describes how\na certain type of house looks and also prescribes how its design should look. In a\nsimilar vein we may characterize a software architectural s tyle such as, say, the\npipes-and-ﬁlter style.\nDifferent engineering principles apply to different archi tectural styles. This often\ngoes hand in hand with the types of materials used. Cottage-s tyle houses and high-\nrise apartment-buildings differ in the materials used and t he engineering principles\napplied. A software design based on abstract data types (= ma terial) emphasizes\nseparation of concerns by encapsulating secrets (= enginee ring principle). A design\nbased on pipes and ﬁlters emphasizes bundling of functional ity in independent\nprocesses.\nWhen selecting a certain architectural style with its corre sponding engineering\nprinciples and materials,", "token_count": 512, "start_token": 172326, "end_token": 172838, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 374, "text": "e ring principle). A design\nbased on pipes and ﬁlters emphasizes bundling of functional ity in independent\nprocesses.\nWhen selecting a certain architectural style with its corre sponding engineering\nprinciples and materials, we are guided by the problem to be s olved as well as\nthe larger context in which the problem occurs. We cannot bui ld a skyscraper from\nwooden posts. Environmental regulations may prohibit us er ecting high-rise buildings\nin rural areas. And, the narrow frontages of many houses on th e Amsterdam canals\nare partly due to the fact that local taxes were based on the nu mber of street-facing\nwindows. Similar problem- and context-speciﬁc elements gu ide us in the selection of\na software architectural style.\nThese similarities between classical architecture and sof tware architecture provide\nus with clues as to what constitutes a software architectura l style and what its\ndescription should look like.\nIn his book A Pattern Language , the architect Christopher Alexander presents\n253 ‘patterns’, ranging in scale from how a city should look d own to rules for the\n296 SOFTWARE ARCHITECTURE\nconstruction of a porch. Perhaps his most famous pattern is a bout the height of\nbuildings:\n‘There is abundant evidence to show that high buildings make people\ncrazy.\n. . .\nHigh buildings have no genuine advantage, except in specula tive gains\nto banks and land owners. They are not cheaper, they do not hel p create\nopen space, they make life difﬁcult for children, they are ex pensive to\nmaintain, they wreck the open spaces near them, and they dama ge the\nlight and air and view. But quite apart from this, empirical e vidence\nshows that they can actually damage people’s minds and feeli ngs.\n. . .\nIn any urban area, no matter how dense, keep the majority of bu ildings\nfour stories high or less. It is possible that certain buildi ngs should exceed\nthis limit, but they should never be buildings for human habi tation.’\nAn Alexandrian pattern is not a cookbook, black-box recipe f or architects, any more\nthan a dictionary is a toolkit for a novelist. Rather, a patte rn is a ﬂexible generic\n", "token_count": 512, "start_token": 172788, "end_token": 173300, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 375, "text": "�\nAn Alexandrian pattern is not a cookbook, black-box recipe f or architects, any more\nthan a dictionary is a toolkit for a novelist. Rather, a patte rn is a ﬂexible generic\nscheme providing a solution to a problem in a given context. I n a narrative form, its\napplication looks like this:\nIF you ﬁnd yourself in\n/BO context/BQ , for example /BO examples/BQ , with\n/BO problem/BQ ,\nTHEN for some /BO reasons/BQ , apply /BO pattern/BQ to construct a solution\nleading to a /BO new context /BQ and /BO other patterns /BQ .\nThe above ‘Four-Story Limit’ pattern may for example be appl ied in a context where\none has to design a suburb. The citation gives some of the reas ons for applying this\npattern. If it is followed, it will give rise to the applicati on of other patterns, such\nas those for planning parking lots, the layout of roads, or th e design of individual\nhouses.2\nShaw (1996) characterizes a number of well-known software a rchitectural styles\nin a framework that resembles a popular way of describing des ign patterns. Both the\ncharacterization and the framework are shaped after Alexan der’s way of describing\n2 Here, we may note another similarity between classical arch itecture and software architecture. In the\n1950s and 1960s, housing was a major problem in Western Europ e and beyond. There were far too few\nhouses available, while those available were mostly of a bad quality (damp, no bathroom, too small). In\nthe post-war economic boom, many suburbs were constructed, with lots of spacious apartments, each one\na container made of steel and concrete. These new suburbs sol ved one problem -- the housing of a large\nnumber of people -- but at the same time created other problem s which only showed themselves much later,\ne.g. lack of community feeling and social ties, high crime ra tes. As a result, massive renovation projects\nhave started and many a high-rise apartment building has bee n demolished. In software development, we\ndeveloped company-wide systems in the 1970s and 1980s, with an emphasis on performance, uniformity,\nand standardized ways of working. Many", "token_count": 512, "start_token": 173250, "end_token": 173762, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 376, "text": " started and many a high-rise apartment building has bee n demolished. In software development, we\ndeveloped company-wide systems in the 1970s and 1980s, with an emphasis on performance, uniformity,\nand standardized ways of working. Many of these systems are u nable to cope satisfactorily with today’s\nrequirements of ﬂexibility and adaptability, and are there fore being renovated.\n11.4. ARCHITECTURAL STYLES 297\nType Description\ncomputational The component performs a computation of some sort.\nUsually, the input and output to the component are fairly\nsimple, e.g. procedure parameters. The component may\nhave a local state, but this state disappears after the com-\nponent has done its job. Example components of this type\nare (mathematical) functions and ﬁlters.\nmemory A memory component maintains a collection of persist ent,\nstructured data, to be shared by a number of other compo-\nnents. Examples are a database, a ﬁle system, or a symbol\ntable.\nmanager A manager component contains a state and a number of\nassociated operations. When invoked, these operations use\nor update the state, and this state is retained between suc-\ncessive invocations of the manager’s operations. Abstract\ndata types and servers are example components of this\ntype.\ncontroller A controller governs the time sequence of other e vents. A\ntop-level control module and a scheduler are examples\nhereof.\nFigure 11.11 Some component types ( Source: M. Shaw & D. Garlan , Software Architec-\nture: Perspectives on an Emerging Discipline, page 149, 1996, Reprinted by permission of\nPrentice-Hall)\npatterns. We will use this framework to describe a number of w ell-known and classic\narchitectural styles. The framework has the following entr ies:\n/AF Problem A description of the type of problem this style addresses. Ce rtain\ncharacteristics of the requirements will guide the designe r in his choice of a\nparticular style. For example, if the problem consists of a s eries of independent\ntransformations, a pipes-and-ﬁlter type of architecture s uggests itself.\n/AF Context A designer will be constrained in the use of a style by certain\ncharacter", "token_count": 512, "start_token": 173712, "end_token": 174224, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 377, "text": " consists of a s eries of independent\ntransformations, a pipes-and-ﬁlter type of architecture s uggests itself.\n/AF Context A designer will be constrained in the use of a style by certain\ncharacteristics of the environment. Or, to put it the other w ay round, a style\nimposes certain requirements on the environment. For examp le, the pipes-and-\nﬁlter style usually relies on operating system support for d ata transfer between\nﬁlters.\n/AF Solution A description of the solution chosen. The major elements of a software\narchitecture are components and connectors. Components are the building\n298 SOFTWARE ARCHITECTURE\nblocks of a software architecture. They usually embody a com putational\nelement of some sort (like a procedure), but a component can a lso be a data\nstore (such as a database). The connectors describe how comp onents interact. 3\nSome typical types of component and connector are given in ﬁg ures 11.11 and\n11.12.\nThe order of execution of components is governed by the control structure .\nThe control structure captures how control is transferred d uring execution.\nThe choice of components and connectors is not independent. Usually, a\nstyle is characterized by a combination of certain types of c omponent and\nconnector, as well as a certain control structure. The system model captures\nthe intuition behind such a combination.\nIt describes the general ﬂavor of the system.\n/AF Variants Architectural styles give a rather general description. Of ten, certain\nvariants or specializations may be identiﬁed, which differ from the general\nstyle.\n/AF Examples One should include references to real examples of a style. Ar chi-\ntectural styles do not stem from theoretical investigation s, but result from\nidentifying and characterizing best practice.\nFigures 11.13--11.18 contain descriptions of six well-kno wn architectural styles:\nthe main program with subroutines, abstract data type, impl icit invocation, pipes and\nﬁlters, repository and layered styles.\nIn the main-program-with-subroutines architectural styl e, the main tasks of the\nsystem are allocated to different components which are call ed, in the appropriate\norder, from a control component. The decomposition", "token_count": 512, "start_token": 174174, "end_token": 174686, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 378, "text": " styles.\nIn the main-program-with-subroutines architectural styl e, the main tasks of the\nsystem are allocated to different components which are call ed, in the appropriate\norder, from a control component. The decomposition is stron gly geared towards an\nordering of the various actions to be performed with respect to time. The top-level\ncomponent controls this ordering.\nComponents in the main-program-with-subroutines type of d ecomposition often\nuse shared data storage. Decisions abaout data representat ions then are in fact a\nmutual property of the components that use those data. We may also try to make\nthose decisions locally rather than globally. In that case t he user does not get direct\naccess to the data structures, but is offered an interface. T he data can only be accessed\nthrough appropriate procedure or method calls. This is the e ssence of the abstract\ndata type architectural style.\nA major advantage of abstract data types over shared data is t hat changes in\ndata representation and algorithms can be accomplished rel atively easily. Changes\nin functionality, however, may be much harder to realize. Th is is because method\ninvocations are explicit, hard-coded in the implementatio n. An alternative is to use\nthe implicit invocation style. In implicit invocation, a co mponent is not invoked\n3 These notions of component and connector are not related to t he ‘component-and-connector’\nviewpoints discussed in section 11.3.\n11.4. ARCHITECTURAL STYLES 299\nType Description\nprocedure call With this type of connector, there is a single thread of\ncontrol between the caller and the called component.\nControl is transferred to the component being called,\nand this component remains in control until its work\nhas ended. Only then is control transferred back to\nthe calling component. The traditional procedure call\nand the remote procedure call are examples of this\ntype of connector.\ndata ﬂow With a data ﬂow connector, processes interact throu gh\na stream of data, as in pipes. The components\nthemselves are independent. Once input data to a\ncomponent is available, it may continue its work.\nimplicit invocation With implicit invocation, a computati on is invoked\nwhen a certain event occurs, rather than by explicit\ninteraction (as in a procedure call). Components ra", "token_count": 512, "start_token": 174636, "end_token": 175148, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 379, "text": " to a\ncomponent is available, it may continue its work.\nimplicit invocation With implicit invocation, a computati on is invoked\nwhen a certain event occurs, rather than by explicit\ninteraction (as in a procedure call). Components rais-\ning events do not know which component is going\nto react and invoked components do not know which\ncomponent raised the event to which they are reacting.\nmessage passing Message passing occurs when we have indepen dent\nprocesses that interact through explicit, discrete trans-\nfer of data, as in TCP/IP. Message passing can be\nsynchronous (in which case the sending/receiving pro-\ncess is blocked until the message has been completely\nsent/received) or asynchronous (in which case the\nprocesses continue their work independently).\nshared data When using shared data connectors, components\noperate concurrently on the same data space, as in\nblackboard systems or multiuser databases. Usually,\nsome blocking scheme prevents concurrent writes to\nthe same data.\ninstantiation With instantiation, one component (the inst antia-\ntor) provides space for the state required by another\ncomponent (the instantiated), as in abstract data types.\nFigure 11.12 Some connector types ( Source: M. Shaw & D. Garlan , Software Architecture:\nPerspectives on an Emerging Discipline, page 149-150, 1996, Reprinted by permission of\nPrentice-Hall)\n300 SOFTWARE ARCHITECTURE\nStyle: Main program with subroutines\nProblem The system can be described as a hierarchy of procedure deﬁni tions. This\nstyle is a natural outcome of a functional decomposition of a system (see\nchapter 12). The top-level module acts as the main program. I ts main task is to\ninvoke the other modules in the right order. As a consequence , there is usually\na single thread of control.\nContext This style naturally ﬁts in with programming languages that allow for nested\ndeﬁnitions of procedures and modules.\nSolution\nSystem model Procedures and modules are deﬁned in a hierarchy. Higher-\nlevel modules call lower-level modules. The hierarchy may b e strict, in\nwhich case modules at level /D2 can only call modules at level /D2 /A0 /BD , or it\nmay be weak, in which case modules at level /D", "token_count": 512, "start_token": 175098, "end_token": 175610, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 380, "text": "level modules. The hierarchy may b e strict, in\nwhich case modules at level /D2 can only call modules at level /D2 /A0 /BD , or it\nmay be weak, in which case modules at level /D2 may call modules at level\n/D2 /A0 /CX , with /CX /AL /BD . Procedures are grouped into modules following such\ncriteria as coupling and cohesion (see chapter 12).\nComponents (Groups of) procedures, which may have their own local data,\nand global data which may be viewed as residing in the main pro gram.\nConnectors Procedure call and shared access to global data.\nControl structure There is a single, centralized thread of control; the main\nprogram pulls the strings.\nVariants This style is usually applied to systems running on one CPU. A bstractly,\nthe model is preserved in systems running on multiple CPUs an d using the\nRemote Procedure Call (RPC) mechanism to invoke processes.\nExamples (Parnas, 1972)\nFigure 11.13 Main-program-with-subroutines architectur al style ( Source: M. Shaw,\nSome Patterns for Software Architectures, in J.M. Vlissides et al. , Pattern Languages of Program\nDesign 2, Reproduced by permission of Addison-Wesley. )\nexplicitly. Instead, a so-called event is generated. Other components in the system\nmay express their interest in this event by associating a met hod with it; this method\nis automatically invoked each time the event is raised. Func tional changes can be\nrealized easily by changing the list of events components ar e interested in.\nSome applications consist of a series of components in which component /CX\nproduces output which is next read and processed by componen t /CX /B7 /BD , in the same\norder in which it is written by component /CX . In such cases, we need not explicitly\n11.4. ARCHITECTURAL STYLES 301\nStyle: Abstract data type\nProblem A central issue is to identify and protect related bodies of i nformation.\nThe style is especially suited for cases where the data repre sentation is likely\nto change during the lifetime of the system. When the design m atches\nthe structure of the data in the problem domain, the resultin g components\nencaps", "token_count": 512, "start_token": 175560, "end_token": 176072, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 381, "text": " style is especially suited for cases where the data repre sentation is likely\nto change during the lifetime of the system. When the design m atches\nthe structure of the data in the problem domain, the resultin g components\nencapsulate problem-domain entities and their operations .\nContext Many design methods, most notably the object-oriented ones , provide\nheuristics to identify real-world objects. These objects a re then encapsulated in\ncomponents of the system. Object-oriented programming lan guages provide\nthe class concept, which allows us to relate similar objects and reuse code\nthrough the inheritance mechanism.\nSolution\nSystem model Each component maintains its own local data. Components\nhide a secret, viz. the representation of their data.\nComponents The components of this style are managers, such as servers,\nobjects, and abstract data types.\nConnectors Operations are invoked through procedure calls (messages) .\nControl structure There is usually a single thread of control. Control is\ndecentralized, however; a component may invoke any compone nt whose\nservices it requires.\nVariants Methods or languages that are not object-oriented only allo w us to hide\ndata representations in modules. Object-oriented methods or languages differ as\nregards their facilities for relating similar objects (sin gle or multiple inheritance)\nand their binding of messages to operations (compile time or runtime); see also\nchapter 12.\nExamples (Parnas, 1972); Booch (1994) gives a number of worked-out ex amples.\nFigure 11.14 Abstract-data-type architectural style ( Source: M. Shaw, Some Patterns for\nSoftware Architectures, in J.M. Vlissides et al. , Pattern Languages of Program Design 2,\nReproduced by permission of Addison-Wesley. )\ncreate these intermediate data structures. Rather, we may u se the pipe-and-ﬁlter mode\nof operation that is well-known from UNIX and directly feed t he output of one\ntransformation into the next one. The components are called ﬁlters and the FIFO\nconnectors are called pipes. An important characteristic o f this scheme is that any\nstructure imposed on the data to be passed between adjacent ﬁ lters has to be explicitly\n302 SOFTWARE ARCHITECTURE\nStyle: Implicit invocation\nProblem We have a loosely-cou", "token_count": 512, "start_token": 176022, "end_token": 176534, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 382, "text": " f this scheme is that any\nstructure imposed on the data to be passed between adjacent ﬁ lters has to be explicitly\n302 SOFTWARE ARCHITECTURE\nStyle: Implicit invocation\nProblem We have a loosely-coupled collection of components, each of which carries\nout some task and may enable other operations. The major char acteristic of\nthis style is that it does not bind recipients of signals to th eir originators. It is\nespecially useful for applications that need to be able to be reconﬁgured, by\nchanging a service provider or by enabling and disabling ope rations.\nContext This style usually requires an event handler that registers components’\ninterests and notiﬁes others. Because of the intrinsically decentralized nature\nof systems designed this way, correctness arguments are dif ﬁcult. For the same\nreason, building a mental model of such systems during progr am comprehension\nis difﬁcult too.\nSolution\nSystem model Processes are independent and reactive. Processes are not\ninvoked explicitly, but implicitly through the raising of a n event.\nComponents Components are processes that signal events without knowin g\nwhich component is going to react to them. Conversely, proce sses react\nto events raised somewhere in the system.\nConnectors Components are connected through the automatic invocation of\nprocesses that have registered interest in certain events.\nControl structure Control is decentralized. Individual components are not\naware of the recipients of signals.\nVariants There are two major categories of systems exploiting implic it invocation.\nThe ﬁrst category comprises the so-called tool-integratio n frameworks as\nexempliﬁed by many software development support environme nts. They consist\nof a number of ‘toolies’ running as separate processes. Even ts are handled by\na separate dispatcher process which uses some underlying op erating system\nsupport such as UNIX sockets; see for example (Reiss, 1990). The second\ncategory consists of languages with specialized notations and support for\nimplicit invocation, such as the ‘when-updated’ features o f some object-oriented\nlanguages; see for example (Sutton et al., 1990).\nExamples (Garlan et al., 1992); (Reiss, 1990); (Sutton et al., 1990).\nFigure 11.15 Implicit", "token_count": 512, "start_token": 176484, "end_token": 176996, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 383, "text": " object-oriented\nlanguages; see for example (Sutton et al., 1990).\nExamples (Garlan et al., 1992); (Reiss, 1990); (Sutton et al., 1990).\nFigure 11.15 Implicit-invocation architectural style ( Source: M. Shaw, Some Patterns for\nSoftware Architectures, in J.M. Vlissides et al. , Pattern Languages of Program Design 2,\nReproduced by permission of Addison-Wesley. )\n11.4. ARCHITECTURAL STYLES 303\nStyle: Pipes and ﬁlters\nProblem A series of independent, sequential transformations on ord ered data. Usu-\nally, the transformations are incremental. Often, the stru cture of the datastreams\nis very simple: a sequence of ASCII characters. If the data ha s a rich structure,\nthis will imply quite some overhead for the parsing and unpar sing of the data.\nContext This style requires that the system can be decomposed into a s eries of\ncomputations, ﬁlters , that incrementally transform one or more input streams.\nIt usually relies on operating system operations to transfe r the data from one\nprocess to another ( pipes). Error handling is difﬁcult to deal with uniformly in a\ncollection of ﬁlters.\nSolution\nSystem model The resulting systems are characterized by continuous data ﬂow\nbetween components, where the components incrementally tr ansform\ndatastreams.\nComponents The components are ﬁlters that perform local processing; i. e.\nthey read part of their input data, transform the data, and pr oduce part of\ntheir output. They have little internal state.\nConnectors Datastreams (usually plain ASCII, as in UNIX).\nControl structure Data ﬂow between components. Each component usually\nhas its own thread of control.\nVariants Pure ﬁlters have little internal state and process their inp ut locally. In the\ndegenerate case they consume all of their input before produ cing any output.\nIn that case, the result boils down to a batch-processing typ e of system.\nExamples (Delisle and Garlan, 1990)\nFigure 11.16 Pipes-and-ﬁlters architectural style ( Source: M. Shaw", "token_count": 512, "start_token": 176946, "end_token": 177458, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 384, "text": ", the result boils down to a batch-processing typ e of system.\nExamples (Delisle and Garlan, 1990)\nFigure 11.16 Pipes-and-ﬁlters architectural style ( Source: M. Shaw, Some Patterns for\nSoftware Architectures, in J.M. Vlissides et al. , Pattern Languages of Program Design 2,\nReproduced by permission of Addison-Wesley. )\nencoded in the datastream that connects these ﬁlters. This e ncoding scheme involves\ndecisions which much be known to both ﬁlters. The data has to b e unparsed by one\nﬁlter while the next ﬁlter must parse its input in order to reb uild that structure. The\nAchilles’ heel of the pipes-and-ﬁlers scheme is error handl ing. If one ﬁlter detects\nan error, it is cumbersome to pass the resulting error messag e through intermediate\nﬁlters all the way to the ﬁnal output. Filters must also be abl e to resynchronize after\nan error has been detected and ﬁlters further downstream mus t be able to tolerate\n304 SOFTWARE ARCHITECTURE\nStyle: Repository\nProblem The central issue is managing and maintaining a richly-stru ctured body of\ninformation. The information must typically be manipulate d in many different\nways. The data is long-lived and its integrity is important.\nContext This style often requires considerable support, in the form of a runtime\nsystem augmented with a database. Data deﬁnitions may have t o be processed\nto generate support to maintain the correct structure of the data.\nSolution\nSystem model The major characteristic of this model is its centralized, r ichly\nstructured body of information. The computational element s acting upon\nthe repository are often independent.\nComponents There is one memory component and many computational\nprocesses.\nConnectors Computational units interact with the memory component by\ndirect access or procedure call.\nControl structure The control structure varies. In traditional database syst ems,\nfor example, control depends on the input to the database fun ctions.\nIn a modern compiler, control is ﬁxed: processes are sequent ial and\nincremental. In blackboard systems", "token_count": 512, "start_token": 177408, "end_token": 177920, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 385, "text": " syst ems,\nfor example, control depends on the input to the database fun ctions.\nIn a modern compiler, control is ﬁxed: processes are sequent ial and\nincremental. In blackboard systems, control depends on the state of the\ncomputation.\nVariants Traditional database systems are characterized by their tr ansaction-oriented\nnature. The computational processes are independent and tr iggered by\nincoming requests. Modern compilers, and software develop ment support\nenvironments, are systems that increment the information c ontained in the\nrepository. Blackboard systems have their origin in AI. The y have been used\nfor complex applications such as speech recognition, in whi ch different com-\nputational elements each solve part of the problem and updat e the information\non the blackboard.\nExamples (Barstow et al., 1984) for software development environmen ts; (Corkill,\n1997) for blackboard architectures.\nFigure 11.17 Repository architectural style ( Source: M. Shaw, Some Patterns for Software\nArchitectures, in J.M. Vlissides et al. , Pattern Languages of Program Design 2, Reproduced\nby permission of Addison-Wesley. )\n11.4. ARCHITECTURAL STYLES 305\nStyle: Layered\nProblem We can identify distinct classes of services that can be arra nged hierar-\nchically. The system can be depicted as a series of concentri c circles, where\nservices in one layer depend on (call) services from inner la yers. Quite often,\nsuch a system is split into three layers: one for basic servic es, one for general\nutilities, and one for application-speciﬁc utilities.\nContext Each class of service has to be assigned to a speciﬁc layer. It may occasionally\nbe difﬁcult to properly identify the function of a layer succ inctly and, as a\nconsequence, assign a given function to the most appropriat e layer. This holds\nthe more if we restrict visibility to just one layer.\nSolution\nSystem model The resulting system consists of a hierarchy of layers. Usua lly,\nvisibility of inner layers is restricted.\nComponents The components in each layer usually consist of collections of\nprocedures.\nConnectors Components generally interact through", "token_count": 512, "start_token": 177870, "end_token": 178382, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 386, "text": " The resulting system consists of a hierarchy of layers. Usua lly,\nvisibility of inner layers is restricted.\nComponents The components in each layer usually consist of collections of\nprocedures.\nConnectors Components generally interact through procedure calls. Be cause\nof the limited visibility, the interaction is limited.\nControl structure The system has a single thread of control.\nVariants A layer may be viewed as a virtual machine, offering a set of ‘i nstructions’ to\nthe next layer. Viewed thus, the peripheral layers get more a nd more abstract.\nLayering may also result from a wish to separate functionali ty, e.g. into a user-\ninterface layer and an application-logic layer. Variants o f the layered scheme\nmay differ as regards the visibility of components to outer l ayers. In the most\nconstrained case, visibility is limited to the next layer up .\nExamples (van der Linden and M ¨ uller, 1995), (Ho and Olsson, 1996), (B ohrer et al.,\n1998).\nFigure 11.18 Layered architectural style ( Source: M. Shaw, Some Patterns for Software\nArchitectures, in J.M. Vlissides et al. , Pattern Languages of Program Design 2, Reproduced\nby permission of Addison-Wesley. )\nincomplete input.\nThe repository style ﬁts situations where the main issue is t o manage a richly\nstructured body of information. In our library example in ch apter 9, the data concerns\nthings like the stock of available books and the collection o f members of the library.\nThese data are persistent and it is important that they alway s reﬂect the true state\n306 SOFTWARE ARCHITECTURE\nof affairs. A natural approach to this problem is to devise da tabase schemas for the\nvarious types of data in the application (books, journals, l ibrary clients, reservations,\nand so on) and store the data in one or more databases. The func tionality of the system\nis incorporated in a number of, relatively independent, com putational elements. The\nresult is a repository architectural style.\nModern compilers are often structured in a similar way. Such a compiler maintains\na central representation of the program to be translated. A r udimentary version of\nthat representation results from the �", "token_count": 512, "start_token": 178332, "end_token": 178844, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 387, "text": " The\nresult is a repository architectural style.\nModern compilers are often structured in a similar way. Such a compiler maintains\na central representation of the program to be translated. A r udimentary version of\nthat representation results from the ﬁrst, lexical, phase: a sequence of tokens rather\nthan a sequence of character glyphs. Subsequent phases, suc h as syntax and semantic\nanalysis, further enrich this structure into, for example, an abstract syntax tree. In\nthe end, code is generated from this representation. Other t ools, such as symbolic\ndebuggers, pretty-printing programs, or static analysis t ools, may also employ the\ninternal representation built by the compiler. The resulti ng architectural style again is\nthat of a repository: one memory component and a number of com putational elements\nthat act on that repository. Unlike the database variant, th e order of invocation of the\nelements matters in the case of a compiler. Also, different c omputational elements\nenrich the internal representation, rather than merely upd ate it.\nThe repository architectural style can also be found in cert ain AI applications. In\ncomputationally complex applications, such as speech reco gnition, an internal repre-\nsentation is built and acted upon by different computationa l elements. For example,\none computational element may ﬁlter noise, another one buil ds up phonemes, etc.\nThe internal representation in this type of system is called a blackboard and the\narchitecture is sometimes referred to as a blackboard archi tecture. A major difference\nwith traditional database systems is that the invocation of computational elements in\na blackboard architecture is triggered by the current state of the blackboard, rather\nthan by (external) inputs. Elements from a blackboard archi tecture enrich and reﬁne\nthe state representation until a solution to the problem is f ound.\nOur ﬁnal example of an architectural style is the layered arc hitectural style.\nA prototypical instance hereof is the ISO Open System Interc onnection Model\nfor network communication. It has seven layers: physical, d ata, network, transport,\nsession, presentation, and application. The bottom layer p rovides basic functionality.\nHigher layers use the functionality of lower layers. The dif ferent layers can be viewed\nas virtual", "token_count": 512, "start_token": 178794, "end_token": 179306, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 388, "text": " physical, d ata, network, transport,\nsession, presentation, and application. The bottom layer p rovides basic functionality.\nHigher layers use the functionality of lower layers. The dif ferent layers can be viewed\nas virtual machines whose ‘instructions’ become more power ful and abstract as we go\nfrom lower layers to higher layers.\nIn a layered scheme, by deﬁnition, lower levels cannot use th e functionality offered\nby higher levels. The other way round, the situation is more v aried. We may choose\nto allow layer /D2 to use the functionality of each layer /D1 , with /D1 /BO /D2 . We may also\nchoose to limit the visibility of functionality offered by e ach layer, and for example\nrestrict layer /D2 to use only the functionality offered by layer /D2 /A0 /BD . A design issue\nin each case is how to assign functionality to the different l ayers of the architecture,\ni.e. how to characterize the virtual machine it embodies. If visibility is not restricted,\nsome of the elegance of the layered architecture gets lost. T his situation resembles\nthat of programming languages containing low-level bit man ipulation operations\n11.4. ARCHITECTURAL STYLES 307\nalongside while statements and procedure calls. If visibility is restricte d, we may end\nup copying functionality to higher levels without increasi ng the level of abstraction.\nvan der Linden and M ¨ uller (1995) give an example of a layered architectural style\nfor use in telecommunications. In this example, layers do no t correspond to different\nlevels of abstraction. Rather, the functionality of the sys tem has been separated. Two\nmain guidelines drive the assignment of functionality to la yers in this architecture:\n– hardware-dependent functionality should be placed in low er-level layers than\napplication-dependent functionality.\n– generic functionality should be placed in lower layers tha n speciﬁc functionality.\nThe resulting architecture has four layers:\n/AF Operating system This layer comprises the runtime system, database, memory\nmanagement, and so on.\n/AF Equipment maintenance This layer houses the control for peripheral devices and\nits interconnection structure. It deals with such things as data distribution\nand fault-handling of peripheral hardware. The bottom two l ayers together\nconstitute the distributed operating", "token_count": 512, "start_token": 179256, "end_token": 179768, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 389, "text": "/AF Equipment maintenance This layer houses the control for peripheral devices and\nits interconnection structure. It deals with such things as data distribution\nand fault-handling of peripheral hardware. The bottom two l ayers together\nconstitute the distributed operating infrastructure upon which applications run.\n/AF Logical-resource management Logical resources come in two ﬂavors. The ﬁrst class\ncontains abstractions from hardware objects. The second cl ass consists of\nsoftware-related logical objects, such as those for call-f orwarding in telephony.\n/AF Service management This layer contains the application functionality.\nA similar line of thought can be followed in other domains. Fo r instance, it is hard to\npredict how future household electronic equipment will be a ssembled into hardware\nboxes. Will the PC and the television be in the same box? Will t he television and\nthe DVD player be combined or will they remain as separate box es? No one seems\nto know. Since the half-life of many of these products is abou t six months, industry\nis forced to use a building-block approach, emphasizing reu se and the development\nof product families rather than products. A division of func tionality into a hardware-\nrelated inner layer, a generic signal processing layer, and a user-oriented service layer\nsuggests itself. The above architecture for telecommunica tions applications can be\nunderstood along the same lines.\nIn practice, we will usually encounter a mixture of architec tural styles. For example,\nmany software development environments can be characteriz ed as a combination\nof the repository and layered architectural styles; see als o chapter 15. The core\nof the system is a repository in which the various objects, ra nging from program\ntexts to work-breakdown structures, reside. Access to thes e objects as well as basic\nmechanisms for the execution and communication of tools are contained in a layer on\ntop of this repository. The tools themselves are conﬁgured i n one or more layers on\ntop of these basic layers. Interaction between tools may yet follow another paradigm,\nsuch as implicit invocation.\n308 SOFTWARE ARCHITECTURE\n11.5 Software Architecture Assessment\nThe software architecture captures early design decisions . Since these early decisions\nhave a large impact, it is important to start testing even at t his early stage. Testing\nsoftware", "token_count": 512, "start_token": 179718, "end_token": 180230, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 390, "text": "\n308 SOFTWARE ARCHITECTURE\n11.5 Software Architecture Assessment\nThe software architecture captures early design decisions . Since these early decisions\nhave a large impact, it is important to start testing even at t his early stage. Testing\nsoftware architectures is commonly referred to as software architecture assessment . In a\nsoftware architecture assessment, the software architect ure is assessed with respect to\nquality attributes such as maintainability, ﬂexibility, a nd so on.\nIt is important to keep in mind that in this process the archit ecture is assessed,\nwhile one hopes the results will hold for a system yet to be bui lt. As a result,\nconclusions will often be at quite a general level. Also, the re is some uncertainty about\nwhether these results will actually be realized. Suppose th e architecture is assessed\nfor maintainability. Even if the outcome is quite positive, a sloppy implementation\nprocess may yet spoil the rosy picture. Figure 11.19 illustr ates this issue. Architecture\nassessment takes place at the left-hand side of the ﬁgure, wh ile one assumes the results\nwill be valid for the right-hand side. predicts\nbehavior\nsystem\nassessment\narchitecture\nimplementation\ntranslate into\nqualitiesproperties\nsystem\nimplemented\narchitecture\nsoftware\nFigure 11.19 The relation between a software architecture a ssessment and actual\nsystem behavior\nThere are two broad classes of techniques to evaluate a softw are architecture.\nThe ﬁrst class comprises measuring techniques, and rely on q uantitative information.\nExamples include architecture metrics and simulation. The second class comprises\nquestioning techniques, in which one investigates how the a rchitecture reacts to\n11.5. SOFTWARE ARCHITECTURE ASSESSMENT 309\ncertain situations. This is often done with the help of scena rios. In the sequel, we\nconcentrate on the latter.\nThere are different types of scenarios one may use in archite cture assessments.\nCommon types are:\n/AF Use cases : these often are already available, or can be derived from th e\nrequirements.\n/AF Change cases : change cases describe possible or likely future situation s. They\ndescribe ”what-if” like situations, like ”what if our libra ry has to be able to\nhandle dvd�", "token_count": 512, "start_token": 180180, "end_token": 180692, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 391, "text": "\n/AF Change cases : change cases describe possible or likely future situation s. They\ndescribe ”what-if” like situations, like ”what if our libra ry has to be able to\nhandle dvd’s next to books and journals”.\n/AF Stress situations : these describe extreme conditions under which the system\nstill has to operate, such as limits with respect to performa nce or the number\nof concurrent users of the system.\n/AF Far-into-the-future scenarios : these are like change cases, but farther away. For\ninstance, we may envision a future in which a library changes from a document\narchive to a memory archive. We may want to retain how an old-f ashioned\nbakery smells, or the sound of a San Francisco tram.\nOne of the best known architecture assessment methods is ATA M: the Architecture\nTradeoff Analysis Method. As the name says, an important goa l of ATAM is to\ndetermine how quality attributes interact. If we decide to i nclude an authorization\ncomponent to increase security, such is likely to degrade pe rformance. By making\nthe consequences of design decisions explicit, it becomes p ossible for stakeholders to\ntrade off the different possibilities, and make informed de cisions, with clear insight\ninto the consequences thereof.\n1. Present method to stakeholders\n2. Present business drivers (by project manager)\n3. Present architecture (by lead architect)\n4. Identify architectural approaches\n5. Generate quality attribute tree\n6. Analyze architectural approaches\n7. Brainstorm and prioritize scenarios\n8. Analyze architectural approaches\n9. Present results\nFigure 11.20 Steps of ATAM\nThe main steps of ATAM are listed in ﬁgure 11.20. There may be a preparatory\nphase in which participants meet to discuss the whole exerci se, and a follow-up phase\n310 SOFTWARE ARCHITECTURE\nat the end in which a written report is delivered. The ﬁrst ste ps are meant to make\nthe participants familiar with the major quality drivers fo r the system (step 2), the\nsolution chosen (step 3), and the approaches and patterns us ed in this solution (step\n4). In step 5, the quality requirements are articulated in mo re detail. The project˘s\ndecision makers are key in this process.", "token_count": 512, "start_token": 180642, "end_token": 181154, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 392, "text": "olution chosen (step 3), and the approaches and patterns us ed in this solution (step\n4). In step 5, the quality requirements are articulated in mo re detail. The project˘s\ndecision makers are key in this process. The end result of thi s exercise is a tree.\nThe root node is termed ”utility”. It expresses the overall q uality of the architecture.\nThe next level contains the quality attributes that will be e valuated. These are again\nbroken down into more detailed constituents. The leaf nodes are concrete scenarios.\nFigure 11.21 gives part of a possible utility tree for assess ing our library system.\nVendor releases new database version\n100 transactions/sec\nMaintainability\nNormal operations\nTraining\nResponse time\nThroughput\nPerformance\nUsabilityUtility\nFigure 11.21 An example utility tree\nThe leaf nodes in ﬁgure 11.21 are printed in italic. This desc ription is incomplete.\nThe full representation has to contain more information, fo r example the type of\ninformation contained in a quality attribute scenario (see section 6.3).\nA complete utility tree may contain more scenarios than can b e analyzed during\nthe assessment. It is then useful to prioritize scenarios. A TAM suggests two criteria\nfor doing so. Using the ﬁrst criterion, the stakeholders ind icate how important\nthe scenarios are (e.g. using a simple 3-point scale: High, M edium, Low). Using\nthe second criterion, the architect ranks the scenarios acc ording to how difﬁcult\nhe believes it will be to satisfy the scenario, using the same 3-point scale. In the\nremainder of the assessment, one may then for instance conce ntrate on the scenarios\nthat score High on both scales.\nIn step 6, the scenarios are discussed one at a time. For each s cenario, the architect\nwalks the stakeholders through the architecture, explaini ng how the architecture\nsupports that scenario. This may trigger a further discussi on of the architectural\napproaches chosen. The end result is a documented list of sen sitivity points, tradeoff\n11.6. SUMMARY 311\npoints, risks and nonrisks, relating the architectural dec isions made to the relevant\nquality attributes.\nA sensitivity point is a property of the architecture that is critical for a certa in", "token_count": 512, "start_token": 181104, "end_token": 181616, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 393, "text": "\n11.6. SUMMARY 311\npoints, risks and nonrisks, relating the architectural dec isions made to the relevant\nquality attributes.\nA sensitivity point is a property of the architecture that is critical for a certa in\nquality attribute. For example, the possibility to undo use r actions critically affects\nthe usability of our library system, and this property there fore is a sensitivity point\nwith respect to usability. At the same time, this decision al so is a sensitivity point\nwith respect to performance. If a decision is a sensitivity p oint for more than one\nquality attribute, it is called a tradeoff point . If performance is of utmost importance, the\ndecision to include an undo facility may be a risk. If this decision is not critical, it is a\nnonrisk.\nThe utility tree is based on the main drivers used during the d esign of the\narchitecture. Its construction is done in consultation wit h the main decision makers.\nThere are other stakeholders, such as a maintenance manager or security expert, that\ncan also be polled for additional scenarios. This is done in s tep 7. And similar to step\n5, these scenarios are prioritized, and a selection is made f or further study. Similar\nto step 6, these additional scenarios are analyzed in step 8. Finally, the collected\ninformation is summarized and presented to all stakeholder s in step 9.\nThe result of an architecture assessment goes way beyond a li st of sensitivity\npoints, tradeoff points, risks and nonrisks. Stakeholders , including the architect,\noften construct a much deeper understanding of the architec ture, its underlying\ndecisions, and the ramiﬁcations thereof. Also, a better doc umentation is often\ndelivered as a byproduct of the assessment. This is similar t o the extra beneﬁts\nsoftware inspections and walkthroughs have besides the ide ntiﬁcation of software\nerrors (see section 13.4.2).\nIn practice, organizations often perform software archite cture assessments in a less\nrigid sense than suggested by the above description of ATAM. Usually, a cafetaria-like\napproach is followed, whereby those elements from ATAM and s imilar methods are\nchosen that best ﬁt the situation at hand (Kazman et al., 2006 ).\n11.6 Summary\nSoftware architecture", "token_count": 512, "start_token": 181566, "end_token": 182078, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 394, "text": "-like\napproach is followed, whereby those elements from ATAM and s imilar methods are\nchosen that best ﬁt the situation at hand (Kazman et al., 2006 ).\n11.6 Summary\nSoftware architecture is concerned with the description of elements from which\nsystems are built, the interaction among those elements, pa tterns that guide their\ncomposition, and constraints on those patterns. The design of a software architecture\nis driven by quality concerns. The resulting software archi tecture is described in\ndifferent views, each of which addresses speciﬁc concerns o n behalf of speciﬁc\nstakeholders. This resembles the way different drawings of a building emphasize\ndifferent aspects on behalf of its different stakeholders.\nIt is important to not only document the resulting solution, but also the decisions\nthat led to that solution, its rationale, and other informat ion that is helpful to guide\nits further evolution.\nSoftware architecture is an important notion, for more than one reason:\n312 SOFTWARE ARCHITECTURE\n/AF The comparison with traditional architecture reveals comm onalities which help\nus to get a better grip on the software design process and its p roducts. Software\narchitecture is not only concerned with the blueprint that i s the outcome of the\ndesign process. The notion of an architectural style has mer its of its own and\nthe relationship between style on the one hand and engineeri ng and materials\non the other hand provide additional insights into what soft ware design entails\n(Perry and Wolf, 1992).\n/AF The ﬁeld may eventually yield a repertoire of concepts that s oftware architects\ncan use in their search for solutions. Expert designers in an y ﬁeld build on a\nvast collection of reusable concepts. These concepts are gi ven unique names,\nwhich are used to communicate them, and serve as labels when r etrieving\nand storing them in human memory. Software architecture is c oncerned\nwith identifying, describing and categorizing components at a high level of\nabstraction. The resulting abstractions are to become part of the vocabulary\nof software engineers, much like abstract data types are alr eady part of that\nvocabulary.\n/AF Phrasing a software design in software architectural terms promotes consistency\nduring development and maintenance. Phrasing the global de sign in terms of\nan architecture forces us to think", "token_count": 512, "start_token": 182028, "end_token": 182540, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 395, "text": " are alr eady part of that\nvocabulary.\n/AF Phrasing a software design in software architectural terms promotes consistency\nduring development and maintenance. Phrasing the global de sign in terms of\nan architecture forces us to think about its general ﬂavor, i n terms of types of\ncomponent and connector, as well as a certain control struct ure. By making\nthis intuition explicit, it both describes and prescribes how the system should look\nand how it may evolve over time.\n/AF A software architecture captures early design decisions. T he architecture can\nbe used to evaluate those decisions. It also provides a way to discuss those\ndecisions and their ramiﬁcations with the various stakehol ders.\n11.7 Further Reading\nShaw and Garlan (1996) is an early inﬂuential source that dis cusses the emerging ﬁeld\nof software architecture, in particular software architec tural styles. Bass et al. (2003)\ngive a broad overview of the ﬁeld, including the various forc es that inﬂuence software\narchitecture and the purposes of a software architecture, a nd ADD. It includes a\nnumber of case studies to illustrate these issues. Clements et al. (2003) is wholly\ndevoted to architecture documentation and architectural v iews. The state of the art\nin software architecture is reﬂected in (Software, 2006). A comparison between the\nclassical ﬁeld of architecture and software architecture i s made in (Perry and Wolf,\n1992). Different architectural views on the same system are the topic of (Kruchten,\n1995) and (Soni et al., 1995). Rozanski and Woods (2005) give a very good catalog\nof useful architectural viewpoints. Architecture as a set o f design decisions is the topic\nof (Tyree and Akerman, 2005).\n11.7. FURTHER READING 313\nSoftware architecture and design patterns have been strong ly inﬂuenced by the\nworks of the architect Christopher Alexander. It is certain ly worthwhile to have a look\nat them (Alexander et al., 1977), (Alexander, 1979). Lea (19 94) gives an introduction\nto his work for software engineers. Alexander (1999) explai ns the origins of pattern\ntheory. Buschmann", "token_count": 512, "start_token": 182490, "end_token": 183002, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 396, "text": "\nat them (Alexander et al., 1977), (Alexander, 1979). Lea (19 94) gives an introduction\nto his work for software engineers. Alexander (1999) explai ns the origins of pattern\ntheory. Buschmann et al. (1996) is an excellent source for ar chitectural patterns. The\ntheory of programming plans stems from (Soloway, 1986).\nClements et al. (2002) discusses software architecture eva luation in great depth.\nMaranzano et al. (2005) discuss experiences with architect ure reviews. A survey of\narchitecture assessment methods is given in (Dobrica and Ni emel ¨ a, 2002).\nMany issues related to software architecture have not been t ouched upon in this\nchapter. These include efforts to classify software archit ectural styles along different\ndimensions (Shaw and Clements, 1996), architecture descri ption languages and\nsupporting tools (Shaw et al., 1995), architecture descrip tion languages (Medvidovic\nand Taylor, 2000), architecture reconstruction (van Deurs en et al., 2004), the role of\nthe software architect (Kruchten, 1999), (Mustapic et al., 2004).\nExercises\n1. Give a deﬁnition of the term ‘software architecture’. Exp lain the different\nelements in this deﬁnition.\n2. What is the difference between software architecture and top-level design?\n3. What is the main purpose of a software architecture?\n4. What is the relation between design decisions and softwar e architecture?\n5. Explain the architecture design method ADD (Attribute Dr iven Design).\n6. What is the role of the backlog in design?\n7. What is the difference between the notions software archi tecture and design\npattern?\n8. What is the difference between the conceptual or logical v iewpoint and the\nimplementation viewpoint?\n9. Explain the difference between module, component and con nector, and\nallocation viewpoints.\n10. Describe in your own words the essence of the implicit-in vocation architec-\ntural style.\n11. In what sense does the abstract-data-type architectura l style constrain the\ndesigner?\n314 SOFTWARE ARCHITECTURE\n12. Why is error-handling dif", "token_count": 512, "start_token": 182952, "end_token": 183464, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 397, "text": "c-\ntural style.\n11. In what sense does the abstract-data-type architectura l style constrain the\ndesigner?\n314 SOFTWARE ARCHITECTURE\n12. Why is error-handling difﬁcult in the pipes-and-ﬁlter a rchitectural style?\n13. Why is language so important in software design?\n14. Deﬁne the following component types: computational, me mory, manager.\n15. Deﬁne the following connector types: data ﬂow, message p assing, shared\ndata.\n16. In what sense may the layers in a layered architecture be v iewed as virtual\nmachines?\n17. What is a software architecture assessment?\n18. Explain the steps of ATAM.\n19. /DJ To what extent may the development organization, backgroun d and\nexpertise of the designer, and the technical environment ha ve inﬂuenced the\narchitecture of the World Wide Web? See also (Bass et al., 200 3, chapter 13).\n20. /DI Take a software system you have been involved in. Identify an d document\nthree important design decisions for that system.\n21. /DI For that same system, develop a module view. Indicate the con cerns this\nview addresses.\n22. /DI For that same system, develop a business oriented view. Indi cate the\nconcerns this view addresses.\n23. /DI What are the possible roles of software architecture and des ign patterns\nduring software comprehension?\n24. /DJ Write an essay on the inﬂuence of social and organizational i ssues on\nsoftware architecture. See for example (Cockburn, 1996).\n25. /DJ Write an essay on the role of the software architect. See for e xample\n(Kruchten, 1999)\n12\nSoftware Design\nLEARNING OBJECTIVES\n/AF To be able to discern desirable properties of a software desi gn\n/AF To understand different notions of complexity, at both the m odule and system\nlevel\n/AF To be aware of some object-oriented metrics\n/AF To be aware of some widely-known classical design methods\n/AF To understand the general ﬂavor of object-oriented analysi s and design methods", "token_count": 512, "start_token": 183414, "end_token": 183926, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 398, "text": " system\nlevel\n/AF To be aware of some object-oriented metrics\n/AF To be aware of some widely-known classical design methods\n/AF To understand the general ﬂavor of object-oriented analysi s and design methods\n/AF To be aware of a global classiﬁcation scheme for design metho ds\n/AF To understand the role of design patterns and be able to illus trate their\nproperties\n/AF To be aware of guidelines for the design documentation\n316 SOFTWARE DESIGN\nSoftware design concerns the decomposition of a system into its constituent\nparts. A good design is the key to the successful implementat ion and evolution\nof a system. A number of guiding principles for this decompos ition help to\nachieve quality designs. These guiding principles underli e the main design\nmethods discussed in this chapter. Unlike more classical de sign ﬁelds, there is\nno visual link between the design representation of a softwa re system and the\nultimate product. This complicates the communication of de sign knowledge\nand raises the importance of proper design representations .\nDuring software development, we should adhere to a planned a pproach. If we\nwant to travel from point A to point B, we will (probably) cons ult a map ﬁrst.\nAccording to some criterion, we will then plan our travel sch eme. The time-loss\ncaused by the planning activity is bound to outweigh the mise ry that occurs if we do\nnot plan our trip at all but just take the ﬁrst turn left, hopin g that this will bring us\nsomewhat closer to our destination.\nIn designing a garden, we will also follow some plan. We will n ot start by planting\na few bulbs in one corner, an apple tree in another, and a popla r next to the front\ndoor.\nThe above examples sound ridiculous. They are. Yet, many a so ftware development\nproject is undertaken in this way. Somewhat exaggeratedly, we may call it the\n‘programmer’s approach’ to software development. Far too m uch software is still being\ndeveloped without a clear design phase. The reasons for this ‘code ﬁrst, design later’\nattitude are many:\n/AF We do not want to, or are not allowed to, ‘waste our", "token_count": 512, "start_token": 183876, "end_token": 184388, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 399, "text": "developed without a clear design phase. The reasons for this ‘code ﬁrst, design later’\nattitude are many:\n/AF We do not want to, or are not allowed to, ‘waste our time’ on des ign activities.\n/AF We have to, or want to, quickly show something to our customer .\n/AF We are judged by the amount of code written per man-month.\n/AF We are, or expect to be, pressed for time.\nSuch an approach grossly underestimates the complexity of s oftware and its devel-\nopment. Just as with the furnishing of a house or the undertak ing of a long trip, it is\nparamount to put thought into a plan, resulting in a blueprin t that is then followed\nduring actual construction. The outcome of this process (th e blueprint) will be termed\nthe design or, if the emphasis is on its notation, the ( technical) speciﬁcation . The\nprocess of making this blueprint is also called design. To a l arge extent, the quality\nof the design determines the quality of the resulting produc t. Errors made during the\ndesign phase often go undetected until the system is operati onal. At that time, they\ncan be repaired only by incurring very high costs.\nDesign is a problem-solving activity and, as such, very much a matter of trial and\nerror. In the presentation of a mathematical proof, subsequ ent steps dovetail well into\neach other and everything drops into place at the end. The act ual discovery of the\n317\nproof was probably quite different. The same holds for the de sign of software. We\nshould not confuse the outcome of the design process with the process itself. The\noutcome of the design process is a ‘rational reconstruction ’ of that process. (Note that\nwe made precisely the same remark with respect to the outcome of the requirements\nengineering process.)\nSoftware design is a ‘wicked problem’. The term originated i n research into the\nnature of design issues in social planning problems. Proper ties of wicked problems in\nthis area are remarkably similar to properties of software d esign:\n/AF There is no deﬁnite formulation of a wicked problem. The desi gn process\ncan hardly be separated from either the preceding requireme nts engineering\nphase or", "token_count": 512, "start_token": 184338, "end_token": 184850, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 400, "text": " remarkably similar to properties of software d esign:\n/AF There is no deﬁnite formulation of a wicked problem. The desi gn process\ncan hardly be separated from either the preceding requireme nts engineering\nphase or the subsequent documentation of the design in a spec iﬁcation. These\nactivities will, in practice, overlap and inﬂuence each oth er. At the more global\n(architectural) stages of system design, the designer will interact with the user\nto assess ﬁtness-for-use aspects of the design. This may lea d to adaptations in\nthe requirements speciﬁcation. The more detailed stages of design often cannot\nbe separated from the speciﬁcation method used.\nOne corollary of this is that the waterfall model does not ﬁt t he type of problem\nit is meant to address.\n/AF Wicked problems have no stopping rule. There is no criterion that tells us\nwhen the solution has been reached. Though we do have a number of quali ty\nmeasures for software designs, there does not exist a single scale against which\nto measure the quality of a design. There probably never will be such a scale.\n/AF Solutions to wicked problems are not true or false. At best, t hey are good\nor bad. The software design process is not analytic. It does n ot consist of a\nsequence of decisions each of which brings us somewhat close r to that one,\noptimal solution. Software design involves making a large n umber of trade-offs,\nsuch as those between speed and robustness. As a consequence , there is a\nnumber of acceptable solutions, rather than one best solution.\n/AF Every wicked problem is a symptom of another problem. Resolv ing one problem\nmay very well result in an entirely different problem elsewh ere. For example,\nthe choice of a particular dynamic data structure may solve t he problem of\nan unknown input size and at the same time introduce an efﬁcie ncy problem.\nA corollary of this is that small changes in requirements may have large\nconsequences in the design or implementation. Elsewhere, w e described this\nby saying that software is not continuous.\nDuring design we may opt for a Taylorian, functionality-cen tered view and consider\nthe design problem as a purely technical", "token_count": 512, "start_token": 184800, "end_token": 185312, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 401, "text": " in the design or implementation. Elsewhere, w e described this\nby saying that software is not continuous.\nDuring design we may opt for a Taylorian, functionality-cen tered view and consider\nthe design problem as a purely technical issue. Alternative ly, we may realize that\ndesign involves user issues as well and therefore needs some form of user involvement.\nThe role of the user during design need not be restricted to th at of a guinea-pig in\nshaping the actual user interface. It may also involve much d eeper issues.\n318 SOFTWARE DESIGN\nRather than approaching system design from the point of view that human\nweaknesses need to be compensated for, we may take a differen t stand and consider\ncomputerized systems as a means to support human strengths. Likewise, systems\nneed not reﬂect the interests of system owners only. In a demo cratic world, systems\ncan be designed so that all those involved beneﬁt. This less t echnocratic attitude\nleads to extensive user involvement during all stages of sys tem development. Agile\ndevelopment methods advocate this type of approach.\nWhereas traditional system development has a production view in which the\ntechnical aspects are optimized, the ‘Scandinavian school ’ pays equal attention to\nthe human system, and holds the view that technology must be c ompatible with\norganizational and social needs. The various possible mode s of interaction between\nthe designer or analyst on the one hand and the user on the othe r hand are also\ndiscussed in section 9.1. In this chapter, we concentrate on the technical issues of\nsoftware design.\nPure agile approaches do suggest to start by just planting a few bulbs in one corner\nof the garden. If we happen to move into our new house in late au tumn and want\nsome color when spring sets in, this sounds like the best thin g we can do. If we change\nour mind at some later point in time, we can always move the bul bs and do some\nadditional garden design. It thus depends on the situation a t hand how much upfront\ndesign is feasible. In this chapter, we assume enough contex t and requirements are\nknown to warrant an explicit design step.\nFrom the technical point of view, the design problem can be fo rmulated as follows:\nhow can we decompose a system into parts such that each part ha s a lower complexity", "token_count": 512, "start_token": 185262, "end_token": 185774, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 402, "text": " and requirements are\nknown to warrant an explicit design step.\nFrom the technical point of view, the design problem can be fo rmulated as follows:\nhow can we decompose a system into parts such that each part ha s a lower complexity\nthan the system as a whole, while the parts together solve the user’s problem. Since\nthe complexity of the individual components should be reaso nable, it is important\nthat the interaction between components not be too complica ted.\nDesign has both a product aspect and a process aspect. The product aspect refers to\nthe result, while the process aspect is about how we get there . At the very global,\narchitectural levels of design, there is little process gui dance, and the result is very\nmuch determined by the experience of the designer. For that r eason, chapter 11\nlargely focuses on the characterization of the result of the global design process, the\nsoftware architecture. In this chapter, we focus on the more detailed stages of design,\nwhere more process guidance has been accumulated in a number of software design\nmethods. But for the more detailed stages of software design too, the representational\naspect is the more important one. This representation is the main communication\nvehicle between the designer and the other stakeholders. Un like more classical design\nﬁelds, there is no visual link between the design representa tions of a software system\nand the ultimate product. The blueprint of a bridge gives us l ots of visual clues as to\nhow that bridge will eventually look like. Such is not the cas e for software, and we\nhave to seek other ways to communicate design knowledge to ou r stakeholders.\nThere really is no universal design method. The design proce ss is a creative one,\nand the quality and expertise of the designers are a critical determinant for its success.\nHowever, over the years a number of ideas and guidelines have emerged which may\n12.1. DESIGN CONSIDERATIONS 319\nserve us in designing software.\nThe single most important principle of software design is information hiding . It\nexempliﬁes how to apply abstraction in software design. Abstraction means that we\nconcentrate on the essential issues and ignore, abstract fr om, details that are irrelevant\nat this stage. Considering the complexity of the problems we are to solve, applying\nsome sort of abstraction is a sheer necessity. It is", "token_count": 512, "start_token": 185724, "end_token": 186236, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 403, "text": " that we\nconcentrate on the essential issues and ignore, abstract fr om, details that are irrelevant\nat this stage. Considering the complexity of the problems we are to solve, applying\nsome sort of abstraction is a sheer necessity. It is simply im possible to take in all the\ndetails at once.\nSection 12.1 discusses desirable design features that bear on quality issues, most\nnotably maintainability and reusability. Five issues are i dentiﬁed that have a strong\nimpact on the quality of a design: abstraction, modularity, information hiding,\ncomplexity, and system structure. Assessment of a design wi th respect to these issues\nallows us to get an impression of design quality, albeit not a very quantitative one yet.\nEfforts to quantify such heuristics have resulted in a numbe r of metrics speciﬁcally\naimed at object-oriented systems.\nA vast number of design methods exist, many of which are stron gly tied to a\ncertain notation. These methods give strategies and heuris tics to guide the design\nprocess. Most methods use a graphical notation to depict the design. Though the\ndetails of those methods and notations differ widely, it is p ossible to provide broad\ncharacterizations in a few classes. The essential characte ristics of those classes are\nelaborated upon in sections 12.2 and 12.3.\nDesign patterns are collections of a few modules (or, in obje ct-oriented circles,\nclasses) which are often used in combination, and which toge ther provide a useful\nabstraction. A design pattern is a recurring solution to a st andard problem. The\nopposite of a pattern is an antipattern: a mistake often made . The prototypical\nexample of a pattern is the MVC (Model--View--Controller) p attern known from\nSmalltalk. Design patterns are discussed in section 12.5.\nDuring the design process too, quite a lot of documentation w ill be generated.\nThis documentation serves various users, such as project ma nagers, designers, testers,\nand programmers. Section 12.6 discusses IEEE Standard 1016 . This standard contains\nuseful guidelines for describing software designs. The sta ndard identiﬁes a number of\nroles and indicates, for each role, the type of design docume ntation needed.\nFinally,", "token_count": 512, "start_token": 186186, "end_token": 186698, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 404, "text": " standard contains\nuseful guidelines for describing software designs. The sta ndard identiﬁes a number of\nroles and indicates, for each role, the type of design docume ntation needed.\nFinally, section 12.7 discusses some veriﬁcation and valid ation techniques that\nmay fruitfully be applied at the design stage.\n12.1 Design Considerations\nUp till now we have used the notion of ‘module’ in a rather intu itive way. It is not\neasy to give an accurate deﬁnition of that notion. Obviously , a module does not\ndenote some random piece of software. We apply certain crite ria when decomposing\na system into modules.\nAt the programming language level, a module usually refers t o an identiﬁable unit\nwith respect to compilation. We will use a similar deﬁnition of the term ‘module’ with\nrespect to design: a module is an identiﬁable unit in the desi gn. It may consist of a\n320 SOFTWARE DESIGN\nsingle procedure, or a class, or even a set of classes. It pref erably has a clean interface\nto the outside world, and the functionality of the module the n is only approached\nthrough that interface.\nThere are, in principle, many ways to decompose a system into modules.\nObviously, not every decomposition is equally desirable. I n this section we are\ninterested in desirable features of a decomposition, irres pective of the type of system\nor the design method used. These features can in some sense be used as a measure of\nthe quality of the design. Designs that have those features a re considered superior to\nthose that do not have them.\nThe design features we are most interested in are those that f acilitate maintenance\nand reuse: simplicity, a clear separation of concepts into d ifferent modules, and\nrestricted visibility (i.e. locality) of information. 1 Systems that have those properties\nare easier to maintain since we may concentrate our attentio n on those parts that are\ndirectly affected by a change. These properties also bear on reusability, because the\nresulting modules tend to have a well-deﬁned functionality that ﬁts concepts from the\napplication domain. Such modules are likely candidates for inclusion in other systems\nthat", "token_count": 512, "start_token": 186648, "end_token": 187160, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 405, "text": " properties also bear on reusability, because the\nresulting modules tend to have a well-deﬁned functionality that ﬁts concepts from the\napplication domain. Such modules are likely candidates for inclusion in other systems\nthat address problems from the same domain.\nIn the following subsections we discuss ﬁve interrelated is sues that have a strong\nimpact on the above features:\n– abstraction,\n– modularity,\n– information hiding,\n– complexity, and\n– system structure.\nFor object-oriented systems, a speciﬁc set of quality heuri stics and associ-\nated metrics has been deﬁned. The main object-oriented metr ics are discussed in\nsection 12.1.6.\n12.1.1 Abstraction\nAbstraction means that we concentrate on the essential feat ures and ignore, abstract\nfrom, details that are not relevant at the level we are currently w orking. Consider, for\nexample, a typical sorting module. From the outside we canno t (and need not be able\nto) discern exactly how the sorting process takes place. We n eed only know that the\noutput is indeed sorted. At a later stage, when the details of the sorting module are\ndecided upon, then we can rack our brains about the most suita ble sorting algorithm.\n1 Obviously, an even more important feature of a design is that the corresponding system should\nperform the required tasks in the speciﬁed way. To this end, t he design should be validated against the\nrequirements.\n12.1. DESIGN CONSIDERATIONS 321\nThe complexity of most software problems makes applying abs traction a sheer\nnecessity. In the ensuing discussion, we distinguish two ty pes of abstraction: procedural\nabstraction and data abstraction .\nThe notion of procedural abstraction is fairly traditional . A programming lan-\nguage offers if-constructs, loop-constructs, assignment statements, and the like. The\ntransition from a problem to be solved to these primitive lan guage constructs is a\nlarge one in many cases. To this end a problem is ﬁrst decompos ed into subproblems,\neach of which is handled in turn. These subproblems correspo nd to major tasks to\nbe accomplished. They can be recognized by their descriptio n in which some verb\nplays", "token_count": 512, "start_token": 187110, "end_token": 187622, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 406, "text": "st decompos ed into subproblems,\neach of which is handled in turn. These subproblems correspo nd to major tasks to\nbe accomplished. They can be recognized by their descriptio n in which some verb\nplays a central role (for example: read the input, sort all records, process the next user\nrequest, compute the net salary). If needed, subproblems are further decompo sed into\neven simpler subproblems. Eventually we get at subproblems for which a standard\nsolution is available. This type of (top-down) decompositi on is the essence of the\nmain-program-with-subroutines architectural style.\nThe result of this type of stepwise decomposition is a hierar chical structure. The\ntop node of the structure denotes the problem to be solved. Th e next level shows its\nﬁrst decomposition into subproblems. The leaves denote pri mitive problems. This is\nschematically depicted in ﬁgure 12.1.\nThe procedure concept offers us a notation for the subproble ms that result from\nthis decomposition process. The application of this concep t is known as procedural\nabstraction. With procedural abstraction, the name of a pro cedure (or method, in\nobject oriented languages) is used to denote the correspond ing sequence of actions.\nWhen that name is used in a program, we need not bother ourselv es about the exact\nway in which its effect is realized. The important thing is th at, after the call, certain\nprestated requirements are fulﬁlled.\nThis way of going about the process closely matches the way in which humans\nare inclined to solve problems. Humans too are inclined to th e stepwise handling of\nproblems. Procedural abstraction thus offers an important means of tackling software\nproblems.\nWhen designing software, we are inclined to decompose the pr oblem so that\nthe result has a strong time orientation. A problem is decomp osed into subproblems\nthat follow each other in time. In its simplest form, this app roach results in input-\n-process--output schemes: a program ﬁrst has to read and sto re its data, next some\nprocess computes the required output from these data, and th e result ﬁnally is output.\nApplication of this technique may result in programs", "token_count": 512, "start_token": 187572, "end_token": 188084, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 407, "text": " a program ﬁrst has to read and sto re its data, next some\nprocess computes the required output from these data, and th e result ﬁnally is output.\nApplication of this technique may result in programs that ar e difﬁcult to adapt and\nhard to comprehend. Applying data abstraction results in a d ecomposition which\nshows this afﬂiction to a far lesser degree.\nProcedural abstraction is aimed at ﬁnding a hierarchy in the program’s control\nstructure: which steps have to be executed and in which order . Data abstraction is\naimed at ﬁnding a hierarchy in the program’s data. Programmi ng languages offer\nprimitive data structures for integers, real numbers, trut h values, characters and\npossibly a few more. Using these building blocks we may const ruct more complicated\ndata structures, such as stacks and binary trees. Such struc tures are of general use in\n322 SOFTWARE DESIGN\nFigure 12.1 The idea of procedural abstraction\napplication software. They occur at a fairly low level in the hierarchy of data structures.\nApplication-oriented objects, such as ‘paragraph’ in text processing software or ‘book’\nin our library system, are found at higher levels of the data s tructure hierarchy. This\nis schematically depicted in ﬁgure 12.2.\nFigure 12.2 The idea of data abstraction\nFor the data, too, we wish to abstract from details that are no t relevant at a certain\nlevel. In fact, we already do so when using the primitive data structures offered by our\nprogramming language. In using these, we abstract from deta ils such as the internal\nrepresentation of numbers and the way in which the addition o f two numbers is\nrealized. At the programming language level we may view the i ntegers as a set of\nobjects (0, 1, -1, 2, -2, . . . ) and a set of operations on these o bjects ( /B7 , /A0 , /A2 , /BP ,\n. . . ). These two sets together determine the data type integer. To be able to use\nthis data type we need only name the set of objects and specify its operations.\nWe may proceed along the same lines for the data structures no t directly supported", "token_count": 512, "start_token": 188034, "end_token": 188546, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 408, "text": " . ). These two sets together determine the data type integer. To be able to use\nthis data type we need only name the set of objects and specify its operations.\nWe may proceed along the same lines for the data structures no t directly supported\nby the programming language. A data type binary-tree is characterized by a set of\n12.1. DESIGN CONSIDERATIONS 323\nobjects (all conceivable binary trees) and a set of operatio ns on those objects. When\nusing binary trees, their representation and the implement ation of the corresponding\noperations need not concern us. We need only ascertain the in tended effect of the\noperations.\nApplying data abstraction during design is sometimes calle d object-oriented\ndesign, since the type of object and the associated operations are e ncapsulated in one\nmodule. The buzzword ‘object-oriented’ however also has a s ubtly different meaning.\nWe will further elaborate upon this notion in section 12.3.\nLanguages such as Ada, Java and C++ offer a language construc t (called package,\nclass, and struct, respectively) that allows us to maintain a syntactic separ ation\nbetween the implementation and speciﬁcation of data types. Note that it is also\npossible to apply data abstraction during design when the ul timate language does not\noffer the concept. However, it then becomes more cumbersome to move from design\nto code.\nWe noticed before that procedural abstraction ﬁts in nicely with the way humans\ntend to tackle problems. To most people, data abstraction is a bit more complicated.\nWhen searching for a solution to a software problem we will ﬁn d that the\nsolution needs certain data structures. At some point we wil l also have to choose a\nrepresentation for these data structures. Rather than maki ng those decisions at an early\nstage and imposing the result on all other components, you ar e better off if you create\na separate subproblem and make only the procedural, impleme ntation-independent,\ninterfaces public. Data abstraction thus is a prime example of information hiding.\nThe development of these abstraction techniques went hand- in-hand with other\ndevelopments, particularly those in the realm of programmi ng languages. Procedures\nwere originally introduced to avoid the repetition of instr uction sequences. At a later\nstage we viewed the name of a procedure as an", "token_count": 512, "start_token": 188496, "end_token": 189008, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 409, "text": "- in-hand with other\ndevelopments, particularly those in the realm of programmi ng languages. Procedures\nwere originally introduced to avoid the repetition of instr uction sequences. At a later\nstage we viewed the name of a procedure as an abstraction of th e corresponding\ninstruction sequence. Only then did the notion of procedura l abstraction get its\npresent connotation. In a similar vein, developments in the ﬁeld of formal data type\nspeciﬁcations and language notions for modules (starting w ith the class concept of\nSIMULA-67) strongly contributed to our present notion of da ta abstraction.\nAs a ﬁnal note we remark that we may identify yet a third type of abstraction,\ncontrol abstraction . In control abstraction we abstract from the precise order i n which\na sequence of events is to be handled. Though control abstrac tion is often implicit\nwhen procedural abstraction is used, it is sometimes conven ient to be able to explicitly\nmodel this type of nondeterminacy, for instance when specif ying concurrent systems.\nThis topic falls outside the scope of this book.\n12.1.2 Modularity\nDuring design, the system is decomposed into a number of modu les and the\nrelationships between those modules are indicated. In anot her design of the same\nsystem, different modules may show up and there may be differ ent relationships\nbetween the modules. We may try to compare those designs by co nsidering both a\n324 SOFTWARE DESIGN\ntypology for the individual modules and the type of connecti ons between them. This\nleads us to two structural design criteria: cohesion and coupling.\nCohesion may be viewed as the glue that keeps the module toget her. It is a\nmeasure of the mutual afﬁnity of the elements of a module. In g eneral we will wish\nto make the cohesion as strong as possible. In their classic t ext on Structured Design ,\nYourdon and Constantine identify the following seven level s of cohesion of increasing\nstrength:\n/AF Coincidental cohesion With coincidental cohesion, elements are grouped into\nmodules in a haphazard way. There is no signiﬁcant relation b etween the\nelements.\n/AF Logical cohesion With logical cohesion, the elements realize tasks that are\nlogically related. One example is a module that contains all input routines", "token_count": 512, "start_token": 188958, "end_token": 189470, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 410, "text": " There is no signiﬁcant relation b etween the\nelements.\n/AF Logical cohesion With logical cohesion, the elements realize tasks that are\nlogically related. One example is a module that contains all input routines.\nThese routines do not call one another and they do not pass inf ormation to\neach other. Their function is just very similar.\n/AF Temporal cohesion A typical example of this type of cohesion is an initializati on\nmodule. The various elements of it are independent but they a re activated at\nabout the same point in time.\n/AF Procedural cohesion A module exhibits procedural cohesion if it consists of a\nnumber of elements that have to be executed in some given orde r. For instance,\na module may have to ﬁrst read some datum, then search a table, and ﬁnally\nprint a result.\n/AF Communicational cohesion This type of cohesion occurs if the elements of a\nmodule operate on the same (external) data. For instance, a m odule may read\nsome data from a disk, perform certain computations on those data, and print\nthe result.\n/AF Sequential cohesion Sequential cohesion occurs if the module consists of a\nsequence of elements where the output of one element serves a s input to the\nnext element.\n/AF Functional cohesion In a module exhibiting functional cohesion all elements\ncontribute to the one single function of that module. Such a m odule often\ntransforms a single input datum into a single output datum. T he well-known\nmathematical subroutines are a typical example of this. Les s trivial examples are\nmodules like ‘execute the next edit command’ and ‘translate the program given’.\nIn a classic paper on structured design, (Stevens et al., 197 4) provide some simple\nheuristics that may be of help in establishing the degree of c ohesion of a module.\nThey suggest writing down a sentence that describes the func tion (purpose) of the\nmodule and examining that sentence. Properties to look for i nclude the following:\n12.1. DESIGN CONSIDERATIONS 325\n/AF If the sentence is compound, has a connective (such as a comma or the word\n‘and’), or contains more than one verb, then that module is pr obably performing\nmore than", "token_count": 512, "start_token": 189420, "end_token": 189932, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 411, "text": " CONSIDERATIONS 325\n/AF If the sentence is compound, has a connective (such as a comma or the word\n‘and’), or contains more than one verb, then that module is pr obably performing\nmore than one function. It is likely to have sequential or com municational\ncohesion.\n/AF If the sentence contains words that relate to time (such as ‘ﬁ rst’, ‘next’, ‘after’,\n‘then’), then the module probably has sequential or tempora l cohesion.\n/AF If the sentence contains words like ‘initialize’, the modul e probably has temporal\ncohesion.\nThe levels of cohesion identiﬁed above reﬂect the cohesion b etween the functions\nthat a module provides. Abstract data types cannot easily be accommodated in this\nscheme. (Macro and Buxton, 1987) therefore propose adding a n extra level, data\ncohesion, to identify modules that encapsulate an abstract data type . Data cohesion\nis even stronger than functional cohesion.\nIt goes without saying that it is not always an easy task to obt ain the strongest\npossible cohesion between the elements of a module. Though f unctional cohesion\nmay be attainable at the top levels and data cohesion at the bo ttom levels, we will\noften have to settle for less at the intermediate levels of th e module hierarchy. The\ntrade-offs to be made here are what makes design such a difﬁcu lt, and yet challenging,\nactivity.\nThe second structural criterion is coupling. Coupling is a measure of the strength\nof the intermodule connections. A high degree of coupling in dicates a strong\ndependence between modules. A high degree of coupling betwe en modules means\nthat we can only fully comprehend this set of modules as a whol e and may result in\nripple effects when a module has to be changed, because such a change is likely to\nincur changes in the dependent modules as well. Loosely-cou pled modules, on the\nother hand, are relatively independent and are easier to com prehend and adapt. Loose\ncoupling therefore is a desirable feature of a design (and it s subsequent realization).\nThe following types of coupling can be identiﬁed (from tight est to loosest", "token_count": 512, "start_token": 189882, "end_token": 190394, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 412, "text": " easier to com prehend and adapt. Loose\ncoupling therefore is a desirable feature of a design (and it s subsequent realization).\nThe following types of coupling can be identiﬁed (from tight est to loosest):\n/AF Content coupling With content coupling, one module directly affects the\nworking of another module. Content coupling occurs when a mo dule changes\nanother module’s data or when control is passed from one modu le to the middle\nof another (as in a jump). This type of coupling can, and shoul d, always be\navoided.\n/AF Common coupling With common coupling, two modules have shared data.\nThe name originates from the use of COMMON blocks in FORTRAN. Its\nequivalent in block-structured languages is the use of glob al variables.\n/AF External coupling With external coupling, modules communicate through an\nexternal medium, such as a ﬁle.\n326 SOFTWARE DESIGN\n/AF Control coupling With control coupling, one module directs the execution of\nanother module by passing the necessary control informatio n. This is usually\naccomplished by means of ﬂags that are set by one module and re acted upon\nby the dependent module.\n/AF Stamp coupling Stamp coupling occurs when complete data structures are\npassed from one module to another. With stamp coupling, the p recise format\nof the data structures is a common property of those modules.\n/AF Data coupling With data coupling, only simple data is passed between modul es.\nThe various types of coupling emerged in the 1970s and reﬂect the data type concepts\nof programming languages in use at that time. For example, pr ogramming languages of\nthat time had simple scalar data types such as real and integer. They allowed arrays\nof scalar values and records were used to store values of diff erent types. Modules\nwere considered data-coupled if they passed scalars or arra ys. They were considered\nstamp-coupled if they passed record data. When two modules a re control-coupled,\nthe assumption is that the control is passed through a scalar value.\nNowadays, programming languages have much more ﬂexible mea ns of passing\ninformation from one module to another, and this requires a m ore detailed set of\ncoupling levels. For example, modules may pass", "token_count": 512, "start_token": 190344, "end_token": 190856, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 413, "text": " value.\nNowadays, programming languages have much more ﬂexible mea ns of passing\ninformation from one module to another, and this requires a m ore detailed set of\ncoupling levels. For example, modules may pass control data through records (as\nopposed to scalars only). Modules may allow some modules acc ess to their data\nand deny it to others. As a result, there are many levels of vis ibility between local\nand global. Finally, the coupling between modules need not b e commutative. When\nmodule A passes a scalar value to B and B returns a value which i s used to control\nthe further execution of A, then A is data-coupled to B, while B is control-coupled\nto A. As a result, people have extended and reﬁned the deﬁniti ons of cohesion and\ncoupling levels.\nCoupling and cohesion are dual characteristics. If the vari ous modules exhibit\nstrong internal cohesion, the intermodule coupling tends t o be minimal, and vice\nversa.\nSimple interfaces -- weak coupling between modules and stro ng cohesion between\na module’s elements -- are of crucial importance for a variet y of reasons:\n/AF Communication between programmers becomes simpler. When d ifferent peo-\nple are working on one and the same system, it helps if decisio ns can be made\nlocally and do not interfere with the working of other module s.\n/AF Correctness proofs become easier to derive.\n/AF It is less likely that changes will propagate to other module s, which reduces\nmaintenance costs.\n/AF The reusability of modules is increased. The fewer assumpti ons that are made\nabout an element’s environment, the greater the chance of ﬁt ting another\nenvironment.\n12.1. DESIGN CONSIDERATIONS 327\n/AF The comprehensibility of modules is increased. Humans have limited memory\ncapacity for information processing. Simple module interf aces allow for an\nunderstanding of a module independent of the context in whic h it is used.\n/AF Empirical studies show that interfaces exhibiting weak cou pling and strong\ncohesion are less error-prone than those that do not have the se properties.\n12.1.3 Information Hiding\nThe concept of information hiding originates from", "token_count": 512, "start_token": 190806, "end_token": 191318, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 414, "text": " Empirical studies show that interfaces exhibiting weak cou pling and strong\ncohesion are less error-prone than those that do not have the se properties.\n12.1.3 Information Hiding\nThe concept of information hiding originates from a seminal paper of David Par-\nnas Parnas (1972). The principle of information hiding is th at each module has a\nsecret which it hides to other modules. Its use as a guiding pr inciple in design is aptly\nillustrated in the KWIC-index example. In the second decomp osition, for example,\nmodule Store hides how lines are stored and module Sort hides how and when shifts\nare sorted.\nDesign involves a sequence of decisions, such as how to repre sent certain\ninformation, or in which order to accomplish tasks. For each such decision we should\nask ourselves which other parts of the system need to know abo ut the decision and\nhow it should be hidden from parts that do not need to know.\nInformation hiding is closely related to the notions of abst raction, cohesion, and\ncoupling. If a module hides some design decision, the user of that module may abstract\nfrom (ignore) the outcome of that decision. Since the outcom e is hidden, it cannot\npossibly interfere with the use of that module. If a module hi des some secret, that\nsecret does not permeate the module’s boundary, thereby dec reasing the coupling\nbetween that module and its environment. Information hidin g increases cohesion,\nsince the module’s secret is what binds the module’s constit uents together. Note that,\nin order to maximize its cohesion, a module should hide one secret only.\nIt depends on the programming language used whether the sepa ration of concerns\nobtained during the design stage will be identiﬁable in the u ltimate code. To some\nextent, this is of secondary concern. The design decomposit ion will be reﬂected, if only\nimplicitly, in the code and should be explicitly recorded (f or traceability purposes) in\nthe technical documentation. It is of great importance for t he later evolution of the\nsystem. A conﬁrmation of the impact of such techniques as inf ormation hiding on the\nmaintainability of software can be found in (Boehm, 1983).\n12.1.4 Complexity\n", "token_count": 512, "start_token": 191268, "end_token": 191780, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 415, "text": "\nsystem. A conﬁrmation of the impact of such techniques as inf ormation hiding on the\nmaintainability of software can be found in (Boehm, 1983).\n12.1.4 Complexity\nLike all good inventions, readability yardsticks can cause harm in misuse. They are\nhandy statistical tools to measure complexity in prose. The y are useful to determine\nwhether writing is gauged to its audience. But they are not fo rmulas for writing\n. . . Writing remains an art governed by many principles. By no means all factors that\ncreate interest and affect clarity can be measured objectiv ely.\n(Gunning, 1968)\n328 SOFTWARE DESIGN\nIn a very general sense, the complexity of a problem refers to the amount of\nresources required for its solution. We may try to determine complexity in this way\nby measuring, say, the time needed to solve a problem. This is a so-called external\nattribute: we are not looking at the entity itself (the probl em), but at how it behaves.\nIn the present context, complexity refers to attributes of t he software that affect\nthe effort needed to construct or change a piece of software. These are internal\nattributes: they can be measured purely in terms of the softw are itself. For example,\nwe need not execute the software to determine their values.\nBoth these notions are very different from the complexity of the computation\nperformed (with respect to time or memory needed). The latte r is a well-established\nﬁeld in which many results have been obtained. This is much le ss true for the type\nof complexity in which we are interested. Software complexi ty in this sense is still a\nrather elusive notion.\nSerious efforts have been made to measure software complexi ty in quantitative\nterms. The resulting metrics are intended to be used as ancho r points for the\ndecomposition of a system, to assess the quality of a design o r program, to guide\nreengineering efforts, etc. We then measure certain attrib utes of a software system,\nsuch as its length, the number of if-statements, or the infor mation ﬂow between\nmodules, and try to relate the numbers thus obtained to the sy stem’s complexity. The\ntype of software attributes considered can be broadly categ orized into two classes:\n– intra", "token_count": 512, "start_token": 191730, "end_token": 192242, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 416, "text": " the infor mation ﬂow between\nmodules, and try to relate the numbers thus obtained to the sy stem’s complexity. The\ntype of software attributes considered can be broadly categ orized into two classes:\n– intra-modular attributes are attributes of individual modules, and\n– inter-modular attributes are attributes of a system viewed as a collection of\nmodules with dependencies.\nIn this subsection we are dealing with intra-modular attrib utes. Inter-modular\nattributes are discussed in the next subsection. We may dist inguish two classes\nof complexity metrics:\n/AF Size-based complexity metrics. The size of a piece of software, such as t he\nnumber of lines of code, is fairly easy to measure. It also giv es a fair indication\nof the effort needed to develop that piece of software (see al so chapter 7). As a\nconsequence, it could also be used as a complexity metric.\n/AF Structure-based complexity metrics. The structure of a piece of software is a\ngood indicator of its design quality, because a program that has a complicated\ncontrol structure or uses complicated data structures is li kely to be difﬁcult to\ncomprehend and maintain, and thus more complex.\nThe easiest way to measure software size is to count the numbe r of lines of code. We\nmay then impose limits on the number of lines of code per modul e. In (Weinberg,\n1971), for instance, the ideal size of a module is said to be 30 lines of code. In a variant\nhereof, limits are imposed on the number of elements per modu le. Some people\nclaim that a module should contain at most seven elements. Th is number seven can\n12.1. DESIGN CONSIDERATIONS 329\nbe traced back to research in psychology, which suggests tha t human memory is\nhierarchically organized with a short-term memory of about seven slots, while there\nis a more permanent memory of almost unlimited capacity. If t here are more than\nseven pieces of information, they cannot all be stored in sho rt-term memory and\ninformation gets lost.\nThere are serious objections to the direct use of the number o f lines of code as\na complexity metric. Some programmers write more verbose pr ograms than others.\nWe should at least normalize the counting to counteract thes e effects and be", "token_count": 512, "start_token": 192192, "end_token": 192704, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 417, "text": " serious objections to the direct use of the number o f lines of code as\na complexity metric. Some programmers write more verbose pr ograms than others.\nWe should at least normalize the counting to counteract thes e effects and be able to\ncompare different pieces of software. This can be achieved b y using a prettyprinter,\na piece of software that reproduces programs in a given langu age in a uniform way.\nA second objection is that this technique makes it hard to com pare programs\nwritten in different languages. If the same problem is solve d in different languages,\nthe results may differ considerably in length. For example, APL is more compact than\nCOBOL.\nFinally, some lines are more complex than others. An assignm ent like\na:= b\nlooks simpler than a loop\nwhile pꜼ .next /BO/BQ nil do p:= p Ꜽ .next\nalthough they each occupy one line.\nHalstead’s method, also known as ‘software science’, uses a reﬁnement of counting\nlines of code. This reﬁnement is meant to overcome the proble ms associated with\nmetrics based on a direct count of lines of code.\nHalstead’s method uses the number of operators and operands in a piece of\nsoftware. The set of operators includes the arithmetic and B oolean operators, as well\nas separators (such as a semicolon\nbetween adjacent instructions) and (pairs of) reserved wor ds. The set of operands\ncontains the variables and constants used. Halstead then de ﬁnes four basic entities:\n– /D2\n/BD\nis the number of unique (i.e. different) operators in the pro gram;\n– /D2\n/BE\nis the number of unique (i.e. different) operands in the prog ram;\n– /C6\n/BD\nis the total number of occurrences of operators;\n– /C6\n/BE\nis the total number of occurrences of operands.\nFigure 12.3 contains a simple sorting program. Table 12.1 li sts the operators and\noperands of this program together with their frequency. Not e that there is no\ngenerally agreed deﬁnition of what exactly an operator or op erand is. So the", "token_count": 512, "start_token": 192654, "end_token": 193166, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 418, "text": ". Table 12.1 li sts the operators and\noperands of this program together with their frequency. Not e that there is no\ngenerally agreed deﬁnition of what exactly an operator or op erand is. So the numbers\ngiven have no absolute meaning. This is part of the criticism of this theory.\nUsing the primitive entities deﬁned above, Halstead deﬁnes a number of derived\nentities, such as:\n330 SOFTWARE DESIGN\n1 procedure sort(var x: array; n: integer);\n2 var i, j, save: integer;\n3 begin\n4 for i:= 2 to n do\n5 for j:= 1 to i do\n6 if x[i] /BO x[j] then\n7 begin save:= x[i];\n8 x[i]:= x[j];\n9 x[j]:= save\n10 end\n11 end;\nFigure 12.3 A simple sorting routine\nTable 12.1 Counting the number of operators and operands in t he sort\nroutine\nOperator Number of Operand Number of\noccurrences occurrences\nprocedure 1 x 7\nsort() 1 n 2\nvar 2 i 6\n: 3 j 5\narray 1 save 3\n; 6 2 1\ninteger 2 1 1\n, 2\nbegin . . . end 2\nfor . . . do 2\nif . . . then 1\n:= 5\n/BO 1\n[ ] 6\n/D2\n/BD\n/BP /BD/BG /C6\n/BD\n/BP /BF/BH /D2\n/BE\n/BP /BJ /C6\n/BE\n/BP /BE/BH\n– Size of the vocabulary: /D2 /BP /D2\n/BD\n/B7 /D2\n/BE\n.\n– Program length: /C6 /BP /C6\n/BD\n/B7 /C6\n/BE\n.\n– Program volume: /CE /BP /C6 /D0/D3/CV\n/BE\n/D2 .\n12.1. DESIGN CONSIDERATIONS 331\nThis is the minimal number of bits needed to store /C6 elements from a set of\ncardinality /D2 .\n– Program level: /C4 /BP /CE\n/A", "token_count": 512, "start_token": 193116, "end_token": 193628, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 419, "text": "1. DESIGN CONSIDERATIONS 331\nThis is the minimal number of bits needed to store /C6 elements from a set of\ncardinality /D2 .\n– Program level: /C4 /BP /CE\n/A3\n/BP/CE .\nHere /CE\n/A3\nis the most compact representation of the algorithm in quest ion. For\nthe example in ﬁgure 12.3 this is sort(x, n); , so /D2 /BP /C6 /BP /BH , and /CE\n/A3\n/BP /BH /D0/D3/CV\n/BE\n/BH .\nFrom the formula it follows that /C4 is at most 1. Halstead postulates that\nthe program level increases if the number of different opera nds increases,\nwhile it decreases if the number of different operators or th e total number\nof operands increases. As an approximation of /C4 , he therefore suggests:\n/CM\n/C4 /BP /B4/BE /BP/D2\n/BD\n/B5/B4 /D2\n/BE\n/BP /C6\n/BE\n/B5 .\n– Programming effort: /BX /BP /CE /BP/C4 .\nThe effort needed increases with volume and decreases as the program level\nincreases. /BX represents the number of mental discriminations (decision s) to be\ntaken while implementing the problem solution.\n– Estimated programming time in seconds:\n/CM\n/CC /BP /BX /BP /BD/BK .\nThe constant 18 is determined empirically. Halstead explai ns this number\nby referring to (Stroud, 1967), which discusses the speed wi th which human\nmemory processes sensory input. This speed is said to be 5--2 0 units per second.\nIn Halstead’s theory, the number 18 is chosen. This number is also referred to\nas Stroud’s number .\nThe above entities can only be determined after the program h as been written. It is,\nhowever, possible to estimate a number of these entities. Wh en doing so, the values\nfor /D2\n/BD\nand /D2\n/BE\nare assumed to be known. This may be the case, for instance, af ter the\ndetailed design step", "token_count": 512, "start_token": 193578, "end_token": 194090, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 420, "text": " these entities. Wh en doing so, the values\nfor /D2\n/BD\nand /D2\n/BE\nare assumed to be known. This may be the case, for instance, af ter the\ndetailed design step. Halstead then estimates program leng th as:\n/CM\n/C6 /BP /D2\n/BD\n/D0/D3/CV\n/BE\n/D2\n/BD\n/B7 /D2\n/BE\n/D0/D3/CV\n/BE\n/D2\n/BE\nAn explanation for this formula can be given as follows. Ther e are /D2\n/BD\n/BE\n/D2\n/BD\n/A2 /D2\n/BE\n/BE\n/D2\n/BE\nways to combine the /D2 given symbols such that operators and operands alternate.\nHowever, the program is organized and organization general ly gives a logarithmic\nreduction in the number of possibilities. Doing so yields th e above formula for\n/CM\n/C6 .\nTable 12.2 lists the values for a number of entities from\nHalstead’s theory for the example program in ﬁgure 12.3.\nA number of empirical studies have addressed the predictive value of Halstead’s\nformulae. These studies often give positive evidence of the validity of the theory.\nThe theory has also been heavily criticized. The underpinni ng of Halstead’s\nformulas is not convincing. Results from cognitive psychol ogy, like Stroud’s number,\nare badly used, which weakens the theoretical foundation. H alstead concentrates on\nthe coding phase and assumes that programmers are 100% devot ed to a programming\ntask for an uninterrupted period of time. Practice is likely to be quite different.\n332 SOFTWARE DESIGN\nTable 12.2 Values for ‘software science’\nentities for the example program in\nﬁgure 12.3\nEntity Value\nSize vocabulary 21\nProgram length 60\nEstimated program length 73\nProgram volume 264\nLevel of abstraction 0.044\nEstimated level of abstraction 0.040\nProgramming effort 6000\nEstimated programming time 333s\nDifferent people use quite different deﬁnitions of the noti ons of operator and\noperand, which may lead", "token_count": 512, "start_token": 194040, "end_token": 194552, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 421, "text": "044\nEstimated level of abstraction 0.040\nProgramming effort 6000\nEstimated programming time 333s\nDifferent people use quite different deﬁnitions of the noti ons of operator and\noperand, which may lead to widely different outcomes for the values of entities.\nYet, Halstead’s work has been very inﬂuential. It was the ﬁrs t major body of work\nto point out the potential of software metrics for software d evelopment.\nThe second class of intra-modular complexity metrics conce rns metrics based on\nthe structure of the software. If we try to derive a complexit y metric from the structure\nof a piece of software, we may focus on the control structure, the data structures, or a\ncombination of these.\nIf we base the complexity metric on the use of data structures , we may for instance\ndo so by considering the number of instructions between succ essive references to one\nand the same object. If this number is large, information abo ut these variables must\nbe retained for a long period of time when we try to comprehend that program text.\nFollowing this line of thought, complexity can be related to the average number of\nvariables for which information must be kept by the reader.\nThe best-known complexity metric from the class of structur e-based complexity\nmetrics is McCabe’s cyclomatic complexity . McCabe bases his complexity metric on a\n(directed) graph depicting the control ﬂow of the program. H e assumes that the\ngraph of a single procedure or single main program has a uniqu e start and end node,\nthat each node is reachable from the start node, and that the e nd node can be reached\nfrom each node. In that case, the graph is connected. If the pr ogram consists of a\nmain program and one or more procedures, then the control gra ph has a number of\nconnected components, one for the main program and one for ea ch of its procedures.\nThe cyclomatic complexity /BV/CE equals the number of predicates (decisions) plus\n1 in the program that corresponds to this control graph. Its f ormula reads\n/BV/CE /BP /CT /A0 /D2 /B7 /D4 /B7 /BD\n12.1. DESIGN CONSIDERATIONS 333\nFigure 12.4 Control", "token_count": 512, "start_token": 194502, "end_token": 195014, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 422, "text": " Its f ormula reads\n/BV/CE /BP /CT /A0 /D2 /B7 /D4 /B7 /BD\n12.1. DESIGN CONSIDERATIONS 333\nFigure 12.4 Control ﬂow graph of the example program from ﬁgu re 12.3\nwhere /CT , /D2 and /D4 denote the number of edges, nodes, and connected components in\nthe control graph, respectively.\nFigure 12.4 shows the control ﬂow graph of the example progra m from ﬁgure 12.3.\nThe numbers inside the nodes correspond to the line numbers f rom ﬁgure 12.3. The\ncyclomatic complexity of this graph is 13-11+1+1=4. The dec isions in the program\nfrom ﬁgure 12.3 occur in lines 4, 5 and 6. In both for-loops the decision is to either\nexit the loop or iterate it. In the if-statement, the choice i s between the then-part and\nthe else-part.\nMcCabe suggests imposing an upper limit of ten for the cyclom atic complexity\nof a program component. McCabe’s complexity metric is also a pplied to testing.\nOne criterion used during testing is to get a good coverage of the possible paths\nthrough the program. Applying McCabe’s cyclomatic complex ity leads to a structured\ntesting strategy involving the execution of all linearly-i ndependent paths (see also\nchapter 13) 2.\n2 The number of linearly-independent paths is related to the s o-called cyclomatic number of a graph,\nwhich is why this is called the ‘cyclomatic complexity’.\n334 SOFTWARE DESIGN\nComplexity metrics like those of Halstead, McCabe and many o thers, all measure\nattributes which are in some sense related to the size of the t ask to be accomplished,\nbe it the time in man-months, the number of lines of code, or so mething else. As\nsuch they may serve various purposes: determining the optim al size of a module,\nestimating the number of errors in a module, or estimating th e cost of a piece of\nsoftware.\nAll known complexity metrics suffer from some serious short comings, though:\n/AF They are not very context-sensitive. For", "token_count": 512, "start_token": 194964, "end_token": 195476, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 423, "text": "\nestimating the number of errors in a module, or estimating th e cost of a piece of\nsoftware.\nAll known complexity metrics suffer from some serious short comings, though:\n/AF They are not very context-sensitive. For example, any progr am with ﬁve\nif-statements has the same cyclomatic complexity. Yet we ma y expect that\ndifferent organizations of those if-statements (consecut ive versus deeply nested,\nsay) have their effect on the perceived complexity of those p rograms. In terms\nof measurement theory, this means that cyclomatic complexi ty does not fulﬁll\nthe ‘representation condition’, which says that the empiri cal relations should\nbe preserved in the numerical relation system. If we empiric ally observe that\nprogram A is more complex than program B, then any complexity metric /BY\nshould be such that /BY\n/BT\n/BQ /BY\n/BU\n.\n/AF They measure only a few facets. Halstead’s method does not ta ke into account\nthe control ﬂow complexity, for instance.\nWe may formulate these shortcomings as follows: complexity metrics tell us something\nabout the complexity of a program (i.e. a higher value of the m etric is likely to induce\na higher complexity), but a more complex program does not nec essarily result in\na higher value for a complexity metric. Complexity is made up of many speciﬁc\nattributes. It is unlikely that there will ever be one ‘gener al’ complexity metric.\nWe should thus be very careful in the use of these complexity m etrics. Since they\nseem to measure along different dimensions of what is percei ved as complexity, the\nuse of multiple metrics is likely to yield better insights. B ut even then the results must\nbe interpreted with care. (Redmond and Ah-Chuen, 1990), for instance, evaluated\nvarious complexity metrics for a few systems, including the MINIX operating system.\nOf the 277 modules in MINIX, 34 have a cyclomatic complexity g reater than ten. The\nhighest value (58) was observed for a module that handles a nu mber of ASCII escape\ncharacter sequences from the keyboard. This module, and mos t others with a large\ncyclomatic complexity, was considered ‘justiﬁably comple", "token_count": 512, "start_token": 195426, "end_token": 195938, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 424, "text": " (58) was observed for a module that handles a nu mber of ASCII escape\ncharacter sequences from the keyboard. This module, and mos t others with a large\ncyclomatic complexity, was considered ‘justiﬁably comple x’. An attempt to reduce the\ncomplexity by splitting those modules would increase the di fﬁculty of understanding\nthem while artiﬁcially reducing its complexity value. Comp lexity yardsticks too can\ncause harm in misuse.\nFinally, we may note that various validations of both softwa re science and\ncyclomatic complexity indicate that they are not substanti ally better indicators of\ncoding effort, maintainability, or reliability than the le ngth of a program (number of\nlines of code). The latter is much easier to determine, thoug h.\nThe high correlation that is often observed between a size-r elated complexity met-\nric and a control-related complexity metric such as McCabe’ s cyclomatic complexity\n12.1. DESIGN CONSIDERATIONS 335\nshould not come as a surprise. Large programs tend to have mor e if-statements than\nsmall programs. What counts, however, is the density with which those if-statements\noccur. This suggests a complexity metric of the form /BV/CE /BP /C4/C7/BV rather than /BV/CE .\n12.1.5 System Structure\nWe may depict the outcome of the design process, a set of modul es and their mutual\ndependencies, in a graph. The nodes of this graph correspond to modules and the\nedges denote relations between modules. We may think of many types of intermodule\nrelations, such as:\n– module A contains module B;\n– module A follows module B;\n– module A delivers data to module B;\n– module A uses module B.\nThe type of dependencies we are interested in are those that d etermine the complexity\nof the relations between modules. The amount of knowledge th at modules have of\neach other should be kept to a minimum. To be able to assess thi s, it is important\nto know, for each module, which other modules it uses, since that tells us which\nknowledge of each other they (potentially) use. In a proper d esign the information\nﬂow between modules is restricted to ﬂow that comes about", "token_count": 512, "start_token": 195888, "end_token": 196400, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 425, "text": " module, which other modules it uses, since that tells us which\nknowledge of each other they (potentially) use. In a proper d esign the information\nﬂow between modules is restricted to ﬂow that comes about thr ough procedure calls.\nThe graph depicting the\nuses-relation is therefore often termed a call graph .\nThe call graph may have different shapes. In its most general form it is a directed\ngraph (ﬁgure 12.5a). 3 If the graph is acyclic, i.e. it does not contain a path of the f orm\n/C5\n/BD\n/BN /C5\n/BE\n/BN /BM /BM /BM /BN /C5\n/D2\n/BN /C5\n/BD\n, the uses-relation forms a hierarchy. We may then decompose\nthe graph into a number of distinct layers such that a module a t one layer uses only\nmodules from lower layers (ﬁgure 12.5b). Going one step furt her, we get at a scheme\nlike the one in ﬁgure 12.5c, where modules from level /CX use only modules from level\n/CX /B7 /BD . Finally, if each module is used by only one other module, the graph reduces to\na tree (ﬁgure 12.5d).\nThere are various aspects of the call graph that can be measur ed. Directly\nmeasurable attributes that relate to the ‘shape’ of the call graph include:\n/AF its size, measured in terms of the number of nodes, the number of edges , or the\nsum of these;\n/AF its depth, the length of the longest path from the root to some leaf node (in an\nacyclic directed graph);\n3 We assume that the graph is connected, i.e. that there is a pat h between each pair of nodes if we\nignore the direction of the arrows that link nodes. This assu mption is reasonable, since otherwise the graph\ncan be split into two or more disjoint graphs between which th ere is no information ﬂow. These disjoint\ngraphs then correspond to independent programs.\n336 SOFTWARE DESIGN\nFigure 12.5 Module hierarchies. (a) directed graph, (b) dir ected acy", "token_count": 512, "start_token": 196350, "end_token": 196862, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 426, "text": "re is no information ﬂow. These disjoint\ngraphs then correspond to independent programs.\n336 SOFTWARE DESIGN\nFigure 12.5 Module hierarchies. (a) directed graph, (b) dir ected acyclic graph, (c)\nlayered graph, (d) tree\n12.1. DESIGN CONSIDERATIONS 337\n/AF its width, the maximum number of nodes at some level (in an acyclic dire cted\ngraph).\nWe do not know of studies that try to quantitatively relate th ose measures to other\ncomplexity-related aspects such as debugging time, mainta inability, etc. They may\nbe used, though, as one of the parameters in a qualitative ass essment of a design.\nIt is often stated that a good design should have a tree-like c all graph. It is\ntherefore worthwhile to consider the tree impurity of a call graph, i.e. the extent\nto which the graph deviates from a pure tree. Suppose we start with a connected\n(undirected) graph (like the ones in ﬁgure 12.5b-d, if we ign ore the direction of the\narrows). If the graph is not a tree, it has at least one cycle, i .e. a path from some node\nA via one or more other nodes back to A again. We may then remove one of the\nedges from this cycle, and the result will still be a connecte d graph. We may continue\nremoving edges from cycles until the result is a tree. We did s o in the transition from\nﬁgure 12.5b to 12.5c to 12.5d. The ﬁnal result is called the gr aph’s spanning tree . The\nnumber of edges removed in this process is an indication of th e graph’s tree impurity.\nIn order to obtain a proper measure of tree impurity we procee d as follows. The\ncomplete graph /C3\n/D2\nis the graph with /D2 nodes and the maximum number of edges.\nThis maximum number of edges is /D2 /B4 /D2 /A0 /BD/B5 /BP /BE . A tree with /D2 nodes has /B4 /D2 /A0 /BD/B5\nedges. Given a", "token_count": 512, "start_token": 196812, "end_token": 197324, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 427, "text": " /D2 /B4 /D2 /A0 /BD/B5 /BP /BE . A tree with /D2 nodes has /B4 /D2 /A0 /BD/B5\nedges. Given a connected graph /BZ with /D2 nodes and /CT edges, we deﬁne its tree\nimpurity /D1 /B4 /BZ /B5 as the number of extra edges divided by the maximum number of\nextra edges:\n/D1 /B4 /BZ /B5 /BP /BE/B4 /CT /A0 /D2 /B7 /BD/B5 /BP /B4 /D2 /A0 /BD/B5/B4 /D2 /A0 /BE/B5\nThis measure of tree impurity ﬁts our intuitive notion of tha t concept. The value of\n/D1 /B4 /BZ /B5 lies between 0 and 1. It is 0 if /BZ is a tree and 1 if it is a complete graph. If we\nadd an edge to /BZ , the value of /D1 /B4 /BZ /B5 increases. Moreover, the ‘penalty’ of extra edges\nis proportional to the size of the spanning tree.\nIt is not always easy, or even meaningful, to strive for a neat hierarchical\ndecomposition. We will often have to settle for a compromise . It may for instance be\nappropriate to decompose a system into a number of clusters, each of which contains\na number of modules. The clusters may then be organized hiera rchically, while the\nmodules within a given cluster show a more complicated inter action pattern. Also,\ntree-like call graphs do not allow for reuse (if a module is re used within the same\nprogram, its node in the call graph has at least two ancestors ).\nThe call graph allows us to assess the structure of a design. In deriving the measures\nabove, each edge in the call graph is treated alike. Yet, the c omplexity of the\ninformation ﬂow that is represented by the edges is likely to vary. As noted in the\nearlier discussion on coupling, we would like the intermodu le connections to be ‘thin’.\nTherefore, we would like a measure which does not merely coun t the edges, but\n", "token_count": 512, "start_token": 197274, "end_token": 197786, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 428, "text": " to vary. As noted in the\nearlier discussion on coupling, we would like the intermodu le connections to be ‘thin’.\nTherefore, we would like a measure which does not merely coun t the edges, but\nwhich also considers the amount of information that ﬂows thr ough them.\nThe best known attempt to measure the total level of informat ion ﬂow between\nthe modules of a system is due to (Henri and Kafura, 1981). The ir measures were able\n338 SOFTWARE DESIGN\nto identify change-prone UNIX procedures and evaluate pote ntial design changes.\n(Shepperd, 1990) studied the information ﬂow measure exten sively and proposed\nseveral reﬁnements, thus obtaining a ‘purer’ metric. Using Shepperd’s deﬁnitions, the\ninformation ﬂow measure is based on the following notions of local and global data\nﬂow:\n/AF A local ﬂow from module A to module B exists if\n(a) A invokes B and passes it a parameter, or\n(b) B invokes A and A returns a value.\n/AF A global ﬂow from module A to module B exists if A updates some global data\nstructure and B retrieves from that structure.\nUsing these notions of local and global data ﬂow, Shepperd de ﬁnes the ‘complexity’\nof a module /C5 as\n\r /D3/D1/D4/D0/CT/DC/CX/D8/DD /B4 /C5 /B5 /BP /B4 fan-in/B4 /C5 /B5 /A2 fan-out/B4 /C5 /B5/B5\n/BE\nwhere\n– fan-in/B4 /C5 /B5 is the number of (local and global) ﬂows whose sink is /C5 , and\n– fan-out/B4 /C5 /B5 is the number of (local and global) ﬂows whose source is /C5 .\nA weak point of the information ﬂow metric is that all ﬂows hav e equal weight.\nPassing one simple integer as parameter and invoking a compl", "token_count": 512, "start_token": 197736, "end_token": 198248, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 429, "text": " global) ﬂows whose source is /C5 .\nA weak point of the information ﬂow metric is that all ﬂows hav e equal weight.\nPassing one simple integer as parameter and invoking a compl ex global data structure\ncontribute equally to this measure of complexity. The abstr act data type architectural\nstyle easily results in modules with a high fan-in and fan-ou t. If the same system is\nbuilt using global data structures, its information ﬂow met ric is likely to have a smaller\nvalue. Yet, the information ﬂow both to and from the modules i n the abstract data\ntype style generally concern simple scalar values only, and are therefore considered\nsimpler.\nIn a more qualitative sense, the information ﬂow metric may i ndicate spots in the\ndesign that deserve our attention. If some module has a high f an-in, this may indicate\nthat the module has little cohesion. Also, if we consider the information ﬂow per\nlevel in a layered architecture, an excessive increase from one level to the next might\nindicate a missing level of abstraction.\nDuring design, we (pre)tend to follow a top-down decomposit ion strategy. We\nmay also take a completely different stand and try to compose a hierarchical system\nstructure from a ﬂat collection of system elements. Element s that are in some sense\n‘closest’ to one another are grouped together. We then have t o deﬁne some measure\nfor the distance between elements and a mathematical techni que known as cluster\nanalysis can be used to do the actual grouping. Elements in th e same group are more\nlike other elements within the same group and less like eleme nts in other groups. If\nthe measure is based on the number of data types that elements have in common,\n12.1. DESIGN CONSIDERATIONS 339\nthis clustering results in abstract data types or, more gene rally, modules having high\ncohesion. If the measure is based on the number of data bindin gs between elements,\nthe result is likely to have a low value for the information-ﬂ ow metric.\nThe measure chosen, in a sense, determines how we deﬁne ‘frie ndship’ between\nelements. Close friends should be grouped in the same module", "token_count": 512, "start_token": 198198, "end_token": 198710, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 430, "text": " for the information-ﬂ ow metric.\nThe measure chosen, in a sense, determines how we deﬁne ‘frie ndship’ between\nelements. Close friends should be grouped in the same module while distant relatives\nmay reside in different modules. The various qualitative an d quantitative design\ncriteria that we discussed above have different, but in esse nce very similar, deﬁnitions\nof friendship.\nThough much work remains to be done, a judicious use of availa ble design metrics\nis already a valuable tool in the design and quality assuranc e of software systems.\n12.1.6 Object-Oriented Metrics\nAt the level of individual methods of an object-oriented sys tem, we may assess\nquality characteristics of components by familiar metrics such as: length, cyclomatic\ncomplexity, and the like. At higher levels of abstraction, o bject-oriented systems\nconsist of a collection of classes that interact by sending m essages. Familiar inter-\nmodular metrics which focus on the relationships between mo dules do not account\nfor the speciﬁcs of object-oriented systems. In this sectio n, we discuss a few metrics\nspeciﬁcally aimed at characteristics of object-oriented s ystems. These metrics are\nlisted in ﬁgure 12.6.\nWMC Weighted Methods per Class\nDIT Depth of class in Inheritance Tree\nNOC Number Of Children\nCBO Coupling Between Object classes\nRFC Response For a Class\nLCOM Lack of Cohesion of a Method\nFigure 12.6 A suite of object-oriented metrics\nWMC is a measure for the size of a class. The assumption is that larger classes are\nin general less desirable. They take more time to develop and maintain, and they are\nlikely to be less reusable. The formula is: WMC =\n/C8\n/D2\n/CX /BP/BD\n\r\n/CX\n, where \r\n/CX\nis the complexity\nof method /CX . For the complexity of an individual method we may choose its length,\ncyclomatic complexity, and so on. Most often, \r\n/CX\nis set at 1. In that case, we simply\ncount the number of methods. Besides being simple, this has t he advantage that the\n", "token_count": 512, "start_token": 198660, "end_token": 199172, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 431, "text": ",\ncyclomatic complexity, and so on. Most often, \r\n/CX\nis set at 1. In that case, we simply\ncount the number of methods. Besides being simple, this has t he advantage that the\nmetric can be applied during design, once the class interfac e has been decided upon.\nNote that each entry in the class interface counts as one meth od, the principle being\nthat each method which requires additional design effort sh ould be counted. For\n340 SOFTWARE DESIGN\nexample, different constructors for one and the same operat ion, as is customary in\nC++, count as different methods.\nClasses in an object-oriented design are related through a s ubtype--supertype\nhierarchy. If the class hierarchy is deep and narrow, a prope r understanding of a\nclass may require knowledge of many of its superclasses. On t he other hand, a wide\nand shallow inheritance structure occurs when classes are m ore loosely coupled. The\nlatter situation may indicate that commonality between ele ments is not sufﬁciently\nexploited. DIT is the distance of a class to the root of its inh eritance tree. Note that\nthe value of DIT is somewhat language-dependent. In Smallta lk, for example, every\nclass is a subclass of Object, and this increases the value of DIT. A widely accepted\nheuristic is to strive for a forest of classes, i.e. a collect ion of inheritance trees of\nmedium height.\nNOC counts the number of immediate descendants of a class. If a class has a large\nnumber of descendants, this may indicate an improper abstra ction of the parent class.\nA large number of descendants also suggests that the class is to be used in a variety\nof settings, which will make it more error-prone. The idea th us is that higher values\nof NOC suggest a higher complexity of the class.\nCBO is the main coupling metric for object-oriented systems . Two classes are\ncoupled if a method of one class uses a method or state variabl e of the other class.\nThe CBO is a count of the number of other classes with which it i s coupled. As with\nthe traditional coupling metric, high values of CBO suggest tight bindings with other\ncomponents, and this is undesirable.\nIn the deﬁnition of CBO,", "token_count": 512, "start_token": 199122, "end_token": 199634, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 432, "text": " the number of other classes with which it i s coupled. As with\nthe traditional coupling metric, high values of CBO suggest tight bindings with other\ncomponents, and this is undesirable.\nIn the deﬁnition of CBO, all couplings are considered equal. However, if we look\nat the different ways in which classes may be coupled, it is re asonable to say that:\n– access to state variables is worse than mere parameter pass ing;\n– access to elements of a foreign class is worse than access to elements of a\nsuperclass;\n– passing many complex parameters is worse than passing a few simple parameters;\n– messages that conform to Demeter’s Law 4 are better than those which don’t.\nIf we view the methods as bubbles, and the couplings as connec tions between\nbubbles, CBO simply counts the number of connections for eac h bubble. In reality,\nwe consider some types of couplings worse than others: some c onnections are ‘thicker’\nthan others, and some connections are to bubbles ‘further aw ay’. For the representation\n4 The Law of Demeter is a generally-accepted design heuristic for object-oriented systems. It says that\nthe methods of a class should only depend on the top-level str ucture of their own class. More speciﬁcally,\nin the context of a class C with method M, M should only send mes sages to:\n– the parameters of C, or\n– the state variables of C, or\n– C itself.\n12.1. DESIGN CONSIDERATIONS 341\ncondition of measurement theory to hold, these empirical relations sh ould be reﬂected\nin the numerical relation system.\nMartin (2002) deﬁnes coupling measures at the package level :\n/AF The afferent coupling (/BV\n/CP\n) of a package /C8 is the number of other packages\nthat depend upon classes within /C8 (through inheritance or associations). It\nindicates the dependence of a package on its environment.\n/AF The efferent coupling (/BV\n/CT\n) of a package /C8 is the number of packages that\nclasses within /C8 depend upon. It indicates the dependence of the environment\non a package.\nAdding these numbers together results in a total coupling me asure", "token_count": 512, "start_token": 199584, "end_token": 200096, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 433, "text": "/CT\n) of a package /C8 is the number of packages that\nclasses within /C8 depend upon. It indicates the dependence of the environment\non a package.\nAdding these numbers together results in a total coupling me asure of a package /C8 .\nThe ratio /C1 /BP /BV\n/CT\n/BP /B4 /BV\n/CT\n/B7 /BV\n/CP\n/B5 indicates the relative dependence of the environment\nto /C8 with respect to the total number of dependencies between P an d its environment.\nIf /BV\n/CT\nequals zero, /C8 does not depend at all on other packages. Then, /C1 /BP /BC as well.\nIf on the other hand /BV\n/CP\nequals zero, /C8 only depends on other packages, and no\nother package depends on /C8 . In that case, /C1 /BP /BD . /C1 thus can be seen as an instability\nmeasure for /C8 . Larger values of /C1 denote a larger instability of the package.\nRFC measures the ‘immediate surroundings’ of a class. Suppo se a class /BV has a\ncollection of methods /C5 . Each method from /C5 may in turn call other methods, from\n/BV or any other class. Let /CU /CA\n/CX\n/CV be the set of methods called from method /C5\n/CX\n. Then\nthe response set of this class is deﬁned as: /CU /C5 /CV /CJ\n/CX\n/CU /CA\n/CX\n/CV , i.e. the set of messages that\nmay potentially be executed if a message is sent to an object o f class /BV . RFC is deﬁned\nas the number of elements in the response set. Note that we onl y count method calls\nup to one level deep. Larger values of RFC means that the immed iate surroundings of\na class is larger in size. There is, then, a lot of communicati on with other methods\nor classes. This makes comprehension of a class more difﬁcul t and increases test time\nand complexity.\nThe ﬁnal object-oriented metric to be discussed is", "token_count": 512, "start_token": 200046, "end_token": 200558, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 434, "text": " lot of communicati on with other methods\nor classes. This makes comprehension of a class more difﬁcul t and increases test time\nand complexity.\nThe ﬁnal object-oriented metric to be discussed is the lack o f cohesion of a\nmethod. The traditional levels of cohesion express the degr ee of mutual afﬁnity of the\ncomponents of a module. It is a measure of the glue that keeps t he module together.\nIf all methods of a class use the same state variables, these s tate variables serve as\nthe glue which ties the methods together. If some methods use a subset of the state\nvariables, while other methods use another subset of the sta te variables, the class lacks\ncohesion. This may indicate a ﬂaw in the design, and it may be b etter to split it into\ntwo or more subclasses. LCOM is the number of disjoint sets of methods of a class.\nAny two methods in the same set share at least one local state v ariable. The preferred\nvalue for LCOM is 0.\nThere are obviously many more metrics that aim to address the speciﬁcs of\nobject-oriented systems. Most of these have not been valida ted extensively, though.\nSeveral experiments have shown that the above set does have s ome merit. Overall,\nWMC, CBO, RFC and LCOM have been found to be the more useful qua lity\nindicators. These metrics for example were able to predict f ault-proneness of classes\n342 SOFTWARE DESIGN\nduring design, and were found to have a strong relationship w ith maintenance effort.\nThe merits of DIT and NCO remain somewhat unclear.\nNote that many of these metrics are correlated with class siz e. One may expect\nthat larger classes have more methods, have more descendant s, have more couplings\nwith other classes, etc. El Emam et al. (2001) indeed found th at class size has a\nconfounding effect on the values of the above metrics. It thu s remains questionable\nwhether these metrics tell more than a plain LOC count.\n12.2 Classical Design Methods\nHaving discussed the properties of a good system decomposit ion, we now come to\na question which is at least as important: how do you get a good decomposition to\nstart with?\n", "token_count": 512, "start_token": 200508, "end_token": 201020, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 435, "text": ".\n12.2 Classical Design Methods\nHaving discussed the properties of a good system decomposit ion, we now come to\na question which is at least as important: how do you get a good decomposition to\nstart with?\nThere exist a vast number of design methods, a sample of which is given in\ntable 12.3. These design methods generally consist of a set o f guidelines, heuristics,\nand procedures on how to go about designing a system. They als o offer a notation to\nexpress the result of the design process. Together these pro vide a systematic means for\norganizing and structuring the design process and its produ cts.\n12.2. CLASSICAL DESIGN METHODS 343\ncontinued on next page\nTable 12.3 A sample of design methods\nDecision tables Matrix representation of complex decision logic at the detailed\ndesign level.\nE--R Entity--Relationship Model. Family of graphical tech niques for\nexpressing data-relationships; see also chapter 10.\nFlowcharts Simple diagram technique to show control ﬂow at t he detailed\ndesign level. Exists in many ﬂavors; see (Tripp, 1988) for an\noverview.\nFSM Finite State Machine. A way to describe a system as a set of\nstates and possible transitions between those states; the r esulting\ndiagrams are called state transition diagrams; see also cha pter 10.\nJSD Jackson System Development; see section 12.2.3. Succes sor to,\nand more elaborate than, JSP; has an object-oriented ﬂavor.\nJSP Jackson Structured Programming. Data-structure-orie nted\nmethod; see section 12.2.3.\nLCP Logical Construction of Programs, also known as the Warn ier--\nOrr method; data-structure-oriented, similar to JSP.\nNoteCards Example hypertext system. Hypertext systems mak e it possible\nto create and navigate through a complex organization of\nunstructured pieces of text (Conklin, 1987).\nOBJ Algebraic speciﬁcation method; highly mathematical (G oguen,\n1986).\nOOD Object-oriented design; exists in many ﬂavors; see sect ion 12.3.\nPDL Program Design Language; example of a constrained n", "token_count": 512, "start_token": 200970, "end_token": 201482, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 436, "text": "�cation method; highly mathematical (G oguen,\n1986).\nOOD Object-oriented design; exists in many ﬂavors; see sect ion 12.3.\nPDL Program Design Language; example of a constrained natur al\nlanguage (‘structured English’) to describe designs at var ious\nlevels of abstraction. Offers the control constructs gener ally\nfound in programming languages. See (Pintelas and Kallistr os,\n1989) for an overview.\n344 SOFTWARE DESIGN\nPetri nets Graphical design representation, well-suited f or concurrent sys-\ntems. A system is described as a set of states and possible\ntransitions between those states. States are associated wi th\ntokens and transitions are described by ﬁring rules. In this way,\nconcurrent activities can be synchronized (Peterson, 1981 ).\nSA/SD Structured Analysis/Structured Design. Data ﬂow des ign tech-\nnique; see also section 12.2.2.\nSA/RT Extension to Structured Analysis so that real-time as pects can\nbe described (Hatley and Pirbhai, 1988).\nSSADM Structured Systems Analysis and Design Method. A high ly\nprescriptive method for performing the analysis and design\nstages; UK standard (Downs et al., 1992).\nFor some methods, such as FSM or Petri nets, emphasis is on the notation, while the\nguidelines on how to tackle design are not very well develope d. Methods like JSD,\non the other hand, offer extensive prescriptive guidelines as well. Most notations are\ngraphical and somewhat informal, but OBJ uses a very formal m athematical language.\nSome methods concentrate on the design stage proper, while o thers are part of a\nwider methodology covering other life cycle phases as well. Examples of the latter\nare SSADM and JSD. Finally, some methods offer features that make them especially\nuseful for the design of certain types of application, such a s SA/RT (real-time systems)\nor Petri nets (concurrent systems).\nIn the following subsections we discuss three classical des ign methods:\n/AF Functional decomposition, which is a rather general approa ch to system\ndesign. It is not tied to any speciﬁc method listed in", "token_count": 512, "start_token": 201432, "end_token": 201944, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 437, "text": " systems).\nIn the following subsections we discuss three classical des ign methods:\n/AF Functional decomposition, which is a rather general approa ch to system\ndesign. It is not tied to any speciﬁc method listed in table 12 .3. Many different\nnotations can be used to depict the resulting design, rangin g from ﬂowcharts\nor pseudocode to algebraic speciﬁcations.\n/AF Data ﬂow design, as exempliﬁed by SA/SD.\n/AF Design based on data structures, as is done in JSP, LCP and JSD .\nA fourth design method, object-oriented design, is discuss ed in section 12.3. Whereas\nthe above three methods concentrate on identifying the functions of the system, object-\noriented design focuses on the data on which the system is to operate. Object-oriented\ndesign is the most popular design approach today, not the lea st because of the\nomnipresence of UML as a notational device for the outcome of both requirements\nengineering and design.\n12.2.1 Functional Decomposition\nIn a functional decomposition the intended function is deco mposed into a number\nof subfunctions that each solve part of the problem. These su bfunctions themselves\n12.2. CLASSICAL DESIGN METHODS 345\nmay be further decomposed into yet more primitive functions , and so on. Functional\ndecomposition is a design philosophy rather than a design me thod. It denotes an\noverall approach to problem decomposition which underlies many a design method.\nWith functional decomposition we apply divide-and-conquer tactics. These\ntactics are analogous to, but not the same as, the technique o f stepwise reﬁnement as\nit is applied in programming-in-the-small. Using stepwise reﬁnement, the reﬁnements\ntend to be context-dependent. As an example, consider the fo llowing pseudo-code\nalgorithm to insert an element into a sorted list:\nprocedure insert(a, n, x);\nbegin insert x at the end of the list;\nk:= n + 1;\nwhile element\n/CZ\nis not at its proper place\ndo swap element\n/CZ\nand element\n/C", "token_count": 512, "start_token": 201894, "end_token": 202406, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 438, "text": ", x);\nbegin insert x at the end of the list;\nk:= n + 1;\nwhile element\n/CZ\nis not at its proper place\ndo swap element\n/CZ\nand element\n/CZ\n/A0 /BD ;\nk:= k-1\nenddo;\nend insert;\nThe reﬁnement of a pseudo-code instruction like element\n/CZ\nis not at its proper\nplace is done within the context of exactly the above routine, usin g knowledge of\nother parts of this routine. In the decomposition of a large s ystem, it is precisely this\ntype of dependency that we try to avoid. The previous section addressed this issue at\ngreat length.\nDuring requirements engineering the base machine has been d ecided upon. This\nbase machine need not be a ‘real’ machine. It can be a programm ing language or\nsome other set of primitives that constitutes the bottom lay er of the design. During\nthis phase too, the functions to be provided to the user have b een ﬁxed. These are\nthe two ends of a rope. During the design phase we try to get fro m one end of this\nrope to the other. If we start from the user function end and ta ke successively more\ndetailed design decisions, the process is called top-down d esign. The reverse is called\nbottom-up design.\nTop-down design Starting from the main user functions at the top, we work down\ndecomposing functions into subfunctions. Assuming we do no t make any mistakes\non the way down, we can be sure to construct the speciﬁed syste m. With top-down\ndesign, each step is characterized by the design decisions i t embodies. To be able to\napply a pure top-down technique, the system has to be fully de scribed. This is hardly\never the case. Working top-down also means that the earliest decisions are the most\nimportant ones. Undoing those decisions can be very costly.\nBottom-up design Using bottom-up design, we start from a set of available base\nfunctions. From there we proceed towards the requirements s peciﬁcation through\nabstraction. This technique is potentially more ﬂexible, e specially since the lower\nlayers of the design could", "token_count": 512, "start_token": 202356, "end_token": 202868, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 439, "text": " of available base\nfunctions. From there we proceed towards the requirements s peciﬁcation through\nabstraction. This technique is potentially more ﬂexible, e specially since the lower\nlayers of the design could be independent of the application and thus have wider\napplicability. This is especially important if the require ments have not been formulated\n346 SOFTWARE DESIGN\nvery precisely yet, or if a family of systems has to be develop ed. A real danger of the\nbottom-up technique is that we may miss the target.\nIn its pure form, neither the top-down nor the bottom-up tech nique is likely to be\nused all that often. Both techniques are feasible only if the design process is a pure\nand rational one. And this is an idealization of reality. The re are many reasons why\nthe design process cannot be rational. Some of these have to d o with the intangibles\nof design processes per se, some originate from accidents th at happen to befall many\na software project. Parnas and Clements (1986) list the foll owing reasons, amongst\nothers:\n– Mostly, users do not know exactly what they want and they are not able to tell\nall they know.\n– Even if the requirements are fully known, a lot of additiona l information is\nneeded. This information is discovered only when the projec t is under way.\n– Almost all projects are subject to change. Changes inﬂuenc e earlier decisions.\n– People make errors.\n– During design, people use the knowledge they already have, experiences from\nearlier projects, and the like.\n– In many projects we do not start from scratch, but we build fr om existing\nsoftware.\nDesign exhibits a ‘yo-yo’ character: something is devised, tried, rejected again, new\nideas crop up, etc. Designers frequently go about in rather o pportunistic ways. They\nfrequently switch from high-level application domain issu es to coding and detailed\ndesign matters, and use a variety of means to gather insight i nto the problem to be\nsolved. At most, we may present the result of the design proce ss as if it came about\nthrough a rational process.\nA general problem with any form of functional decomposition is that it is often\nnot immediately clear along which dimension the system is de composed", "token_count": 512, "start_token": 202818, "end_token": 203330, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 440, "text": " we may present the result of the design proce ss as if it came about\nthrough a rational process.\nA general problem with any form of functional decomposition is that it is often\nnot immediately clear along which dimension the system is de composed. If we\ndecompose along the time-axis, the result is often a main pro gram that controls the\norder in which a number of subordinate modules is called. In Y ourdon’s classiﬁcation,\nthe resulting cohesion type is temporal. If we decompose wit h respect to the grouping\nof data, we obtain the type of data cohesion exhibited in abst ract data types. Both\nthese functional decompositions can be viewed as an instanc e of some architectural\nstyle. Rather than worrying about which dimension to focus o n during functional\ndecomposition, you had better opt for a particular architec tural style and let that style\nguide the decomposition.\nAt some intermediate level, the set of interrelated compone nts comprises the\nsoftware architecture as discussed in chapter 11. This soft ware architecture is a\nproduct which serves various purposes: it can be used to disc uss the design with\n12.2. CLASSICAL DESIGN METHODS 347\ndifferent stakeholders; it can be used to evaluate the quali ty of the design; it can\nbe the basis for the work breakdown structure; it can be used t o guide the testing\nprocess, etc. If a software architecture is required, it nec essitates a design approach in\nwhich, at quite an early stage, each and every component and c onnection is present.\nA bottom-up or top-down approach does not meet this requirem ent, since in both\nthese approaches only part of the solution is available at in termediate points in time.\nParnas (1978) offers the following useful guidelines for a s ound functional\ndecomposition:\n1. Try to identify subsystems. Start with a minimal subset and deﬁne minimal\nextensions to this subset.\nThe idea behind this guideline is that it is extremely difﬁcu lt, if not impossible,\nto get a complete picture of the system during requirements e ngineering. People\nask too much or they ask the wrong things. Starting from a mini mal subsystem,\nwe may add functionality incrementally, using the experien ce gained with the\nactual use of the system.", "token_count": 512, "start_token": 203280, "end_token": 203792, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 441, "text": " the system during requirements e ngineering. People\nask too much or they ask the wrong things. Starting from a mini mal subsystem,\nwe may add functionality incrementally, using the experien ce gained with the\nactual use of the system. The idea is very similar to that of ag ile approaches,\ndiscussed in chapter 3.\n2. Apply the information hiding principle.\n3. Try to deﬁne extensions to the base machine step by step. Th is holds for\nboth the minimal machine and its extensions. Such increment al extensions\nlead to the concept of a virtual machine . Each layer in the system hierarchy\ncan be viewed as a machine. The primitive operations of this m achine are\nimplemented by the lower layers of the hierarchy. This machi ne view of the\nmodule hierarchy nicely maps onto a layered architectural s tyle. It also adds a\nfurther dimension to the system structuring guidelines off ered in section 12.1.5.\n4. Apply the uses-relation and try to place the dependencies thus obtained in a\nhierarchical structure.\nObviously, the above guidelines are strongly interrelated . It has been said before\nthat a strictly hierarchical tree structure of system compo nents is often not feasible.\nA compromise that often is feasible is a layered system struc ture as depicted in\nﬁgure 12.7.\nThe arrows between the various nodes in the graph indicate th e uses-relation.\nVarious levels can be distinguished in the structure depict ed. Components at a given\nlevel only use components from the same, or lower, levels. Th e layers distinguished\nin this picture are not the same as those induced by the acycli city of the graph\n(as discussed in section 12.1.5) but are rather the result of viewing a distinct set of\nmodules as an abstract, virtual machine. Deciding how to gro up modules into layers\nin this way involves considering the semantics of those modu les. Lower levels in this\nhierarchy bring us closer to the ‘real’ machine on which the s ystem is going to be\nexecuted. Higher levels are more application-oriented. Th e choice of the number of\nlevels in such an architecture is a, problem-dependent, des ign decision.\n348 SOFTWARE DESIGN\nFigure 12.7 A layered system structure\nThis work of Parnas heralds some of the notions that", "token_count": 512, "start_token": 203742, "end_token": 204254, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 442, "text": " choice of the number of\nlevels in such an architecture is a, problem-dependent, des ign decision.\n348 SOFTWARE DESIGN\nFigure 12.7 A layered system structure\nThis work of Parnas heralds some of the notions that were late r recognized\nas important guiding principles in the ﬁeld of software arch itecture. The idea of a\nminimal subset to which extensions are deﬁned is very simila r to the notion of a\nproduct-line architecture: a basic architecture from whic h a family of similar systems\ncan be derived. The layered approach is one of the basic archi tectural styles discussed\nin section 11.4.\n12.2.2 Data Flow Design (SA/SD)\nThe data ﬂow design method originated in the early 1970s with Yourdon and\nConstantine. In its simplest form, data ﬂow design is but a fu nctional decomposition\nwith respect to the ﬂow of data. A component (module) is a blac k box which\ntransforms some input stream into some output stream. In dat a ﬂow design, heavy\nuse is made of graphical representations known as Data Flow D iagrams (DFD) and\nStructure Charts. Data ﬂow diagrams were introduced as a mod eling notation in\nsection 10.1.3.\nData ﬂow design is usually seen as a two-step process. First, a logical design\nis derived in the form of a set of data ﬂow diagrams. This step i s referred to\nas Structured Analysis (SA). Next, the logical design is transformed into a program\nstructure represented as a set of structure charts. The latt er step is called Structured\nDesign (SD). The combination is referred to as SA/SD.\nStructured Analysis can be viewed as a proper requirements a nalysis method\ninsofar it addresses the modeling of some Universe of Discou rse. It should be noted\nthat, as data ﬂow diagrams are reﬁned, the analyst performs a n implicit (top-down)\nfunctional decomposition of the system as well. At the same t ime, the diagram\n12.2. CLASSICAL DESIGN METHODS 349\nreﬁnements result in corresponding data reﬁnements. The an alysis", "token_count": 512, "start_token": 204204, "end_token": 204716, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 443, "text": " the system as well. At the same t ime, the diagram\n12.2. CLASSICAL DESIGN METHODS 349\nreﬁnements result in corresponding data reﬁnements. The an alysis process thus has\ndesign aspects as well.\nStructured Design, being a strategy to map the information ﬂ ow contained in\ndata ﬂow diagrams into a program structure, is a genuine comp onent of the (detailed)\ndesign phase.\nThe main result of Structured Analysis is a series of data ﬂow diagrams. Four types\nof data entity are distinguished in these diagrams:\nExternal entities are the source or destination of a transaction. These entiti es are\nlocated outside the domain considered in the data ﬂow diagra m. External entities are\nindicated as squares.\nProcesses transform data. Processes are denoted by circles.\nData ﬂows between processes, external entities and data stores. A dat a ﬂow is\nindicated by an arrow. Data ﬂows are paths along which data st ructures travel.\nData stores lie between two processes. This is indicated by the name of th e data store\nbetween two parallel lines. Data stores are places where dat a structures are stored\nuntil needed.\nWe will illustrate the various process steps of SA/SD by anal yzing and designing a\nsimple library automation system. The system allows librar y clients to borrow and\nreturn books. It also reports to library management about ho w the library is used by\nits clients (for example, the average number of books on loan and authors much in\ndemand).\nAt the highest level we draw a context diagram . A context diagram is a data ﬂow\ndiagram with one process, denoting ‘the system’. Its main pu rpose is to depict the\ninteraction of the system with the environment (the collect ion of external entities).\nFor our simple library system this is done in ﬁgure 12.8. This diagram has yet to be\nsupplemented by a description of the structure of both the in put and output to the\ncentral process.\nFigure 12.8 Context diagram for library automation\nNext, this top-level diagram is further decomposed. For our example, this could\nlead to the data ﬂow diagram of ﬁgure 12.", "token_count": 512, "start_token": 204666, "end_token": 205178, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 444, "text": "central process.\nFigure 12.8 Context diagram for library automation\nNext, this top-level diagram is further decomposed. For our example, this could\nlead to the data ﬂow diagram of ﬁgure 12.9. In this diagram, we have expanded the\n350 SOFTWARE DESIGN\nFigure 12.9 Data ﬂow diagram for library automation\ncentral process node of the context diagram. A client reques t is ﬁrst analyzed in a\nprocess labeled ‘preliminary processing’. As a result, one of ‘borrow title’ or ‘return title’\nis activated. Both these processes update a data store label ed ‘catalog administration’.\nClient requests are logged in a data store ‘log ﬁle’. This dat a store is used to produce\nmanagement reports.\nFor more complicated applications, various diagrams could be drawn, one for each\nsubsystem identiﬁed. These subsystems in turn are further d ecomposed into diagrams\nat yet lower levels. We thus get a hierarchy of diagrams. As an example, a possible\nreﬁnement of the ‘preliminary processing’ node is given in ﬁ gure 12.10. In the lower\nlevel diagrams also, the external entities are usually omit ted.\nThe top-down decomposition stops when a process becomes suf ﬁciently straight-\nforward and does not warrant further expansion. These primi tive processes are\n12.2. CLASSICAL DESIGN METHODS 351\nFigure 12.10 Data ﬂow diagram for ‘preliminary processing’\ndescribed in minispecs. A minispec serves to communicate the algorithm of the proce ss\nto relevant parties. It may use notations like structured na tural language, pseudocode,\nor decision tables. Example screen layouts can be added to il lustrate how the input\nand output will look. An example minispec for the process lab eled ‘process request’ is\ngiven in ﬁgure 12.11.\nIdentiﬁcation: Process request\nDescription:\n1. Enter type of request\n1.1 If invalid, issue a warning and repeat step 1\n1.2 If step 1 has been repeated ﬁve times, terminate the trans action\n", "token_count": 512, "start_token": 205128, "end_token": 205640, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 445, "text": "�cation: Process request\nDescription:\n1. Enter type of request\n1.1 If invalid, issue a warning and repeat step 1\n1.2 If step 1 has been repeated ﬁve times, terminate the trans action\n2. Enter book identiﬁcation\n2.1 If invalid, issue a warning and repeat step 2\n2.2 If step 2 has been repeated ﬁve times, terminate the trans action\n3. Log the client identiﬁcation, request type and book ident iﬁcation\n4. . . .\nFigure 12.11 Example minispec for ’process request’\nThe contents of the data ﬂows in a DFD are recorded in a data dic tionary. Though\nthis name suggests something grand, it is nothing more than a precise description of\nthe structure of the data. This is often done in the form of reg ular expressions, like the\n352 SOFTWARE DESIGN\nexample in ﬁgure 12.12. Nowadays, the static aspects of the d ata tend to be modeled\nin ER diagrams; see chapter 10.\nborrow-request = client-id /B7 book-id\nreturn-request = client-id /B7 book-id\nlog-data = client-id /B7 [borrow /CY return] /B7 book-id\nbook-id = author-name /B7 title /B7 (isbn) /B7 [proc /CY series /CY other]\nConventions: [ ] means: include one of the enclosed options; /B7 means: AND; ()\nmeans: enclosed items are optional; options are separated b y /CY\nFigure 12.12 Example data dictionary entries\nFigure 12.13 From data ﬂow diagram to structure chart\nThe result of Structured Analysis is a logical model of the sy stem. It consists of a\nset of DFDs, augmented by descriptions of its constituents i n the form of minispecs,\nformats of data stores, and so on. In the subsequent Structur ed Design step, the data\nﬂow diagrams are transformed into a collection of modules (s ubprograms) that call\none another and pass data. The result of the Structured Desig n step is expressed in\na hierarchical set of structure charts . There are no strict", "token_count": 512, "start_token": 205590, "end_token": 206102, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 446, "text": "�ow diagrams are transformed into a collection of modules (s ubprograms) that call\none another and pass data. The result of the Structured Desig n step is expressed in\na hierarchical set of structure charts . There are no strict rules for this step. Text\nbooks on the data ﬂow technique give guidelines, and sometim es even well-deﬁned\nstrategies, for how to get from a set of data ﬂow diagrams to a h ierarchical model\nfor the implementation. These guidelines are strongly insp ired by the various notions\ndiscussed in section 12.1, most notably cohesion and coupli ng.\nThe major heuristic involves the choice of the top-level str ucture chart. Many\ndata-processing systems are essentially transform-cente red. Input is read and possibly\nedited, a major transformation is done, and the result is out put. One way to decide\nupon the central transformation is to trace the input throug h the data ﬂow diagram\n12.2. CLASSICAL DESIGN METHODS 353\nuntil it can no longer be considered input. The same is done, i n the other direction,\nfor the output. The bubble in between acts as the central transform . If we view the\nbubbles in a DFD as beads, and the data ﬂows as threads, we obta in the corresponding\nstructure chart by picking the bead that corresponds to the c entral transformation\nand shaking the DFD. 5 The processes in the data ﬂow diagram become the modules\nof the corresponding structure chart and the data ﬂows becom e module calls. Note\nthat the arrows in a structure chart denote module calls, whe reas the arrows in a data\nﬂow diagram denote ﬂows of data. These arrows often point in o pposite directions;\na ﬂow of data from A to B is often realized through a call of B to A . Sometimes it\nis difﬁcult to select one central transformation. In that ca se, a dummy root element\nis added and the resulting Input--Process--Output scheme i s of the form depicted in\nﬁgure 12.13.\nBecause of the transformation orientation of the structure chart, the relations\nbetween modules in the graph have a producer--consumer char acter. One module\nproduces", "token_count": 512, "start_token": 206052, "end_token": 206564, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 447, "text": " i s of the form depicted in\nﬁgure 12.13.\nBecause of the transformation orientation of the structure chart, the relations\nbetween modules in the graph have a producer--consumer char acter. One module\nproduces a stream of data which is then consumed by another mo dule. The control\nﬂow is one whereby modules call subordinate modules so as to r ealize the required\ntransformation. There is a potentially complex stream of in formation between\nmodules, corresponding to the data ﬂow that is passed betwee n producer and\nconsumer. The major contribution of Structured Design is fo und in the guidelines\nthat aim to reduce the complexity of the interaction between modules. These\nguidelines concern the cohesion and coupling criteria disc ussed in section 12.1.\n12.2.3 Design based on Data Structures\nThe best-known technique for design based on data structure s originates with Michael\nJackson. The technique is known as Jackson Structured Progr amming (JSP). Essentials\nof JSP have been carried over to Jackson System Development ( JSD). JSP is a technique\nfor programming-in-the-small and JSD is a technique for pro gramming-in-the-large.\nWe will discuss both techniques in turn.\nThe basic idea of JSP is that a good program reﬂects the struct ure of both the\ninput and the output in all its facets. Given a correct model o f these data structures, we\nmay straightforwardly derive the corresponding program fr om the model. It is often\npostulated that the structure of the data is much less volati le than the transformations\napplied to the data. As a consequence, designs that take the d ata as their starting\npoint should be ‘better’ too. This same argument is also used in the context of\nobject-oriented analysis and design.\nJSP distinguishes elementary and compound components. Ele mentary compo-\nnents are not further decomposed. There are three types of co mpound component:\nsequence, iteration and selection. Compound components ar e represented by dia-\ngrams (also called Jackson diagrams or structure diagrams ) or some sort of pseudocode\n(called structure text or schematic logic ). The base forms of both are given in\n5 We do the same when turning a free tree into an oriented tree. A free tree has", "token_count": 512, "start_token": 206514, "end_token": 207026, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 448, "text": " Jackson diagrams or structure diagrams ) or some sort of pseudocode\n(called structure text or schematic logic ). The base forms of both are given in\n5 We do the same when turning a free tree into an oriented tree. A free tree has no root. By selecting\none node of the tree as the root, the parent--child relations are brought about.\n354 SOFTWARE DESIGN\nﬁgure 12.14. In the structure text, ‘seq’ denotes sequencin g, ‘itr’ denotes iteration, ‘sel’\ndenotes selection, and ‘alt’ denotes alternatives.\nFigure 12.14 Compound components in Jackson’s notation\nMost modern programming languages have structures (loops, if-statements and\nsequential composition) for each of these diagrammatic not ations or, for that matter,\nthe corresponding pseudocode for the structure of data. The essence of Jackson’s\ntechnique is that the structure diagrams of the input and out put can be merged, thus\nyielding the global structure of the program.\nTo illustrate this line of thought, consider the following f ragment from a library\nsystem. The system keeps track of which books from which auth ors are being\nborrowed (and returned). From this log, we want to produce a r eport which lists how\noften each title is borrowed. Using Jackson’s notation, the input for this function\ncould be as speciﬁed in ﬁgure 12.15. 6 A possible structure for the output is given in\nﬁgure 12.16.\nThe program diagram to transform the log into a report is now o btained by\nmerging the two diagrams; see ﬁgure 12.17. The structure of t he resulting program\ncan be derived straightforwardly from this diagram, and is o f the form given in\nﬁgure 12.18.\nThis merging of diagrams does not work for the lower levels of our problem:\n‘process mutation’ and its subordinate nodes. The cause is s omething called a structure\nclash: the input and output data structures do not really match. Th e reason is that\nthe input consists of a sequence of mutations. In the output, all mutations for one\n6 For simplicity’s sake, we have assumed that the input is alre ady", "token_count": 512, "start_token": 206976, "end_token": 207488, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 449, "text": " data structures do not really match. Th e reason is that\nthe input consists of a sequence of mutations. In the output, all mutations for one\n6 For simplicity’s sake, we have assumed that the input is alre ady sorted by author.\n12.2. CLASSICAL DESIGN METHODS 355\nFigure 12.15 Log of books borrowed and returned, in JSP notat ion\ngiven book are taken together. So, the mutations have to be so rted ﬁrst. We have to\nrestructure the system, for instance as depicted in ﬁgure 12 .19.\nA clear disadvantage of the structure thus obtained is that t here is now an\nintermediate ﬁle. Closer inspection shows that we do not rea lly need this ﬁle. This is\nimmediately clear if we depict the structure as in ﬁgure 12.2 0.\nHere, we may invert component A1 and code it such that it serves as a replacement\nof component B2. Alternatively (and in this case more likely ), we may invert B1\nand substitute the result for component A2. In either case, t he ﬁrst-in-ﬁrst-out type\nof intermediate ﬁle between the two components is removed by making one of the\ncomponents a subordinate of the other.\nThis example shows the fundamental issues involved in the us e of JSP:\n1. Modeling input and output using structure diagrams,\n2. Merging the diagrams to create the program structure, mea nwhile\n3. Resolving possible structure clashes, and ﬁnally\n356 SOFTWARE DESIGN\nFigure 12.16 Report of books borrowed, in JSP notation\n4. Optimizing the result through program inversion.\nIf we choose a linear notation for the structure diagrams, th e result falls into the class\nof ‘regular expressions’. Thus, the expressive power of the se diagrams is that of a ﬁnite\nautomaton. Some of the structure clashes crop up if the probl em cannot be solved by\na ﬁnite automaton.\nBoth in the functional decomposition and in the data ﬂow desi gn methods, the\nproblem structure is mapped onto a functional structure. Th is functional structure is\nnext mapped onto a program structure. In contrast,", "token_count": 512, "start_token": 207438, "end_token": 207950, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 450, "text": " automaton.\nBoth in the functional decomposition and in the data ﬂow desi gn methods, the\nproblem structure is mapped onto a functional structure. Th is functional structure is\nnext mapped onto a program structure. In contrast, JSP maps t he problem structure\nonto a data structure and the program structure is derived fr om this data structure.\nJSP is not much concerned with the question of how the mapping from problem\nstructure to data structure is to be obtained.\nJackson System Development (JSD) tries to ﬁll this gap. JSD d istinguishes three\nstages in the software development process:\n/AF A modeling stage in which a description is made of the real-world problem\nthrough the identiﬁcation of entities and actions;\n/AF A network stage in which the system is modeled as a network of communicating\nconcurrent processes;\n/AF An implementation stage in which the network of processes is transformed\ninto a sequential design.\n12.2. CLASSICAL DESIGN METHODS 357\nFigure 12.17 Result of merging the input and output diagrams\nmake header\nuntil EOF loop\nprocess author:\nuntil end\nof author loop\nprocess mutation:\n. . .\nendloop\nendloop.\nFigure 12.18 Top-level structure of the program to produce a report\nThe ﬁrst step in JSD is to model the part of reality we are inter ested in, the Universe\nof Discourse (UoD). JSD models the UoD as a set of entities, ob jects in the real\nworld that participate in a time-ordered sequence of action s. For each entity a process\n358 SOFTWARE DESIGN\nFigure 12.19 Restructuring of the system\nFigure 12.20 A different view of the system\nis created which models the life cycle of that entity. Action s are events that happen\nto an entity. For instance, in a library the life cycle of an en tity Book could be as\ndepicted in ﬁgure 12.21. The life cycle of a book starts when i t is acquired. After\nthat it may be borrowed and returned any number of times. The l ife cycle ends\nwhen the book is either archived or disposed of. The life cycl e is depicted using\nprocess structure diagrams (PSDs). PSDs are hierarchical diagrams that resemble the\nstructure diagrams", "token_count": 512, "start_token": 207900, "end_token": 208412, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 451, "text": " returned any number of times. The l ife cycle ends\nwhen the book is either archived or disposed of. The life cycl e is depicted using\nprocess structure diagrams (PSDs). PSDs are hierarchical diagrams that resemble the\nstructure diagrams of JSP, with its primitives to denote con catenation (ordering in\ntime), repetition and selection. PSDs have a pseudocode equ ivalent called structure\ntext which looks like the schematic logic of JSP.\nProcess structure diagrams are ﬁnite state diagrams. In tra ditional ﬁnite state\ndiagrams, the bubbles (nodes) represent possible states of the entity being modeled\nwhile the arrows denote possible transitions between state s. The opposite is true for\nPSDs. In a PSD, nodes denote state transitions and arrows den ote states.\nFollowing this line of thought, an entity Member can be described as in\nﬁgure 12.22: members enter the library system, after which t hey may borrow and\nreturn books until they cease to be a member.\nThe modeling stage is concerned with identifying entities a nd the events (actions)\nthat happen to them. These actions collectively constitute the life cycle of an entity.\n12.2. CLASSICAL DESIGN METHODS 359\nFigure 12.21 Process structure diagram for the entity Book\nAs with other design methods, there is no simple recipe to det ermine the set of\nentities and actions. The approach generally taken has a lin guistic stance. From notes,\ndocumentation, interviews and the like, we may draw up a prel iminary list of actions\nand entities. One heuristic is to look for real-world object s with which the system is to\ninteract. Since a library is all about books, an entity Book immediately suggests itself.\nFrom statements like ‘members borrow books’ we may infer tha t an event Borrow\noccurs in the life cycle of both books and members. Once such a preliminary list is\nmade up, further reﬂection should lead to a precisely demarc ated life cycle of the\nentities identiﬁed.\nEntities are made up of actions. These actions are atomic, i. e. they cannot be\nfurther decomposed into subactions. Actions respond to eve nts in the real world. The\naction Acquire that is part of the life cycle of the", "token_count": 512, "start_token": 208362, "end_token": 208874, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 452, "text": " up of actions. These actions are atomic, i. e. they cannot be\nfurther decomposed into subactions. Actions respond to eve nts in the real world. The\naction Acquire that is part of the life cycle of the entity Book is triggered when a\nreal-world event, the actual acquisition of a book, takes pl ace. In the process structure\ndiagram, actions show up as leaf nodes.\nEvents are communicated to the system through data messages , called attributes.\nIn a procedural sense these attributes constitute the param eters of the action. For the\naction Acquire we may have such attributes as ISBN, date-of-acquisition, title and\nauthors.\nEntities have attributes as well: local variables that keep information from the\npast and collectively determine its state. The entity Book for example may retain\nsome or all of the information that was provided upon acquisi tion ( ISBN, title, etc).\n360 SOFTWARE DESIGN\nFigure 12.22 Process structure diagram for the entity Member\nEntities also have two special attributes. First, the identiﬁer attribute uniquely identiﬁes\nthe entity. Second, each entity has an attribute that indica tes its status. This attribute\ncan be viewed as a pointer to some leaf node of the process stru cture diagram.\nEach entity can be viewed as a separate, long-running, proce ss. In the library\nexample, each book and each member has its own life cycle. The processes though are\nnot completely independent. During the network stage, the s ystem is modeled as a net-\nwork of interconnected processes. This network is depicted in a system speciﬁcation\ndiagram (SSD). JSD has two basic mechanisms for interprocess commun ication:\n/AF An entity may inspect the state vector of another entity. This state vector\ndescribes the local state of an entity at some point in time.\n/AF An entity may asynchronously pass information to another en tity through a\ndatastream.\nRecall that the actions Borrow and Return occur in the life cycle of both Book and\nMember (see ﬁgures 12.21 and 12.22). Such common actions create a li nk between\nthese entities. As a consequence, the life cycles of these en tities will be synchronized\nwith respect to these events.\nIf a member wants to borrow a book", "token_count": 512, "start_token": 208824, "end_token": 209336, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 453, "text": "21 and 12.22). Such common actions create a li nk between\nthese entities. As a consequence, the life cycles of these en tities will be synchronized\nwith respect to these events.\nIf a member wants to borrow a book, certain information about that book is\nrequired. A Member entity may obtain that information by inspecting the state\nvector of the appropriate Book entity. This type of communication is indicated by\n12.3. OBJECT-ORIENTED ANALYSIS AND DESIGN METHODS 361\nthe diamond in ﬁgure 12.23. In an implementation, state vect or communication is\nusually handled through database access.\nIf our system is to log information on books being borrowed, w e may model\nthis by means of a datastream from an entity Book to an entity Log. A datastream\nis handled on a FIFO basis; it behaves like the UNIX ﬁlter. The notation for the\ndatastream type of communication is given in ﬁgure 12.24.\nFigure 12.23 State vector communication (SV) between Member and Book\nFigure 12.24 Datastream communication (DS) between Book and Log\nThe ﬁnal stage of JSD is the implementation stage. In the impl ementation stage\nthe concurrent model that is the result of the network stage i s transformed into an\nexecutable system. One of the key concepts for this stage is program inversion :\nthe communication between processes is replaced by a proced ure call, so that one\nprocess becomes a subordinate of another process. This is ve ry similar to the notion\nof program inversion as present in JSP.\n12.3 Object-Oriented Analysis and Design Methods\nThe key concepts that play a\nrole in the object-oriented approach to analysis and design have been mentioned\nalready in chapter 10: objects, their attributes and servic es, and the relationships\nbetween objects. It follows quite naturally from the above t hat the object-oriented\napproach to systems analysis and design involves three majo r steps:\n362 SOFTWARE DESIGN\n1. identify the objects;\n2. determine their attributes and services;\n3. determine the relationships between objects.\nObviously, these steps are highly interrelated and some for m of iteration will be\nneeded before the ﬁnal design is obtained. The resulting pic ture of the system\nas", "token_count": 512, "start_token": 209286, "end_token": 209798, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 454, "text": ";\n3. determine the relationships between objects.\nObviously, these steps are highly interrelated and some for m of iteration will be\nneeded before the ﬁnal design is obtained. The resulting pic ture of the system\nas a collection of objects and their interrelationships des cribes the static structure\n(decomposition) of the system. This static model is graphic ally depicted in some\nvariant of the class diagram as described in section 10.3.1.\nAn object instance is created, updated zero or more times, an d ﬁnally destroyed.\nFinite state diagrams depicting the possible states of an ob ject and the transitions\nbetween those states are a good help in modeling this life cyc le. Object-oriented\nmethods generally use some variant of the state machine diag ram of UML to show\nthis dynamic model of the behavior of system components; see section 10.3 .2.\nComponents of the system communicate by sending messages. T hese messages\nare part of a task that the system has to perform. We may ﬁnd out which messages\nare needed, and in which order they have to be exchanged, by co nsidering typical\nusage scenarios. Scenario analysis is a requirements elici tation technique. In object-\noriented circles, this technique is known as use-case analysis . The resulting model\nof the communication between system components is depicted in a sequence or\ncommunication diagram; see sections 10.3.3 and 10.3.4. The se views are also part of\nthe dynamic model.\nThe guidelines for ﬁnding objects and their attributes and s ervices are mostly\nlinguistic in nature, much like the ones mentioned in our dis cussion of JSD in\nsection 12.2.3. Indeed, the modeling stage of JSD is object- oriented too. The guide-\nlines presented below are loosely based on (Coad and Yourdon , 1991) and (Rumbaugh\net al., 1991). Their general ﬂavor is similar to that found in other object-oriented\napproaches. The global process models of some well-known ob ject-oriented methods\nare discussed in sections 12.3.1--12.3.2.\nThe problem statement for a library automation system given in ﬁgure 12.25 will\nserve as an example to illustrate the major steps in object", "token_count": 512, "start_token": 209748, "end_token": 210260, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 455, "text": "\nare discussed in sections 12.3.1--12.3.2.\nThe problem statement for a library automation system given in ﬁgure 12.25 will\nserve as an example to illustrate the major steps in object-o riented analysis and design.\nWe will elaborate part of this problem in the text, and leave a number of detailed\nissues as exercises.\nA major guiding principle for identifying objects is to look for important concepts\nfrom the application domain. Objects to be found in a library include Books,\nFileCabinets, Customers, etc. In an ofﬁce environment, we may have Folders,\nLetters, Clerks, etc. These domain-speciﬁc entities are our prime candidat es for\nobjects. They may be real-world objects, like books; roles p layed, like the customer of\na library; organizational units, like a department; locati ons, like an ofﬁce; or devices,\nlike a printer. Potential objects can also be found by consid ering existing classiﬁcation\nor assembly (whole-parts) structures. From interviews, do cumentation, and so on, a\nﬁrst inventory of objects can be made.\n12.3. OBJECT-ORIENTED ANALYSIS AND DESIGN METHODS 363\nProblem statement\nDesign the software to support the operation of a public libr ary. The system has a\nnumber of stations for customer transactions. These statio ns are operated by library\nemployees. When a book is borrowed, the identiﬁcation card o f the client is read.\nNext, the station’s bar code reader reads the book’s code. Wh en a book is returned,\nthe identiﬁcation card is not needed and only the book’s code needs to be read.\nClients may search the library catalog from any of a number of PCs located in the\nlibrary. When doing so, the user is ﬁrst asked to indicate how the search is to be\ndone: by author, by title, or by keyword.\n. . .\nSpecial functionality of the system concerns changing the c ontents of the catalog and\nthe handling of ﬁnes. This functionality is restricted to li brary personnel. A password\nis required for these", "token_count": 512, "start_token": 210210, "end_token": 210722, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 456, "text": " or by keyword.\n. . .\nSpecial functionality of the system concerns changing the c ontents of the catalog and\nthe handling of ﬁnes. This functionality is restricted to li brary personnel. A password\nis required for these functions.\n. . .\nFigure 12.25 Problem statement for library automation\nFrom the ﬁrst paragraph of the problem description in ﬁgure 1 2.25, the following\nlist of candidate objects can be deduced, by simply listing a ll the nouns:\nsoftware\nlibrary\nsystem\nstation\ncustomer\ntransaction\nbook\nlibrary employee\nidentiﬁcation card\nclient\nbar code reader\nbook’s code\nSome objects on this candidate list should be eliminated, th ough. Software, e.g.,\nis an implementation construct which should not be included in the model at this\npoint in time. A similar fate should befall terms like algorithm or linked list . At the\ndetailed design stage, there may be reasons to introduce (or reintroduce) them as\nsolution-oriented objects.\nVague terms should be replaced by more concrete terms or elim inated. System is\na vague term in our candidate list. The stations and PCs will b e connected to the same\nhost computer, so we might as well use the notion computer instead of system.\n364 SOFTWARE DESIGN\nCustomer and client are synonymous terms in the problem statement. Only\none of them is therefore retained. We must be careful in how we model client and\nlibrary employee . One physical person may assume both roles. Whether it is use ful\nto model these as distinct objects or as different roles of on e object is difﬁcult to\ndecide at this point. We will treat them as separate objects f or now, but keep in mind\nthat this may change when the model gets reﬁned.\nThe term transaction refers to an operation applied to objects, rather than an\nobject in itself. It involves a sequence of actions such as ha nding an identiﬁcation\ncard and a book copy to the employee, inserting the identiﬁca tion card in the station,\nreading the book’s bar code, and so on. Only if the transactio ns themselves have\nfeatures which are important to the system, should they be mo deled as objects. For\ninstance, if the system has to produce", "token_count": 512, "start_token": 210672, "end_token": 211184, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 457, "text": "\nreading the book’s bar code, and so on. Only if the transactio ns themselves have\nfeatures which are important to the system, should they be mo deled as objects. For\ninstance, if the system has to produce proﬁle information ab out client preferences, it\nis useful to have an object transaction.\nThe term book is a bit tricky in this context. A book in a library system may\ndenote both a physical copy and an abstract key denoting a par ticular /CU author, title /CV\ncombination. The former meaning is intended when we speak ab out the borrowing\nof a book, while the latter is intended where it concerns entr ies in the library catalog.\nInexperienced designers may equate these interpretations and end up with the wrong\nsystem. We are interested (in this part of the system) in mode ling book copies.\nThe last entry to be dropped from the list is book’s code . This term describes\nan individual object rather than a class of objects. It shoul d be restated as an attribute\nof an object, to wit book copy .\nFigure 12.26 lists the relationships between objects that c an be inferred from\nthe problem statement. These relationships are directly co pied from the problem\nstatement, or they are part of the tacit knowledge we have of t he domain.\nThe resulting objects and relationships are included in the initial class diagram of\nﬁgure 12.27. We have only included the names of the relations hips in this diagram.\nFurther adornments, such as cardinality constraints and ge neralization/specialization\ninformation, may be included when the model gets reﬁned.\nWe next identify the attributes of objects. Attributes desc ribe an instance of an\nobject. Collectively, the attributes constitute the state of the object. Attributes are\nidentiﬁed by considering the characteristics that disting uish individual instances, yet\nare common properties of the instances of an object type. We t hereby look for atomic\nattributes rather than composite ones. For our library cust omer, we would for example\nobtain attributes Name and Address rather than a composite attribute NameAn-\ndAddress. At this stage, we also try to prevent redundancies in the set of attributes.\nSo rather than having attributes BooksOnLoan and NumberOfBooksOnLoan, we\nsettle for the former", "token_count": 512, "start_token": 211134, "end_token": 211646, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 458, "text": " attribute NameAn-\ndAddress. At this stage, we also try to prevent redundancies in the set of attributes.\nSo rather than having attributes BooksOnLoan and NumberOfBooksOnLoan, we\nsettle for the former only, since the latter can be computed f rom that attribute.\nThe major services provided by an object are those that relat e to its life cycle. For\nexample, a copy of a book is acquired, is borrowed and returne d zero or more times,\nand ﬁnally it goes out of circulation. A person becomes a memb er of the library and\nmay borrow and return books, reserve titles, change address , pay ﬁnes, and so on,\nuntil he ﬁnally ceases to be a member.\n12.3. OBJECT-ORIENTED ANALYSIS AND DESIGN METHODS 365\nFrom the problem statement:\nemployee operates station\nstation has bar code reader\nbar code reader reads book copy\nbar code reader reads identiﬁcation card\nTacit knowledge:\nlibrary owns computer\nlibrary owns stations\ncomputer communicates with station\nlibrary employs employee\nclient is member of library\nclient has identiﬁcation card\nFigure 12.26 Relationships inferred from the problem state ment\nThese services concern the state of an object: they read and w rite the object’s\nattributes. Services that provide information about the st ate of an object may or\nmay not involve some type of computation. Note that it is alwa ys possible to\noptimize the actual implementation by keeping redundant in formation in the state as\nit is maintained by the object. For example, we may decide to i nclude the number\nof books on loan in the state as implemented, rather than comp uting it when\nrequired. This need not concern us at this stage though. Whet her services are actually\nimplemented by computational means or by a simple lookup pro cedure is invisible to\nthe object that requests the information.\nFurther insight into which services are required can be obta ined by investigating\nusage scenarios. We may prepare typical dialogs between com ponents of the system\nin both normal and exceptional situations. For example, we m ay consider the situation\nin which a client successfully borrows a book, one in which th e client’s identiﬁcation\ncard is no longer valid", "token_count": 512, "start_token": 211596, "end_token": 212108, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 459, "text": " system\nin both normal and exceptional situations. For example, we m ay consider the situation\nin which a client successfully borrows a book, one in which th e client’s identiﬁcation\ncard is no longer valid, one in which he still has to pay an outs tanding ﬁne, and so\non. A sequence diagram for the normal situation of borrowing a book is shown in\nﬁgure 12.28. A number of events take place when this interact ion takes place. These\nevents will be handled by operations of the objects involved .\nServices are but one way through which objects may be related . The relations\nwhich give systems a truly object-oriented ﬂavor are those w hich result from\nwhole--part and generalization--specialization classiﬁ cations.\nPart of the classiﬁcation of objects may result from the pre- existing real-world\nclassiﬁcations that the system is to deal with. Further clas siﬁcation of objects into an\nobject hierarchy involves a search for relations between ob jects. To start with, we\n366 SOFTWARE DESIGN\nFigure 12.27 (Part of) the initial object model for a library system\nmay consider an object as a generalization of other possible objects. For instance,\nthe object Book may be viewed as a generalization of objects Novel, Poetry and\nReferenceBook. Whether these specializations are meaningful depends on t he\nproblem at hand. If the system does not need to distinguish be tween novels and\npoetry, we should not deﬁne separate objects for them. The di stinction between\nnovels and poetry on the one hand and reference books on the ot her is sensible,\nthough, if novels and poetry can be borrowed, but reference b ooks cannot.\nIn a similar way, we may consider similarities between objec ts, thus viewing them\nas specializations of a more general object. If our library s ystem calls for objects\nBook and Journal that have a number of attributes in common, we may introduce a\nnew object Publication as a generalization of these objects. The common attributes\nare lifted to the object Publication; Book and Journal then inherit these attributes.\nNote that generalizations should still reﬂect meaningful r eal-world entities. There is\nno point in introducing a generalization of Book", "token_count": 512, "start_token": 212058, "end_token": 212570, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 460, "text": " common attributes\nare lifted to the object Publication; Book and Journal then inherit these attributes.\nNote that generalizations should still reﬂect meaningful r eal-world entities. There is\nno point in introducing a generalization of Book and FileCabinet simply because\nthey have a common attribute Location.\nThe object Publication introduced above is an abstract object . It is an object for\n12.3. OBJECT-ORIENTED ANALYSIS AND DESIGN METHODS 367\nFigure 12.28 Sequence diagram for borrowing a book\nwhich there are no instances. The library only contains inst ances of objects that are\na specialization of Publication, such as Book and Journal. Its function in the object\nhierarchy is to relate these other objects and to provide an i nterface description to\nits users. The attributes and services deﬁned at the level of Publication together\nconstitute the common interface for all its descendants.\nThe generalization--specialization hierarchy also makes it possible to lift services\nto higher levels of the hierarchy. Doing so often gives rise t o so-called virtual func-\ntions. Virtual functions are services of an object for which a (def ault) implementation\nis provided which can be redeﬁned by specializations of that object. The notion of\nvirtual functions greatly enhances reusability, since a va riant of some object can now\nbe obtained by constructing a specialization of that object in which some services are\nredeﬁned.\nDecisions as to which objects and attributes to include in a d esign, and how to\nrelate them in the object hierarchy, are highly intertwined . For instance, if an object\nhas one attribute only, it is generally better to include it a s an attribute in other\n368 SOFTWARE DESIGN\nobjects. Also, the instances of an object should have common attributes. If some\nattributes are only meaningful for a subset of all instances , then we really have a\nclassiﬁcation structure. If some books can be borrowed, but others cannot, this is an\nindication of a classiﬁcation structure where the object Book has specializations such\nas Novel and ReferenceBook.\nNote also that, over time, the set of attributes of and servic es provided by an\nobject tends to evolve, while the object hierarchy remains r elatively stable. If our\nlibrary decides to offer an extra service to its", "token_count": 512, "start_token": 212520, "end_token": 213032, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 461, "text": " ReferenceBook.\nNote also that, over time, the set of attributes of and servic es provided by an\nobject tends to evolve, while the object hierarchy remains r elatively stable. If our\nlibrary decides to offer an extra service to its customers, s ay borrowing records, we\nmay simply adapt the set of attributes and extend the set of se rvices for the object\nCustomer.\nObject-oriented design can be classiﬁed as a middle-out design method. The set\nof objects identiﬁed during the ﬁrst modeling stages consti tutes the middle level of the\nsystem. In order to implement these domain-speciﬁc entitie s, lower-level objects are\nused. These lower-level objects can often be taken from a cla ss library. For the various\nobject-oriented programming languages, quite extensive c lass libraries already exist.\nThe higher levels of the design constitute the application- dependent interaction of\nthe domain-speciﬁc entities.\nIn the following subsections, we discuss three design metho ds that typify the\nevolution of object-oriented analysis and design:\n/AF The Booch method, an early object-oriented analysis and des ign method, with\nan emphasis on employing a new and rich set of notations.\n/AF Fusion, developed at HP, with a much larger emphasis on the va rious process\nsteps of the method.\n/AF The Rational Uniﬁed Process (RUP), a full life cycle model as sociated with\nUML.\n12.3.1 The Booch Method\nThe global process model of the method described in (Booch, 1 994) is shown in\nﬁgure 12.29. It consists of four steps, to be carried out in ro ughly the order speciﬁed.\nThe process is iterative, so each of the steps may have to be do ne more than once. The\nﬁrst cycles are analysis-oriented, while later ones are des ign-oriented. The blurring\nof activities in this process model is intentional. Analysi s and design activities are\nassumed to be under opportunistic control. It is therefore n ot deemed realistic to\nprescribe a purely rational order for the activities to be ca rried out.\nThe ﬁrst step is aimed", "token_count": 512, "start_token": 212982, "end_token": 213494, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 462, "text": " and design activities are\nassumed to be under opportunistic control. It is therefore n ot deemed realistic to\nprescribe a purely rational order for the activities to be ca rried out.\nThe ﬁrst step is aimed at identifying classes and objects. Th e purpose of this step\nis to establish the boundaries of the problem and to obtain a ﬁ rst decomposition.\nDuring analysis, emphasis is on ﬁnding meaningful abstract ions from the domain of\napplication. During design, objects from the solution doma in may be added. The\nmajor outcome of this step is a data dictionary containing a p recise description of the\nabstractions identiﬁed.\n12.3. OBJECT-ORIENTED ANALYSIS AND DESIGN METHODS 369\nFigure 12.29 The process model of Booch ( Source: G. Booch , Object-Oriented Analysis\nand Design, Benjamin Cummings, 1994. Reproduced with permission. )\nThe second step is concerned with determining the behavior a nd attributes of\neach abstraction, and the distribution of responsibilitie s over components of the\nsystem. Attributes and desired behavior are identiﬁed by an alyzing typical usage\nscenarios. As this process proceeds, responsibilities may be reallocated to get a more\nbalanced design, or be able to reuse (scavenge) existing des igns. The outcome of\nthis step is a reasonably complete set of responsibilities a nd operations for each\nabstraction. The results are documented in the data diction ary and, at a later stage,\nin interface speciﬁcations for each abstraction. The seman tics of usage scenarios are\ncaptured in sequence and communication diagrams (termed interaction diagram and\nobject diagram , respectively, in (Booch, 1994)).\nThe third step is concerned with ﬁnding relationships betwe en objects. During\nanalysis, emphasis is on ﬁnding relationships between abst ractions. During design,\ntactical decisions about inheritance, instantiation, and the like are made. The results\nare shown in class diagrams, communication diagrams, and so -called module diagrams\nwhich show the modular structure of a system.\nFinally, the abstractions are reﬁned up to a detailed level. A decision is made about\nthe representation of each abstraction, algorithms are sel", "token_count": 512, "start_token": 213444, "end_token": 213956, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 463, "text": " and so -called module diagrams\nwhich show the modular structure of a system.\nFinally, the abstractions are reﬁned up to a detailed level. A decision is made about\nthe representation of each abstraction, algorithms are sel ected, and solution-oriented\nclasses are added where needed.\nThe most notable characteristics of Booch’s method are:\n370 SOFTWARE DESIGN\n– A rich set of notations: it uses six types of diagram, each wi th a fairly elaborate\nvocabulary; as a result, many aspects of a system can be model ed.\n– A poor process model: it is difﬁcult to decide when to iterat e, and what to do\nin a speciﬁc iteration.\n12.3.2 Fusion\nThe Fusion method for object-oriented analysis and design h as two major phases:\nanalysis and design. Its global process model is shown in ﬁgu re 12.30.\nThe analysis phase is aimed at determining the system’s obje cts and their\ninteractions. The static structure is shown in a class diagr am (called an object model\nin Fusion), and documented in a data dictionary. The dynamic s are shown in the\ninterface model. The interface model consists of a life cycl e model for each object,\ndenoted by a regular expression (i.e., a ﬂat representation of a state machine diagram)\nand a speciﬁcation of the semantics of each operation in a pre - and postcondition\nstyle. The analysis process is assumed to be an iterative pro cess. This iteration stops\nwhen the models are complete and consistent.\nFusion’s design phase results in four models, which are esse ntially derived in the\norder indicated in ﬁgure 12.30. Object interaction graphs r esemble communication\ngraphs. They describe how objects interact at runtime: what objects are involved in\na computation and how they are combined to realize a given spe ciﬁcation. Visibility\ngraphs describe how the communications between objects are realized. For each\nobject, it is determined which other objects must be referen ced and how. Different\nkinds of references are distinguished, taking into account aspects like the lifetime\nof the reference and whether references can be shared. Next, the object model,\ninteraction graphs and visibility graphs are used", "token_count": 512, "start_token": 213906, "end_token": 214418, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 464, "text": " must be referen ced and how. Different\nkinds of references are distinguished, taking into account aspects like the lifetime\nof the reference and whether references can be shared. Next, the object model,\ninteraction graphs and visibility graphs are used to derive a description of each class.\nThe operations and the initial set of attributes for each obj ect are established at\nthis stage. Finally, the inheritance relations are decided upon, and depicted in the\ninheritance graph, which is a class diagram. The class descr iptions then are updated\nto reﬂect this inheritance structure.\nThe most notable characteristics of Fusion are:\n/AF The large attention paid to the design phase. Fusion deﬁnes f our models for\nthe design phase and gives detailed guidelines for the kind o f things that have\nto be incorporated in these models.\n/AF The version of the method as published in (Coleman et al., 199 4) hinges on\nthe availability of a good requirements document. Extensio ns to this version\ninclude the absorption of use cases to drive the analysis pro cess.\n/AF As a method, Fusion is very prescriptive. The contrast with t he opportunistic\napproach of Booch is striking. Fusion’s prescriptiveness m ight be considered\nboth a strength and a weakness.\n12.3. OBJECT-ORIENTED ANALYSIS AND DESIGN METHODS 371\nFigure 12.30 The process model of Fusion\n12.3.3 RUP Revisited\nRUP, the Rational Uniﬁed Process, is a full process model; se e also section 3.3. RUP\nhas a number of workﬂows, such as a requirements workﬂow, ana lysis and design\nworkﬂow, and test workﬂow, and four phases: inception, elab oration, construction\n372 SOFTWARE DESIGN\nand transition. Workﬂows describe the activities to be carr ied out, while the phases\nindicate the organization along the time axis. Most workﬂow s extend over most\nphases.\nHere, we discuss the analysis and design workﬂow, in which th e requirements are\ntransformed into a design. RUP is an iterative process, so th is transformation is carried\nout in a number of iterations as well. The ﬁ", "token_count": 512, "start_token": 214368, "end_token": 214880, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 465, "text": " analysis and design workﬂow, in which th e requirements are\ntransformed into a design. RUP is an iterative process, so th is transformation is carried\nout in a number of iterations as well. The ﬁrst iterations tak e place in the elaboration\nphase of RUP. In that phase, the architecture of the system is determined. The RUP\nway of doing architectural design reasonably ﬁts the global workﬂow model discussed\nin section 11.2. In subsequent iterations, concerning the l ower-level design, the main\nactivities are termed Analyze behavior and Design components .\nThe purpose of the Analyze behavior step is to transform the u se cases into a set\nof design elements that together serve as a model of the probl em domain. It is about\nwhat the system is to deliver. It produces a black box model of the s olution. The\npurpose of the Design elements step is to reﬁne the deﬁnition s of the design elements\ninto classes, relationships, interfaces and the like. In th is activity, the black box what\nmodel is turned into a white box how model.\nDuring both activities, the resulting design is reviewed, a nd the results thereof\nare fed back into the next iteration.\nNotable characteristics of RUP are:\n/AF It is a very complete, iterative model that goes much further than mere analysis\nand design.\n/AF It makes heavy use of the Uniﬁed Modeling Language to represe nt artifacts and\nviews.\n/AF Use cases play a central role. They provide thread informati on from one\nworkﬂow to another. For example, the analysis and design wor kﬂow produces\nuse case realizations , which describe how use cases are actually realized by a\ncollection of interacting objects and classes.\n12.4 How to Select a Design Method\nIt is not easy to compare the many design methods that exist. T hey all have their pros\nand cons. None of them gives us a straightforward recipe as to how to proceed from\na list of requirements to a successfully implemented system . We always need some\nsort of magic in order to get a speciﬁc decomposition. The exp ertise and quality of\nthe people involved have a major impact on the end result of th e design process.\nProblem", "token_count": 512, "start_token": 214830, "end_token": 215342, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 466, "text": " We always need some\nsort of magic in order to get a speciﬁc decomposition. The exp ertise and quality of\nthe people involved have a major impact on the end result of th e design process.\nProblem solving is based on experience. It is estimated that an expert has over 50\n000 chunks of domain-speciﬁc knowledge at his disposal. Whe n solving a problem,\nwe try to map the problem at hand onto the knowledge available . The greater this\nknowledge is, and the more accessible it is, the more success ful this process will be.\nThe prescriptiveness of the design methods differs conside rably. The various\nvariants of functional decomposition and the object-orien ted design methods rely\n12.4. HOW TO SELECT A DESIGN METHOD 373\nheavily on the heuristic knowledge of the designers. Jackso n’s techniques seem to\nsuffer less from this need. Especially if structure clashes do not occur, JSP provides\na well-deﬁned framework for how to tackle design. The prescr iptive nature of JSP\npossibly explains to some extent its success, especially in the realm of administrative\ndata-processing. JSD offers similar advantages. Its stric t view of describing data\nstructures as a list of events may lead to problems, however, if the data structures do\nnot ﬁt this model. JSP has a static view of the data. More impor tantly, it does not tell\nus how to organize the data. As such, this technique seems most suit ed for problems\nwhere the structure of the data has been ﬁxed beforehand. JSD and object-oriented\nmethods offer better support as regards the structuring of d ata. Though these methods\ngive useful heuristics for the identiﬁcation of objects, ob taining a well-balanced set\nof objects is still very much dependent on the skills of the de signer.\nThe data ﬂow technique has a more dynamic view of the data stre ams that are the\nbase of the system to be constructed. We may often view the bub bles from a data ﬂow\ndiagram as clerks that perform certain transformations on i ncoming data to produce\ndata for other clerks. The technique seems well-suited for c ircumstances where an\nexisting manual system", "token_count": 512, "start_token": 215292, "end_token": 215804, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 467, "text": "es from a data ﬂow\ndiagram as clerks that perform certain transformations on i ncoming data to produce\ndata for other clerks. The technique seems well-suited for c ircumstances where an\nexisting manual system is to be replaced by a computerized on e. A real danger,\nthough, is that the existing system is just copied, while add itional requirements are\noverlooked.\nIf we take into account that a substantial part of the cost of s oftware is spent in\nmaintaining that software, it is clear that such factors as ﬂexibility, c omprehensibility\nand modularity should play a crucial role when selecting a sp eciﬁc design technique.\nThe ideas and guidelines of Parnas are particularly relevan t in this respect. The\nobject-oriented philosophy incorporates these ideas and i s well-matched to current\nprogramming languages, which allow for a smoother transiti on between the different\ndevelopment phases.\nQuite a few attempts have been made to classify design method s along various\ndimensions, such as the products they deliver, the kind of re presentations used, or\ntheir level of formality. A simple but useful framework is pr oposed in (Blum, 1994). It\nhas two dimensions: an orientation dimension and a model dim ension.\nIn the orientation dimension, a distinction is made between problem-oriented\ntechniques and product-oriented techniques. Problem-ori ented techniques con-\ncentrate on producing a better understanding of the problem and its solution.\nProblem-oriented techniques are human-oriented. Their ai m is to describe, commu-\nnicate, and document decisions. Problem-oriented techniq ues usually have one foot\nin the requirements engineering domain. Conversely, produ ct-oriented techniques\nfocus on a correct transformation from a speciﬁcation to an i mplementation. The\nsecond dimension relates to the products, i.e. models, that are the result of the design\nprocess. In this dimension, a distinction is made between co nceptual models and\nformal models. Conceptual models are descriptive. They des cribe an external reality,\nthe Universe of Discourse. Their appropriateness is establ ished through validation.\nFormal models on the other hand are prescriptive. They presc ribe the behavior of the\nsystem to be developed. Formal models", "token_count": 512, "start_token": 215754, "end_token": 216266, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 468, "text": ",\nthe Universe of Discourse. Their appropriateness is establ ished through validation.\nFormal models on the other hand are prescriptive. They presc ribe the behavior of the\nsystem to be developed. Formal models can be veriﬁed.\n374 SOFTWARE DESIGN\nProblem-oriented Product-oriented\nI II\nConceptual ER modeling Structured Design\nStructured Analysis OO Design\nOO Analysis\nIII IV\nFormal JSD Functional decomposition\nVDM JSP\nFigure 12.31 Classiﬁcation of design techniques\nUsing this framework, we may classify a number of techniques discussed in\nthis book as in ﬁgure 12.31. The four quadrants of this matrix have the following\ncharacteristics:\nI) Understand the problem These techniques are concerned with understanding\nthe problem, and expressing a solution in a form that can be di scussed with\ndomain specialists (i.e. the users).\nII) Transform to implementation Techniques in this category help to transform a\ncollection of UoD-related concepts into an implementation structure.\nIII) Represent properties These techniques facilitate reasoning about the problem\nand its solution.\nIV) Create implementation units This category contains techniques speciﬁcally\naimed at creating implementation units such as modules.\nThe above arguments relate to characteristics of the proble m to be solved. There are\nseveral other environmental factors that may impact the cho ice of a particular design\ntechnique and, as a consequence, the resulting design (simi lar arguments hold for the\nsoftware architecture; see chapter 11):\n/AF Familiarity with the problem domain. If the designers are we ll-acquainted with\nthe type of problem to be solved, a top-down technique or a tec hnique based\non data structures may be very effective. If the design is exp erimental, one will\ngo about it in a more cautious way, and a bottom-up design tech nique then\nseems more appropriate.\n/AF Designer’s experience. Designers that have a lot of experie nce with a given\nmethod will, in general, be more successful in applying that method. They\n12.4. HOW TO SELECT A DESIGN METHOD 375\nare aware of the constraints and limitations of the method an d will be able to\nsuccessfully bypass the potential problems.\n/AF Available tools. If", "token_count": 512, "start_token": 216216, "end_token": 216728, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 469, "text": " applying that method. They\n12.4. HOW TO SELECT A DESIGN METHOD 375\nare aware of the constraints and limitations of the method an d will be able to\nsuccessfully bypass the potential problems.\n/AF Available tools. If tools are available to support a given de sign method, it is only\nnatural to make use of them. In general, this also implies tha t the organization\nhas chosen that design method.\n/AF Overall development philosophy. Many design methods are em bedded in a\nwider philosophy which also addresses other aspects of syst em development,\nranging from ways to conduct interviews or reviews to full-s cale models of the\nsoftware life cycle. The organized and disciplined overall approach endorsed\nby such a development philosophy is an extra incentive for us ing the design\nmethod that goes with it.\n12.4.1 Object Orientation: Hype or the Answer?\nMoving from OOA to OOD is a progressive expansion of the model .\n(Coad and Yourdon, 1991, p. 178)\nThe transition from OOA to OOD is difﬁcult.\n(Davis, 1995)\nStrict modeling of the real world leads to a system that reﬂec ts today’s reality but not\nnecessarily tomorrow’s. The abstractions that emerge duri ng design are key to making a\ndesign ﬂexible.\n(Gamma et al., 1995)\nThe above quotes hint at some important questions still left unanswered in our\ndiscussion of object-oriented methods:\n– do object-oriented methods adequately capture the requir ements engineering\nphase?\n– do object-oriented methods adequately capture the design phase?\n– do object-oriented methods adequately bridge the gap betw een these phases,\nif such a gap exists?\n– are object-oriented methods really an improvement over mo re traditional\nmethods?\nThe goal of requirements engineering is to model relevant as pects of the real world,\nthe world in which the application has to operate. Requireme nts engineering activities\nconcern both capturing knowledge of this world, and modelin g it. The language and\nmethods for doing so should be problem-oriented (domain-or iented). They should\nease communication with users as well as validation of the re quirements by users.\n376 SOFTWARE DESIGN\nMost object-oriented methods assume that the", "token_count": 512, "start_token": 216678, "end_token": 217190, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 470, "text": " for doing so should be problem-oriented (domain-or iented). They should\nease communication with users as well as validation of the re quirements by users.\n376 SOFTWARE DESIGN\nMost object-oriented methods assume that the requirements have been established\nbefore the analysis starts. Of the four processes distingui shed in chapter 9, elicitation,\nspeciﬁcation, validation and negotiation, object-orient ed methods by and large only\ncover the requirements speciﬁcation subprocess. Though many object-oriented methods\nhave incorporated use-case analysis, the purpose thereof p rimarily is to model the\nfunctional behavior of the system rather than to elicit user requirements.\nA rather common view of OO proponents is that object-oriente d analysis (OOA)\nand object-oriented design (OOD) are very much the same. OOD simply adds\nimplementation-speciﬁc classes to the analysis model. Thi s view, however, can be\ndisputed. OOA should be problem-oriented; its goal is to inc rease our understanding\nof the problem. The purpose of design, whether object-orien ted or otherwise, is to\ndecide on the parts of a solution, their interaction, and the speciﬁcation of each of\nthese parts. This difference in scope places OOA and OOD at a d ifferent relative\n‘distance’ from a problem and its solution, as shown in ﬁgure 12.32.\nFigure 12.32 The ‘distance’ between OOA, OOD and a problem an d its solution\nThere are good reasons to distinguish OOA-type activities a nd OOD-type\nactivities, as is done in Fusion, for example. During design , attention is focused on\nspecifying how to create and destroy objects, on identifyin g generalizations (abstract,\nif necessary) of objects in order to promote reuse or maintai nability, and so on. An\nobject Publication as a generalization of Book and Journal need not be considered\nduring analysis, since it does not increase our understandi ng of the domain. On the\nother hand, an object like identiﬁcation card may well disappear from the model\nduring design.\nMost software development organizations have accumulated a lot of experience\nin developing software following the traditional, functio n- or process", "token_count": 512, "start_token": 217140, "end_token": 217652, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 471, "text": "\nother hand, an object like identiﬁcation card may well disappear from the model\nduring design.\nMost software development organizations have accumulated a lot of experience\nin developing software following the traditional, functio n- or process-oriented style.\nA lot of legacy software has been developed and documented th at way. As a\nconsequence, knowledge of these methods is still required i n many an organization.\n12.5. DESIGN PATTERNS 377\nMany organizations have switched to some kind of object-ori ented analysis and\ndesign approach. Hard evidence of increased productivity o r quality has not been\ndetermined, though. Several experiments have been done to t est the effectiveness\nof the OO paradigm, and the results do seem to indicate some de eper problems\ntoo. For example, in one experiment it was tested how effecti ve object-oriented\nmodels are as the main vehicle of communication between the t ypical customer\nand the developer (Moynihan, 1996). It was found that the tra ditional, functional\nmodels were easier to understand, provoked more questions a nd comments, gave\na more holistic understanding of the business, and better he lped to evaluate likely\nimplementations. In another experiment it was tested wheth er novice analysts are\nable to develop requirements more easily with certain metho ds than with others,\nand whether they learn to use certain methods more readily th an others (Vessey\nand Conger, 1994). And again, the results were negative for O O: novice analysts\nwere better able to apply the process-oriented method, and s igniﬁcant learning only\noccurred for the process-oriented method.\nIn a similar vein, (Arisholm and Sjøberg, 2004) found that no vice users have fewer\nproblems maintaining systems that have centralized contro l compared to systems\nhaving delegated control. In a centralized control style, o ne or a few large classes\nare in control. These large classes coordinate the work of a l ot of smaller classes.\nThis resembles the hierarchical main-program-with-subro utines architectural style.\nIn a delegated style, responsibilities are distributed ove r a larger set of classes. OO\nproponents usually advocate a delegated control style. It s eems one needs a certain\nmaturity to be effective with this style.\nThe inheritance mechanism of object-orientation needs to", "token_count": 512, "start_token": 217602, "end_token": 218114, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 472, "text": " distributed ove r a larger set of classes. OO\nproponents usually advocate a delegated control style. It s eems one needs a certain\nmaturity to be effective with this style.\nThe inheritance mechanism of object-orientation needs to b e handled with care\ntoo, as noted in section 12.1.6. Deep hierarchies require on e to comprehend design\nor implementation units that may be wide apart. Such designs tend to be error\nprone (Bieman et al., 2001) and more difﬁcult to inspect (Dun smore et al., 2002),\nbecause of the delocalized nature of information in them.\nThere may well be some truth in the observation that users do n ot think in\nobjects; they think in tasks. From that point of view, use-ca se analysis may be seen as\none way to introduce a functional view into an otherwise obje ct-oriented approach.\n12.5 Design Patterns\nA design pattern is a recurring structure of communicating c omponents that solves\na general design problem within a particular context. A desi gn pattern differs from\nan architectural style in that it does not address the struct ure of a complete system,\nbut only that of a few (interacting) components. Design patt erns may thus be termed\nmicro-architectures. On the other hand, a design pattern en compasses more than a\nsingle component, procedure or module.\nThe archetypical example of a design pattern is the Model--V iew--Controller\n(MVC) pattern. Interactive systems consist of computation al elements as well as\nelements to display data and handle user input. It is conside red good design practice\n378 SOFTWARE DESIGN\nto separate the computational elements from those that hand le I/O. This separation\nof concerns is achieved by the MVC pattern.\nMVC involves three components: the Model, the View, and the C ontroller. The\nmodel component encapsulates the system’s data as well as th e operations on those\ndata. The model component is independent of how the data is re presented or how\ninput is done. A view component displays the data that it obta ins from the model\ncomponent. There can be more than one view component. Finall y, each view has an\nassociated controller component. A controller handles inp ut actions. Such an input\naction may cause the controller to send a", "token_count": 512, "start_token": 218064, "end_token": 218576, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 473, "text": "ta ins from the model\ncomponent. There can be more than one view component. Finall y, each view has an\nassociated controller component. A controller handles inp ut actions. Such an input\naction may cause the controller to send a request to the model , for example to update\nits data, or to its view, for example to scroll.\nFor any given situation, the above description has to be cons iderably reﬁned and\nmade more precise. For instance, a controller may or may not d epend on the state\nof the model. If the controller does not depend on the state of the model, there is\na one-way ﬂow of information: the controller signals an inpu t event and notiﬁes the\nmodel. If the controller does depend on the state of the model , information ﬂows in\nthe other direction as well. The latter type of dependence ca n be observed in most\nword-processing systems for example, where menu entries ar e made active or inactive\ndepending on the state of the model.\nMVC was ﬁrst used in the Smalltalk environment. Since then it has been applied\nin many applications. In various graphical user interface p latforms, a variant has been\napplied in which the distinction between the view and the con troller has been relaxed.\nThis variant is called the Document--View pattern; see (Kru glinski, 1996).\nDesign patterns have a number of properties which explain wh at they offer, as\nwell as why and how they do so:\n/AF A pattern addresses a recurring design problem that arises i n speciﬁc design\nsituations and presents a solution to it. Many software syst ems include compu-\ntational elements as well as user-interface elements. For r easons of ﬂexibility,\nwe may wish to separate these as much as possible. MVC offers a solution to\nprecisely this recurring problem.\n/AF A pattern must balance a set of opposing forces, i.e. charact eristics of the\nproblem that have to be dealt with in its solution. For exampl e, in interactive\napplications we want to be able to present information in dif ferent ways,\nchanges to the data must be reﬂected immediately in all views affected by these\nchanges, and different ‘look and feel", "token_count": 512, "start_token": 218526, "end_token": 219038, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 474, "text": " in interactive\napplications we want to be able to present information in dif ferent ways,\nchanges to the data must be reﬂected immediately in all views affected by these\nchanges, and different ‘look and feel’ interfaces should no t affect the application\ncode. MVC seeks to balance all these forces.\n/AF Patterns document existing, well-proven design experienc e. Patterns are not\ninvented; they evolve with experience. They reﬂect best pra ctices. MVC, for\nexample, is used in various application frameworks as well a s in scores of\ninteractive systems.\n/AF Patterns identify and specify abstractions above the level of single components.\nMVC has three, interacting components which together solve a given problem.\n12.5. DESIGN PATTERNS 379\n/AF Patterns provide a common vocabulary and understanding for design principles.\nBy now, MVC has become a widely known label for a certain solut ion to a\ncertain problem. We may use the term in conversation and writ ing much as we\nuse terms like ‘quicksort’ or ‘Gauss interpolation’. Patte rns thus become part of\nour language for describing software designs.\n/AF Patterns are a means of documentation. As with software arch itectures, patterns\nboth describe and prescribe things. Descriptively, patter ns offer a way to\ndocument your software, for example by simply using pattern names in its\ndocumentation. Prescriptively, pattern names give users h ints as to how to\nextend and modify software without violating the pattern’s vision. If your\nsystem employs MVC, computational aspects are strictly sep arated from\nrepresentational aspects, and you know that this separatio n must be maintained\nduring the system’s evolution.\n/AF Patterns support the construction of software with deﬁned p roperties. On\nthe one hand, MVC offers a skeleton for the construction of in teractive\nsystems. MVC however also addresses certain non-functiona l requirements,\nsuch as ﬂexibility and changeability of user interfaces. Th ese non-functional\nrequirements often constitute the major problem directly a ddressed by the\npattern.\nWhen describing patterns it is customary to use a schema simi lar to that used for\ndescribing architectural styles. The main entries of", "token_count": 512, "start_token": 218988, "end_token": 219500, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 475, "text": " ese non-functional\nrequirements often constitute the major problem directly a ddressed by the\npattern.\nWhen describing patterns it is customary to use a schema simi lar to that used for\ndescribing architectural styles. The main entries of such a schema therefore are:\n– context: the situation giving rise to a design problem,\n– problem: a recurring problem arising in that situation, and\n– solution: a proven solution to that problem.\nWe will illustrate design patterns by sketching a possible a pplication of two such\npatterns in a library automation system.\nSuppose our library system involves a central database and a number of users,\nsome of which are based at remote sites. We wish to optimize th ese remote accesses,\nfor example by using a cache. However, we do not wish to clutte r the application\ncode with code that handles such optimizations. The Proxy pattern addresses this\nproblem. In the Proxy pattern, a client does not directly add ress an original. Rather,\nthe client addresses a proxy, a representative of that origi nal. This proxy shields the\nnon-application speciﬁc aspects, like the optimization th rough a cache in the above\nexample. This Proxy pattern can be described as in ﬁgure 12.3 37.\nThe Proxy pattern exists in many variants. The variant discu ssed above could\nbe termed a Cache Proxy : emphasis is on sharing results from remote components.\nOther variants are: the Remote Proxy (which shields network access, inter-process\n7 See (Buschmann et al., 1996, pp 263-275) for a more elaborate description.\n380 SOFTWARE DESIGN\nContext A client needs services from another component. Though dire ct access is\npossible, this may not be the best approach.\nProblem We do not want to hard-code access to a component into a client .\nSometimes, such direct access is inefﬁcient; in other cases it may be unsafe. This\ninefﬁciency or insecurity is to be handled by additional con trol mechanisms,\nwhich should be kept separate from both the client and the com ponent to\nwhich it needs access.\nSolution The client communicates with a representative rather than t he compo-\nnent itself. This representative, the proxy, also does any additional pre- and\npostprocessing that is needed.\nFigure 12.33 The Proxy", "token_count": 512, "start_token": 219450, "end_token": 219962, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 476, "text": " needs access.\nSolution The client communicates with a representative rather than t he compo-\nnent itself. This representative, the proxy, also does any additional pre- and\npostprocessing that is needed.\nFigure 12.33 The Proxy pattern\ncommunication, and so on), the Protection Proxy (protection from unauthorized access)\nand the Firewall Proxy (protection of local clients from the outside world). World\nWide Web servers typically use a Firewall Proxy pattern to pr otect users from the\noutside world. Other example uses of the Proxy pattern can be found in frameworks\nfor object-based client/server systems, such as the Common Object Request Broker\nArchitecture (CORBA) and Microsoft’s DCOM (Lewandowski, 1 998).\nMost users of the library system are incidental users for whi ch we want a\nfriendly interface, including powerful undo facilities. O n the other hand, experienced\nlibrary employees want a user interface with keyboard short cuts for most commands.\nFurthermore, we want to be able to log user requests for later analysis, for example\nto ﬁnd out which authors are much in demand. We want to separat e these ‘extras’\nfrom the actual application code. The Command Processor pattern addresses this issue.\nExample uses of the Command Processor pattern can be found in user interface\ntoolkits like ET++ and MacApp. Its characteristics are give n in ﬁgure 12.34 8.\nApplications typically involve a mixture of details that pe rtain to different realms,\nsuch as the application domain, the representation of data t o the user, the access to a\nremote compute server, and so on. If these details are mixed u p in the software, the\nresult will be difﬁcult to comprehend and maintain.\nExpert designers have learned to separate such aspects so as to increase the\nmaintainability, ﬂexibility, adaptability (in short, the quality) of the systems they\ndesign. If needed, they introduce some intermediate abstra ct entity to bridge aspects\nof a solution they wish to keep separate. The Proxy and Comman d Processor patterns,\nas well as many other design patterns found in (Gamma et al., 1 995) and (Buschmann\net al., 1996), offer elegant and ﬂexible solutions to precis ely these divide-and-conquer\ntype design situations.", "token_count": 512, "start_token": 219912, "end_token": 220424, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 477, "text": " patterns found in (Gamma et al., 1 995) and (Buschmann\net al., 1996), offer elegant and ﬂexible solutions to precis ely these divide-and-conquer\ntype design situations.\n8 see (Buschmann et al., 1996, pp 277--290) for a more elaborat e description.\n12.5. DESIGN PATTERNS 381\nContext User interfaces which must be ﬂexible or provide functional ity that goes\nbeyond the direct handling of user functions. Examples are u ndo facilities or\nlogging functions.\nProblem We want a well-structured solution for mapping an interface to the internal\nfunctionality of a system. All ‘extras’ which have to do with the way user\ncommands are input, additional commands such as undo or redo , and any\nnon-application-speciﬁc processing of user commands, suc h as logging, should\nbe kept separate from the interface to the internal function ality.\nSolution A separate component, the command processor , takes care of all commands.\nThe command processor component schedules the execution of commands,\nstores them for later undo, logs them for later analysis, and so on. The actual\nexecution of the command is delegated to a supplier componen t within the\napplication.\nFigure 12.34 The Command Processor pattern\nPatterns describe common practices that have proven useful . Antipatterns describe\nrecurring practices that have proven to generate problems. Next to collections of\npatterns, people have developed collections of mistakes of ten made, and described\nthem as antipatterns. Knowledge of antipatterns is useful d uring design to prevent\ncommon pitfalls, and during evolution to improve an evolvin g design. In the latter\ncase, one actually searches for antipatterns and next appli es a technique called\nrefactoring to improve the design; see also chapter 14. Descriptions of a ntipatterns\nusually include the refactoring remedy. Some well-known an tipatterns are:\n/AF The God Class. In this situation, there is one central class t hat is in control\nand holds most responsibilities. It is linked to a lot of othe r classes that\nexecute relatively simple tasks. It is also known as The Blob . When such a\ndesign is refactored, responsibilities are more", "token_count": 512, "start_token": 220374, "end_token": 220886, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 478, "text": " hat is in control\nand holds most responsibilities. It is linked to a lot of othe r classes that\nexecute relatively simple tasks. It is also known as The Blob . When such a\ndesign is refactored, responsibilities are more evenly dis tributed. Note though\nthat we previously observed that centralized designs are of ten more easily\ncomprehended by novices.\n/AF Lava ﬂow. At the code level, this amounts to dead code. Follow ing the slogan\n”If it ain’t broken, don’t touch it”, obsolete code and obsol ete design elements\nmay be dragged along indeﬁnitely.\n/AF Poltergeists. These are classes that have limited responsi bilities and usually live\nshortly. Their role often is to just start up other processes .\n/AF Golden Hammer. This occurs when an available solution is app lied to a problem\nthat it does not really ﬁt (”If the only available tool is a ham mer, everything\nelse is a nail”). This antipattern is common practice when or ganizations feel\n382 SOFTWARE DESIGN\nthey have to use database package X or interface toolkit Y, si mply because\nthey have a license, or because their employees have deep kno wledge of that\ntechnology. At the level of an individual designer, it shows up as the obsessive\nuse of a small set of patterns.\n/AF Stovepipe. This phenomenon occurs if multiple systems are d eveloped inde-\npendently, and each one uses its own set of technologies for t he user interface,\ndatabase, platform, and the like. Integration and cooperat ion then becomes\ndifﬁcult. Such a situation is often encountered when organi zations merge or\ndifferent organizations link their information systems in a chain. At a more\nlocal level it occurs if developers or design teams reinvent the wheel.\n/AF Swiss Army Knife. This is an excessively complex class inter face. It occurs\nwhen a designer wants to make a class as general and reusable a s possible.\n12.6 Design Documentation\nA requirements speciﬁcation is developed during requireme nts engineering. That\ndocument serves a number of purposes. It speciﬁes the users’ requirements and as such\nit often has legal meaning. It is also the", "token_count": 512, "start_token": 220836, "end_token": 221348, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 479, "text": " speciﬁcation is developed during requireme nts engineering. That\ndocument serves a number of purposes. It speciﬁes the users’ requirements and as such\nit often has legal meaning. It is also the starting point for t he design and thus serves\nanother class of user.\nThe same applies to the design documentation. The descripti on of the design\nserves different users, who have different needs. A proper o rganization of the design\ndocumentation is therefore very important.\nIEEE Standard 1016 discusses guidelines for the descriptio n of a design. This\nstandard mainly addresses the kind of information needed an d its organization. For\nthe actual description of its constituent parts any existin g design notation can be\nused.\nBarnard et al. (1986) distinguishes between seven user role s for the design\ndocumentation:\n1. The project manager needs information to plan, control and manage the\nproject. He must be able to identify each system component an d understand\nits purpose and function. He also needs information to make c ost estimates and\ndeﬁne work packages.\n2. The conﬁguration manager needs information to be able to assemble the\nvarious components into one system and to control changes.\n3. The designer needs information about the function and use of each compone nt\nand its interfaces to other components.\n4. The programmer must know about algorithms to be used, data structures, and\nthe kinds of interaction with other components.\n12.6. DESIGN DOCUMENTATION 383\n5. The unit tester must have detailed information about components, such as\nalgorithms used, required initialization, and data needed .\n6. The integration tester must know about relations between components and\nthe function and use of the components involved.\n7. The maintenance programmer must have an overview of the relations between\ncomponents. He must know how the user requirements are reali zed by the\nvarious components. When changes are to be realized, he assu mes the role of\nthe designer.\nIn IEEE Standard 1016, the project documentation is describ ed as an information\nmodel. The entities in this model are the components identiﬁ ed during the design\nstage. We used the term ‘modules’ for these entities. Each of these modules has a\nnumber of relevant attributes, such as its name, function,", "token_count": 512, "start_token": 221298, "end_token": 221810, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 480, "text": " in this model are the components identiﬁ ed during the design\nstage. We used the term ‘modules’ for these entities. Each of these modules has a\nnumber of relevant attributes, such as its name, function, a nd dependencies. We may\nnow construct a matrix in which it is indicated which attribu tes are needed for which\nuser roles. This matrix is depicted in ﬁgure 12.35.\nAttributes User roles\n1 2 3 4 5 6 7\nIdentiﬁcation /A2 /A2 /A2 /A2 /A2 /A2 /A2\nType /A2 /A2 /A2 /A2\nPurpose /A2 /A2 /A2\nFunction /A2 /A2 /A2\nSubordinates /A2\nDependencies /A2 /A2 /A2\nInterface /A2 /A2 /A2 /A2\nResources /A2 /A2 /A2 /A2\nProcessing /A2 /A2\nData /A2 /A2\nFigure 12.35 User roles and attributes ( Source: H.J. Barnard et al, A recommended practice\nfor describing software designs: IEEE Standards Project 10 16, IEEE Transactions on Software\nEngineering SE-12, 2, Copyright 1986, IEEE. )\nIEEE Standard 1016 distinguishes ten attributes. These att ributes are minimally\nrequired in each project. The documentation about the desig n process is strongly\nrelated to the above design documentation. The design proce ss documentation\nincludes information pertaining to, among others, the desi gn status, alternatives that\nhave been rejected, and revisions that have been made. It is p art of conﬁguration\ncontrol, as discussed in chapter 4. The attributes from IEEE Standard 1016 are:\n384 SOFTWARE DESIGN\n/AF Identiﬁcation : the component’s name, for reference purposes. This name mu st\nbe unique.\n/AF Type: the kind of component, such as subsystem, procedure, modul e, ﬁle.\n/AF Purpose: what is the speciﬁc purpose of the component. This entry wil l refer\nback to the requirements speciﬁcation.\n/AF Function: what does the component accomplish. For a number of compone nts,", "token_count": 512, "start_token": 221760, "end_token": 222272, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 481, "text": " is the speciﬁc purpose of the component. This entry wil l refer\nback to the requirements speciﬁcation.\n/AF Function: what does the component accomplish. For a number of compone nts,\nthis information will occur in the requirements speciﬁcati on.\n/AF Subordinates: which components the present entity is composed of. It iden tiﬁes\na static is-composed-of relation between entities.\n/AF Dependencies: a description of the relationships with other components.\nIt concerns the uses-relation, see section 12.1.5, and incl udes more detailed\ninformation on the nature of the interaction (including com mon data structures,\norder of execution, parameter interfaces, and the like).\n/AF Interface: a description of the interaction with other components. Th is concerns\nboth the method of interaction (how to invoke an entity, how c ommunication is\nachieved through parameters) and rules for the actual inter action (encompassing\nthings like data formats, constraints on values and the mean ing of values).\n/AF Resources: the resources needed. Resources are entities external to t he design,\nsuch as memory, printers, or a statistical library. This inc ludes a discussion of\nhow to solve possible race or deadlock situations.\n/AF Processing: a description of algorithms used, way of initialization, a nd handling\nof exceptions. It is a reﬁnement of the function attribute.\n/AF Data: a description of the representation, use, format and meani ng of internal\ndata.\nFigure 12.35 shows that different users have different need s as regards design docu-\nmentation. A sound organization of this documentation is ne eded so that each user\nmay quickly ﬁnd the information he is looking for.\nIt is not necessarily advantageous to incorporate all attri butes into one document:\neach user gets much more than the information needed to play h is role. However, it\nis not necessarily advantageous to provide separate docume ntation for each user role:\nin that case, some items will occur three or four times, which is difﬁcult to handle and\ncomplicates the maintenance of the documentation.\nIn IEEE 1016 the attributes have been grouped into four clust ers. The decompo-\nsition is made such that most", "token_count": 512, "start_token": 222222, "end_token": 222734, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 482, "text": " times, which is difﬁcult to handle and\ncomplicates the maintenance of the documentation.\nIn IEEE 1016 the attributes have been grouped into four clust ers. The decompo-\nsition is made such that most users need information from onl y one cluster, while\nthese clusters contain a minimum amount of superﬂuous infor mation for that user.\nThis decomposition is given in table 12.4. It is interesting to note that each cluster\nhas its own view on the design. Each such view gives a complete description, thereby\n12.6. DESIGN DOCUMENTATION 385\nconcentrating on certain aspects of the design. This may be c onsidered an application\nof the IEEE recommended practice for architectural descrip tions IEEE (2000) long\nbefore that standard was developed.\nThe decomposition description describes the decomposition of the system into\nmodules. Using this description we may follow the hierarchi cal decomposition and\nas such describe the various abstraction levels.\nThe dependencies description gives the coupling between modules. It also sums up\nthe resources needed. We may then derive how parameters are p assed and which\ncommon data are used. This information is helpful when plann ing changes to the\nsystem and when isolating errors or problems in resource usa ge.\nThe interface description tells us how functions are to be used. This informa-\ntion constitutes a contract between different designers an d between designers and\nprogrammers. Precise agreements about this are especially needed in multi-person\nprojects.\nThe detail description gives internal details of each module. Programmers need the se\ndetails. This information is also useful when composing mod ule tests.\nTable 12.4 Views on the design ( Source: H.J. Barnard et al, A recommended practice for\ndescribing software designs: IEEE Standards Project 1016 , IEEE Transactions on Software\nEngineering SE-12, 2, Copyright 1986, IEEE .)\nDesign view Description Attributes User roles\nDecomposition Decomposition of\nthe system into\nmodules\nIdentiﬁcation,\ntype, purpose,\nfunction, subcom-\nponents\nProject manager\nDependencies Relations between\nmodules and\nbetween resources\nIdentiﬁcation,\ntype, purpose,\ndependencies,\nresources\nConﬁguration\nmanager,\nmaintenance\nprogrammer,\nintegration tester\n", "token_count": 512, "start_token": 222684, "end_token": 223196, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 483, "text": " Relations between\nmodules and\nbetween resources\nIdentiﬁcation,\ntype, purpose,\ndependencies,\nresources\nConﬁguration\nmanager,\nmaintenance\nprogrammer,\nintegration tester\nInterface How to use mod-\nules\nIdentiﬁcation,\nfunction, inter-\nfaces\nDesigner, integra-\ntion tester\nDetail Internal details of\nmodules\nIdentiﬁcation,\ncomputation, data\nModule tester,\nprogrammer\n386 SOFTWARE DESIGN\n12.7 Veriﬁcation and Validation\nErrors made at an early stage are difﬁcult to repair and incur high costs if they are not\ndiscovered until a late stage of development. It is therefor e necessary to pay extensive\nattention to testing and validation issues during the desig n stage.\nThe way in which the outcome of the design process can be subje ct to testing\nstrongly depends upon the way in which the design is recorded . If some formal\nspeciﬁcation technique is used, the resulting speciﬁcatio n can be tested formally.\nIt may also be possible to do static tests, such as checks for c onsistency. Formal\nspeciﬁcations may sometimes be executed, which offers addi tional ways to test the\nsystem. Such prototypes are especially suited to test the us er interface. Users often\nhave little idea of the possibilities to be expected and a spe ciﬁcation-based prototype\noffers good opportunities for aligning users’ requirement s and designers’ ideas.\nOften, the design is stated in less formal ways, limiting the possibilities for\ntesting to forms of reading and critiquing text, such as insp ections and walkthroughs.\nHowever, such design reviews provide an extremely powerful means for assessing\ndesigns.\nDuring the design process the system is decomposed into a num ber of modules.\nWe may develop test cases based on this process. These test ca ses may be used during\nfunctional testing at a later stage. Conversely, the softwa re architecture can be used\nto guide the testing process. A set of scenarios of typical or anticipated future usage\ncan be used to test the quality of the software architecture.\nA more comprehensive discussion of the various test techniq ues is", "token_count": 512, "start_token": 223146, "end_token": 223658, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 484, "text": "wa re architecture can be used\nto guide the testing process. A set of scenarios of typical or anticipated future usage\ncan be used to test the quality of the software architecture.\nA more comprehensive discussion of the various test techniq ues is given in\nchapter 13.\n12.8 Summary\nJust like designing a house, designing software is an activi ty which demands creativity\nand a fair dose of craftsmanship. The quality of the designer is of paramount\nimportance in this process. Mediocre designers will not del iver excellent designs.\nThe essence of the design process is that the system is decomp osed into parts that\neach have less complexity than the whole. Some form of abstra ction is always used in\nthis process. We have identiﬁed several guiding principles for the decomposition of a\nsystem into modules. These principles result in desirable p roperties for the outcome\nof the design process, a set of modules with mutual dependenc ies:\n/AF Modules should be internally cohesive, i.e. the constituen ts of a module should\n‘belong together’ and ‘be friends’. By identifying differe nt levels of cohesion, a\nqualitative notion of module cohesion is obtained.\n/AF The interfaces between modules should be as ‘thin’ as possib le. Again, various\nlevels of module coupling have been identiﬁed, allowing for an assessment of\nmutual dependencies between modules.\n12.8. SUMMARY 387\n/AF Each module should hide one secret. Information hiding is a powerful design\nprinciple, whereby each module is characterized by a secret which it hides\nfrom its environment. Abstract data types are a prime exampl e of the application\nof this principle.\n/AF The structure of the system, depicted as a graph whose nodes a nd edges\ndenote modules and dependencies between modules, respecti vely, should have\na simple and regular shape. The most constrained form of this graph is a tree.\nIn a less constrained form the graph is acyclic, in which case the set of modules\ncan be split into a number of distinct layers of abstraction.\nAbstraction is central to all of these features. In a properl y-designed system we should\nbe able to concentrate on the relevant issues and ignore the i rrelevant ones. This\nis an essential prerequisite for comprehending a", "token_count": 512, "start_token": 223608, "end_token": 224120, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 485, "text": ".\nAbstraction is central to all of these features. In a properl y-designed system we should\nbe able to concentrate on the relevant issues and ignore the i rrelevant ones. This\nis an essential prerequisite for comprehending a system, fo r implementing parts of\nit successfully without having to consider design decision s made elsewhere, and for\nimplementing changes locally, thus allowing for a smooth ev olution of the system.\nThe above features are highly interrelated and reinforce on e another. Information\nhiding results in modules with high cohesion and low couplin g. Cohesion and\ncoupling are dual characteristics. A clear separation of co ncerns results in a neat\ndesign structure.\nWe have discussed several measures to quantify properties o f a design. The most\nextensive research in this area concerns complexity metric s. These complexity metrics\nconcern both attributes of individual modules (called intr a-modular attributes) and\nattributes of a set of modules (called inter-module attribu tes).\nA word of caution is needed, though. Software complexity is a very illusive notion,\nwhich cannot be captured in a few simple numbers. Different c omplexity metrics\nmeasure along different dimensions of what is perceived as c omplexity. Also, large\nvalues for any such metric do not necessarily imply a bad desi gn. There may be good\nreasons to incorporate certain complex matters into one com ponent.\nA judicious and knowledgeable use of multiple design metric s is a powerful tool\nin the hands of the craftsman. Thoughtless application, how ever, will not help. To\nparaphrase Gunning, the inventor of the fog index (a popular readability measure for\nnatural language prose): design metrics can cause harm in mi suse.\nThere exist a great many design methods. They consist of a num ber of guidelines,\nheuristics and procedures on how to approach designing a sys tem and notations to\nexpress the result of that process. Design methods differ co nsiderably in their pre-\nscriptiveness, formality of notation, scope of applicatio n, and extent of incorporation\nin a more general development paradigm. Several tentative e fforts have been made to\ncompare design methods along different dimensions.\nWe discussed four design methods in this chapter:\n– functional decomposition,\n– data ﬂow design,\n388 SOFTWARE DESIGN\n– data structure design", "token_count": 512, "start_token": 224070, "end_token": 224582, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 486, "text": " fforts have been made to\ncompare design methods along different dimensions.\nWe discussed four design methods in this chapter:\n– functional decomposition,\n– data ﬂow design,\n388 SOFTWARE DESIGN\n– data structure design, and\n– object-oriented design.\nThe ﬁrst three design methods have been around longest. Obje ct-oriented analysis\nand design came later, and this is now the most widely used app roach, partly caused\nalso by the popularity of the notations of the Uniﬁed Modelin g Language (UML), its\nassociated tools, and full-scale development methods like RUP.\nProponents of object-oriented methods have claimed a numbe r of advantages of\nthe object-oriented approach over the more traditional, fu nction-oriented, approaches\nto design:\n/AF The object-oriented approach is more natural. It ﬁts the way we view the world\naround us. The concepts that show up in the analysis model hav e a direct\ncounterpart in the UoD being modeled, thus providing a direc t link between\nthe model and the world being modeled. This makes it easier fo r the client to\ncomprehend the model and discuss it with the analyst.\n/AF The object-oriented approach focuses on structuring the pr oblem rather than\nany particular solution to it. This point is closely related to the previous one.\nIn designs based on the functional paradigm the modules tend to correspond\nto parts of a solution to the problem. It may then not be easy to relate these\nmodules to the original problem. The result of an object-ori ented analysis\nand design is a hierarchy of objects with their associated at tributes which still\nresembles the structure of the problem space.\n/AF The object-oriented approach provides for a smoother trans ition from require-\nments analysis to design to code. In our discussion of the obj ect-oriented\napproach it is often difﬁcult to strictly separate UoD model ing aspects from\ndesign aspects. The object hierarchy that results from this process can be\ndirectly mapped onto the class hierarchy of the implementat ion (provided\nthe implementation language is object-oriented too). The a ttributes of objects\nbecome encapsulated by services provided by the objects in t he implementation.\n/AF The object-oriented approach leads to more �", "token_count": 512, "start_token": 224532, "end_token": 225044, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 487, "text": " implementat ion (provided\nthe implementation language is object-oriented too). The a ttributes of objects\nbecome encapsulated by services provided by the objects in t he implementation.\n/AF The object-oriented approach leads to more ﬂexible systems that are easier to\nadapt and change. Because the real-world objects have a dire ct counterpart in the\nimplementation, it becomes easy to link change requests to t he corresponding\nprogram modules. Through the inheritance mechanism, chang es can often be\nrealized by adding another specialized object rather than t hrough tinkering\nwith the code. For example, if we wish to extend our system dea ling with\nfurniture by adding another type of chair, say armchair, we d o so by deﬁning\na new object ArmChair, together with its own set of attributes, as another\nspecialization of Chair.\n/AF The object-oriented approach promotes reuse by focusing on the identiﬁcation\nof real-world objects from the application domain. In contr ast, more traditional\n12.8. SUMMARY 389\napproaches focus on identifying functions. In an evolving w orld, the objects\ntend to be stable, while the functions tend to change. For ins tance, in an ofﬁce\nenvironment the functions performed are likely to change wi th time, but there\nwill always be letters, folders, and so on. Thus, an object-o riented design is less\nsusceptible to changes in the world being modeled.\n/AF The inheritance mechanism adds to reusability. New objects can be created\nas specializations of existing objects, inheriting attrib utes from the existing\nobjects. At the implementation level, this kind of reuse is a ccomplished\nthrough code sharing. The increasing availability of class libraries contributes\nto this type of code reuse.\n/AF Objects in an object-oriented design encapsulate abstract data types. As such,\nan object-oriented design potentially has all the right pro perties (information\nhiding, abstraction, high cohesion, low coupling, etc).\nThe object-oriented approach, however, does not by deﬁniti on result in a good\ndesign. It is a bit too naive to expect that the identiﬁcation of domain-speciﬁc entities\nis all there is to good design. The", "token_count": 512, "start_token": 224994, "end_token": 225506, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 488, "text": " deﬁniti on result in a good\ndesign. It is a bit too naive to expect that the identiﬁcation of domain-speciﬁc entities\nis all there is to good design. The following issues must be ke pt in mind:\n/AF There are other objects besides the ones induced by domain co ncepts. Objects\nthat have to do with system issues such as memory management o r error\nrecovery do not naturally evolve from the modeling of the UoD . Likewise,\n‘hypothetical’ objects that capture implicit knowledge fr om the application\ndomain may be difﬁcult to identify.\n/AF The separation of concerns that results from the encapsulat ion of both state\nand behavior into one component need not be the one that is mos t desirable.\nFor example, for many an object it might be necessary to be abl e to present\nsome image of that object to the user. In a straightforward ap plication of the\nobject-oriented method, this would result in each object de ﬁning its own ways\nfor doing so. This, however, is against good practices of sys tem design, where\nwe generally try to isolate the user interface from the compu tational parts. A\nclearly identiﬁable user interface component adds to consi stency and ﬂexibility.\n/AF With objects too, we have to consider the uses relation. An ob ject uses another\nobject if it requests a service from that other object. It doe s so by sending\na message. The bottom-up construction of a collection of obj ects may result\nin a rather loosely-coupled set, in which objects freely sen d messages to\nother objects. With a nod at the term spaghetti-code to denot e overly complex\ncontrol patterns in programs, this is known as the ravioli problem (or antipatern).\nIf objects have a complicated usage pattern, it is difﬁcult t o view one object\nwithout having to consider many others as well.\nA design pattern is a recurring structure of communicating c omponents that solves a\ngeneral design problem within a particular context. A desig n pattern thus encompasses\n390 SOFTWARE DESIGN\nmore than a single component. It involves some, usually 2--5 , communicating\ncomponents which together solve a problem. The problem that the pattern", "token_count": 512, "start_token": 225456, "end_token": 225968, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 489, "text": " design problem within a particular context. A desig n pattern thus encompasses\n390 SOFTWARE DESIGN\nmore than a single component. It involves some, usually 2--5 , communicating\ncomponents which together solve a problem. The problem that the pattern solves is a\ngeneral, recurring one, which can be characterized by the co ntext in which it arises.\nA design pattern differs from an architectural style in that it does not address the\nstructure of a complete system, but only that of a few (intera cting) components.\nDesign patterns may thus be termed micro-architectures. No t surprisingly, the good\nthings about design patterns are essentially the same as tho se listed for software\narchitectures in chapter 11.\nDesign patterns describe best practices. They represent th e collective experience\nof some of the most experienced and successful software desi gners. Likewise, antipat-\nterns describe widely shared bad experiences. The descript ion of both patterns and\nantipatterns, as found in textbooks, is the result of endles s carving and smoothing.\nSome are the outcome of writers’ workshops, a format commonl y used to review\nliterature, suggesting that we should review software lite rature with a profoundness\nlike that used to review poetry (as a consequence, these writ ers’ workshops are also\nknown as workers’ write shops).\nThe distinction between the notions software architecture and design pattern is\nby no means sharp. Some authors for example use the term ‘arch itectural pattern’ to\ndenote the architectural styles we discussed in section 11. 4. The notions application\nframework and idiom are generally used to denote a software a rchitecture and design\npattern, respectively, at a more concrete, implementation -speciﬁc level. But again,\nthe distinction is not sharp.\nFinally, the design itself must also be documented. IEEE Sta ndard 1016 may\nserve as a guideline for this documentation. It lists a numbe r of attributes for each\ncomponent of the design. These attributes may be clustered i nto four groups, each\nof which represents a certain view on the design. This resemb les the way IEEE 1471\nadvocates to document a software architecture.\nUnfortunately, the design documentation typically descri bes only the design result\nand not the process that led to that particular result. Yet, i nformation about", "token_count": 512, "start_token": 225918, "end_token": 226430, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 490, "text": " This resemb les the way IEEE 1471\nadvocates to document a software architecture.\nUnfortunately, the design documentation typically descri bes only the design result\nand not the process that led to that particular result. Yet, i nformation about choices\nmade, alternatives rejected, and deliberations on the desi gn decisions is a valuable\nadditional source of information when a design is to be imple mented, assessed, or\nchanged.\n12.9 Further Reading\nBudgen (2003) is a good textbook on software design. I found t he ‘software as a\nwicked problem’ analogy in that text. Bergland and Gordon (1 981) and Freeman\nand Wasserman (1983) are compilations of seminal articles o n software design. For\nan interesting discussion on the ‘Scandinavian’ approach t o system development, see\n(Floyd et al., 1989) or (CACM, 1993a). Wieringa (1998) provi des an extensive survey\nof both classical and object-oriented design methods and th eir notations.\nThe classic text on Structured Analysis and Design is (Yourd on and Constantine,\n1975). Other names associated with the development of SA/SD are DeMarco\n12.9. FURTHER READING 391\n(DeMarco, 1979) and Gane and Sarson (Gane and Sarson, 1979).\nFor a full exposition of JSP, the reader is referred to (Jacks on, 1975) or (King,\n1988). JSP is very similar to a method developed by J.-D. Warn ier in France at\nabout the same time (Warnier, 1974). The latter is known as Lo gical Construction of\nPrograms (LCP) or the Warnier--Orr method, after Ken Orr who was instrumental\nin the translation of Warnier’s work. For a full exposition o f JSD, see (Jackson, 1983),\n(Cameron, 1989) or (Sutcliffe, 1988). The graphical notati ons used in this chapter\nare those of (Sutcliffe, 1988).\nBooch’ method for object-oriented analysis and design is di scussed in (Booch,\n1994). Fusion is described in (Coleman et al., 1994). Update s to this 1994 version\ncan be found in (Coleman, 1996). RUP is", "token_count": 512, "start_token": 226380, "end_token": 226892, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 491, "text": " object-oriented analysis and design is di scussed in (Booch,\n1994). Fusion is described in (Coleman et al., 1994). Update s to this 1994 version\ncan be found in (Coleman, 1996). RUP is discussed in (Kruchte n, 2003). A critical\ndiscussion of the differences and similarities between obj ect-oriented analysis and\nobject-oriented design is given in (Davis, 1995) and (Hødal svik and Sindre, 1993).\nFenton and Pﬂeeger (1996) presents a rigorous approach to th e topic of software\nmetrics. The authors explain the essentials of measurement theory and illustrate\nthese using a number of proposed metrics (including those fo r complexity, quality\nassessment, and cost estimation).\nCohesion and coupling were introduced in (Yourdon and Const antine, 1975).\nEfforts to objectify these notions can be found in (Offutt et al., 1993), (Patel et al.,\n1992) and(Xia, 2000). Darcy (2005) describes empirical stu dies to validate the\nimportance of weak coupling and strong cohesion.\nHalstead’s method, ‘software science’, is described in (Ha lstead, 1977) and\n(Fitzsimmons and Love, 1978). Positive evidence of its vali dity is reported in (Curtis\net al., 1979) and (Elshoff, 1976). A good overview of the crit icism of this method\n(as well as McCabe’s cyclomatic complexity and Henri and Kaf ura’s information ﬂow\nmetric) is given in (Shepperd and Ince, 1993). McCabe’s cycl omatic complexity is\nintroduced in (McCabe, 1976). In most discussions of this me tric, the wrong formula\nis used; see exercise 24 or (Henderson Sellers, 1992). Discu ssions in favor of using a\n(cyclomatic) complexity density metric can be found in (Mata-Toledo and Gustafson,\n1992) and (Hops and Sherif, 1995).\nDeﬁnitions of the object-oriented metrics introduced in se ction 12.1.6 can be\nfound in (Chidamber and Kemerer, 1994). A critical assessme nt of these metrics is\ngiven in (Hitz", "token_count": 512, "start_token": 226842, "end_token": 227354, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 492, "text": "�nitions of the object-oriented metrics introduced in se ction 12.1.6 can be\nfound in (Chidamber and Kemerer, 1994). A critical assessme nt of these metrics is\ngiven in (Hitz and Montazeri, 1996) and (Churcher and Sheppe rd, 1995). To meet\nsome of this criticism, we have adopted the deﬁnition of LCOM , as suggested in (Li\nand Henry, 1993). Experiments to validate the Chidamber--K emerer metrics suite\nare reported in (Succi et al., 2003), (Darcy and Kemerer, 200 5) and (Gyim ´ othy et al.,\n2005).\nDesign patterns have their origin in the work of Cunningham a nd Beck, who\ndeveloped patterns for user interfaces in Smalltalk, such a s ‘no more than three panes\nper window’ (Power and Weiss, 1987, p. 16). MVC was ﬁrst used i n the Smalltalk\nenvironment (Krasner and Pope, 1988). Since that time, the t opic has drawn a lot of\nattention, especially in object-oriented circles. A major collection of design patterns\nwas published by the ‘Gang of Four’ in 1995 (Gamma et al., 1995 ). Another good\n392 SOFTWARE DESIGN\ncollection of design patterns can be found in (Buschmann et a l., 1996). The latter text\nhas a somewhat less object-oriented perspective than (Gamm a et al., 1995). Brown\net al. (1998) describes a collection of well-known antipatt erns. Since 1994, there\nhas been an annual conference on Pattern Languages of Progra mming (PLOP). The\nformat for describing patterns has not only been used for des ign patterns; there are\nalso collections of analysis patterns, process patterns, t est patterns, etc.\nExercises\n1. What is the difference between procedural abstraction an d data abstraction?\n2. List and explain Yourdon and Constantine’s seven levels o f cohesion.\n3. Explain the notions cohesion and coupling.\n4. In what sense are the various notions of coupling technolo gy-dependent?\n5. What is the essence of information hiding?\n6. Give an outline of Halstead’s software science.\n7. Determine the cyclomatic complexity of", "token_count": 512, "start_token": 227304, "end_token": 227816, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 493, "text": " what sense are the various notions of coupling technolo gy-dependent?\n5. What is the essence of information hiding?\n6. Give an outline of Halstead’s software science.\n7. Determine the cyclomatic complexity of the following pro gram:\nno 6:= true; sum:= 0;\nfor i to no of courses do\nif grade[i] /BO 7 then no 6:= false endif;\nsum:= sum + grade[i]\nendfor;\naverage:= sum / no of courses;\nif average /AL 8 and no 6\nthen print(”with distinction”)\nendif;\n8. Would the cyclomatic complexity be any different if the la st if-statement\nwere written as follows:\nif average /AL 8 then\nif no 6\nthen print(”with distinction”)\nendif\nendif;\nDoes this concur with your own ideas of a control complexity m easure, i.e.\ndoes it fulﬁll the representation condition?\n12.9. FURTHER READING 393\n9. Give the formula and a rationale for the information ﬂow co mplexity metric.\n10. Is cyclomatic complexity a good indicator of system comp lexity?\n11. Draw the call graphs for a non-trivial program you have wr itten, and determine\nits tree impurity. Does the number obtained agree with our in tuitive idea\nabout the ‘quality’ of the decomposition?\n12. Compute Henri and Kafura’s information ﬂow metric for th e design of two\nsystems you have been involved in. Do these numbers agree wit h our intuitive\nunderstanding?\n13. Why is DIT -- the depth of a class in the inheritance tree -- a useful metric to\nconsider when assessing the quality of an object-oriented s ystem?\n14. What does RFC -- Response For a Class -- measure?\n15. How does the Law of Demeter relate to the maintainability of object-oriented\nsystems?\n16. Discuss the relative merits and drawbacks of deep and nar row versus wide\nand shallow inheritance trees.\n17. What is functional decomposition?\n18. Give a global sketch of the Data Flow Design method.\n19. Explain what a structure clash is in JSP.\n20. What is the main difference between", "token_count": 512, "start_token": 227766, "end_token": 228278, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 494, "text": "and shallow inheritance trees.\n17. What is functional decomposition?\n18. Give a global sketch of the Data Flow Design method.\n19. Explain what a structure clash is in JSP.\n20. What is the main difference between problem-oriented an d product-oriented\ndesign methods?\n21. Discuss the general ﬂavor of RUP˘s Analysis and Design wo rkﬂow.\n22. What are the differences between object-oriented desig n and the simple\napplication of the information hiding principle?\n23. What are the properties of a design pattern?\n24. /DI Make it plausible that the formula for the cyclomatic comple xity should\nread /BV /CE /BP /CT /A0 /D2 /B7 /D4 /B7 /BD rather than /BV /CE /BP /CT /A0 /D2 /B7 /BE /D4 . (Hint: consider\nthe following program:\nbegin\nif A then B else C endif;\ncall P;\nprint(”done”)\nend;\n394 SOFTWARE DESIGN\nprocedure P;\nbegin\nif X then Y else Z endif\nend P;\nDraw the ﬂow graph for this program as well as for the program o btained\nby substituting the body of procedure P inline. Determine the cyclomatic\ncomplexity of both variants, using both formulae. See also ( Henderson Sellers,\n1992).)\n25. /DJ Write the design documentation for a project you have been in volved in,\nfollowing IEEE 1016.\n26. /DJ Discuss the pros and cons of:\n– functional decomposition,\n– data ﬂow design,\n– design based on data structures, and\n– object-oriented design\nfor the design of each of:\n– a compiler,\n– a patient monitoring system, and\n– a stock control system.\n27. /DJ Discuss the possible merits of those design techniques with respect to\nreusability.\n28. /DJ Augment IEEE Standard 1016 such that it also describes the de sign\nrationale. Which user roles are in need of this type of inform ation?\n29. /DI According to (Fenton and Pﬂeeger, 1996), any tree impurity m etric /D1\nshould have the following properties", "token_count": 512, "start_token": 228228, "end_token": 228740, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 495, "text": " Which user roles are in need of this type of inform ation?\n29. /DI According to (Fenton and Pﬂeeger, 1996), any tree impurity m etric /D1\nshould have the following properties:\na. /D1 /B4 /BZ /B5 /BP /BC if and only if /BZ is a tree;\nb. /D1 /B4 /BZ\n/BD\n/B5 /BQ /D1 /B4 /BZ\n/BE\n/B5 if /BZ\n/BD\ndiffers from /BZ\n/BE\nonly by the insertion of an extra\narc;\nc. For /CX /BP /BD /BN /BE let /BT\n/CX\ndenote the number of arcs in /BZ\n/CX\nand /C6\n/CX\nthe number of\nnodes in /BZ\n/CX\n. Then if /C6\n/BD\n/BQ /C6\n/BE\nand /BT\n/BD\n/A0 /C6\n/BD\n/B7 /BD /BP /BT\n/BE\n/A0 /C6\n/BE\n/B7 /BD , then\n/D1 /B4 /BZ\n/BD\n/B5 /BO /D1 /B4 /BZ\n/BE\n/B5 .\n12.9. FURTHER READING 395\nd. For all graphs /BZ , /D1 /B4 /BZ /B5 /AK /D1 /B4 /C3\n/C6\n/B5 /BP /BD where /C6 = number of nodes of /BZ\nand /C3\n/C6\nis the (undirected) complete graph of /C6 nodes.\nGive an intuitive rationale for these properties. Show that the tree impurity\nmetric discussed in section 12.1.5 has these properties.\n30. /DI Extend the object model of ﬁgure 12.27 such that it also model s user\nqueries to the catalog.\n31. /DI Extend the model from the previous exercise such that it also includes the\nattributes and services of objects.\n32. /DJ Write an essay on the differences and similarities of analys is and design\n", "token_count": 512, "start_token": 228690, "end_token": 229202, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 496, "text": "eries to the catalog.\n31. /DI Extend the model from the previous exercise such that it also includes the\nattributes and services of objects.\n32. /DJ Write an essay on the differences and similarities of analys is and design\nactivities in object-oriented analysis and design.\n33. /DI Why would object-oriented design be more ‘natural’ than, sa y, data ﬂow\ndesign?\n34. /DJ Discuss the assertion ‘The view that object-oriented metho ds make change\neasy is far too simplistic’. Consult (Lubars et al., 1992), w ho found that\nchanges to object models were fairly localized, whereas cha nges to behavior\nmodels had more far-reaching consequences.\n35. /DI The Document--View pattern relaxes the separation of view a nd controller\nin MVC. Describe the Document--View pattern in terms of the c ontext\nin which it arises, the problem addressed, and its solution. Compare your\nsolution with the Observer pattern in (Gamma et al., 1995, p. 293).\n36. /DI How do design patterns impact the quality of a design?\n13\nSoftware Testing\nLEARNING OBJECTIVES\n/AF To be aware of the major software testing techniques\n/AF To see how different test objectives lead to the selection of different testing\ntechniques\n/AF To appreciate a classiﬁcation of testing techniques, based on the objectives\nthey try to reach\n/AF To be able to compare testing techniques with respect to thei r theoretical\npower as well as practical value\n/AF To understand the role and contents of testing activities in different life cycle\nphases\n/AF To be aware of the contents and structure of the test document ation\n/AF To be able to distinguish different test stages\n/AF To be aware of some mathematical models to estimate the relia bility of software\n397\nTesting should not be conﬁned to merely executing a system to see whether\na given input yields the correct output. During earlier phas es, intermediate\nproducts can, and should, be tested as well. Good testing is d ifﬁcult. It\nrequires careful planning and documentation. There exist a large number of\ntest technieques. We discuss the major classes of test techn iques with their\ncharacteristics.\nSuppose you are asked to answer the", "token_count": 512, "start_token": 229152, "end_token": 229664, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 497, "text": "ﬁcult. It\nrequires careful planning and documentation. There exist a large number of\ntest technieques. We discuss the major classes of test techn iques with their\ncharacteristics.\nSuppose you are asked to answer the kind of questions posed in (Baber, 1982):\n– Would you trust a completely-automated nuclear power plan t?\n– Would you trust a completely-automated pilot whose softwa re was written by\nyourself? What if it was written by one of your colleagues?\n– Would you dare to write an expert system to diagnose cancer? What if you are\npersonally held liable in a case where a patient dies because of a malfunction of\nthe software?\nYou will (probably) have difﬁculties answering all these qu estions in the afﬁrmative.\nWhy? The hardware of an airplane probably is as complex as the software for an\nautomatic pilot. Yet, most of us board an airplane without an y second thoughts.\nAs our society’s dependence on automation ever increases, t he quality of the\nsystems we deliver increasingly determines the quality of o ur existence. We cannot\nhide from this responsibility. The role of automation in cri tical applications and the\nthreats these applications pose should make us ponder. ACM Software Engineering Notes\nruns a column ‘Risks to the public in computer systems’ in whi ch we are told of\nnumerous (near) accidents caused by software failures. The discussion on software\nreliability provoked by the Strategic Defense Initiative i s a case in point (Parnas,\n1985; Myers, 1986; Parnas, 1987). Discussions, such as thos e about the Therac-25\naccidents or the maiden ﬂight of the Ariane 5 (see section 1.4 ), should be compulsory\nreading for every software engineer.\nSoftware engineering is engineering. Engineers aim for the perfect solution, but\nknow this goal is generally unattainable. During software c onstruction, errors are\nmade. To locate and ﬁx those errors through excessive testin g is a laborious affair and\nmostly not all the errors are found. Good testing is at least a s difﬁcult as good design.\nWith the current state of the art we are not able to deliver fau lt-free software.\nDifferent studies indicate that 30--85", "token_count": 512, "start_token": 229614, "end_token": 230126, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 498, "text": " are found. Good testing is at least a s difﬁcult as good design.\nWith the current state of the art we are not able to deliver fau lt-free software.\nDifferent studies indicate that 30--85 errors per 1000 line s of source code are made.\nThese ﬁgures seem not to improve over time. During testing, q uite a few of those\nerrors are found and subsequently ﬁxed. Yet, some errors do r emain undetected.\nMyers (1986) gives examples of extensively-tested softwar e that still contains 0.5--3\nerrors per 1000 lines of code. A fault in the seat reservation system of a major airline\ncompany incurred a loss of $50M in one quarter. The computeri zed system reported\nthat cheap seats were sold out while this was in fact not the ca se. As a consequence,\n398 SOFTWARE TESTING\nclients were referred to other companies. The problems were not discovered until\nquarterly results were found to lag considerably behind tho se of their competitors.\nTesting is often taken to mean executing a program to see whet her it produces\nthe correct output for a given input. This involves testing t he end-product, the\nsoftware itself. As a consequence, the testing activity oft en does not get the attention\nit deserves. By the time the software has been written, we are often pressed for time,\nwhich does not encourage thorough testing.\nPostponing test activities for too long is one of the most sev ere mistakes often\nmade in software development projects. This postponement m akes testing a rather\ncostly affair. Figure 13.1 shows the results of an early stud y by Boehm about the\ncost of error correction relative to the phase in which the er ror is discovered. This\npicture shows that errors which are not discovered until aft er the software has\nbecome operational incur costs that are 10 to 90 times higher than those of errors\nthat are discovered during the design phase. This ratio stil l holds for big and critical\nsystems (Boehm and Basili, 2001). For small, noncritical sy stems the ratio may be\nmore like 1 to 5.\nThe development methods and techniques that are applied in t he pre-implementation\nphases are least developed, relatively. It is therefore not surprising that most of the\nerrors are made in those early phases. An", "token_count": 512, "start_token": 230076, "end_token": 230588, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 499, "text": "more like 1 to 5.\nThe development methods and techniques that are applied in t he pre-implementation\nphases are least developed, relatively. It is therefore not surprising that most of the\nerrors are made in those early phases. An early study by Boehm showed that over\n60% of the errors were introduced during the design phase, as opposed to 40% during\nimplementation (Boehm, 1975). Worse still, two-thirds of t he errors introduced at the\ndesign phase were not discovered until after the software ha d become operational.\nIt is therefore incumbent on us to plan carefully our testing activities as early\nas possible. We should also start the actual testing activit ies at an early stage. An\nextreme form hereof is test-driven development, one of the p ractices of XP, in\nwhich development starts with writing tests. If we do not start testing until after\nthe implementation stage, we are really far too late. The req uirements speciﬁcation,\ndesign, and design speciﬁcation may also be tested. The rigo r hereof depends on the\nform in which these documents are expressed. This has alread y been hinted at in\nprevious chapters. In section 13.2, we will again highlight the various veriﬁcation and\nvalidation activities that may be applied at the different p hases of the software life\ncycle. The planning and documentation of these activities i s discussed in section 13.3.\nBefore we decide upon a certain approach to testing, we have t o determine our\ntest objectives. If the objective is to ﬁnd as many errors as p ossible, we will opt\nfor a strategy which is aimed at revealing errors. If the obje ctive is to increase our\nconﬁdence in the proper functioning of the software we may we ll opt for a completely\ndifferent strategy. So the objective will have its impact on the test approach chosen,\nsince the results have to be interpreted with respect to the o bjectives set forth.\nDifferent test objectives and the degree to which test appro aches ﬁt these objectives\nare the topic of section 13.1.\nTesting software shows only the presence of errors, not thei r absence. As such,\nit yields a rather negative result: up to now, only /D2 (/D2 /AL /BC ) errors have", "token_count": 512, "start_token": 230538, "end_token": 231050, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 500, "text": " section 13.1.\nTesting software shows only the presence of errors, not thei r absence. As such,\nit yields a rather negative result: up to now, only /D2 (/D2 /AL /BC ) errors have been found.\nOnly when the software is tested exhaustively are we certain about its functioning\n399\nFigure 13.1 Relative cost of error correction ( Source: Barry B. Boehm , Software Engi-\nneering Economics, ﬁg. 4.2, page 40, 1981, Reprinted by permission of Prentice H all, Inc.\nEnglewood Cliffs, NJ )\ncorrectly. In practice this seldom happens. A simple progra m like\nfor i from 1 to 100 do\nprint ( if a[i] = true then 1 else 0 endif);\nhas /BE\n/BD/BC/BC\ndifferent outcomes. Even on a very fast machine -- say a machi ne which\nexecutes 10 million print instructions per second -- exhaus tively testing this program\nwould take /BF /A2 /BD/BC\n/BD/BG\nyears.\nAn alternative to this brute force approach to testing is to p rove the correctness\nof the software. Proving the correctness of software very so on becomes a tiresome\nactivity, however. It furthermore applies only in circumst ances where software\nrequirements are stated formally. Whether these formal req uirements are themselves\ncorrect has to be decided upon in a different way.\n400 SOFTWARE TESTING\nWe are thus forced to make a choice. It is of paramount importa nce to choose\na sufﬁciently small, yet adequate, set of test cases. Test te chniques may be classiﬁed\naccording to the criterion used to measure the adequacy of a s et of test cases:\nCoverage-based testing In coverage-based testing, testing requirements are speci ﬁed\nin terms of the coverage of the product (program, requiremen ts document, etc.) to\nbe tested. For example, we may specify that all statements of the program should\nbe executed at least once if we run the complete test set, or th at all elementary\nrequirements from the requirements speciﬁcation should be exercised at least once.\nFault-based testing Fault-based techniques focus on detecting faults. The faul t\ndetecting ability", "token_count": 512, "start_token": 231000, "end_token": 231512, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 501, "text": " set, or th at all elementary\nrequirements from the requirements speciﬁcation should be exercised at least once.\nFault-based testing Fault-based techniques focus on detecting faults. The faul t\ndetecting ability of the test set then determines its adequa cy. For example, we may\nartiﬁcially seed a number of faults in a program, and then req uire that a test set reveal\nat least, say, 95% of these artiﬁcial faults.\nError-based testing Error-based techniques focus on error-prone points, based on\nknowledge of the typical errors that people make. For exampl e, off-by-1 errors are\noften made at boundary values such as 0 or the maximum number o f elements in a\nlist, and we may speciﬁcally aim our testing effort at these b oundary points.\nAlternatively, we may classify test techniques based on the source of information\nused to derive test cases:\nBlack-box testing , also called functional or speciﬁcation-based testing . In black-box\ntesting, test cases are derived from the speciﬁcation of the software, i.e. we do not\nconsider implementation details.\nWhite-box testing , also called structural or program-based testing . This is a com-\nplementary approach, in which we do consider the internal logical structure of the\nsoftware in the derivation of test cases.\nWe will use the ﬁrst classiﬁcation, and discuss different te chniques for coverage-based,\nfault-based and error-based testing in sections 13.5--13. 7. These techniques involve\nthe actual execution of a program. Manual techniques which d o not involve program\nexecution, such as code reading and inspections, are discus sed in section 13.4. In\nsection 13.8 we assess some empirical and theoretical studi es that aim to put these\ndifferent test techniques in perspective.\nThe above techniques are applied mainly at the component lev el. This level of\ntesting is often done concurrently with the implementation phase. It is also called\nunit testing . Besides the component level, we also have to test the integr ation of a\nset of components into a system. Possibly also, the ﬁnal syst em will be tested once\nmore under direct supervision", "token_count": 512, "start_token": 231462, "end_token": 231974, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 502, "text": "\nunit testing . Besides the component level, we also have to test the integr ation of a\nset of components into a system. Possibly also, the ﬁnal syst em will be tested once\nmore under direct supervision of the prospective user. In se ction 13.9 we will sketch\nthese different test phases.\nAt the system level, the goal pursued often shifts from detec ting faults to\nbuilding trust, by quantitatively assessing reliability. Software reliability is discussed\nin section 13.10.\n13.1. TEST OBJECTIVES 401\n13.1 Test Objectives\nUntil now, we have not been very precise in our use of the notio n of an ‘error’. In order\nto appreciate the following discussion, it is important to m ake a careful distinction\nbetween the notions error, fault and failure. An error is a human action that produces an\nincorrect result. The consequence of an error is software co ntaining a fault. A fault\nthus is the manifestation of an error. If encountered, a faul t may result in a failure. 1\nSo, what we observe during testing are failures. These failu res are caused by faults,\nwhich are in turn the result of human errors. A failure may be c aused by more than\none fault, and a fault may cause different failures. Similar ly, the relation between\nerrors and faults need not be 1--1.\nOne possible aim of testing is to ﬁnd faults in the software. T ests are then intended\nto expose failures. It is not easy to give a precise, unique, d eﬁnition of the notion\nof failure. A programmer may take the system’s speciﬁcation as reference point. In\nthis view, a failure occurs if the software does not meet the s peciﬁcations. The user,\nhowever, may consider the software erroneous if it does not m atch expectations.\n‘Failure’ thus is a relative notion. If software fails, it do es so with respect to something\nelse (a speciﬁcation, user manual, etc). While testing soft ware, we must always be\naware of what the software is being tested against.\nIn this respect a distinction is often made between ‘veriﬁca tion’ and ‘validation’.\nThe", "token_count": 512, "start_token": 231924, "end_token": 232436, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 503, "text": " testing soft ware, we must always be\naware of what the software is being tested against.\nIn this respect a distinction is often made between ‘veriﬁca tion’ and ‘validation’.\nThe IEEE Glossary deﬁnes veriﬁcation as the process of evaluating a system or\ncomponent to determine whether the products of a given devel opment phase satisfy\nthe conditions imposed at the start of that phase. Veriﬁcati on thus tries to answer the\nquestion: Have we built the system right?\nThe term ‘validation’ is deﬁned in the IEEE Glossary as the process of evaluating a\nsystem or component during or at the end of the development pr ocess to determine\nwhether it satisﬁes speciﬁed requirements. Validation the n boils down to the question:\nHave we built the right system?\nEven with this subtle distinction in mind, the situation is n ot all that clear-cut.\nGenerally, a program is considered correct if it consistent ly produces the right output.\nWe may, though, easily conceive of situations where the prog rammer’s intention is not\nproperly reﬂected in the program but the errors simply do not manifest themselves.\nAn early empirical study showed that many faults are never ac tivated during the\nlifetime of a system (Adams, 1984). Is it worth ﬁxing those fa ults? For example, some\nentry in a case statement may be wrong, but this fault never sh ows up because it\nhappens to be subsumed by a previous entry. Is this program co rrect, or should it\nrather be classiﬁed as a program with a ‘latent’ fault? Even i f it is considered correct\n1 The IEEE Glossary of Software Engineering Terminology gives four deﬁnitions of the word ‘error’. To\ndistinguish between these deﬁnitions, the words ‘error’, ‘ fault’, ‘failure’ and ‘mistake’ are used. The word\n‘error’ in the Glossary is used to denote a measurement error, while ‘mistake’ is use d to denote a human\nerror. Though ‘mistake’ has", "token_count": 512, "start_token": 232386, "end_token": 232898, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 504, "text": "’ are used. The word\n‘error’ in the Glossary is used to denote a measurement error, while ‘mistake’ is use d to denote a human\nerror. Though ‘mistake’ has the advantage of being less cond emning, we follow the accepted software\nengineering literature in this respect. Our deﬁnitions of ‘ fault’ and ‘failure’ are the same as those in the\nGlossary.\n402 SOFTWARE TESTING\nwithin the context at hand, chances are that we get into troub le if the program is\nchanged or parts of it are reused in a different environment.\nAs an example, consider the maiden ﬂight of the Ariane 5. With in 40 seconds after\ntake-off, at an altitude of 3700 meters, the launcher explod ed. This was ultimately\ncaused by an overﬂow in a conversion of a variable from a 64-bi t ﬂoating point\nnumber to a 16-bit signed integer. The piece of software cont aining this error was\nreused from the Ariane 4 and had never caused a problem in any of the Ariane 4 ﬂights.\nThis is explained by the fact that the Ariane 5 builds up speed much faster than the\nAriane 4, which in turn resulted in excessive values for the p arameter in question; see\nalso section 1.4.1.\nWith the above deﬁnitions of error and fault, such programs m ust be considered\nfaulty, even if we cannot devise test cases that reveal the fa ults. This still leaves\nopen the question of how to deﬁne errors. Since we cannot but g uess what the\nprogrammer’s real intentions were, this can only be decided upon by an oracle.\nGiven the fact that exhaustive testing is not feasible, the t est process can be\nthought of as depicted in ﬁgure 13.2. The box labeled P denote s the object (program,\ndesign document, etc.) to be tested. The test strategy invol ves the selection of a\nsubset of the input domain. For each element of this subset, P is used to ‘compute’ the\ncorresponding output. The expected output is determined by an oracle, something\noutside the test activity. Finally,", "token_count": 512, "start_token": 232848, "end_token": 233360, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 505, "text": "subset of the input domain. For each element of this subset, P is used to ‘compute’ the\ncorresponding output. The expected output is determined by an oracle, something\noutside the test activity. Finally, the two answers are comp ared.\nFigure 13.2 Global view of the test process\nThe most crucial step in this process is the selection of the s ubset of the input\ndomain which will serve as the test set. This test set must be a dequate with respect\nto some chosen test criterion. In section 13.1.1 we elaborat e upon the notion of test\nadequacy.\nTest techniques generally use some systematic means to deri ve test cases. These\ntest cases are meant to provoke failures. Thus, the main obje ctive is fault detection.\nAlternatively, our test objective could be to increase our c onﬁdence in failure-free\nbehavior. These quite different test objectives, and their impact on the test selection\nproblem, are the topic of section 13.1.2.\n13.1. TEST OBJECTIVES 403\nTo test whether the objectives are reached, test cases are tr ied in order that faults\nmanifest themselves. A quite different approach is to view t esting as fault prevention.\nThis leads us to another dimension of test objectives, which to a large extent parallels\nthe evolution of testing strategies over the years. This evo lution is discussed in\nsection 13.1.3.\nFinally, the picture so far considers each fault equally haz ardous. In reality,\nthere are different types of fault, and some faults are more h armful than others. All\ntechniques to be discussed in this chapter can easily be gene ralized to cover multiple\nclasses of faults, each with its own acceptance criteria.\nSome faults are critical and we will have to exert ourselves i n order to ﬁnd those\ncritical faults. Special techniques, such as fault tree ana lysis, have been developed\nto this end. Using fault tree analysis, we try to derive a cont radiction by reasoning\nbackwards from a given, undesirable, end situation. If such a contradiction can be\nderived, we have shown that that particular situation can ne ver be reached.\n13.1.1 Test Adequacy Criteria\nConsider the program text in ﬁgure 13.3 and a test set\n/", "token_count": 512, "start_token": 233310, "end_token": 233822, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 506, "text": " can be\nderived, we have shown that that particular situation can ne ver be reached.\n13.1.1 Test Adequacy Criteria\nConsider the program text in ﬁgure 13.3 and a test set\n/CB containing just one test case:\nn = 2, A[1] = 10, A[2] = 5\nIf we execute the program using /CB , then all statements are executed at least once.\nIf our criterion to judge the adequacy of a test set is that 100 % of the statements\nare executed, then /CB is adequate. If our criterion is that 100% of the branches are\nexecuted, then /CB is not adequate, since the (empty) else-branch of the if-sta tement is\nnot executed by /CB .\nA test adequacy criterion thus speciﬁes requirements for testing. It can be used\nin different ways: as stopping rule, as measurement, or as te st case generator. If a test\nadequacy criterion is used as a stopping rule, it tells us whe n sufﬁcient testing has\nbeen done. If statement coverage is the criterion, we may sto p testing if all statements\nhave been executed by the tests done so far. In this view, a tes t set is either good\nor bad; the criterion is either met, or it isn’t. If we relax th is requirement a bit and\nuse, say, the percentage of statements executed as a test qua lity criterion, then the\ntest adequacy criterion is used as a measurement. Formally, it is a mapping from the\ntest set to the interval /CJ/BC /BN /BD℄ . Note that the stopping rule view is in fact a special\ncase of the measurement view. Finally, the test adequacy cri terion can be used in the\ntest selection process. If a 100% statement coverage has not been achieved yet, an\nadditional test case is selected that covers one or more stat ements yet untested. This\ngenerative view is used in many test tools.\nTest adequacy criteria are closely linked to test technique s. For example, coverage-\nbased test techniques keep track of which statements, branc hes, and so on, are\nexecuted, and this gives us an easy handle to determine wheth er a coverage-based\nadequacy criterion has been met or", "token_count": 512, "start_token": 233772, "end_token": 234284, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 507, "text": ", coverage-\nbased test techniques keep track of which statements, branc hes, and so on, are\nexecuted, and this gives us an easy handle to determine wheth er a coverage-based\nadequacy criterion has been met or not. The same test techniq ue, however, does not\nhelp us in assessing whether all error-prone points in a prog ram have been tested.\n404 SOFTWARE TESTING\nIn a sense, a given test adequacy criterion and the correspon ding test technique are\nopposite sides of the same coin.\n13.1.2 Fault Detection Versus Conﬁdence Building\nFailures are needles in the haystack of the input domain\n(Hamlet and Taylor, 1990)\nSuppose we wish to test some component P which sorts an array A[1..n] of integers,\n1\n/AK n /AK 1000. Since exhaustive testing is not feasible, we are looki ng for a strategy\nin which only a small number of tests are exercised. One possi ble set of test cases is\nthe following:\nLet n assume values 0, 1, 17 and 1000. For each of n = 17 and n = 1000, choose three\nvalues for the array A:\n– A consists of randomly selected integers;\n– A is sorted in ascending order;\n– A is sorted in descending order.\nIn following this type of constructive approach, the input d omain is partitioned\ninto a ﬁnite, small number of subdomains. The underlying ass umption is that these\nsubdomains are equivalence classes , i.e. from a testing point of view each member\nfrom a given subdomain is as good as any other. For example, we have tacitly assumed\nthat one random array of length 17 is as good a test as any other random array of\nlength\n/CX with /BD /BO /CX /BO /BD/BC/BC/BC .\nSuppose the actual sorting algorithm used is the one from ﬁgu re 13.3. If the tests\nuse positive integers only, the output will be correct. The o utput will not be correct\nif a test input happens to contain negative integers.\nThe test set using positive integers only does not reveal the fault because the\ninputs in the subdomains are not really interchangeable (in stead of comparing the\nvalues of array entries, the algorithm compares", "token_count": 512, "start_token": 234234, "end_token": 234746, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 508, "text": " test input happens to contain negative integers.\nThe test set using positive integers only does not reveal the fault because the\ninputs in the subdomains are not really interchangeable (in stead of comparing the\nvalues of array entries, the algorithm compares their absol ute values). Any form of\ntesting which partitions the input domain works perfectly i f the right subdomains\nare chosen. In practice however, we generally do not know whe re the needles are\nhidden, and the partition of the input domain is likely to be i mperfect.\nBoth functional and structural testing schemes use a system atic means to determine\nsubdomains. They often use peculiar inputs to test peculiar cases. Their intention is to\nprovoke failure behavior. Their success hinges on the assum ption that we can indeed\nidentify subdomains with a high failure probability. Thoug h this is a good strategy\nfor fault detection, it does not necessarily inspire conﬁde nce.\nThe user of a system is interested in the probability of failu re-free behavior.\nFollowing this line of thought, we are not so much interested in the faults themselves,\nbut rather in their manifestations. A fault which frequentl y manifests itself will in\n13.1. TEST OBJECTIVES 405\nprocedure selection-sort (A, n);\ninteger i, j, small, temp;\nbegin\nfor i:= 1 to n-1 do\nsmall:= i;\nfor j:= i+1 to n do\nif abs(A[j])\n/BO abs(A[small]) then small:= j endif\nenddo;\ntemp:= A[i]; A[i]:= A[small]; A[small]:= temp\nenddo\nend selection-sort;\nFigure 13.3 Erroneous selection sort procedure\ngeneral cause more damage than a fault which seldom shows up. This is precisely\nwhat we hinted at above when we discussed fault detection and conﬁdence building\nas possible test objectives.\nIf failures are more important than faults, the goal pursued during the test phase\nmay also change. In that case, we will not pursue the discover y of as many faults\nas possible but will strive for a high reliability. Random te sting does not work all\nthat well if we want to ﬁnd as many faults as possible -- hence t he development of\ndifferent test techniques. When pursuing", "token_count": 512, "start_token": 234696, "end_token": 235208, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 509, "text": " as many faults\nas possible but will strive for a high reliability. Random te sting does not work all\nthat well if we want to ﬁnd as many faults as possible -- hence t he development of\ndifferent test techniques. When pursuing a high reliabilit y, however, it is possible to\nuse random input.\nIn order to obtain conﬁdence in the daily operation of a softw are system, we have\nto mimic that situation. This requires the execution of a lar ge number of test cases\nthat represent typical usage scenarios. Random testing doe s at least as good a job in\nthis respect as any form of testing based on partitioning the input domain.\nThis approach has been applied in the Cleanroom development method. In this\nmethod, the development of individual components is done by programmers who\nare not allowed to actually execute their code. The programm er must then convince\nhimself of the correctness of his components using manual te chniques such as stepwise\nabstraction (see also section 13.4).\nIn the next step, these components are integrated and tested by someone else.\nThe input for this process is generated according to a distri bution which follows the\nexpected operational use of the system. During this integra tion phase, one tries to\nreach a certain required reliability level. Experiences wi th this approach are positive.\nThe quantitative assessment of failure probability brings us into the area of\nsoftware reliability. Section 13.10 is devoted to this topi c.\n406 SOFTWARE TESTING\n13.1.3 From Fault Detection to Fault Prevention\nIn the early days of computing, programs were written and the n debugged to make\nsure that they ran properly. Testing and debugging were larg ely synonymous terms.\nBoth referred to an activity near the end of the development p rocess when the\nsoftware had been written, but still needed to be ‘checked ou t’.\nToday’s situation is rather different. Testing activities occur in every phase of the\ndevelopment process. They are carefully planned and docume nted. The execution of\nsoftware to compare actual behavior with expected behavior is only one aspect out\nof many.\nGelperin and Hetzel (1988) identify four major testing mode ls. These roughly\nparallel the historical development of test practices. The models and their primary\ngoals are given in ﬁgure 13.4", "token_count": 512, "start_token": 235158, "end_token": 235670, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 510, "text": "\nGelperin and Hetzel (1988) identify four major testing mode ls. These roughly\nparallel the historical development of test practices. The models and their primary\ngoals are given in ﬁgure 13.4.\nModel Primary goal\nPhase models\nDemonstration Make sure that the software satisﬁes its spec i-\nﬁcation\nDestruction Detect implementation faults\nLife cycle models\nEvaluation Detect requirements, design and implemen-\ntation faults\nPrevention Prevent requirements, design and implemen-\ntation faults\nFigure 13.4 Major testing models ( Source: D. Gelperin & B. Hetzel, The growth of software\ntesting, Communications of the ACM 31, 6 (1988) 687-695. Reproduced by permission of the\nAssociation for Computing Machinery, Inc. )\nThe primary goal of the demonstration model is to make sure th at the program\nruns and solves the problem. The strategy is like that of a con structive mathematical\nproof. If the software passes all tests from the test set, it i s claimed to satisfy the\nrequirements. The strategy gives no guidelines as to how to o btain such a test set. A\npoorly-chosen test set may mask poor software quality.\nMost programmers will be familiar with the process of testin g their own programs\nby carefully reading them or executing them with selected in put data. If this is done\nvery carefully, it can be beneﬁcial. This method also holds s ome dangers, however.\nWe may be inclined to consider this form of testing as a method to convince\n13.1. TEST OBJECTIVES 407\nourselves or someone else that the software does not contain errors. We will then,\npartly unconsciously, look for test cases which support thi s hypothesis. This type of\ndemonstration-oriented approach to testing is not to be adv ocated.\nProper testing is a very destructive process. A program shou ld be tested with the\npurpose of ﬁnding as many faults as possible. A test can only b e considered successful\nif it leads to the discovery of at least one fault. (In a simila r way, a visit to your\nphysician is only successful if he ﬁnds a ‘fault’ and we will g enerally consider such a", "token_count": 512, "start_token": 235620, "end_token": 236132, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 511, "text": " to the discovery of at least one fault. (In a simila r way, a visit to your\nphysician is only successful if he ﬁnds a ‘fault’ and we will g enerally consider such a\nvisit unsatisfactory if we are sent home with the message tha t nothing wrong could\nbe found.)\nIn order to improve the chances of producing a high quality sy stem, we should\nreverse the strategy and start looking for test cases that do reveal faults. This may be\ntermed a proof by contradiction. The test set is then judged b y its ability to detect\nfaults.\nSince we do not know whether any residual faults are left, it i s difﬁcult to decide\nwhen to stop testing in either of these models. In the demonst ration-oriented model,\nthe criteria most often used to determine this point in time s eem to be the following:\n– stop if the test budget has run out;\n– stop if all test cases have been executed without any failur es occurring.\nThe ﬁrst criterion is pointless, since it does not tell us any thing about the quality\nof the test effort. If there is no money at all, this criterion is most easily satisﬁed.\nThe second criterion is pointless as well, since it does not t ell us anything about the\nquality of the test cases.\nThe destruction-oriented model usually entails some syste matic way of deriving\ntest cases. We may then base our stop criterion on the test ade quacy criterion that\ncorresponds to the test technique used. An example of this mi ght be: ‘We stop testing\nif 100% of the branches are covered by the set of test cases, an d all test cases yield\nan unsuccessful result’.\nBoth these models view testing as one phase in the software de velopment process.\nAs noted before, this is not a very good strategy. The life cyc le testing models extend\ntesting activities to earlier phases. In the evaluation-or iented model, the emphasis\nis on analysis and review techniques to detect faults in requ irements and design\ndocuments. In the prevention model, emphasis is on the caref ul planning and design\nof test activities. For example, the early design of test cas es may reveal that certain\nrequirements cannot be tested and thus such an activity help s", "token_count": 512, "start_token": 236082, "end_token": 236594, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 512, "text": "documents. In the prevention model, emphasis is on the caref ul planning and design\nof test activities. For example, the early design of test cas es may reveal that certain\nrequirements cannot be tested and thus such an activity help s to prevent errors from\nbeing made in the ﬁrst place. Test-driven development falls into this category as well.\nWe may observe a gradual shift of emphasis in test practice, f rom a demonstration-\nlike approach to prevention-oriented methods. Though many organizations still\nconcentrate their test effort late in the development life c ycle, various organizations\nhave shown that upstream testing activities can be most effe ctive. Quantitative\nevidence hereof is provided in section 13.8.3.\nTesting need not only result in software with fewer errors. T esting also results in\nvaluable knowledge (error-prone constructs and so on) whic h can be fed back into\n408 SOFTWARE TESTING\nthe development process. In this view, testing is a learning process, which can be\ngiven its proper place in an improvement process.\n13.2 Testing and the Software Life Cycle\nIn the following subsections we will discuss the various ver iﬁcation and validation\nactivities which can be performed during the requirements e ngineering, design,\nimplementation and maintenance phases. In doing so, we will also indicate the\ntechniques and tools that may be applied. These techniques a nd tools will be further\ndiscussed in subsequent sections. A summary is given in ﬁgur e 13.5.\nPhase Activities\nRequirements engineering -- determine test strategy\n-- test requirements speciﬁcation\n-- generate functional test data\nDesign -- check consistency between design and require-\nments speciﬁcation\n-- evaluate the software architecture\n-- test the design\n-- generate structural and functional test data\nImplementation -- check consistency between design and imp le-\nmentation\n-- test implementation\n-- generate structural and functional test data\n-- execute tests\nMaintenance -- repeat the above tests in accordance with the\ndegree of redevelopment\nFigure 13.5 Activities in the various phases of the software life cycle (Adapted from\nW.R. Adrion, M.A. Branstad & J.C. Cherniavski, Validation, veriﬁcation, and testing of computer\nsoftware, ACM Computing Surveys 14, 2 (1982),", "token_count": 512, "start_token": 236544, "end_token": 237056, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 513, "text": "R. Adrion, M.A. Branstad & J.C. Cherniavski, Validation, veriﬁcation, and testing of computer\nsoftware, ACM Computing Surveys 14, 2 (1982), Reproduced by permission of the Association\nfor Computing Machinery, Inc. )\nSoftware developers aim for clean code that works. We try to a ccomplish that by\nﬁrst focusing on the ”clean code” part, and next on the ”that w orks” part. The clean\ncode part is about proper analysis and design, writing elega nt and robust code, and\nthe like. Only after we’re done with that, do we start testing to make sure the software\nworks properly. Test-driven development (TDD) takes the op posite approach: we\n13.2. TESTING AND THE SOFTWARE LIFE CYCLE 409\nﬁrst make sure the software works, and then tackle the clean c ode part. We discuss\ntest-driven development in section 13.2.5.\n13.2.1 Requirements Engineering\nThe veriﬁcation and validation techniques applied during t his phase are strongly\ndependent upon the way in which the requirements speciﬁcati on has been laid down.\nSomething which should be done at the very least is to conduct a careful review or\ninspection in order to check whether all aspects of the syste m have been properly\ndescribed. As we saw earlier, errors made at this stage are ve ry costly to repair if\nthey go unnoticed until late in the development process. Boe hm gives four essential\ncriteria for a requirements speciﬁcation (Boehm, 1984b):\n– completeness;\n– consistency;\n– feasibility;\n– testability.\nTesting a requirements speciﬁcation should primarily be ai med at testing these\ncriteria.\nThe aim of testing the completeness criterion then is to dete rmine whether all\ncomponents are present and described completely. A require ments speciﬁcation is\nincomplete if it contains such phrases as ‘to be determined’ or if it contains references\nto undeﬁned elements. We should also watch for the omission o f functions or\nproducts, such as back-up or restart procedures and test too ls to be delivered to", "token_count": 512, "start_token": 237006, "end_token": 237518, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 514, "text": "�to be determined’ or if it contains references\nto undeﬁned elements. We should also watch for the omission o f functions or\nproducts, such as back-up or restart procedures and test too ls to be delivered to the\ncustomer.\nA requirements speciﬁcation is consistent if its component s do not contradict\neach other and the speciﬁcation does not conﬂict with extern al speciﬁcations. We\nthus need both internal and external consistency. Moreover , each element in the\nrequirements speciﬁcation must be traceable. It must, for i nstance, be possible to\ndecide whether a natural language interface is really neede d.\nAccording to Boehm, feasibility has to do with more than func tional and\nperformance requirements. The beneﬁts of a computerized sy stem should outweigh\nthe associated costs. This must be established at an early st age and necessitates timely\nattention to user requirements, maintainability, reliabi lity, and so on. In some cases,\nthe project’s success is very sensitive to certain key facto rs, such as safety, speed,\navailability of certain types of personnel; these risks mus t be analyzed at an early\nstage.\nLastly, a requirements speciﬁcation must be testable. In th e end, we must be able\nto decide whether or not a system fulﬁlls its requirements. S o requirements must\nbe speciﬁc, unambiguous, and quantitative. The quality-at tribute scenario framework\nfrom (Bass et al., 2003) is an example of how to specify such re quirements; see also\nsection 6.3.\n410 SOFTWARE TESTING\nMany of these points are raised by Poston (1987). According t o Poston, the\nmost likely errors in a requirements speciﬁcation can be gro uped into the following\ncategories:\n– missing information (functions, interfaces, performanc e, constraints, reliability,\nand so on);\n– wrong information (not traceable, not testable, ambiguou s, and so forth);\n– extra information (bells and whistles).\nUsing a standard format for documenting the requirements sp eciﬁcation, such as IEEE\nStandard 830 discussed in chapter 9, may", "token_count": 512, "start_token": 237468, "end_token": 237980, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 515, "text": " ambiguou s, and so forth);\n– extra information (bells and whistles).\nUsing a standard format for documenting the requirements sp eciﬁcation, such as IEEE\nStandard 830 discussed in chapter 9, may help enormously in p reventing these types\nof errors to occur in the ﬁrst place.\nUseful techniques for testing the degree to which criteria h ave been met, are\nmostly manual (reading documents, inspections, reviews). Scenarios for the expected\nuse of the system can be devised with the prospective users of the system. If\nrequirements are already expressed in use cases, such scena rios are readily available.\nIn this way, a set of functional tests is generated.\nAt this stage also, a general test strategy for subsequent ph ases must be formulated.\nIt should encompass the choice of particular test technique s; evaluation criteria; a test\nplan; a test scheme; and test documentation requirements. A test team may also be\nformed at this stage. These planning activities are dealt wi th in section 13.3.\n13.2.2 Design\nThe criteria mentioned in the previous subsection (complet eness, consistency, feasi-\nbility and testability) are also essential for the design. T he most likely errors in design\nresemble the kind of errors one is inclined to make in a requir ements speciﬁcation:\nmissing, wrong, and extraneous information. For the design too, a precise documen-\ntation standard is of great help in preventing these types of errors. IEEE Standard\n1016, discussed in chapter 12, is one such standard.\nDuring the design phase, we decompose the total system into s ubsystems and\ncomponents, starting from the requirements speciﬁcation. We may then develop tests\nbased on this decomposition process. Design is not a one-sho t process. During the\ndesign process a number of successive reﬁnements will be mad e, resulting in layers\nshowing increasing detail. Following this design process, more detailed tests can be\ndeveloped as the lower layers of the design are decided upon.\nDuring the architectural design phase, a high-level concep tual model of the\nsystem is developed in terms of components and their interac tion. This architecture\ncan be assessed, for example by generating scenarios which e xpress quality concerns", "token_count": 512, "start_token": 237930, "end_token": 238442, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 516, "text": "\nDuring the architectural design phase, a high-level concep tual model of the\nsystem is developed in terms of components and their interac tion. This architecture\ncan be assessed, for example by generating scenarios which e xpress quality concerns\nsuch as maintainability and ﬂexibility in very concrete ter ms, and next evaluating how\nthe architecture handles these scenarios; see also section 11.5.\nDuring the design phase, we may also test the design itself. T his includes tracing\nelements from the requirements speciﬁcation to the corresp onding elements in the\n13.2. TESTING AND THE SOFTWARE LIFE CYCLE 411\ndesign description, and vice versa. Well-known techniques for doing so are, amongst\nothers, simulation, design walkthroughs, and design inspe ctions.\nAt the requirements engineering phase, the possibilities f or formally document-\ning the resulting speciﬁcation are limited. Most requireme nts speciﬁcations make\nexcessive use of natural language descriptions. For the des ign phase, there are ample\nopportunities to formally document the resulting speciﬁca tion. The more formally the\ndesign is speciﬁed, the more possibilities we have for apply ing veriﬁcation techniques,\nas well as formal checks for consistency and completeness.\n13.2.3 Implementation\nDuring the implementation phase, we do the ‘real’ testing. O ne of the most effective\ntechniques to ﬁnd errors in a program text is to carefully rea d that text, or have it read.\nThis technique has been successfully applied for a long time . Somewhat formalized\nvariants are known as code-inspection and code-walkthroug h. We may also apply the\ntechnique of stepwise abstraction. In stepwise abstractio n, the function of the code is\ndetermined in a number of abstraction steps, starting from t he code itself. The various\nmanual test techniques will be discussed in section 13.4.\nThere are many tools to support the testing of code. We may dis tinguish between\ntools for static analysis and tools for dynamic analysis. St atic analysis tools inspect\nthe program code without executing it. They include tests li ke: have all variables\nbeen declared and given a value before they are used?\nDynamic analysis tools are used", "token_count": 512, "start_token": 238392, "end_token": 238904, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 517, "text": " for static analysis and tools for dynamic analysis. St atic analysis tools inspect\nthe program code without executing it. They include tests li ke: have all variables\nbeen declared and given a value before they are used?\nDynamic analysis tools are used in conjunction with the actu al execution of the\ncode, for example tools that keep track of which portions of t he code have been\ncovered by the tests so far.\nWe may try to prove the correctness of the code using formal ve riﬁcation\ntechniques.\nAll of the above techniques are aimed at evaluating the quali ty of the source code\nas well as its compliance with design speciﬁcations and code documentation.\nIt is crucial to control the test information properly while testing the code. Tools\nmay help us in doing so, for example test drivers, test stubs a nd test data generators.\nA test driver is a tool that generates the test environment fo r a component to be\ntested. A test stub does the opposite: it simulates the funct ion of a component not\nyet available. In bottom-up testing, we will, in general, ma ke much use of test drivers,\nwhile top-down testing implies the use of test stubs. The tes t strategy (top-down\nversus bottom-up) may be partly inﬂuenced by the design tech nique used. If the high\nlevel, architectural design is implemented as a skeletal sy stem whose holes yet have\nto be ﬁlled in, that skeletal system can be used as a test drive r.\nTools may also be proﬁtable while executing the tests (test h arnesses and test\nsystems). A simple and yet effective tool is one which compar es test results with\nexpected results. The eye is a very unreliable medium. After a short time, all results\nlook OK. An additional advantage of this type of tool support is that it helps to\nachieve a standard test format. This in turn helps with regre ssion testing.\n412 SOFTWARE TESTING\n13.2.4 Maintenance\nOn average, more than 50% of total life-cycle costs is spent o n maintenance. If we\nmodify the software after a system has become operational (b ecause an error is found\nlate on, or because the system must be adapted to changed requ irements), we will\nhave to test the system anew. This is", "token_count": 512, "start_token": 238854, "end_token": 239366, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 518, "text": " If we\nmodify the software after a system has become operational (b ecause an error is found\nlate on, or because the system must be adapted to changed requ irements), we will\nhave to test the system anew. This is called regression testi ng. To have this proceed\nsmoothly, the quality of the documentation and the possibil ities for tool support, are\ncrucial factors.\nIn a retest-all approach, all tests are rerun. Since this may consume a lot of time and\neffort, we may also opt for a selective retest , in which only some of the tests are rerun.\nA regression test selection technique is then used to decide which subset should be\nrerun. We would like this technique to include all tests in wh ich the modiﬁed and\noriginal program produce different results, while omittin g tests that produce the same\nresults.\n13.2.5 Test-Driven Development (TDD)\nSuppose our library system needs to be able to block borrowin g items to members that\nare on a black list. We could start by redesigning part of the s ystem and implementing\nthe necessary changes: a new table BlackList, and appropriate checks in method\nBorrow. We also have to decide when members are put on the black list, and how\nto get them off that list. After having done all the necessary analysis and design,\nand implemented the changes accordingly, we devise test cas es to test for the new\nfunctionality.\nThis order of events is completely reversed in test-driven development (TDD) .\nIn test-driven development, we ﬁrst write a few tests for the new functionality. We\nmay start very simple, and add a test in the start-up method to ensure that the black\nlist is initially empty:\nassertEquals(0, BlackList)\nOf course, this test will fail. To make it succeed, we have to i ntroduce BlackList,\nand set it equal to 0. At the same time, we make a list of things still to be done,\nsuch as devising a proper type for BlackList, including operations to add and remove\nmembers to that list, an update of Borrow to check whether a person borrowing an\nitem is on the black list, and the like. This list of things to b e done is similar to", "token_count": 512, "start_token": 239316, "end_token": 239828, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 519, "text": " BlackList, including operations to add and remove\nmembers to that list, an update of Borrow to check whether a person borrowing an\nitem is on the black list, and the like. This list of things to b e done is similar to the\nbacklog used by architects while architecting a system (see section 11.2).\nAfter we have made the simple test to work, the new version of t he system is\ninspected to see whether it can be improved. And next another small change is\ncontemplated. We may for example decide to make BlackList into a proper list, and\nwrite some simple tests to see that after adding some item to t he list, that item is\nindeed in the list. Again, the test will fail, and we update th e system accordingly.\nPossibly, improvements can be made now since the library sys tem probably contains\nother list-type classes that we can inherit from, and some du plicate code can be\nremoved. And so on.\n13.3. VERIFICATION AND VALIDATION PLANNING AND DOCUMENTAT ION413\nTest-driven development is one of the practices of eXtreme P rogramming (see\nsection 3.2.4). As such, it is part of the agile approach to sy stem development which\nfavors small increments and redesign (refactoring) where n eeded over big design\nefforts. The practice is usually supported by an automated u nit testing framework,\nsuch as JUnit for Java, that keeps track of the test set and rep orts back readable\nerror messages for tests that failed (Hunt and Thomas, 2003) . The assertEqual\nmethod used above is one of the methods provided by the JUnit f ramework. The\nframework allows for a smooth integration of coding and unit testing. On the ﬂy, a\ntest set is built that forms a reusable asset during the furth er evolution of the system.\nJUnit and similar frameworks have greatly contributed to th e success of test-driven\ndevelopment.\nThe way of working in each iteration of test-driven developm ent consists of the\nfollowing steps:\n1. Add a test\n2. Run all tests, and observe that the one added will fail\n3. Make a small change to the system to make the test work\n4. Run al tests again, and observe that they run properly\n5. Refactor", "token_count": 512, "start_token": 239778, "end_token": 240290, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 520, "text": " test\n2. Run all tests, and observe that the one added will fail\n3. Make a small change to the system to make the test work\n4. Run al tests again, and observe that they run properly\n5. Refactor the system to remove duplicate code and improve i ts design.\nIn pure eXtreme Programming, iterations are very small, and may take a few minutes\nup to, say, an hour. But test-driven development can also be d one in bigger leaps, and\nbe combined with more traditional approaches.\nTest-driven development is much more than a test method. It i s a different way of\ndeveloping software. The effort put into the upfront develo pment of test cases forces\none to think more carefully of what it means for the current it eration to succeed or\nfail. Writing down explicit test cases subsumes part of the a nalysis and design work.\nRather than producing UML diagrams during requirements ana lysis, we produce\ntests. And these tests are used immediately, by the same pers on that implemented the\nfunctionality that the test exercises. Testing then is not a n afterthought, but becomes\nan integral part of the development process. Another beneﬁt is that we have a test\nset and a test criterion to decide on the success of the iterat ion. Experiments with\ntest-driven development indicate that it increases produc tivity and reduces defect\nrates.\n13.3 Veriﬁcation and Validation Planning and Docu-\nmentation\nLike the other phases and activities of the software develop ment process, the testing\nactivities need to be carefully planned and documented. Sin ce test activities start\n414 SOFTWARE TESTING\nearly in the development life cycle and span all subsequent p hases, timely attention\nto the planning of these activities is of paramount importan ce. A precise description\nof the various activities, responsibilities and procedure s must be drawn up at an early\nstage.\nThe planning of test activities is described in a document ca lled the Software\nVeriﬁcation and Validation Plan. We will base our discussio n of its contents on\nthe corresponding IEEE Standard 1012. Standard 1012 descri bes veriﬁcation and\nvalidation activities for a waterfall-like life cycle in wh ich the following phases are\nidentiﬁed:\n/AF Concept phase\n/AF Requirements", "token_count": 512, "start_token": 240240, "end_token": 240752, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 521, "text": ". Standard 1012 descri bes veriﬁcation and\nvalidation activities for a waterfall-like life cycle in wh ich the following phases are\nidentiﬁed:\n/AF Concept phase\n/AF Requirements phase\n/AF Design phase\n/AF Implementation phase\n/AF Test phase\n/AF Installation and checkout phase\n/AF Operation and maintenance phase\nThe ﬁrst of these, the concept phase, is not discussed in the p resent text. Its aim is\nto describe and evaluate user needs. It produces documentat ion which contains, for\nexample, a statement of user needs, results of feasibility s tudies, and policies relevant\nto the project. The veriﬁcation and validation plan is also p repared during this phase.\nIn our approach, these activities are included in the requir ements engineering phase.\nThe sections to be included in the Veriﬁcation and Validatio n (V&V) Plan are\nlisted in ﬁgure 13.6. The structure of this plan resembles th at of other standards\ndiscussed earlier. The plan starts with an overview and give s detailed information on\nevery aspect of the topic being covered. The various constit uents of the Veriﬁcation\nand Validation Plan are discussed in appendix ??.\nMore detailed information on the many V&V tasks covered by th is plan can be\nfound in (IEEE1012, 1986). Following the organization prop osed in this standard,\nthe bulk of the test documentation can be structured along th e lines identiﬁed in\nﬁgure 13.7. The Test Plan is a document describing the scope, approach, resources,\nand schedule of intended test activities. It can be viewed as a further reﬁnement of\nthe Veriﬁcation and Validation Plan and describes in detail the test items, features to\nbe tested, testing tasks, who will do each task, and any risks that require contingency\nplanning.\nThe Test Design documentation speciﬁes, for each software f eature or combina-\ntion of such features, the details of the test approach and id entiﬁes the associated\ntests. The Test Case documentation speciﬁes inputs, predic ted outputs and execu-\ntion conditions for each test item. The Test Procedure doc", "token_count": 512, "start_token": 240702, "end_token": 241214, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 522, "text": " the details of the test approach and id entiﬁes the associated\ntests. The Test Case documentation speciﬁes inputs, predic ted outputs and execu-\ntion conditions for each test item. The Test Procedure docum entation speciﬁes the\n13.3. VERIFICATION AND VALIDATION PLANNING AND DOCUMENTAT ION415\n1. Purpose\n2. Referenced documents\n3. Deﬁnitions\n4. Veriﬁcation and validation overview\n4.1. Organization\n4.2. Master schedule\n4.3. Resources summary\n4.4. Responsibilities\n4.5. Tools, techniques and methodologies\n5. Life-cycle veriﬁcation and validation (V&V)\n5.1. Management of V&V\n5.2. Requirements phase V&V\n5.3. Design phase V&V\n5.4. Implementation phase V&V\n5.5. Test phase V&V\n5.6. Installation and checkout phase V&V\n5.7. Operation and maintenance phase V&V\n6. Software veriﬁcation and validation reporting\n7. Veriﬁcation and validation administrative procedures\n7.1. Anomaly reporting and resolution\n7.2. Task iteration policy\n7.3. Deviation policy\n7.4. Control procedures\n7.5. Standards, practices and conventions\nFigure 13.6 p of the Veriﬁcation and Validation Plan ( Source: IEEE Standard for\nSoftware Veriﬁcation and Validation Plans, IEEE Std. 1012, 1986. Reproduced by permission\nof IEEE. )\nsequence of actions for the execution of each test. Together , the ﬁrst four documents\ndescribe the input to the test execution.\nThe Test Item Transmittal Report speciﬁes which items are go ing to be tested. It\nlists the items, speciﬁes where to ﬁnd them, and the status of each item. It constitutes\nthe release information for a given test execution.\nThe ﬁnal three items are the output of the test execution. The Test Log gives\na chronological record of events. The Test Incident Report d ocuments all events\nobserved that require further investigation. In particula r", "token_count": 512, "start_token": 241164, "end_token": 241676, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 523, "text": "\nThe ﬁnal three items are the output of the test execution. The Test Log gives\na chronological record of events. The Test Incident Report d ocuments all events\nobserved that require further investigation. In particula r, this includes the tests whose\noutputs were not as expected. Finally, the Test Summary Repo rt gives an overview\nand evaluation of the ﬁndings. A detailed description of the contents of these various\ndocuments is given in the IEEE Standard for Software Documen tation (IEEE829,\n416 SOFTWARE TESTING\n1998).\nTest Plan\nTest Design Speciﬁcation\nTest Case Speciﬁcation\nTest Procedure Speciﬁcation\nTest Item Transmittal Report\nTest Log\nTest Incident Report\nTest Summary Report\nFigure 13.7 Main constituents of test documentation, after (IEEE829, 1998)\n13.4 Manual Test Techniques\nA lot of research effort is spent on ﬁnding techniques and too ls to support testing. Yet,\na plethora of heuristic test techniques have been applied si nce the beginning of the\nprogramming era. These heuristic techniques, such as walkt hroughs and inspections,\noften work quite well, although it is not always clear why.\nTest techniques can be separated into static and dynamic analysis techniques.\nDuring dynamic analysis, the program is executed. With this form of testing, the\nprogram is given some input and the results of the execution a re compared with the\nexpected results. During static analysis, the software is g enerally not executed. Many\nstatic test techniques can also be applied to non-executabl e artifacts such as a design\ndocument or user manual. It should be noted, though, that the borderline between\nstatic and dynamic analysis is not very sharp.\nA large part of the static analysis is nowadays done by the lan guage compiler.\nThe compiler then checks whether all variables have been dec lared, whether each\nmethod call has the proper number of actual parameters, and s o on. These constraints\nare part of the language deﬁnition. We may also apply a more st rict analysis of the\nprogram text, such as a check for initialization of variable s, or a check on the use\nof non-standard, or error-prone, language constructs. In a number of cases, the call\nto a compiler is", "token_count": 512, "start_token": 241626, "end_token": 242138, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 524, "text": " analysis of the\nprogram text, such as a check for initialization of variable s, or a check on the use\nof non-standard, or error-prone, language constructs. In a number of cases, the call\nto a compiler is parameterized to indicate the checks one wan ts to be performed.\nSometimes, separate tools are provided for these checks.\nThe techniques to be discussed in the following subsections are best classiﬁed\nas static techniques. The techniques for coverage-based, f ault-based and error-based\ntesting, to be discussed in sections 13.5--13.7, are mostly dynamic in nature.\n13.4. MANUAL TEST TECHNIQUES 417\n13.4.1 Reading\nWe all read, and reread, and reread, our program texts. It is t he most traditional test\ntechnique we know of. It is also a very successful technique t o ﬁnd faults in a program\ntext (or a speciﬁcation, or a design).\nIn general, it is better to have someone else read your texts. The author of a\ntext knows all too well what the program (or any other type of d ocument) ought to\nconvey. For this reason, the author may be inclined to overlo ok things, suffering from\nsome sort of trade blindness.\nA second reason why reading by the author himself might be les s fruitful, is that\nit is difﬁcult to adopt a destructive attitude towards one’s own work. Yet such an\nattitude is needed for successful testing.\nA somewhat institutionalized form of reading each other’s p rograms is known\nas peer review . This is a technique for anonymously assessing programs as r egards\nquality, readability, usability, and so on.\nEach person partaking in a peer review is asked to hand in two p rograms: a ‘best’\nprogram and one of lesser quality. These programs are then ra ndomly distributed\namongst the participants. Each participant assesses four p rograms: two ‘best’ programs\nand two programs of lesser quality. After all results have be en collected, each\nparticipant gets the (anonymous) evaluations of their prog rams, as well as the\nstatistics of the whole test.\nThe primary goal of this test is to give the programmer", "token_count": 512, "start_token": 242088, "end_token": 242600, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 525, "text": ". After all results have be en collected, each\nparticipant gets the (anonymous) evaluations of their prog rams, as well as the\nstatistics of the whole test.\nThe primary goal of this test is to give the programmer insigh t into his own\ncapabilities. The practice of peer reviews shows that progr ammers are quite capable\nof assessing the quality of their peers’ software.\nA necessary precondition for successfully reading someone else’s code is a business-\nlike attitude. Weinberg (1971) coined the term egoless programming for this. Many\nprogrammers view their code as something personal, like a di ary. Derogatory remarks\n(‘how could you be so stupid as to forget that initialization ’) can disastrously impair\nthe effectiveness of such assessments. The opportunity for such an antisocial attitude\nto occur seems to be somewhat smaller with the more formalize d manual techniques.\n13.4.2 Walkthroughs and Inspections\nWalkthroughs and inspections are both manual techniques th at spring from the\ntraditional desk-checking of program code. In both cases it concerns teamwork,\nwhereby the product to be inspected is evaluated in a formal s ession, following\nprecise procedures.\nInspections are sometimes called Fagan inspections , after their originator (Fagan,\n1976, 1986). In an inspection, the code to be assessed is gone through statement\nby statement. The members of the inspection team (usually fo ur) get the code, its\nspeciﬁcation, and the associated documents a few days befor e the session takes place.\nEach member of the inspection team has a well-deﬁned role. Th e moderator is\nresponsible for the organization of inspection meetings. H e chairs the meeting\nand ascertains that follow-up actions agreed upon during th e meeting are indeed\n418 SOFTWARE TESTING\nperformed. The moderator must ensure that the meeting is con ducted in a businesslike,\nconstructive way and that the participants follow the corre ct procedures and act as\na team. The team usually has two inspectors or readers, knowledgeable peers that\nparaphrase the code. Finally, the code author is a largely silent observer. He knows the\ncode to be inspected all too well and is easily inclined to exp ress what he intended\nrather than what is actually written down. He may, though, be", "token_count": 512, "start_token": 242550, "end_token": 243062, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 526, "text": " code. Finally, the code author is a largely silent observer. He knows the\ncode to be inspected all too well and is easily inclined to exp ress what he intended\nrather than what is actually written down. He may, though, be consulted by the\ninspectors.\nDuring the formal session, the inspectors paraphrase the co de, usually a few lines\nat a time. They express the meaning of the text at a higher leve l of abstraction than\nwhat is actually written down. This gives rise to questions a nd discussions which\nmay lead to the discovery of faults. At the same time, the code is analyzed using a\nchecklist of faults that often occur. Examples of possible e ntries in this checklist are:\n– wrongful use of data: variables not initialized, array ind ex out of bounds,\ndangling pointers, etc.;\n– faults in declarations: the use of undeclared variables or the declaration of the\nsame name in nested blocks, etc.;\n– faults in computations: division by zero, overﬂow (possib le in intermediate\nresults too), wrong use of variables of different types in th e same expression,\nfaults caused by an erroneous understanding of operator pri orities, etc.;\n– faults in relational expressions: using an incorrect oper ator ( /BQ instead of /AL ,\n/BP instead of /BP/BP ) or an erroneous understanding of priorities of Boolean\noperators, etc.;\n– faults in control ﬂow: inﬁnite loops or a loop that gets exec uted /D2 /B7 /BD or /D2 /A0 /BD\ntimes rather than /D2 times, etc.;\n– faults in interfaces: an incorrect number of parameters, p arameters of the wrong\ntype, or an inconsistent use of global variables, etc.\nThe result of the session is a list of problems identiﬁed.\nThese problems are not resolved during the formal session it self. This might easily\nlead to quick ﬁxes and distract the team from its primary goal . After the meeting,\nthe code author resolves all issues raised and the revised co de is veriﬁed once again.\nDepending on the number of problems identiﬁed and their seve rity, this second\ninspection may be done by the moderator only or by the complet e inspection team.", "token_count": 512, "start_token": 243012, "end_token": 243524, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 527, "text": " veriﬁed once again.\nDepending on the number of problems identiﬁed and their seve rity, this second\ninspection may be done by the moderator only or by the complet e inspection team.\nSince the goal of an inspection is to identify as many problem s as possible in order\nto improve the quality of the software to be developed, it is i mportant to maintain\na constructive attitude towards the programmer whose code i s being assessed. 2 The\nresults of an inspection therefore are often marked conﬁden tial. These results should\ncertainly not play a role in the formal assessment of the programmer in ques tion.\n2 One way of creating a non-threatening atmosphere is to alway s talk about ‘problems’ rather than\n‘faults’.\n13.4. MANUAL TEST TECHNIQUES 419\nIn a walkthrough, the team is guided through the code using te st data. These test\ndata are mostly of a fairly simple kind. Otherwise, tracing t he program logic soon\nbecomes too complicated. The test data serves as a means to st art a discussion, rather\nthan as a serious test of the program. In each step of this proc ess, the designer may\nbe questioned regarding the rationale of the decisions. In m any cases, a walkthrough\nboils down to some sort of manual simulation.\nBoth walkthroughs and inspections may proﬁtably be applied at all stages of the\nsoftware life cycle. The only precondition is that there is a clear, testable document.\nIt is estimated that these review methods detect 50 to 90% of d efects (Boehm and\nBasili, 2001). Both techniques not only serve to ﬁnd faults. If properly applied, these\ntechniques may help to promote team spirit and morale. At the technical level, the\npeople involved may learn from each other and enrich their kn owledge of algorithms,\nprogramming style, programming techniques, error-prone c onstructions, and so on.\nThus, these techniques also serve as a vehicle for process im provement. Under the\ngeneral umbrella of ‘peer reviews’, they are part of the CMM l evel 3 key process area\nVeriﬁcation (see section 6.6).\nA potential danger of this type of review is that it remains to", "token_count": 512, "start_token": 243474, "end_token": 243986, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 528, "text": " of ‘peer reviews’, they are part of the CMM l evel 3 key process area\nVeriﬁcation (see section 6.6).\nA potential danger of this type of review is that it remains to o shallow. The\npeople involved become overwhelmed with information, they may have insufﬁcient\nknowledge of the problem domain, their responsibilities ma y not have been clearly\ndelineated. As a result, the review process does not pay off s ufﬁciently.\nParnas and Weiss (1987) describe a type of review process in w hich the people\ninvolved have to play a more active role. Parnas distinguish es between different types\nof specialized design review. Each of these reviews concent rates on certain desirable\nproperties of the design. As a consequence, the responsibil ities of the people involved\nare clear. The reviewers have to answer a list of questions (‘ under which conditions\nmay this function be called’, ‘what is the effect of this func tion on the behavior of\nother functions’, and the like). In this way, the reviewers a re forced to study carefully\nthe design information received. Problems with the questio nnaire and documentation\ncan be posed to the designers, and the completed questionnai res are discussed by the\ndesigners and reviewers. Experiments suggest that inspect ions with specialized review\nroles are more effective than inspections in which review ro les are not specialized.\nA very important component of Fagan inspections is the meeti ng in which the\ndocument is discussed. Since meetings may incur considerab le costs or time-lags,\none may try to do without them. Experiments suggest that the a dded value of group\nmeetings, as far as the number of problems identiﬁed is conce rned, is quite small.\n13.4.3 Correctness Proofs\nThe most complete static analysis technique is the proof of c orrectness. In a proof\nof correctness we try to prove that a program meets its speciﬁ cation. In order to be\nable to do so, the speciﬁcation must be expressed formally. W e mostly do this by\nexpressing the speciﬁcation in terms of two assertions whic h hold before and after\nthe program’s execution, respectively. Next, we prove that the program", "token_count": 512, "start_token": 243936, "end_token": 244448, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 529, "text": " must be expressed formally. W e mostly do this by\nexpressing the speciﬁcation in terms of two assertions whic h hold before and after\nthe program’s execution, respectively. Next, we prove that the program transforms\n420 SOFTWARE TESTING\none assertion (the precondition) into the other (the postco ndition). This is generally\ndenoted as\n/CU P/CV S /CU Q/CV\nHere, S is the program, P is the precondition, and Q is the postcondition. Termination\nof the program is usually proved separately. The above notat ion should thus be read\nas: if P holds before the execution of S, and S terminates, then Q holds after the\nexecution of S.\nFormally verifying the correctness of a not-too-trivial pr ogram is a very complex\naffair. Some sort of tool support is helpful, therefore. Too ls in this area are often\nbased on heuristics and proceed interactively.\nCorrectness proofs are very formal and, for that reason, the y are often difﬁcult\nfor the average programmer to construct. The value of formal correctness proofs is\nsometimes disputed. We may state that the thrust in software is more important than\nsome formal correctness criterion. Also, we cannot formall y prove every desirable\nproperty of software. Whether we built the right system can o nly be decided upon\nthrough testing (validation).\nOn the other hand, it seems justiﬁed to state that a thorough k nowledge of this\ntype of formal technique will result in better software.\n13.4.4 Stepwise Abstraction\nIn the top-down development of software components we often employ stepwise\nreﬁnement. At a certain level of abstraction the function to be executed will then\nbe denoted by a description of that function. At the next leve l, this description is\ndecomposed into more basic units.\nStepwise abstraction is just the opposite. Starting from th e instructions of the\nsource code, the function of the component is built up in a num ber of steps. The\nfunction thus derived should comply with the function as des cribed in the design or\nrequirements speciﬁcation.\nBelow, we will illustrate this technique with a small exampl e. Consider the\nsearch routine of ﬁ", "token_count": 512, "start_token": 244398, "end_token": 244910, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 530, "text": "function thus derived should comply with the function as des cribed in the design or\nrequirements speciﬁcation.\nBelow, we will illustrate this technique with a small exampl e. Consider the\nsearch routine of ﬁgure 13.8. We know, from the accompanying documentation, for\ninstance, that the elements in array A are sorted when this routine is called.\nWe start the stepwise abstraction with the instructions at t he innermost nesting\nlevel, the if-statement on lines 7--10. In these lines, x is being compared with A[mid].\nDepending on the result of this comparison, one of high, low and found is given a\nnew value. If we take into account the initializations on lin es 4 and 6, the function of\nthis if-statement can be summarized as\nstop searching ( found:= true) if x = A[mid] , or\nshorten the interval [low .. high] that might contain x, to an interval\n[low’ .. high’] , where high’ - low’\n/BO high - low\nAlternatively, this may be described as a postcondition to t he if-statement:\n13.4. MANUAL TEST TECHNIQUES 421\n1 procedure binsearch\n2 (A: array [1..n] of integer; x: integer): integer;\n3 var low, high, mid: integer; found: boolean;\n4 begin low:= 1; high:= n; found:= false;\n5 while (low /AK high) and not found do\n6 mid:= (low + high) div 2;\n7 if x /BO A[mid] then high:= mid - 1 else\n8 if x /BQ A[mid] then low:= mid + 1 else\n9 found:= true\n10 endif\n11 enddo;\n12 if found then return mid else return 0 endif\n13 end binsearch;\nFigure 13.8 A search routine\n(found = true and x = A[mid]) or\n(found = false and x\n/BP/BE A[1 .. low’ - 1] and\nx /BP/BE A[high’ + 1 .. n] and high’ - low’ /BO high - low)\nNext, we consider the loop in lines 5--11, together with the i nitialization", "token_count": 512, "start_token": 244860, "end_token": 245372, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 531, "text": "\nx /BP/BE A[high’ + 1 .. n] and high’ - low’ /BO high - low)\nNext, we consider the loop in lines 5--11, together with the i nitialization on line 4.\nAs regards termination of the loop, we may observe the follow ing. If 1 /AK n upon\ncalling the routine, then low /AK high at the ﬁrst execution of lines 5--11. From this, it\nfollows that low /AK mid /AK high. If the element searched for is found, the loop stops\nand the position of that element is returned. Otherwise, eit her high gets assigned a\nsmaller value, or low gets assigned a higher value. Thus, the interval [low .. high]\ngets smaller. At some point in time, the interval will have le ngth of 1, i.e. low = high\n(assuming the element still is not found). Then, mid will be assigned that same value.\nIf x still does not occur at position mid, either high will get the value low - 1 , or\nlow will get the value high + 1 . In both cases, low /BQ high, and the loop terminates.\nTogether with the postcondition given earlier, it then foll ows that x does not occur\nin the array A. The function of the complete routine can then be described a s:\nresult = 0 /B0 x /BP/BE A[1 .. n]\n1 /AK result /AK n /B0 x = A[result]\nSo, stepwise abstraction is a bottom-up process to deduce th e function of a piece of\nprogram text from that text.\n422 SOFTWARE TESTING\n13.5 Coverage-Based Test Techniques\nQuestion: What do you do when you see a graph?\nAnswer: Cover it!\n(Beizer, 1995)\nIn coverage-based test techniques, the adequacy of testing is expressed in terms of\nthe coverage of the product to be tested, for example, the per centage of statements\nexecuted or the percentage of functional requirements test ed.\nCoverage-based testing is often based on the number of instr uctions, branches or\npaths visited during the execution of a program. It is helpfu l to base the discussion\nof this type of coverage-based testing on the notion of a cont rol graph. In", "token_count": 512, "start_token": 245322, "end_token": 245834, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 532, "text": " on the number of instr uctions, branches or\npaths visited during the execution of a program. It is helpfu l to base the discussion\nof this type of coverage-based testing on the notion of a cont rol graph. In this\ncontrol graph, nodes denote actions, while the (directed) e dges connect actions with\nsubsequent actions (in time). A path is a sequence of nodes co nnected by edges.\nThe graph may contain cycles, i.e. paths\n/D4\n/BD\n/BN /BM /BM /BM /BN /D4\n/D2\nsuch that /D4\n/BD\n/BP /D4\n/D2\n. These cycles\ncorrespond to loops in the program (or gotos). A cycle is call ed simple if its inner\nnodes are distinct and do not include /D4\n/BD\n(or /D4\n/D2\nfor that matter). Note that a sequence\nof actions (statements) that has the property that whenever the ﬁrst action is executed,\nthe other actions are executed in the given order may be colla psed into a single,\ncompound, action. So when we draw the control graph for the pr ogram in ﬁgure 13.9,\nwe may put the statements on lines 10--14 in different nodes, but we may also put\nthem all in a single node.\nIn sections 13.5.1 and 13.5.2 we discuss a number of test tech niques which are\nbased on coverage of the control graph of the program. Sectio n 13.5.3 illustrates how\nthese coverage-based techniques can be applied at the requi rements speciﬁcation\nlevel.\n13.5.1 Control-Flow Coverage\nDuring the execution of a program, we will follow a certain pa th through its control\ngraph. If some node has multiple outgoing edges, we choose on e of those (which is\nalso called a branch). In the ideal case, the tests collectively traverse all pos sible paths.\nThis so-called All-Paths coverage is equivalent to exhaustively testing the program.\nIn general, this is not possible. A loop often results in an in ﬁnite number of\npossible paths. If we do not have loops, but only branch-inst ructions, the number of", "token_count": 512, "start_token": 245784, "end_token": 246296, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 533, "text": " testing the program.\nIn general, this is not possible. A loop often results in an in ﬁnite number of\npossible paths. If we do not have loops, but only branch-inst ructions, the number of\npossible paths increases exponentially with the number of b ranching points. There\nmay also be paths that are never executed (quite likely, the p rogram contains a fault\nin that case). We therefore search for a criterion which expr esses the degree to which\nthe test data approximates the ideal covering.\nMany such criteria can be devised. The most obvious is the cri terion which counts\nthe number of statements (nodes in the graph) executed. It is called the All-Nodes\ncoverage, or statement coverage . This criterion is rather weak because it is relatively\nsimple to construct examples in which 100% statement covera ge is achieved, while\nthe program is nevertheless incorrect.\n13.5. COVERAGE-BASED TEST TECHNIQUES 423\n1 procedure bubble\n2 ( var a: array [1..n] of integer; n: integer);\n3 var i, j, temp: integer;\n4 begin\n5 for i:= 2 to n do\n6 if a[i] /AL a[i-1] then goto next endif;\n7 j:= i;\n8 loop: if j\n/AK 1 then goto next endif;\n9 if a[j] /AL a[j-1] then goto next endif;\n10 temp:= a[j];\n11 a[j]:= a[j-1];\n12 a[j-1]:= temp;\n13 j:= j-1;\n14 goto loop;\n15 next: skip;\n16 enddo\n17 end;\nFigure 13.9 A sort routine\nConsider as an example the program given in ﬁgure 13.9. It is e asy to see that one\nsingle test, with n = 2, a[1] = 5, a[2] = 3 , will result in each statement being executed\nat least once. So, this one test achieves a 100% statement cov erage. However, if we\nchange, for example, the test a[i]\n/AL a[i - 1] in line 6 to a[i] = a[i - 1] , we still obtain\n", "token_count": 512, "start_token": 246246, "end_token": 246758, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 534, "text": " statement cov erage. However, if we\nchange, for example, the test a[i]\n/AL a[i - 1] in line 6 to a[i] = a[i - 1] , we still obtain\na 100% statement coverage with this test. Although this test also yields the correct\nanswer, the changed program is incorrect.\nWe get a stronger criterion if we require that at each branchi ng node in the control\ngraph, all possible branches are chosen at least once. This i s known as All-Edges\ncoverage or branch coverage . Here too, a 100% coverage is no guarantee of program\ncorrectness.\nNodes that contain a condition, such as the boolean expressi on in an if-statement,\ncan be a combination of elementary predicates connected by l ogical operators. A\ncondition of the form\ni /BQ 0 /CN j /BQ 0\nrequires at least two tests to guarantee that both branches a re taken. For example,\ni = 1, j = 1\nand\ni = 0, j = 1\n424 SOFTWARE TESTING\nwill do. Other possible combinations of truth values of the a tomic predicates ( i = 1,\nj = 0 and i = 0, j = 0) need not be considered to achieve branch coverage. Multiple\ncondition coverage requires that all possible combinations of elementary pred icates\nin conditions be covered by the test set. This criterion is al so known as extended\nbranch coverage .\nFinally, McCabe’s cyclomatic complexity metric (McCabe, 1 976) has also been\napplied to testing. This criterion is also based on the contr ol graph representation of\na program.\nA basis set is a maximal linearly-independent set of paths th rough a graph. The\ncyclomatic complexity ( /BV/CE ) equals this number of linearly-independent paths (see\nalso section 12.1.4). Its formula is\n/BV/CE /B4 /BZ /B5 /BP /CE /B4 /BZ /B5 /B7 /BD\nHere, /CE /B4 /BZ /B5 is the graph’s cyclomatic number:\n/CE /B4 /BZ /B5 /BP /CT /A0 /D2 /B7 /D4/BN\nwhere\n/CT = the number of edges", "token_count": 512, "start_token": 246708, "end_token": 247220, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 535, "text": " is the graph’s cyclomatic number:\n/CE /B4 /BZ /B5 /BP /CT /A0 /D2 /B7 /D4/BN\nwhere\n/CT = the number of edges in the graph\n/D2 = the number of nodes\n/D4 = the number of components (a component is a maximal subgraph that is\nconnected, i.e. a maximal subgraph for which each pair of nod es is connected\nby some path)\n1 procedure insert(a, b, n, x);\n2 begin bool found:= false;\n3 for i:= 1 to n do\n4 if a[i] = x\n5 then found:= true; goto leave endif\n6 enddo;\n7 leave:\n8 if found\n9 then b[i]:= b[i] + 1\n10 else n:= n + 1; a[n]:= x; b[n]:= 1 endif\n11 end insert;\nFigure 13.10 An insertion routine\n13.5. COVERAGE-BASED TEST TECHNIQUES 425\nAs an example, consider the program text of ﬁgure 13.10. The c orresponding\ncontrol graph is given in ﬁgure 13.11. For this graph, /CT /BP /BD/BF , /D2 /BP /BD/BD , and /D4 /BP /BD . So\n/CE /B4 /BZ /B5 /BP /BF and /BV/CE /B4 /BZ /B5 /BP /BG . A possible\nset of linearly-independent paths for this graph is: /CU 1--2--3--4--5--6--7--8--9--11,\n3--7, 4--6--3, 8--10--11 /CV .\nFigure 13.11 Control-ﬂow graph of the insert routine from ﬁg ure 13.10\nA possible test strategy is to construct a test set such that a ll linearly-independent\npaths are covered. This adequacy criterion is known as the cyclomatic-number\ncriterion.\n13.5.2 Dataﬂow Coverage\nStarting from the control graph of a program, we may also cons ider how variables\nare treated along the various paths. This is termed data�", "token_count": 512, "start_token": 247170, "end_token": 247682, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 536, "text": "omatic-number\ncriterion.\n13.5.2 Dataﬂow Coverage\nStarting from the control graph of a program, we may also cons ider how variables\nare treated along the various paths. This is termed dataﬂow a nalysis. With dataﬂow\nanalysis too, we may deﬁne test adequacy criteria and use the se criteria to guide\ntesting.\nIn dataﬂow analysis, we consider the deﬁnitions and uses of v ariables along\nexecution paths. A variable is deﬁned in a certain statement if it is assigned a (new)\nvalue because of the execution of that statement. After that , the new value will be used\n426 SOFTWARE TESTING\nin subsequent statements. A deﬁnition in statement X is alive in statement Y if there\nexists a path from X to Y in which that variable does not get ass igned a new value at\nsome intermediate node. In the example in ﬁgure 13.9, for ins tance, the deﬁnition of\nj at line 7 is still alive at line 13 but not at line 14. A path such as the one from line 7\nto 13 is called deﬁnition-clear (with respect to j). Algorithms to determine such facts\nare commonly used in compilers in order to allocate variable s optimally to machine\nregisters.\nWe distinguish between two types of variable use: P-uses and C-uses. P-uses are\npredicate uses, like those in the conditional part of an if-s tatement. All other uses are\nC-uses. Examples of the latter are uses in computations or I/ O statements.\nA possible test strategy is to construct tests which travers e a deﬁnition-clear path\nbetween each deﬁnition of a variable to each (P- or C-) use of t hat deﬁnition and\neach successor of that use. (We have to include each successo r of a use to force\nall branches following a P-use to be taken.) We are then sure t hat each possible\nuse of a deﬁnition is being tested. This strategy is known as All-Uses coverage . A\nslightly stronger criterion requires that each deﬁnition", "token_count": 512, "start_token": 247632, "end_token": 248144, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 537, "text": " taken.) We are then sure t hat each possible\nuse of a deﬁnition is being tested. This strategy is known as All-Uses coverage . A\nslightly stronger criterion requires that each deﬁnition- clear path is either cycle-free\nor a simple cycle. This is known as All-DU-Paths coverage. Several weaker dataﬂow\ncriteria can be deﬁned as well:\n– All-defs coverage simply requires the test set to be such that each deﬁnition is\nused at least once.\n– All-C-uses/Some-P-uses coverage requires deﬁnition-clear paths from each\ndeﬁnition to each computational use. If a deﬁnition is used o nly in predicates,\nat least one deﬁnition-clear path to a predicate use must be e xercised.\n– All-P-Uses/Some-C-uses coverage requires deﬁnition-clear paths from each\ndeﬁnition to each predicate use. If a deﬁnition is used only i n computations, at\nleast one deﬁnition-clear path to a computational use must b e exercised.\n– All-P-Uses coverage requires deﬁnition-clear paths from each deﬁnition to\neach predicate use.\n13.5.3 Coverage-Based Testing of Requirements Speciﬁcati ons\nProgram code can be easily transformed into a graph model, th us allowing for all kinds\nof test adequacy criteria based on graphs. Requirements spe ciﬁcations, however, may\nalso be transformed into a graph model. As a consequence, the various coverage-based\nadequacy criteria can be used in both black-box and white-bo x testing techniques.\nConsider the example fragment of a requirements speciﬁcati on document for our\nlibrary system in ﬁgure 13.12. We may rephrase these require ments a bit and present\nthem in the form of elementary requirements and relations be tween them. The result\ncan be depicted as a graph, where the nodes denote elementary requirements and the\nedges denote relations between elementary requirements; s ee ﬁgure 13", "token_count": 512, "start_token": 248094, "end_token": 248606, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 538, "text": "them in the form of elementary requirements and relations be tween them. The result\ncan be depicted as a graph, where the nodes denote elementary requirements and the\nedges denote relations between elementary requirements; s ee ﬁgure 13.13. We may\n13.6. FAULT-BASED TEST TECHNIQUES 427\nuse this graph model to derive test cases and apply any of the c ontrol-ﬂow coverage\ncriteria to assess their adequacy.\nFunction Order allows the user to order new books. The user is shown a ﬁll-in- the-\nblanks screen with ﬁelds like Author, Title, Publisher, Price and Department. The\nTitle, Price and Department ﬁelds are mandatory. The Department ﬁeld is used\nto check whether the department’s budget is large enough to p urchase this book. If\nso, the book is ordered and\nthe department’s budget is reduced accordingly.\nFigure 13.12 A requirements speciﬁcation fragment\nA very similar route can be followed if the requirement is exp ressed in the form of\na use case. Figure 13.14 gives a possible rewording of the fra gment from ﬁgure 13.12.\nIt uses the format from (Cockburn, 2001). The use case descri bes both the normal\ncase, called the Main Success Scenario, as well as extension s that cover situations\nthat branch off the normal path because of some condition. Fo r each extension,\nboth the condition and the steps taken are listed. Note that ﬁ gure 13.13 directly\nmimics the use case description from 13.14. The use case desc ription also allows us\nto straightforwardly derive test cases and apply control-ﬂ ow coverage criteria.\nGenerally speaking, a major problem in determining a set of t est cases is to\npartition the program domain into a (small) number of equiva lence classes. We try to\ndo so in such a way that testing a representative element from a class sufﬁces for the\nwhole class. Using control-ﬂow coverage criteria, for exam ple, we assume that any\ntest of some node or branch is as good as any other such test. In the above example,\nfor instance, we assume that any", "token_count": 512, "start_token": 248556, "end_token": 249068, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 539, "text": "ole class. Using control-ﬂow coverage criteria, for exam ple, we assume that any\ntest of some node or branch is as good as any other such test. In the above example,\nfor instance, we assume that any execution of the node labeled ‘check dept. budget’\nwill do.\nThe weak point in this procedure is the underlying assumptio n that the program\nbehaves equivalently on all data from a given class. If such a ssumption is true, the\npartition is perfect and so is the test set.\nSuch assumption will in general not hold however (see also se ction 13.1.2).\n13.6 Fault-Based Test Techniques\nIn coverage-based testing techniques, we consider the stru cture of the problem or\nits solution, and the assumption is that a more comprehensiv e covering is better.\nIn fault-based testing strategies, we do not directly consider the artifact being tested\nwhen assessing the test adequacy. We only take into account t he test set. Fault-based\ntechniques are aimed at ﬁnding a test set with a high ability t o detect faults.\nWe will discuss two fault-based testing techniques: error s eeding and mutation\ntesting.\n428 SOFTWARE TESTING\nFigure 13.13 Graph model of requirements speciﬁcation frag ment\n13.6.1 Error Seeding\nText books on statistics often contain examples along the fo llowing lines: if we want\nto estimate the number of pikes in Lake Soft, we proceed as fol lows:\n1. Catch a number of pikes,\n/C6 , in Lake Seed;\n2. Mark them and throw them into Lake Soft;\n3. Catch a number of pikes,\n/C5 , in Lake Soft.\n13.6. FAULT-BASED TEST TECHNIQUES 429\nUse Case: Order new Book\nPrimary Actor : Library user\nScope: Library\nLevel: User goal\nStakeholders and Interests :\nUser---wants to acquire new books\nDepartment---wants to guard its budget\nPrecondition: User is logged on\nMinimum Guarantee : User id has been validated\nSuccess Guarantee : Order is accepted\nMain Success Scenario :\n1. User ﬁlls in form\n2. Book information is checked\n3. Department budget is checked\n4. Order is placed", "token_count": 512, "start_token": 249018, "end_token": 249530, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 540, "text": " User id has been validated\nSuccess Guarantee : Order is accepted\nMain Success Scenario :\n1. User ﬁlls in form\n2. Book information is checked\n3. Department budget is checked\n4. Order is placed\n5. User is informed about placed order\nExtensions:\n2a. Book information is not valid\n2a1. User is asked to correct information\n3a. Department budget is inadequate\n3a1. Order is rejected, user is notiﬁed\nFigure 13.14 Requirement in the form of a use case\nSupposing that /C5 /BC out of the /C5 pikes are found to be marked, the total number of\npikes originally present in Lake Soft is then estimated as /B4 /C5 /A0 /C5 /BC /B5 /A2 /C6 /BP /C5 /BC .\nA somewhat unsophisticated technique is to try to estimate t he number of faults\nin a program in a similar way. The easiest way to do this is to ar tiﬁcially seed a number\nof faults in the program. When the program is tested, we will d iscover both seeded\nfaults and new ones. The total number of faults is then estima ted from the ratio of\nthose two numbers.\nWe must be aware of the fact that a number of assumptions under lie this method\n-- amongst others, the assumption that both real and seeded f aults have the same\ndistribution.\nThere are various ways of determining which faults to seed in the program. A not\nvery satisfactory technique is to construct them by hand. It is unlikely that we will\nbe able to construct very realistic faults in this way. Fault s thought up by one person\nhave a fair chance of having been thought up already by the per son that wrote the\nsoftware.\n430 SOFTWARE TESTING\nAnother technique is to have the program independently test ed by two groups.\nThe faults found by the ﬁrst group can then be considered seed ed faults for the\nsecond group. In using this technique, though, we must reali ze that there is a chance\nthat both groups will detect (the same type of) simple faults . As a result, the picture\nmight well get distorted.\nA useful rule of thumb for this technique is the following: if we ﬁnd many\nseeded faults and relatively few others", "token_count": 512, "start_token": 249480, "end_token": 249992, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 541, "text": " detect (the same type of) simple faults . As a result, the picture\nmight well get distorted.\nA useful rule of thumb for this technique is the following: if we ﬁnd many\nseeded faults and relatively few others, the result can be tr usted. The opposite is not\ntrue. This phenomenon is more generally applicable: if, dur ing testing of a certain\ncomponent, many faults are found, it should not be taken as a p ositive sign. Quite the\ncontrary, it is an indication that the component is probably of low quality. As Myers\nobserved: ‘The probability of the existence of more errors i n a section of a program\nis proportional to the number of errors already found in that section.’ (Myers, 1979).\nThe same phenomenon has been observed in some experiments, w here a strong linear\nrelationship was found between the number of defects discov ered during early phases\nof development and the number of defects discovered later.\n13.6.2 Mutation Testing\nSuppose we have some program\n/C8 which produces the correct results for some tests\n/CC\n/BD\nand /CC\n/BE\n. We next generate some variant /C8 /BC of /C8 . /C8 /BC differs from /C8 in just one\nplace. For instance, a /B7 is replaced by a /A0 , or the value v\n/BD\nin a loop of the form\nfor var:= v\n/BD\nto v\n/BE\ndo\nis changed into v\n/BD\n/B7 /BD or v\n/BD\n/A0 /BD . Next, /C8 /BC is tested using tests /CC\n/BD\nand /CC\n/BE\n. Let us\nassume that /CC\n/BD\nproduces the same result in both cases, whereas /CC\n/BE\nproduces different\nresults. Then /CC\n/BD\nis the more interesting test case, since it does not discrimi nate\nbetween two variants of a program, one of which is certainly w rong.\nIn mutation testing , a (large) number of variants of a program is generated.\nEach of those variants, or mutants, slightly differs from th e original version. Usually,\nmutants are obtained by mechanically applying a set of simpl e transformations called\nmutation operators. Figure 13", "token_count": 512, "start_token": 249942, "end_token": 250454, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 542, "text": " number of variants of a program is generated.\nEach of those variants, or mutants, slightly differs from th e original version. Usually,\nmutants are obtained by mechanically applying a set of simpl e transformations called\nmutation operators. Figure 13.15 lists a number of such muta tion operators.\nNext, all these mutants are executed using a given test set. A s soon as a test\nproduces a different result for one of the mutants, that muta nt is said to be dead.\nMutants that produce the same results for all of the tests are said to be alive. As an\nexample, consider the erroneous sort procedure in ﬁgure 13. 3 and the correct variant\nthereof which compares array elements rather than their abs olute values. Tests with\nan array which happens to contain positive numbers only will leave both variants\nalive. If a test set leaves us with many live mutants, then tha t test set is of low quality,\nsince it is not able to discriminate between all kinds of vari ants of a given program.\nIf we assume that the number of mutants that is equivalent to t he original program\nis 0 (normally, this number will certainly be very small), th en the mutation adequacy\nscore of a test set equals /BW /BP /C5 , where /BW is the number of dead mutants and /C5 is the\ntotal number of mutants.\n13.6. FAULT-BASED TEST TECHNIQUES 431\nReplace a constant by another constant\nReplace a variable by another variable\nReplace a constant by a variable\nReplace an arithmetic operator by another arithmetic opera tor\nReplace a logical operator by another logical operator\nInsert a unary operator\nDelete a statement\nFigure 13.15 A sample of mutation operators\nThere are two major variants of mutation testing: strong mutation testing and\nweak mutation testing . Suppose we have a program /C8 with a component /CC . In strong\nmutation testing, we require that tests produce different r esults for program /C8 and\na mutant /C8 /BC . In weak mutation testing, we only require that component /CC and its\nmutant /CC /BC produce different results. At the level of /C8 , this difference need not crop\nup. Weak mutation adequacy is often easier to establish. Con sider a component /CC of\nthe form\nif x /BO 4.5", "token_count": 512, "start_token": 250404, "end_token": 250916, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 543, "text": "BC produce different results. At the level of /C8 , this difference need not crop\nup. Weak mutation adequacy is often easier to establish. Con sider a component /CC of\nthe form\nif x /BO 4.5 then . . .\nWe may then compute a series of mutants of /CC , such as\nif x /BQ 4.5 then . . .\nif x /BP 4.5 then . . .\nif x /BQ 4.6 then . . .\nif x /BO 4.4 then . . .\n. . .\nNext, we have to devise a test set that produces different res ults for the original\ncomponent /CC and at least one of its variants. This test set is then adequat e for /CC .\nMutation testing is based on two assumptions: the Competent Programmer Hypothesis\nand the Coupling Effect Hypothesis . The Competent Programmer Hypothesis states that\ncompetent programmers write programs that are ‘close’ to be ing correct. So the\nprogram actually written may be incorrect, but it will diffe r from a correct version by\nrelatively minor faults. If this hypothesis is true, we shou ld be able to detect these\nfaults by testing variants that differ slightly from the cor rect program, i.e. mutants.\nThe second hypothesis states that tests that can reveal simp le faults can also reveal\ncomplex faults. Experiments give some empirical evidence f or these hypotheses.\n432 SOFTWARE TESTING\n13.7 Error-Based Test Techniques\nSuppose our library system maintains a list of ‘hot’ books. E ach newly-acquired book\nis automatically added to the list. After six months, it is re moved again. Also, if a book\nis more than four months old and is being borrowed less than ﬁv e times a month\nor is more than two months old and is being borrowed at most twi ce a month, it is\nremoved from the list.\nThis rather complex requirement can be graphically depicte d as in ﬁgure 13.16. It\nshows that the two-dimensional (age, average number of loan s) domain can be parti-\ntioned into four subdomains. These subdomains directly rel ate to the requirements as\nstated above. The subdomains are separated by borders such a", "token_count": 512, "start_token": 250866, "end_token": 251378, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 544, "text": "dimensional (age, average number of loan s) domain can be parti-\ntioned into four subdomains. These subdomains directly rel ate to the requirements as\nstated above. The subdomains are separated by borders such a s the line\n/CP/CV/CT /BP /BI . For\neach border, it is indicated which of the adjacent subdomain s is closed at that border\nby placing a hachure at that side of the border. A subdomain /CB is closed at a border if\nthat border belongs to /CB ; otherwise, it is open at that border.\nFigure 13.16 Partitioning of the input space\nAn obvious test technique for this requirement is to use an in put from each of\nthese subdomains. If the program follows the logic of the req uirement, then test\nadequacy for that requirement equals path coverage for the c orresponding program.\nHowever, in error-based testing, we focus on error prone poi nts, and these are often\nfound near the borders of subdomains.\n13.8. COMPARISON OF TEST TECHNIQUES 433\nOne such test strategy concentrates on ON and OFF points. An O N point is a\npoint on the border of a subdomain. If a subdomain is open with respect to some\nborder, then an OFF point of a border is a point just inside tha t border. If a subdomain\nis closed with respect to some border, then an OFF point lies j ust outside that border.\nTwo adjacent subdomains share the same ON point; they may sha re the same OFF\npoint. In ﬁgure 13.16, the solid circle on the line /CP/CV/CT /BP /BI is an ON point of both /BT\nand /BU , while the circle just off this line is an OFF point of both the se subdomains.\nSuppose we have subdomains /BW\n/CX\n/BN /CX /BP /BD /BN /BM /BM /BM /BN /D2 . We may then construct a test set\nwhich contains /C6 test cases for ON points of each border /BU of each subdomain /BW\n/CX\n,\nand at least one test case for an OFF point of each border. The r esulting test set is\ncalled /C6 /A2 /BD domain", "token_count": 512, "start_token": 251328, "end_token": 251840, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 545, "text": " each border /BU of each subdomain /BW\n/CX\n,\nand at least one test case for an OFF point of each border. The r esulting test set is\ncalled /C6 /A2 /BD domain adequate .\nAbove, we have illustrated this error-based technique in it s black-box, speciﬁcation-\nbased form. The same technique can be applied to program text , though. If a program\ncontains code of the form\nif x /BQ 6 then . . .\nelsif x /BQ 4 and y /BO 5 then . . .\nelsif x /BQ 2 and y /AK 2 then . . .\nelse . . .\nthen we may identify the same four subdomains and use the same technique to test for\nboundary cases. In fact, this technique is just a systematic way to do what experienced\nprogrammers have done for a long time past: test for boundary values, such as 0, nil,\nlists with 0 or 1 element, and so on.\n13.8 Comparison of Test Techniques\nMost test techniques are heuristic in nature and lack a sound theoretical basis. Manual\ntest techniques rely heavily on the qualities of the partici pants in the test process.\nBut even the systematic approaches taken in functional and s tructural test techniques\nhave a rather weak underpinning and are based on assumptions that are generally not\ntrue.\nExperiments show that it is sometimes deceptively simple to make a system\nproduce faults or even let it crash. Miller et al. (1990) desc ribe one such experiment,\nin which they were able to crash or hang approximately 30% of t he UNIX utilities\non seven versions of the UNIX operating system. The utilitie s tested included\ncommonly-used text editors and text formatters.\nSimilar results have been obtained in mutation analysis exp eriments. In one\nsuch experiment (Knight and Ammann, 1985), 17 programs deve loped by different\nprogrammers from one and the same speciﬁcation were used. Th ese programs had all\nbeen thoroughly tested. Some of them had successfully withs tood one million tests.\nFor each of those programs, 24 mutants were created, each mut ant containing one\nseeded fault. The programs thus obtained were each tested 25 000 times. The results\ncan be summarized as follows:\n434 SOFTWARE", "token_count": 512, "start_token": 251790, "end_token": 252302, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 546, "text": "od one million tests.\nFor each of those programs, 24 mutants were created, each mut ant containing one\nseeded fault. The programs thus obtained were each tested 25 000 times. The results\ncan be summarized as follows:\n434 SOFTWARE TESTING\n– Some seeded faults were found quickly, some needed quite a f ew tests, and\nsome remained undetected even after 25 000 tests. This patte rn was found for\neach of the 17 programs;\n– In some cases, the original program failed, while the modiﬁ ed program yielded\nthe right result.\nIn the past, several attempts have been made to obtain more in sights into the\ntheoretical aspects of test techniques. An example is the re search that is aimed at\nrelating different test adequacy criteria. Test adequacy c riteria serve as rules used\nto determine whether or not testing can be terminated. An imp ortant issue then is\nto decide whether one such criterion is ‘better’ than anothe r. In section 13.8.1, we\ncompare the strength of a number of test adequacy criteria di scussed in previous\nsections. In section 13.8.2 we investigate a number of funda mental properties of test\nadequacy criteria. This type of research is aimed at gaining a deeper insight into\nproperties of different test techniques.\nSeveral experiments have been done to compare different tes t techniques. Real\ndata from a number of projects are also available on the fault -detection capabilities\nof test techniques used in those projects. In section 13.8.3 we discuss several of these\nﬁndings which may provide some practical insight into the vi rtues of a number of test\ntechniques.\n13.8.1 Comparison of Test Adequacy Criteria\nA question that may be raised is whether, say, the All-Uses ad equacy criterion is\nstronger or weaker than the All-Nodes or All-Edges adequacy criteria. We may\ndeﬁne the notion ‘stronger’ as follows: criterion X is stron ger than criterion Y if, for\nall programs P and all test sets T, X-adequacy implies Y-adeq uacy. In the testing\nliterature this relation is known as ‘subsume’. In this sens e, the All-Edges criterion is\nstronger than", "token_count": 512, "start_token": 252252, "end_token": 252764, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 547, "text": " sets T, X-adequacy implies Y-adeq uacy. In the testing\nliterature this relation is known as ‘subsume’. In this sens e, the All-Edges criterion is\nstronger than (subsumes) the All-Nodes criterion. The All- Uses criterion, however,\nis not stronger than the All-Nodes criterion. This is caused by the fact that programs\nmay contain statements which only refer to constants. For th e program\nif a\n/BO b\nthen print(0)\nelse print(1)\nthe All-Uses criterion will be satisﬁed by any non-empty tes t set, since this criterion\ndoes not require that each statement be executed. If we ignor e references to\nconstants, the All-Uses criterion is stronger than the All- Nodes criterion. With the\nsame exception, the All-Uses criterion is also stronger tha n the All-Edges criterion.\nA problem with any graph-based adequacy criterion is that it can only deal\nwith paths that can be executed (feasible paths). Paths whic h cannot be executed are\nknown as ’infeasible paths’. Infeasible paths result if par ts of the graph are unreachable,\nas in\n13.8. COMPARISON OF TEST TECHNIQUES 435\nif true\nthen x:= 1\nelse x:= 2\nThe else-branch is never executed, yet most adequacy criter ia require this branch to\nbe taken. Paths that are infeasible also result from loops. I f a loop is of the form\nfor i from 1 to 10 do\nbody\nthere will be no feasible paths that traverse the resulting c ycle in the graph any other\nthan ten times.\nThere does not exist a simple linear scale along which the str ength of all\nprogram-based adequacy criteria can be depicted. For the cr iteria discussed in\nsections 13.5--13.7, the subsume hierarchy is depicted in ﬁ gure 13.17, as far as it is\nknown. An arrow A /AX B indicates that A is stronger than (subsumes) B. In most\ncases, the subsume relation holds for both the feasible and n ot feasible versions of\nthe criteria. Arrows adorned with an asterisk denote relati", "token_count": 512, "start_token": 252714, "end_token": 253226, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 548, "text": " A /AX B indicates that A is stronger than (subsumes) B. In most\ncases, the subsume relation holds for both the feasible and n ot feasible versions of\nthe criteria. Arrows adorned with an asterisk denote relati ons which hold only for the\nnot feasible version.\nThe subsume relation compares the thoroughness of test tech niques, not their\nability to detect faults. Especially if an adequacy criteri on is used in an a priori sense,\ni.e. if it is used to generate the next test case, the subsume r elations of ﬁgure 13.17 do\nnot necessarily imply better fault detection. However, if s ome other tool is used to\ngenerate test cases, and the criterion is only used a posteri ori to decide when to stop\ntesting, a stronger adequacy criterion implies better faul t-detection ability as well.\nThe theoretical upper bounds for the number of test cases nee ded to satisfy\nmost of the coverage-based adequacy criteria are quadratic or exponential. Empirical\nstudies, however, show that, in practice, these criteria ar e usually linear in the number\nof conditional statements.\n13.8.2 Properties of Test Adequacy Criteria\nA major problem with any test technique is to decide when to st op testing. As noted,\nfunctional and structural test techniques provide only wea k means for doing so.\nWeyuker (1988) provides an interesting set of properties of test adequacy criteria.\nAlthough it is intuitively clear that any test adequacy crit erion should satisfy all of\nthe properties listed, it turns out that even some of the well -known test techniques\nsuch as All-Nodes coverage and All-Edges coverage fail to sa tisfy several of them.\nThe characteristics identiﬁed relate to program-based ade quacy criteria, i.e.\ncriteria that involve the program’s structure. The ﬁrst fou r criteria, however, are fairly\ngeneral and should apply to any test adequacy criterion. The following 11 properties\nare identiﬁed in (Weyuker, 1988) 3:\n3 Reproduced by permission of the Association for Computing M achinery, Inc.\n436 SOFTWARE TESTING\nFigure 13.17 Subsume hierarchy for program-based adequacy criteria\n", "token_count": 512, "start_token": 253176, "end_token": 253688, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 549, "text": " (Weyuker, 1988) 3:\n3 Reproduced by permission of the Association for Computing M achinery, Inc.\n436 SOFTWARE TESTING\nFigure 13.17 Subsume hierarchy for program-based adequacy criteria\n13.8. COMPARISON OF TEST TECHNIQUES 437\n/AF Applicability property For every program, there exists an adequate test set.\nExhaustive testing obviously satisﬁes this criterion but, in general, we will look\nfor a reasonably-sized test set. Both All-Nodes and All-Edg es coverage criteria\ndo not fulﬁll this property. If the program contains unexecu table code, there\nsimply are no tests to cover those parts of the program.\n/AF Non-exhaustive applicability property This property says that, even if exhaus-\ntive testing may be required in some cases, a criterion shoul d certainly not\nrequire exhaustive testing in all circumstances.\n/AF Monotonicity property This property states that once a program has been\nadequately tested, running some additional tests can do no h arm. Obviously,\nthe additional tests may reveal further faults, but this doe s not deem the original\ntest set inadequate. It merely improves the quality of the te st process.\n/AF Inadequate empty set property The empty test set is not an adequate test set\nfor any program. A test adequacy criterion should measure ho w well the testing\nprocess has been conducted. If a program has not been tested a t all, it certainly\nhas not been adequately tested.\n/AF Antiextensionality property This property states that semantic equivalence is\nnot sufﬁcient to imply that the programs are to be tested in th e same way.\nFor instance, routines BubbleSort and QuickSort are likely to require different\ntest sets. This property is speciﬁc for program-based adequ acy criteria, which\ndepend on the implementation rather than the function being implemented. In\na speciﬁcation-based approach this property need not hold.\n/AF General multiple change property Whereas the previous property states that\nsemantic ‘closeness’ is not sufﬁcient to imply that two prog rams can be tested\nin the same way, this property states that syntactic closene ss is not sufﬁcient\neither", "token_count": 512, "start_token": 253638, "end_token": 254150, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 550, "text": " ‘closeness’ is not sufﬁcient to imply that two prog rams can be tested\nin the same way, this property states that syntactic closene ss is not sufﬁcient\neither. Programs are said to be syntactically close if they h ave the same structure\nand the same dataﬂow characteristics. This is the case, for i nstance, when some\nof the relational or arithmetic operators in those programs differ. Though the\nshape of these programs is the same, testing them on the same d ata may well\ncause different paths through the ﬂow graph being executed.\n/AF Antidecomposition property This property states that if a component is\nadequately tested in one environment, this does not imply th at it is adequately\ntested for some other environment. Put in other words: if som e assembly\nof components is adequately tested, this does not imply that the individual\ncomponents have been adequately tested as well. For example , a sorting routine\nmay well be adequately tested in an environment where the siz e of the array is\nalways less than ten. If we move that routine to an environmen t which requires\nmuch larger arrays to be sorted, it must be tested anew in that environment.\n438 SOFTWARE TESTING\n/AF Anticomposition property This property reﬂects just the opposite: even if\ncomponents have been adequately tested in isolation, we sti ll have to test their\ncomposition in order to ascertain that their interfaces and interactions work\nproperly.\n/AF Renaming property If two programs differ only in inessential ways, as is the\ncase when different variable names are used, then an adequat e test set for one\nof these programs also sufﬁces for the other.\n/AF Complexity property Intuitively, more complex programs require more testing.\nThis property reﬂects this intuition by stating that for eve ry program there\nexists other programs that require more testing.\n/AF Statement coverage property One central property of program-based adequacy\ncriteria is that they should at least cause every executable statement of the\nprogram to be executed.\nAs noted, the All-Nodes and All-Edges coverage metrics fail to satisfy the applicability\ncriterion. This is rather unsatisfactory, since it implies that we may not be able to", "token_count": 512, "start_token": 254100, "end_token": 254612, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 551, "text": " of the\nprogram to be executed.\nAs noted, the All-Nodes and All-Edges coverage metrics fail to satisfy the applicability\ncriterion. This is rather unsatisfactory, since it implies that we may not be able to\ndecide whether testing has been adequate. If a 50% coverage h as been obtained using\neither of these criteria, we do not know whether additional t ests will help. It may be\nthat the other 50% of the statements or branches is not execut ed by any input.\nBoth the All-Nodes and All-edges criteria do not satisfy the antidecomposition\nand anticomposition criteria either. For example, if all st atements of individual\ncomponents are executed using some given test set, then this same test set is likely\nto satisfy that criterion on their composition. Further res earch along these lines is\nexpected to deepen our insight into what test techniques may or may not accomplish.\n13.8.3 Experimental Results\nWhen one vacuums a rug in one direction only, one is likely to p ick up less dirt than if\nthe vacuuming occurs in two directions.\n(Cha et al., 1988, p. 386)\nThe most common techniques for unit testing have been discus sed in the previous\nsections. The effectiveness of those techniques is discuss ed in (Basili and Selby,\n1987). There, Basili and Selby describe an experiment in whi ch both professional\nprogrammers and students participated. Three techniques w ere compared:\n– stepwise abstraction;\n– functional testing based on equivalence classes and bound ary value analysis\n(see section 13.7);\n– structural testing with 100% statement coverage.\n13.8. COMPARISON OF TEST TECHNIQUES 439\nBasili and Selby compared the effectiveness of these techni ques as regards detecting\nfaults, the associated costs, and the kinds of faults found. Some of the results of this\nexperiment were:\n/AF The professional programmers detected more faults with ste pwise abstraction.\nAlso, they did so faster than with the other techniques. They discovered more\nfaults with functional testing as compared with structural testing. The speed\nwith which they did so did not differ.\n/AF In one group of students, the various test techniques yielde d the same results as\nregards the number of faults found. In a second group, struct", "token_count": 512, "start_token": 254562, "end_token": 255074, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 552, "text": " structural testing. The speed\nwith which they did so did not differ.\n/AF In one group of students, the various test techniques yielde d the same results as\nregards the number of faults found. In a second group, struct ural testing turned\nout to be inferior to both other techniques. The speed with wh ich faults were\ndetected did not differ.\n/AF The number of faults found, the speed of fault detection, and the total effort\nneeded depended upon the kind of program being tested.\n/AF More interface faults were found with stepwise abstraction .\n/AF More faults in the control structure were found with functio nal testing.\nOther experiments also indicate that there is no uniform ‘be st’ test technique.\nDifferent test techniques tend to reveal different types of fault. The use of multiple\ntest techniques certainly results in the discovery of more faults. It is difﬁcult though to\nascribe the discovery of faults to the use of a speciﬁc techni que. It may well be that\nthe mere fact that test techniques force us to pay systematic attention to the software\nis largely responsible for their success.\nSeveral studies have reported on the fault detection capabi lities of (Fagan)\ninspections. Myers (1988) reports that about 85% of the majo r errors in the Space\nShuttle software were found during early inspections. Insp ections have been found\nto be superior to other manual techniques such as walkthroug hs. Inspections were\nalso found to have the additional beneﬁt of improving both qu ality and productivity.\nThere is some controversy about the added value of group meet ings.\nFinally, there is ample empirical evidence that early atten tion to fault detection\nand removal really pays off. Boehm’s data presented in the in troduction to this chapter\ncan be augmented by other results, such as those of (Collofel lo and Woodﬁeld, 1989).\nHis data stem from a large real-time software project, consi sting of about 700 000\nlines of code developed by over 400 people. Some of his ﬁnding s are reproduced in\nﬁgure 13.18. For example, of the 676 design faults that could have been caught, 365\nwere caught during the design review (=54%). The overall des ign review ef", "token_count": 512, "start_token": 255024, "end_token": 255536, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 553, "text": "�nding s are reproduced in\nﬁgure 13.18. For example, of the 676 design faults that could have been caught, 365\nwere caught during the design review (=54%). The overall des ign review efﬁciency\nwas not much different from code review efﬁciency, while the testing phase was\nsomewhat less efﬁcient. The latter is not all that surprisin g, since the design and code\nreviews are likely to have removed many of the faults that wer e easy to detect. These\nresults again suggest that the use of multiple techniques is preferable to the use of a\nsingle technique.\n440 SOFTWARE TESTING\nThe results become much more skewed if we take into account th e cost-\neffectiveness of the different test techniques. The cost-e ffectiveness metric used is\nthe ratio of ‘costs saved by the process’ to ‘costs consumed b y the process’. The costs\nsaved by the process are the costs that would have been spent i f the process had not\nbeen performed and faults had to have been corrected later. T he cost-effectiveness\nresults found in this study are given in ﬁgure 13.19. These re sults indicate that, for\nevery hour spent in design reviews and correcting design fau lts, more than eight hours\nof work are saved. The cost-effectiveness of the testing pha se itself is remarkably low.\nThis is not really surprising, since much time is wasted duri ng the actual testing phase\nin performing tests that do not reveal any faults. These ﬁndi ngs once more conﬁrm\nthe statement that early testing really pays off.\n% of design faults % of coding faults Combined\nfound found efﬁciency\nDesign review 54 -- 54\nCode review 33 84 64\nTesting 38 38 38\nFigure 13.18 Fault-detection efﬁciency\nDesign review Code review Testing\n8.44 1.38 0.17\nFigure 13.19 Cost-effectiveness results found in (Collofe llo and Woodﬁeld, 1989)\n13.9 Different Test Stages\nDuring the design phase, the system to be built has been decom posed into compo-\nnents. Generally, these components form some hierarchical structure. During", "token_count": 512, "start_token": 255486, "end_token": 255998, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 554, "text": " Woodﬁeld, 1989)\n13.9 Different Test Stages\nDuring the design phase, the system to be built has been decom posed into compo-\nnents. Generally, these components form some hierarchical structure. During testing,\nwe will often let ourselves be led by this structure. We do not immediately start to\ntest the system as a whole but start by testing the individual components (called unit\n13.9. DIFFERENT TEST STAGES 441\ntesting). Next, these components are incrementally integrated int o a system. Testing\nthe composition of components is called integration testing .\nIn doing this, we may take one of two approaches. In the ﬁrst ap proach, we\nstart by testing the low-level components which are then int egrated and coupled\nwith components at the next higher level. The subsystem thus obtained is tested\nnext. Then gradually we move towards the highest-level comp onents. This is known\nas bottom-up testing. The alternative approach is top-down testing. In top-down\ntesting, the top-level components are tested ﬁrst and are gr adually integrated with\nlower-level components.\nIn bottom-up testing, we often have to simulate the environm ent in which the\ncomponent being tested is to be integrated. This an environm ent is called a test\ndriver. In top-down testing the opposite is true: we have to s imulate lower-level\ncomponents, through so-called test stubs.\nBoth methods have advantages and disadvantages. For instan ce, in bottom-up\ntesting it may be difﬁcult to get a sound impression of the ﬁna l system during the early\nstages of testing because whilst the top-level components a re not integrated, there is\nno system, only bits and pieces. With top-down testing, on th e other hand, writing\nthe stubs can be rather laborious. If the implementation str ategy is one whereby a\nskeletal system is built ﬁrst and then populated with compon ents, this skeletal system\ncan be used as a test driver and the test order then becomes muc h less of an issue.\nIn practice, it is often useful to combine both methods. It is not necessarily\nthe case that some given design or implementation technique drives us in selecting\na particular test technique", "token_count": 512, "start_token": 255948, "end_token": 256460, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 555, "text": " driver and the test order then becomes muc h less of an issue.\nIn practice, it is often useful to combine both methods. It is not necessarily\nthe case that some given design or implementation technique drives us in selecting\na particular test technique. If the testing is to partly para llel the implementation,\nordering constraints induced by the order of implementatio n have to be obeyed,\nthough.\nThe program-based adequacy criteria make use of an underlyi ng language model.\nSubtle differences in this underlying model may lead to subt le differences in the\nresulting ﬂow graphs as used in coverage-based criteria, fo r instance. Roughly\nspeaking, the results reported hold at the level of a procedu re or subroutine in\nlanguages like FORTRAN, Pascal, and so on.\nAs a consequence, the corresponding test techniques apply a t the level of indi-\nvidual methods in object-oriented programs. Testing large r components of OO\nprograms, such as parameterized classes or classes that inh erit part of their functional-\nity from other classes, resembles regression testing as don e during maintenance. We\nthen have to decide how much retesting should be done if metho ds are redeﬁned in\na subclass, or a class is instantiated with another type as a p arameter.\nOther forms of testing exist besides unit testing and integr ation testing. One\npossibility is to test the whole system against the user docu mentation and requirements\nspeciﬁcation after integration testing has ﬁnished. This i s called the system test . A\nsimilar type of testing is often performed under supervisio n of the user organization\nand is then called acceptance testing . During acceptance testing, emphasis is on\ntesting the usability of the system, rather than compliance of the code against some\nspeciﬁcation. Acceptance testing is a major criterion upon which the decision to\n442 SOFTWARE TESTING\naccept or reject a system is based. In order to ensure a proper delivery of all necessary\nartifacts of a software development project, it is useful to let the future maintenance\norganization have a right of veto in the acceptance testing p rocess.\nIf the system has to become operational in an environment dif ferent from the one\nin which it has been developed, a separate installation test is usually performed.\nThe test", "token_count": 512, "start_token": 256410, "end_token": 256922, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 556, "text": " have a right of veto in the acceptance testing p rocess.\nIf the system has to become operational in an environment dif ferent from the one\nin which it has been developed, a separate installation test is usually performed.\nThe test techniques discussed in the previous sections are o ften applied during\nunit and integration testing. When testing the system as a wh ole, the tests often\nuse random input, albeit that the input is chosen such that it is representative of\nthe system’s operational use. Such tests can also be used to q uantitatively assess the\nsystem’s reliability. Software reliability is the topic of section 13.10.\nThe use of random input as test data has proven to be successfu l in the Cleanroom\ndevelopment method. In several experiments, it was found th at aselect testing resulted\nin a high degree of statement and branch coverage. If a branch was not executed, it\noften concerned the treatment of an exceptional case.\n13.10 Estimating Software Reliability\nIn much of this book the reader will ﬁnd references to the fact that most software does\nnot function perfectly. Faults are found in almost every run -of-the-mill software sys-\ntem: the software is not 100% reliable. In this section we con centrate on quantitative,\nstatistical, notions of software reliability.\nOne beneﬁt of such information is that it can be put to use in pl anning our\nmaintenance effort. Another reason for collecting reliabi lity information could be\ncontractual obligations regarding a required reliability level. Software for telephone\nswitching systems, for instance, requires such quantitati ve knowledge of the system’s\nexpected availability. We need to know what the probability is of wrong connections\nbeing due to faults in the software.\nA second application of reliability data is found in testing . A major problem with\ntesting is deciding when to stop. One possibility is to base t his decision on reaching\na certain reliability level. If the required reliability le vel is not reached, we need an\nestimate of the time it will take to reach that level.\nIn order to be able to answer this type of question, a number of software\nreliability models have been developed which strongly resemble the well-known\nhardware reliability models. These are statistical models where the starting point is a\ncertain probability distribution for expected failures. T he precise distribution is not", "token_count": 512, "start_token": 256872, "end_token": 257384, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 557, "text": " question, a number of software\nreliability models have been developed which strongly resemble the well-known\nhardware reliability models. These are statistical models where the starting point is a\ncertain probability distribution for expected failures. T he precise distribution is not\nknown a priori. We must measure the points in time at which the ﬁrst\n/D2 failures\noccur and look for a probability distribution that ﬁts those data. We can then make\npredictions using the probability distribution just obtai ned.\nIn this section we will concentrate on two models which are no t too complicated\nand yet yield fairly good results: the basic execution time model and the logarithmic\nPoisson execution time model .\nThe goal of many test techniques discussed in this chapter is to ﬁnd as many faults\nas possible. What we in fact observe are manifestations of faults, i.e. failures. The system\n13.10. ESTIMATING SOFTWARE RELIABILITY 443\nfails if the output does not meet the speciﬁcation. Faults in a program are static in\nnature, failures are dynamic. A program can fail only when it is executed. From the\nuser’s point of view, failures are much more important than f aults. For example, a fault\nin a piece of software that is never, or hardly ever, used is, i n general, less important\nthan a fault which manifests itself frequently. Also, one an d the same fault may show\nup in different ways and a failure may be caused by more than on e fault.\nIn the following discussion on reliability, we will not be co ncerned with the\nexpected number of faults in a program. Rather, the emphasis will be on the expected\nnumber of failures. The notion of time plays an essential rol e. For the moment, we\nwill deﬁne reliability as: the probability that the program will not fail during a certain\nperiod of time.\nThe notion of time deserves further attention. Ultimately, we are interested\nin statements regarding calendar time. For example, we migh t want to know the\nprobability that a given system will not fail in a one-week ti me period, or we might\nbe interested in the number of weeks of system testing still n eeded to reach a certain\nreliability level.\nBoth models discussed below use the notion of execution time . Execution time\n", "token_count": 512, "start_token": 257334, "end_token": 257846, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 558, "text": " a one-week ti me period, or we might\nbe interested in the number of weeks of system testing still n eeded to reach a certain\nreliability level.\nBoth models discussed below use the notion of execution time . Execution time\nis the time spent by the machine actually executing the softw are. Reliability models\nbased on execution time yield better results than those base d on calendar time. In\nmany cases, an a posteriori translation of execution time to calendar time is possible.\nTo emphasize this distinction, execution time will be denot ed by /AS and calendar time\nby /D8 .\nThe failure behavior of a program depends on many factors: qu ality of the\ndesigners, complexity of the system, development techniqu es used, etc. Most of these\ncannot adequately be dealt with as variables in a reliabilit y model and therefore are\nassumed to be ﬁxed. Reliability, when discussed in this sect ion, will therefore always\nconcern one speciﬁc project.\nSome factors affecting failure behavior can be dealt with, t hough. As noticed\nbefore, the models discussed are based on the notion of execu tion time. This is\nsimple to measure if we run one application on a stand-alone c omputer. Translation\nbetween machines that differ in speed can be taken care of rel atively easily. Even if\nthe machine is used in multiprogramming mode, translation f rom the time measured\nto proper execution time may be possible. This is the case, fo r instance, if time is\nrelatively uniformly distributed over the applications be ing executed.\nThe input to a program is also variable. Since we estimate the model’s parameters\non the basis of failures observed, the predictions made will only hold insofar as future\ninput resembles the input which led to the observed failure b ehavior. The future has to\nresemble the past. In order to get reliable predictions, the tests must be representative\nof the later operational use of the system. If we are able to al locate the possible inputs\nto different equivalence classes, simple readjustments ar e possible here too.\nWe may summarize this discussion by including the environme nt in the deﬁnition\nof our notion of software reliability. Reliability then is d eﬁned as the probability that\na system will not fail during a certain period of time in a", "token_count": 512, "start_token": 257796, "end_token": 258308, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 559, "text": " the environme nt in the deﬁnition\nof our notion of software reliability. Reliability then is d eﬁned as the probability that\na system will not fail during a certain period of time in a cert ain environment.\n444 SOFTWARE TESTING\nFinally, software systems are not static entities. Softwar e is often implemented\nand tested incrementally. Reliability of an evolving syste m is difﬁcult to express. In\nthe ensuing discussion, we therefore assume that our system s are stable over time.\nWe may characterize the failure behavior of software in diff erent ways. For\nexample, we may consider the expected time to the next failur e, the expected time\ninterval between successive failures, or the expected numb er of failures in a certain\ntime interval. In all cases, we are concerned with random var iables, since we do not\nknow exactly when the software will fail. There are at least t wo reasons for this\nuncertainty. Firstly, we do not know where the programmer ma de errors. Secondly,\nthe relation between a certain input and the order in which th e corresponding set\nof instructions is being executed is not usually known. We ma y therefore model\nsubsequent failures as a stochastic process. Such a stochas tic process is characterized\nby, amongst other things, the form and probability distribu tion of the random\nvariables.\nWhen the software fails, we try to locate and repair the fault that caused this\nfailure. In particular, this situation arises during the te st phase of the software life\ncycle. Since we assume a stable situation, the application o f reliability models is\nparticularly appropriate during system testing, when the i ndividual components have\nbeen integrated into one system. This system-test situatio n in particular will be\ndiscussed below.\nIn this situation, the failure behavior will not follow a con stant pattern but\nwill change over time, since faults detected are subsequent ly repaired. A stochastic\nprocess whose probability distribution changes over time i s called non-homogeneous. The\nvariation in time between successive failures can be descri bed in terms of a function\n/AM /B4 /AS /B5 which denotes the average number of failures until time /AS . Alternatively, we\nmay consider the failure intensity function /AL /B4 /AS /B5 , the average number of", "token_count": 512, "start_token": 258258, "end_token": 258770, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 560, "text": " a function\n/AM /B4 /AS /B5 which denotes the average number of failures until time /AS . Alternatively, we\nmay consider the failure intensity function /AL /B4 /AS /B5 , the average number of failures per\nunit of time at time /AS . /AL /B4 /AS /B5 then is the derivative of /AM /B4 /AS /B5 . If the reliability of a\nprogram increases through fault correction, the failure in tensity will decrease.\nThe relationship between /AL /B4 /AS /B5 , /AM /B4 /AS /B5 and /AS is graphically depicted in ﬁgure 13.20.\nThe models to be discussed below, the basic execution time mo del (BM) and the\nlogarithmic Poisson execution time model (LPM), differ in t he form of the failure\nintensity function /AL /B4 /AS /B5 .\nBoth BM and LPM assume that failures occur according to a non- homogeneous\nPoisson process. Poisson processes are often used to descri be the stochastic behavior\nof real-world events. Examples of Poisson processes are: th e number of telephone\ncalls expected in a given period of time, or the expected numb er of car accidents in\na given period of time. In our case, the processes are non-hom ogeneous, since the\nfailure intensity changes as a function of time, assuming a ( partly) successful effort to\nrepair the underlying errors.\nIn BM, the decrease in failure intensity, as a function of the number of failures\nobserved, is constant. The contribution to the decrease in f ailure intensity thus is the\nsame for each failure observed. In terms of the mean number of failures observed ( /AM ),\n13.10. ESTIMATING SOFTWARE RELIABILITY 445\nwe obtain\n/AL /B4 /AM /B5 /BP /AL\n/BC\n/B4/BD /A0 /AM/BP/AN\n/BC\n/B5\nHere, /AL\n/BC\ndenotes the initial failure intensity, i.e. the failure int ensity at time 0. /AN\n/BC\nFigure 13.20 Failure intensity /AL /B4 /AS /B5 and mean failures /AM /B4 /AS /B5 as functions of /AS", "token_count": 512, "start_token": 258720, "end_token": 259232, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 561, "text": ". the failure int ensity at time 0. /AN\n/BC\nFigure 13.20 Failure intensity /AL /B4 /AS /B5 and mean failures /AM /B4 /AS /B5 as functions of /AS (Source:\nJ.D. Musa, A. Iannino and K. Okumoto , Software Reilability, Copyright McGraw-Hill Book\nCompany, 1987. Reproduced by permission of McGraw-Hill, In c.)\ndenotes the number of failures observed if the program is exe cuted for an inﬁnite time\nperiod. Note that, since /AL is the derivative of /AM , and both are functions of /AS , /AL in fact\nonly depends on /AS . We will return to this later.\nIn LPM, the ﬁrst failure contributes more to the decrease in f ailure intensity than\nany subsequent failures. More precisely, the failure inten sity is exponential in the\nnumber of failures observed. We then get:\n/AL /B4 /AM /B5 /BP /AL\n/BC\n/CT/DC/D4\n/A0 /AI /AM\nIn this model, /AI denotes the decrease in failure intensity. For both models, the relation\nbetween /AL and /AM is depicted in ﬁgure 13.21. (Note that the two curves interse ct in\n446 SOFTWARE TESTING\nthis picture. This need not necessarily be the case. It depen ds on the actual values of\nthe model parameters.)\nBoth models have two parameters: /AL\n/BC\nand /AN\n/BC\nfor BM, and /AL\n/BC\nand /AI for LPM.\nThese parameters have yet to be determined, for instance fro m the observed failure\nbehavior during a certain period of time.\nFigure 13.21 Failure intensity /AL as a function of /AM (Source: J.D. Musa, A. Iannino and K.\nOkumoto, Software Reilability, Copyright McGraw-Hill Book Company, 1987. Reproduced by\npermission of McGraw-Hill, Inc. )\nWe can explain the shape of these functions as follows: given a certain input, the\nprogram in question will execute a certain sequence of instr uctions. A completely\ndifferent input may result in a completely different sequen ce", "token_count": 512, "start_token": 259182, "end_token": 259694, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 562, "text": ", Inc. )\nWe can explain the shape of these functions as follows: given a certain input, the\nprogram in question will execute a certain sequence of instr uctions. A completely\ndifferent input may result in a completely different sequen ce of instructions to be\nexecuted. We may partition all possible inputs into a number of classes such that\ninput from any one class results in the execution of the same s equence of instructions.\nSome example classes could be a certain type of command in an o perating system or\na certain type of transaction in a database system.\nThe user will select input from the various possible classes according to some\nprobability distribution. We deﬁne the operational proﬁle as the set of possible input\nclasses together with the probabilities that input from tho se classes is selected.\nThe basic execution time model implies a uniform operationa l proﬁle. If all input\nclasses are selected equally often, the various faults have an equal probability of\nmanifesting themselves. Correction of any of those faults t hen contributes the same\n13.10. ESTIMATING SOFTWARE RELIABILITY 447\namount to the decrease in failure intensity. It has been foun d that BM still models the\nsituation fairly well in the case of a fairly non-uniform ope rational proﬁle.\nWith a strong non-uniform operational proﬁle the failure in tensity curve will have\na convex shape, as in LPM. Some input classes will then be sele cted relatively often.\nAs a consequence, certain faults will show up earlier and be c orrected sooner. These\ncorrections will have a larger impact on the decrease in fail ure intensity.\nIn both models, /AL and /AM are functions of /AS (execution time). Furthermore, failure\nintensity /AL is the derivative of mean failures /AM . For BM, we may therefore write\n/AL /B4 /AM /B5 /BP /AL\n/BC\n/B4/BD /A0 /AM/BP/AN\n/BC\n/B5\nas\n/CS /AM /B4 /AS /B5\n/CS /AS\n/BP /AL\n/BC\n/B4/BD /A0 /AM /B4 /AS /B5 /BP/AN\n/BC\n/B5\nSolving this", "token_count": 512, "start_token": 259644, "end_token": 260156, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 563, "text": " /B5\n/CS /AS\n/BP /AL\n/BC\n/B4/BD /A0 /AM /B4 /AS /B5 /BP/AN\n/BC\n/B5\nSolving this differential equation yields\n/AM /B4 /AS /B5 /BP /AN\n/BC\n/B4/BD /A0 /CT/DC/D4\n/A0 /AL\n/BC\n/AS /BP/AN\n/BC\n/B5\nand\n/AL /B4 /AS /B5 /BP /AL\n/BC\n/CT/DC/D4\n/A0 /AL\n/BC\n/AS /BP/AN\n/BC\nIn a similar way, we obtain for LPM:\n/AM /B4 /AS /B5 /BP /D0/D2/B4 /AL\n/BC\n/AI /AS /B7 /BD/B5 /BP/AI\nand\n/AL /B4 /AS /B5 /BP /AL\n/BC\n/BP /B4 /AL\n/BC\n/AI /AS /B7 /BD/B5\nFor LPM, the expected number of failures in inﬁnite time is in ﬁnite. Obviously, the\nnumber of failures observed during testing is ﬁnite.\nBoth models allow that fault correction is not perfect. In BM the effectiveness of\nfault correction is constant, though not necessarily 100%. This again shows up in the\nlinearity of the failure intensity function. In LPM, the eff ectiveness of fault correction\ndecreases with time. Possible reasons could be that it becom es increasingly more\ndifﬁcult to locate the faults, for example because the softw are becomes less structured,\nor the personnel less motivated.\nIf the software has become operational and faults are not bei ng corrected any\nmore, the failure intensity will remain constant. Both mode ls then reduce to a\nhomogeneous Poisson process with failure intensity /AL as the parameter. The number\nof failures expected in a certain time period will then follo w a Poisson-distribution.\nThe probability of exactly /D2 failures being observed in a time period of length /AS is\nthen given by\n/C8\n/D2\n/B4 /AS /", "token_count": 512, "start_token": 260106, "end_token": 260618, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 564, "text": " then follo w a Poisson-distribution.\nThe probability of exactly /D2 failures being observed in a time period of length /AS is\nthen given by\n/C8\n/D2\n/B4 /AS /B5 /BP /B4 /AL/AS /B5\n/D2\n/A2 /CT/DC/D4\n/A0 /AL/AS\n/BP/D2 /AX\n448 SOFTWARE TESTING\nThe probability of 0 failures in a time frame of length /AS then is /C8\n/BC\n/B4 /AS /B5 /BP /CT/DC/D4/B4 /A0 /AL/AS /B5 .\nThis is precisely what we earlier denoted by the term softwar e reliability.\nGiven a choice of one of the models BM or LPM, we are next faced w ith the\nquestion of how to estimate the model’s parameters. We may do so by measuring the\npoints in time at which the ﬁrst /C6 failures occur. This gives us points /CC\n/BD\n/BN /BM /BM /BM /BN /CC\n/D2\n.\nThese points can be translated into pairs /B4 /AS /BN /AM /B4 /AS /B5/B5 . We may then determine the\nmodel’s parameters so that the resulting curve ﬁts the set of measuring points.\nTechniques like Maximum Likelihood or Least Squares are sui ted for this.\nOnce these parameters have been determined, predictions ca n be made. For\nexample, suppose the measured data result in a present failu re intensity /AL\n/C8\nand the\nrequired failure intensity is /AL\n/BY\n. If we denote the additional test time required to reach\nfailure intensity /AL\n/BY\nby /A1 /AS , then we obtain for BM:\n/A1 /AS /BP /B4 /AN\n/BC\n/BP/AL\n/BC\n/B5 /D0/D2 /B4 /AL\n/C8\n/BP/AL\n/BY\n/B5\nAnd for LPM we get\n/A1 /AS /BP /B4/BD /BP/AI /B5/B4/BD /BP/AL\n/BY\n", "token_count": 512, "start_token": 260568, "end_token": 261080, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 565, "text": "BP/AL\n/BY\n/B5\nAnd for LPM we get\n/A1 /AS /BP /B4/BD /BP/AI /B5/B4/BD /BP/AL\n/BY\n/A0 /BD /BP/AL\n/C8\n/B5\nObviously, we may also start from the equations for /AM . We then obtain estimates\nfor the number of failures that have yet to be observed before the required failure\nintensity level is reached.\nFor BM, this extrapolation is graphically depicted in ﬁgure 13.22. Since estimating\nthe model’s parameters is a statistical process, we do not ac tually obtain one solution.\nRather, we get reliability intervals. Such a reliability in terval denotes the interval\nwhich will contain a parameter with a certain probability. F or example, /AL\n/BC\nmay be\nin the interval [80,100] with probability 0.75. So the curve in ﬁgure 13.22 is actually\na band. The narrower this band is, the more accurately the par ameters have been\nestimated for the same reliability of the interval. In gener al the estimates will be more\naccurate if they are based on more data.\nIn the above discussion, we used the notion of execution time . That calendar time\nis a less useful notion on which to base our model can be seen as follows: suppose\nthe points in time at which the ﬁrst /C6 failures occurred were expressed in terms of\ncalendar time. Suppose also that we try to correct a fault as s oon as it manifests itself.\nIf the manpower available for fault correction is limited, a nd this manpower is capable\nof solving a ﬁxed number of problems per day, the failure inte nsity will be constant if\nit is based on calendar time. We then do not observe any progre ss.\nQuite a few reliability models have been proposed in the lite rature. The major\ndifferences concern the total number of failures (ﬁnite or i nﬁnite) that can be\nexperienced in inﬁnite time and the distribution of the fail ures experienced at a given\npoint in time (Poisson, binomial, etc.).\nAn important question then arises as to which model to choose . By studying a\n", "token_count": 512, "start_token": 261030, "end_token": 261542, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 566, "text": " in inﬁnite time and the distribution of the fail ures experienced at a given\npoint in time (Poisson, binomial, etc.).\nAn important question then arises as to which model to choose . By studying a\nnumber of failure data sets, it has been observed that no one m odel is consistently\nthe best. We therefore have to look for the model that gives th e best prediction on a\n13.11. SUMMARY 449\nFigure 13.22 A conceptual view of the parameter-estimating process ( Source: J.D. Musa,\nA. Iannino and K. Okumoto , Software Reilability, Copyright McGraw-Hill Book Company,\n1987. Reproduced by permission of McGraw-Hill, Inc. )\nproject-by-project basis. Since we do not know in advance wh ich model will perform\nbest, it is wise to adopt an eclectic approach, and use a numbe r of different models\nsimultaneously.\n13.11 Summary\nIn this chapter we discussed a great number of test technique s. We emphasized the\nimportance of early fault detection. It is important to pay a ttention to testing during\nthe early stages of the software development process. Early testing activities are\nthe ones that are most cost effective. Early testing activit ies provide opportunities\nto prevent errors from being made in the ﬁrst place. An extrem e form hereof is\ntest-driven development, where writing tests is the very ﬁr st thing we do.\n450 SOFTWARE TESTING\nIn practice, the various manual test techniques seem to be us ed most often. They\nturn out to be at least as successful as the various structura l and functional techniques.\nInspections in particular have been found to be a very cost-e ffective test technique.\nNext to the test techniques used, a major element in software fault detection and\nremoval is the choice of personnel -- some people are signiﬁc antly better at ﬁnding\nand removing faults than others.\nSince exhaustive testing is generally not feasible, we have to select an adequate\nset of test cases. Test techniques can be classiﬁed accordin g to the criterion used\nto measure the adequacy of this a test set. Three broad catego ries of test adequacy\ncriteria can be distinguished:\n", "token_count": 512, "start_token": 261492, "end_token": 262004, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 567, "text": " cases. Test techniques can be classiﬁed accordin g to the criterion used\nto measure the adequacy of this a test set. Three broad catego ries of test adequacy\ncriteria can be distinguished:\n– Coverage-based testing , in which testing requirements are speciﬁed in terms\nof the coverage of the product to be tested, for example, the p ercentage of\nstatements executed.\n– Fault-based testing , in which the focus is on detecting faults, for example, the\npercentage of seeded faults detected.\n– Error-based testing , which focuses on testing error-prone points, such as 0, 1,\nor the upper bound of an array.\nA test adequacy criterion can be used as stopping rule, as a me asurement instrument,\nor as a generator of test cases. Test adequacy criteria and th e corresponding test\ntechniques can be viewed as two sides of the same coin. A cover age-based test\ntechnique makes it easy to measure coverage-based criteria , but does not help us in\nassessing whether all error-prone points have been tested.\nExperimental evaluations show that there is no uniform best test technique.\nDifferent techniques tend to reveal different types of erro r. It is therefore wise to\n‘vacuum the carpet in more than one direction’.\nOne line of research addresses the relative power of test ade quacy criteria. A\nwell-known measure to compare program-based test adequacy criteria is the subsume\nrelation: criterion X subsumes Y if, for all programs P and al l test sets T, X-adequacy\nimplies Y-adequacy. Many of the well-known adequacy criter ia have been related to\none another in a subsume hierarchy.\nAs with any other life cycle activity, testing has to be caref ully planned, controlled,\nand documented. Some of the IEEE Standards provide useful gu idelines for doing\nthis (IEEE829, 1998; IEEE1012, 1986).\nThe last part of this chapter was devoted to a discussion of ho w to quantitatively\nestimate the reliability of a piece of software. The current ly-available software\nreliability models are limited in their immediate practica l value. In particular, no\nmodel consistently performs best.\n13.12. FURTHER READING 451\n13.", "token_count": 512, "start_token": 261954, "end_token": 262466, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 568, "text": " of a piece of software. The current ly-available software\nreliability models are limited in their immediate practica l value. In particular, no\nmodel consistently performs best.\n13.12. FURTHER READING 451\n13.12 Further Reading\nWell-known textbooks on testing are (Myers, 1979) (or its up dated version (Myers,\n2004)) and (Beizer, 1995). Whittaker (2000) gives a concise overview of the ﬁeld.\nFor a further discussion of safety issues, see (Leveson, 199 1). Fault-tree analysis is\ndiscussed in (Leveson, 1986). Zhu et al. (1997) gives a very g ood overview of the\ntypes of test strategy discussed in sections 13.5--13.7 and the associated adequacy\ncriteria. Rothermel and Harrold (1996) and Harrold (1999) g ive a very good overview\nof regression test techniques. Testing object-oriented so ftware is addressed in (Binder,\n2000).\nThe ﬁrst attempts at developing some theory on testing date b ack to the\n1970s (Goodenough and Gerhart, 1975), (Howden, 1982), and ( Howden, 1985).\nThereafter, much of that research has been directed towards ﬁnding and relating test\nadequacy criteria (Weyuker, 1988), (Clarke et al., 1989), ( Weyuker, 1990), (Frankl\nand Weyuker, 1993a), (Frankl and Weyuker, 1993b), (Parrish and Zweben, 1995),\nand (Zhu, 1996). Experimental evaluations of test adequacy criteria can be found in\n(Frankl and Weiss, 1993), (Weyuker, 1993), (Offutt and Lee, 1994), (Harrold et al.,\n1997), and (Frankl et al., 1997). Experiments that compare m anual and functional or\nstructural test techniques are reported upon in (Basili and Selby, 1987), (Kamsties\nand Lott, 1995), and (Wood et al., 1997). Juristo et al. (2004 ) give an overview of 25\nyears of testing technique experiments.\nThe Cleanroom development method is described in (Selby et a l., 1987) and\n(Mills et al", "token_count": 512, "start_token": 262416, "end_token": 262928, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 569, "text": " al., 1997). Juristo et al. (2004 ) give an overview of 25\nyears of testing technique experiments.\nThe Cleanroom development method is described in (Selby et a l., 1987) and\n(Mills et al., 1987). Experiences with Cleanroom are discus sed in (Currit et al., 1986)\nand (Trammell et al., 1992). Stepwise abstraction is descri bed in (Linger et al., 1979).\nBeck (2003) describes test-driven development. Janzen and Saiedian (2005) give\na somewhat wider perspective on its potential. Hunt and Thom as (2003) is one of the\nmany textbooks describing JUnit. Effects of test-driven de velopment on productivity\nand errors are reported in (Maximilien and Williams, 2003) a nd (Erdogmus et al.,\n2005).\nInspections were introduced by Fagan in the 1970s (Fagan, 19 76) and (Fagan,\n1986). Gilb and Graham (1993) is a text book on inspections; W iegers (2002) is\na text book on peer reviews. There have been many experimenta l evaluations of\ninspections; see for instance (Knight and Myers, 1993), (We ller, 1993), (Grady and\nvan Slack, 1994), (Porter et al., 1995), (Porter et al., 1997 ), (Porter et al., 1998) and\n(Bifﬂ and Halling, 2002). Parnas and Lawford (2003a) and Par nas and Lawford (2003b)\nare introductions to two companion special journal issues o n software inspections.\nCiolkowski et al. (2003) discusses the state of the art in sof tware reviews. The value\nof formal correctness proofs is disputed in (DeMillo et al., 1979). Heated debates in\nthe literature show that this issue has by no means been resol v (Fetzer, 1988).\nThe basic execution time model and the logarithmic Poisson e xecution time model\nare extensively discussed, and compared with a number of oth er models, in Musa\net al. (1987). Lyu (1995) is a very comprehensive source on so ftware reliability.\nExperiences with software reliability modeling are report ed in (Jeske and Zhang,\n452 SOFTWARE TESTING\n2005", "token_count": 512, "start_token": 262878, "end_token": 263390, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 570, "text": " in Musa\net al. (1987). Lyu (1995) is a very comprehensive source on so ftware reliability.\nExperiences with software reliability modeling are report ed in (Jeske and Zhang,\n452 SOFTWARE TESTING\n2005). Whittaker and Voas (2000) give criteria other than ti me and operational\nproﬁle that affect reliability.\nExercises\n1. What is a test adequacy criterion? Which kinds of uses does it have?\n2. Describe the following categories of test technique: cov erage-based testing,\nfault-based testing, and error-based testing.\n3. What assumptions underlie the mutation testing strategy ?\n4. What is the difference between black-box testing and whit e-box testing?\n5. Deﬁne the following terms: error, fault, and failure.\n6. What is a Fagan inspection?\n7. What is test-driven development?\n8. Deﬁne the following categories of control-ﬂow coverage: All-Paths coverage,\nAll-Edges coverage, All-Statements coverage.\n9. Consider the following routine (in Modula-2):\nprocedure SiftDown(var A: array of integer; k, n: integer);\nvar parent, child, insert, Ak: integer;\nbegin\nparent:= k; child:= k + k;\nAk:= A[k]; insert:= Ak;\nloop\nif child /BQ n then exit end;\nif child /BO n then\nif A[child] /BQ A[child+1] then child:= child+1 end\nend;\nif insert /BO = A[child]\nthen exit\nelse A[parent]:= A[child];\nparent:= child; child:= child + child\nend\nend;\nA[parent]:= Ak\nend SiftDown;\n(This operation performs the sift-down operation for heaps ; if needed, you\n13.12. FURTHER READING 453\nmay consult any text on data structures to learn more about he aps.) The\nroutine is tested using the following input:\nn = 5, k = 2,\nA[1] = 80, A[2] = 60, A[3] = 90, A[4] = 70", "token_count": 512, "start_token": 263340, "end_token": 263852, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 571, "text": "ps.) The\nroutine is tested using the following input:\nn = 5, k = 2,\nA[1] = 80, A[2] = 60, A[3] = 90, A[4] = 70, A[5] = 10.\nWill the above test yield a 100% statement coverage? If not, p rovide one or\nmore additional test cases this that a 100% statement covera ge is obtained.\n10. For the example routine from exercise 9, construct a test set that yields 100%\nbranch coverage.\n11. For the example routine from exercise 9, construct a test set that achieves\nAll-Uses coverage.\n12. Consider the following two program fragments:\nFragment 1:\nfound:= false; counter:= 1;\nwhile (counter /BO n) and (not found)\ndo\nif table[counter] = element then found:= true end;\ncounter:= counter + 1\nend;\nif found then writeln (”found”) else writeln (”not found”) end;\nFragment 2:\nfound:= false; counter:= 1;\nwhile (counter /BO n) and (not found)\ndo\nfound:= table[counter] = element;\ncounter:= counter + 1\nend;\nif found then writeln (”found”) else writeln (”not found”) end;\nCan the same test set be used if we wish to achieve a 100% branch coverage\nfor both fragments?\n13. What is mutation testing?\n14. Which assumptions underlie mutation testing? What does that say about the\nstrengths and weaknesses of this testing technique?\n15. When is one testing technique stronger than another?\n454 SOFTWARE TESTING\n16. What is the difference between a system test and an accept ance test?\n17. Contrast top-down and bottom-up integration testing.\n18. What is the major difference between the basic execution time model and\nthe logarithmic Poisson execution time model of software re liability?\n19. Give a deﬁnition of software reliability. Give a rationa le for the various parts\nof this deﬁnition.\n20. Why is it important to consider the operational proﬁle of a system while\nassessing its reliability?", "token_count": 512, "start_token": 263802, "end_token": 264314, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 572, "text": "ition of software reliability. Give a rationa le for the various parts\nof this deﬁnition.\n20. Why is it important to consider the operational proﬁle of a system while\nassessing its reliability?\n21. Can you think of reasons why reliability models based on e xecution time\nyield better results than those based on calendar time?\n22. Can software reliability be determined objectively?\n23. /DJ Read (DeMillo et al., 1979) and both (Fetzer, 1988) and the re actions to\nit (cited in the bibliography entry for that article). Write a position paper on\nthe role of correctness proofs in software development.\n24. /DJ For a (medium-sized) system you have developed, write a Soft ware\nVeriﬁcation and Validation Plan (SVVP) following IEEE Stan dard 1012.\nWhich of the issues addressed by this standard were not dealt with during\nthe actual development? Could a more thorough SVVP have impr oved the\ndevelopment and testing process?\n25. /DI Consider the following sort routine:\nprocedure selectsort(var r: array [1 .. n] of integer);\nvar j, k, small: integer;\nbegin\nif n /BQ 1 then\nfor k:= 1 to n - 1 do\nsmall:= k;\nfor j:= k + 1 to n do\nif r[j] /BO r[small] then small:= j end\nend;\nswap(r[k], r[small])\nend\nend\nend selectsort;\n13.12. FURTHER READING 455\nDetermine the function (by means of pre- and postconditions ) of this routine\nusing stepwise abstraction.\n26. /DI Generate ten mutants of the procedure in exercise 20. Next, t est these\nmutants using the following set of test cases:\n– an empty array;\n– an array of length 1;\n– a sorted array of length 10;\n– an array of 10 elements that all have the same value;\n– an array of length 10 with random elements.\nWhich of these mutants stay alive? What does this tell you abo ut the quality\nof these tests?\n27. /DI Construct an example showing that the antidecomposition an d anticompo-\n", "token_count": 512, "start_token": 264264, "end_token": 264776, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 573, "text": " 10 with random elements.\nWhich of these mutants stay alive? What does this tell you abo ut the quality\nof these tests?\n27. /DI Construct an example showing that the antidecomposition an d anticompo-\nsition axioms from section 13.8.2 do not hold for the All-Nod es and All-Edges\ntesting criteria. Why are these axioms important?\n28. /DJ With one or two fellow students or colleagues, inspect a requ irements or\ndesign document not produced by yourself. Is the documentat ion sufﬁcient\nto do a proper inspection? Discuss the ﬁndings of the process with the author\nof the document. Repeat the process with a document of which y ou are the\nauthor.\n29. /DI Assess the strengths and weaknesses of:\n– functional or structural testing,\n– correctness proofs,\n– random testing, and\n– inspections\nfor fault ﬁnding and conﬁdence building, respectively.\n30. /DI One way of testing a high-level document such as a requiremen ts speciﬁ-\ncation is to devise and discuss possible usage scenarios wit h prospective users\nof the system to be developed. What additional merits can thi s a technique\nhave over other types of review?\n31. /DI How do you personally feel about a Cleanroom-like approach t o software\ndevelopment?\n456 SOFTWARE TESTING\n32. /DI Discuss the following claim: ‘Reliability assessment is mo re important than\ntesting’. Can you think of reasons why both are needed?\n14\nSoftware Maintenance\nLEARNING OBJECTIVES\n/AF To know about well-known categories of maintenance tasks an d data on their\ndistribution\n/AF To be able to discern major causes of maintenance problems\n/AF To be aware of reverse engineering, its limitations, and too ls to support it\n/AF To appreciate different ways in which maintenance activiti es can be organized\n/AF To understand major differences between development and ma intenance and\nthe consequences thereof\n458 SOFTWARE MAINTENANCE\nSoftware maintenance is not limited to the correction of fau lts. A large part\nof maintenance deals with accommodating new or changed user requirements\nand adapting software to a changed environment. It is about e volution, rather\nthan just maintenance. We discuss the various types", "token_count": 512, "start_token": 264726, "end_token": 265238, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 574, "text": " to the correction of fau lts. A large part\nof maintenance deals with accommodating new or changed user requirements\nand adapting software to a changed environment. It is about e volution, rather\nthan just maintenance. We discuss the various types of maint enance tasks, and\nhow to organize them.\nLike living organisms and most natural phenomena, software projects follow a life cycle\nthat starts from emptiness, is followed by rapid growth duri ng infancy, enters a long\nperiod of maturity, and then begins a cycle of decay that almo st resembles senility.\n(Jones, 1989)\nSoftware, unlike a child, does not grow smarter and more capa ble; unfortunately, it does\nseem to grow old and cranky.\n(Lyons, 1981)\nConsider UBank, a multinational bank, a typical large organ ization that is heavily\ndependent upon automation for its daily operation. UBank is the result of a number\nof mergers and takeovers.\nUBank has hundreds of ofﬁces spread all over the world. It has a number of\nmainframes at a central site, as well as thousands of worksta tions and printers\nconnected. It has internet connectivity, all over the world , and strives for /BE/BG /A3 /BJ\navailability. The workload is an enormous number of transac tions per hour. The bank\nhas hundreds of application systems averaging over 100 000 l ines of code. Programs\nare written in a variety of languages, most notably COBOL, va rious 4GLs and JCL.\nThe systems make use of huge databases implemented under IDM S, INGRES, and so\non. Some of the basic information is shared by many systems.\nQuite likely, the bank has no complete overview of its applic ation portfolio.\nBecause of the mergers and acquisitions, integration of app lications is a big issue.\nThere are many wrappers, bridges, and other temporary means to glue systems\ntogether. There are more people involved in maintaining UBa nk’s information\nsystems, than there are people involved in developing new sy stems for UBank.\nThere are many organizations like UBank, organizations who se portfolio of\ninformation systems is vital for their day-to-day operatio n. At the same time, these\ninformation systems are ageing and it becomes increasingly difﬁcult to keep them ‘up", "token_count": 512, "start_token": 265188, "end_token": 265700, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 575, "text": "Bank, organizations who se portfolio of\ninformation systems is vital for their day-to-day operatio n. At the same time, these\ninformation systems are ageing and it becomes increasingly difﬁcult to keep them ‘up\nand running’. An increasing percentage of the annual budget of these organizations is\nspent on keeping installed systems functioning properly.\nIt is estimated that there are more than 100 billion lines of c ode in production in\nthe world. As much as 80% of it is unstructured, patched, and b adly documented. It is a\ngargantuan task to keep these software systems operational : errors must be corrected,\nand systems must be adapted to changing environments and use r needs. This is what\nsoftware maintenance is about. Software maintenance is deﬁ ned as (IEEE610, 1990):\n459\nThe process of modifying a software system or component afte r delivery\nto correct faults, improve performance or other attributes , or adapt to a\nchanged environment.\nSo software maintenance is, in particular, not limited to the correction of latent faults.\nThe distinction between development and maintenance is fuz zy, to say the least. This\nmakes it hard to very bold about percentages and types of main tenance categories.\nIn section 14.1, we revisit the discussion about types of mai ntenance activities from\nchapter 1 and provide a more balanced view.\nChanges in both the system’s environment and user requireme nts are inevitable.\nSoftware models part of reality, and reality changes, wheth er we like it or not. So the\nsoftware has to change too. It has to evolve. A large percenta ge of what we are used\nto calling maintenance, is actually evolution.\nWhen looking for ways to reduce the maintenance problem, it i s worth bearing in\nmind the classiﬁcation of maintenance activities given in c hapter 1. Possible solutions\nto be considered include:\n/AF Higher-quality code, better test procedures, better docum entation and adher-\nence to standards and conventions may help to save on correct ive maintenance;\n/AF By anticipating changes during requirements engineering a nd design and by\ntaking them into account during realization, future perfec tive and adaptive\nmaintenance can be realized more easily. In particular, the explicit evaluation\nof a software architecture with respect to ease of change is t o", "token_count": 512, "start_token": 265650, "end_token": 266162, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 576, "text": " a nd design and by\ntaking them into account during realization, future perfec tive and adaptive\nmaintenance can be realized more easily. In particular, the explicit evaluation\nof a software architecture with respect to ease of change is t o be recommended.\nThrough its inheritance and virtual typing capabilities, t he object-oriented\ndevelopment paradigm in particular offers opportunities f or isolating parts that\nare susceptible to changes from those that are less so. Many d esign patterns are\naimed at encapsulating change-prone elements;\n/AF Finer tuning to user needs may lead to savings in perfective m aintenance.\nThis may, for example, be achieved through prototyping tech niques or a more\nintensive user participation during the requirements engi neering and design\nphase;\n/AF Less maintenance is needed when less code is written. The she er length of\nthe source code is the main determinant of total cost, both du ring initial\ndevelopment and during maintenance. In particular, a 10% ch ange in a module\nof 200 LOC is more expensive than a 20% change in a module of 100 LOC. The\nreuse of existing software in particular has a very direct im pact on maintenance\ncosts.\nThese possible actions are all concerned with initial softw are development. This is\nnot surprising, since the key to better maintainable softwa re is to be found there. All\nthese issues have been discussed at great length in previous chapters.\nBetter initial development though will not automatically r esult in lower main-\ntenance costs. Worse, Dekleva (1992) found exactly the oppo site. He found that\n460 SOFTWARE MAINTENANCE\ndevelopment projects with analysis and design phases that p roduce a logical pre-\nsentation of the system’s function incur higher maintenance cost than projects that\ndid not produce such a presentation. The explanation is that the users eventually\nlearn what can reasonably be asked during maintenance. If th ey know a structured\napproach has been followed, they expect enhancements can be asked for, and will be\nrealized. So they will ask for enhancements. If they know no s tructured approach has\nbeen followed, they expect only the necessary bug ﬁxing is fe asible, and maintenance\nrequests will remain moderate. So higher quality may well in cur higher maintenance\ncost.\nMaintenance problems are there to stay. Some of these proble ms are inherent", "token_count": 512, "start_token": 266112, "end_token": 266624, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 577, "text": " the necessary bug ﬁxing is fe asible, and maintenance\nrequests will remain moderate. So higher quality may well in cur higher maintenance\ncost.\nMaintenance problems are there to stay. Some of these proble ms are inherent\n-- systems degrade when they are changed over and over again - - while others are\ncaused by simple facts of life: real development and mainten ance activities are carried\nout in less than perfect ways. The major causes of the resulti ng maintenance problems\nare addressed in section 14.2.\nThis discussion of maintenance problems suggests two appro aches to improve\nthe situation. Section 14.3 discusses various ways to redis cover lost facts (‘what does\nthis routine accomplish’, ‘which design underlies a given s ystem’, and the like) and\nrestructure existing software systems in order to improve t heir maintainability.\nThe second approach, discussed in section 14.5, entails a nu mber of organizational\nand managerial actions to improve software maintenance.\n14.1 Maintenance Categories Revisited\nLet us recall part of the discussion from chapter 1. Followin g Lientz and Swanson\n(1980), we distinguished four types of maintenance activit y1 :\n/AF Corrective maintenance deals with the repair of faults found.\n/AF Adaptive maintenance deals with adapting software to changes in the envi-\nronment, such as new hardware or the next release of an operat ing system.\nAdaptive maintenance does not lead to changes in the system’ s functionality.\n/AF Perfective maintenance mainly deals with accommodating new or changed user\nrequirements. It concerns functional enhancements to the s ystem. Perfective\nmaintenance also includes activities to increase the syste m’s performance or to\nenhance its user interface.\n/AF Preventive maintenance concerns activities aimed at increasing the sys-\ntem’s maintainability, such as updating documentation, ad ding comments,\nand improving the modular structure of the system.\n1 The IEEE uses slightly different deﬁnitions. In particular , they combine Lientz and Swanson’s adaptive\nand perfective categories, and call the combination adapti ve maintenance. The reader should be aware of\nthese different deﬁnitions of maintenance categories, esp ecially when interpreting percentages spent on\nthe different categories.\n14.1. MAINTENANCE CATEGORIES", "token_count": 512, "start_token": 266574, "end_token": 267086, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 578, "text": "i ve maintenance. The reader should be aware of\nthese different deﬁnitions of maintenance categories, esp ecially when interpreting percentages spent on\nthe different categories.\n14.1. MAINTENANCE CATEGORIES REVISITED 461\nNotice that ‘real’ maintenance activities -- the correctio n of faults -- accounts for about\n25% of the total maintenance effort only. Half of the mainten ance effort concerns\nchanges to accommodate changing user needs, while the remai ning 25% largely\nconcerns adapting software to changes in the external envir onment (see ﬁgure 14.1).\nRecall also that the total cost of system maintenance is esti mated to com-\nprise at least 50% of total life cycle costs. Similar ﬁgures h old for the personnel\ninvolved. Figure 14.2 gives an estimate of the number of peop le working in software\ndevelopment compared to software maintenance according to (Jones, 2006).\nFigure 14.1 Distribution of maintenance activities\nYear Development Maintenance Maintenance\npercentage\n1975 350,000 75,000 17.65\n1990 900,000 800,000 47.06\n2005 775,000 2,500,000 76.34\nFigure 14.2 US distribution of developers and maintainers\nThe data in ﬁgure 14.1 are based on (Lientz and Swanson, 1980) and reﬂect the\nstate of the practice in the 1970s. Later studies have shown t hat the situation has not\nchanged for the better. Nosek and Palvia (1990) raised the ma jor maintenance issues\nonce again and came to the disturbing conclusion that mainte nance problems have\nremained pretty much the same, notwithstanding advances in structured development\nmethodologies and techniques. Other studies, such as Basil i et al. (1996) give roughly\nthe same results. The relative distribution of maintenance activities is about the\n462 SOFTWARE MAINTENANCE\nsame as it was 20 years ago. Systems though have become larger , maintenance staff\nhas grown, there are more systems, and there is a deﬁnite tren d to an increase in\nmaintenance effort relative to development effort.\nSome studies give results that are quite different from the g eneral picture sketched\nabove. Schach et al. (2003), for instance, investigated mai ntenance effort in three", "token_count": 512, "start_token": 267036, "end_token": 267548, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 579, "text": " increase in\nmaintenance effort relative to development effort.\nSome studies give results that are quite different from the g eneral picture sketched\nabove. Schach et al. (2003), for instance, investigated mai ntenance effort in three\nsystems and found corrective maintenance percentages of 50 % and more, and very\nlow percentages for adaptive maintenance. There is no convi ncing argument for these\ndifferences.\nIn many organizations, the deﬁnition of software maintenan ce does not follow\nthe IEEE deﬁnition. Some organizations for instance deﬁne c hange efforts larger than,\nsay, three months, as development rather than maintenance. This blurs the picture\neven further. In practice also, people ﬁnd it difﬁcult to dis tinguish between adaptive\nand perfective maintenance. What remains then is a distinct ion between correcting\nfault and ’the rest’. The latter mostly caters for 75% or more of the maintenance effort.\nThe maintenance categories from (Lientz and Swanson, 1980) refer to the software\nonly. Keeping software alive incurs other costs too, though . For instance, new users\nmust be trained, and the helpdesk needs to be staffed. Nowada ys, it is not uncommon\nthat these supporting costs account for around 25% of the cos t of keeping a system\ndeployed.\nAnother way to look at the distribution of maintenance cost a nd prevailing types\nof maintenance tasks is along the time dimension. We may dist inguish the following\nmaintenance life cycle stages:\n/AF During the introductory stage of a new system, most of the effort is spent on\nuser support. Users have to be trained, and they will often co ntact the helpdesk\nfor clariﬁcation.\n/AF Next follows a growth stage in which more and more users start to explore the\nsystem’s possibilities. As far as maintenance is concerned , emphasis during this\nstage is on correcting faults.\n/AF The growth stage is followed by a period of maturity. Users know what the\nsystem can and cannot do, and ask for enhancements.\n/AF Finally, a period of decline sets in. Technology replacement, such as another\nplatform or user interface kit, constitutes a major categor y of maintenance tasks\nduring this period.\nSuccessful maintenance requires knowledge of the applic", "token_count": 512, "start_token": 267498, "end_token": 268010, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 580, "text": " for enhancements.\n/AF Finally, a period of decline sets in. Technology replacement, such as another\nplatform or user interface kit, constitutes a major categor y of maintenance tasks\nduring this period.\nSuccessful maintenance requires knowledge of the applicat ion. After initial delivery,\nthis knowledge usually is available. Either knowledge of th e application is explicitly\ntransferred to the maintenance organization via documenta tion, training, and the like,\nor the developers have become maintainers of the applicatio n they just developed.\nBut over time, this knowledge vaporizes, and at some point in time, it has become\nscant. This point in time more or less coincides with the tran sition from the mature\nstage to the declining stage. The ”if it ain’t broken don’t ﬁx it” adagium then becomes\n14.2. MAJOR CAUSES OF MAINTENANCE PROBLEMS 463\nprevalent. Bennett and Rajlich (2000) use the terms evolution stage and servicing\nstage to distinguish between the period in which the system can suc cessfully evolve\nand the subsequent period where this is no longer the case. In the latter stage, changes\nbecome tactical. For example, necessary changes are realiz ed through patches and\nwrappers.\nFinally, we may consider the distribution of effort over the activities of a single\nmaintenance task. For the code-related tasks, the main acti vities are:\n/AF Isolation The ﬁrst activity is concerned with determining the part of t he system\n(modules, classes) that needs to be changed.\n/AF Modiﬁcation This concerns the actual changes. One or more components are\nadapted to accommodate the change.\n/AF Testing After the changes have been made, the system has to be tested a new\n(regression testing).\nAs a rule of thumb, isolation takes about 40% of effort, while the other two activities\neach take about 30%. This distribution is not the same for all types of maintenance.\nFor corrective maintenance, isolation often takes an even l arger share, while for\nadaptive maintenance tasks, the actual modiﬁcation takes l onger. During corrective\nmaintenance, the fault that caused the failure has to be foun d, and this may take a lot\nof effort. Once it is found, the actual modi", "token_count": 512, "start_token": 267960, "end_token": 268472, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 581, "text": " actual modiﬁcation takes l onger. During corrective\nmaintenance, the fault that caused the failure has to be foun d, and this may take a lot\nof effort. Once it is found, the actual modiﬁcation often is f airly small. For adaptive\nmaintenance tasks, the reverse holds.\n14.2 Major Causes of Maintenance Problems\nThe following story reveals many of the problems that befall a typical software\nmaintenance organization. It is based on an anecdote once to ld by David Parnas and\nconcerns the re-engineering of software for ﬁghter planes.\nThe plane in question has two altimeters. The onboard softwa re tries to read either\nmeter and displays the result. The software for doing so is de picted in ﬁgure 14.3.\nThe code is unstructured and does not contain any comments. W ith a little effort\nthough its functioning can be discerned. A structured versi on of the same code is\ngiven in ﬁgure 14.4. What puzzles us is the meaning of the defa ult value 3000. Why\non earth does the system display the value 3000 (which, at ﬁrs t sight is not very\npeculiar) when both altimeters cannot be read?\nThe rationale for the default value could not be discerned fr om the (scarce or\nnonexistent) documentation. Eventually, the programmer w ho had written this code\nwas traced. He said that, when writing this piece of code, he d id not know what\nto display in case both altimeters were unreadable. So he ask ed one of the ﬁghter\npilots what their average ﬂying altitude was. The pilot made a back-of-the-envelope\ncalculation and came up with the above value: the average ﬂyi ng altitude is 3000 feet.\nHence this fragment.\n464 SOFTWARE MAINTENANCE\nIF not-read1 (V1) GOTO DEF1;\ndisplay (V1);\nGOTO C;\nDEF1: IF not-read2 (V2) GOTO DEF2;\ndisplay (V2);\nGOTO C;\nDEF2: display (3000);\nC:\nFigure 14.3 Unstructured code to read altimeters\nif read-meter1 (", "token_count": 512, "start_token": 268422, "end_token": 268934, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 582, "text": "V2) GOTO DEF2;\ndisplay (V2);\nGOTO C;\nDEF2: display (3000);\nC:\nFigure 14.3 Unstructured code to read altimeters\nif read-meter1 (V1) then display (V1) else\nif read-meter2 (V2) then display (V2) else\ndisplay (3000)\nendif;\nFigure 14.4 Structured code to read altimeters\nThe person reengineering the software rightfully thought t hat this was not the\nproper way to react to malfunctioning hardware. Fighter pla nes either ﬂy at a very\nhigh altitude or very close to the ground. They don’t ﬂy in bet ween. So he contacted\nthe ofﬁcials in charge and asked permission to display a clea r warning message instead,\nsuch as a ﬂashing ‘PULL UP’.\nThe permission to change the value displayed was denied. Gen erations of ﬁghter\npilots were by now trained to react appropriately to the curr ent default message. Their\ntraining manual even stated a warning phrase like ‘If the alt imeter reader displays the\nvalue 3000 for more than a second, PULL UP’.\nThis story can’t be true. Or can it? It does illustrate some of the major causes of\nmaintenance problems:\n– unstructured code,\n– maintenance programmers having insufﬁcient knowledge of the system or\napplication domain. Understanding the rationale behind co de is one of the\nmost serious problems maintainers face.\n– documentation being absent, out of date, or at best insufﬁc ient.\n– software maintenance has a bad image (this is not illustrat ed by the anecdote\nbut is deﬁnitely a maintenance problem).\n14.2. MAJOR CAUSES OF MAINTENANCE PROBLEMS 465\nUnstructured code is used here as a generic term for systems t hat are badly designed\nor coded. It manifests itself in a variety of ways: the use of g otos, long procedures,\npoor and inconsistent naming, high module complexity, weak cohesion and strong\ncoupling, unreachable code, deeply-nested if statements, and so on.\nEven if systems were originally designed and built well, the y", "token_count": 512, "start_token": 268884, "end_token": 269396, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 583, "text": " long procedures,\npoor and inconsistent naming, high module complexity, weak cohesion and strong\ncoupling, unreachable code, deeply-nested if statements, and so on.\nEven if systems were originally designed and built well, the y may have become\nharder to maintain in the course of time. Much software that i s to be maintained was\ndeveloped in the pre-structured programming era. Parts of i t may still be written in\nassembly language. It was designed and written for machines with limited processing\nand memory capacities. It may have been moved to different ha rdware or software\nplatforms more than once without its basic structure having changed.\nThis is not the whole story either. The bad structure of many p resent-day systems\nat both the design and code level is not solely caused by their age. As a result of\ntheir studies of the dynamics of software systems, Lehman an d Belady formulated a\nseries of Laws of Software Evolution (see also chapter 3). Th e ones that bear most on\nsoftware maintenance are:\nLaw of continuing change A system that is being used undergoes continuing change,\nuntil it is judged more cost-effective to restructure the sy stem or replace it by a\ncompletely new version.\nLaw of increasing complexity A program that is changed, becomes less and less\nstructured (the entropy increases) and thus becomes more co mplex. One has to invest\nextra effort in order to avoid increasing complexity.\nLarge software systems tend to stay in production for a long t ime. After being put into\nproduction, enhancements are inevitable. As a consequence of the implementation of\nthese enhancements, the entropy of software systems increa ses over time. The initial\nstructure degrades and complexity increases. This in turn c omplicates future changes\nto the system. Such software systems show signs of arthritis . Preventive maintenance\nmay delay the onset of entropy but, usually, only a limited am ount of preventive\nmaintenance is carried out.\nEventually, systems cannot be properly maintained any more . In practice, it\nis often impossible to completely replace old systems by new ones. Developing\ncompletely new systems from scratch is either too expensive , or they will contain\ntoo many residual errors to start with, or it is impossible to re-articulate the original\nrequirements. Usually, a combination of these factors appl ies. Increasing attention is\ntherefore given to ways to ‘re", "token_count": 512, "start_token": 269346, "end_token": 269858, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 584, "text": " contain\ntoo many residual errors to start with, or it is impossible to re-articulate the original\nrequirements. Usually, a combination of these factors appl ies. Increasing attention is\ntherefore given to ways to ‘rejuvenate’ or ‘recycle’ existi ng software systems, ways to\ncreate structured versions of existing operational system s in order that they become\neasier to maintain.\nEntropy is not only caused by maintenance. In agile methods, such as XP, it is\nan accepted intermediate stage. These methods have an expli cit step to improve the\ncode. This is known as refactoring. Refactoring is based on identifying ‘bad smells’\nand rework the code to improve its design (see also section 14 .3.1).\n466 SOFTWARE MAINTENANCE\nAt a low level the code improvement process can be supported b y tools such\nas code restructurers and reformatters. To get higher-leve l abstractions generally\nrequires human guidance and a sufﬁcient understanding of th e system.\nThis leads us to the second maintenance problem: the scant kn owledge mainte-\nnance programmers have of the system or application domain. Note that the lack of\napplication domain knowledge pertains to software develop ment in general (Curtis\net al., 1988). The situation with respect to software mainte nance is aggravated by\nthe fact that there are usually scarce sources that can be use d to build such an\nunderstanding. In many cases, the source code is the only rel iable source. A major\nissue in software maintenance then is to gain a sufﬁcient und erstanding of a system\nfrom its source code. The more spaghetti-like this code is, t he less easy it becomes\nto disentangle it. An insufﬁcient understanding results in changes that may have\nunforeseen ripple effects which in turn incurs further main tenance tasks.\nMaintenance is also hampered if documentation is absent, in sufﬁcient, or out-of-\ndate. Experienced programmers have learnt to distrust docu mentation: a disappointing\nobservation in itself, albeit realistic. During initial de velopment, documentation often\ncomes off badly because of deadlines and other time constrai nts. Maintenance\nitself often occurs in a ‘quick-ﬁx�", "token_count": 512, "start_token": 269808, "end_token": 270320, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 585, "text": "servation in itself, albeit realistic. During initial de velopment, documentation often\ncomes off badly because of deadlines and other time constrai nts. Maintenance\nitself often occurs in a ‘quick-ﬁx’ mode whereby the code is p atched to accommodate\nchanges. Technical documentation and other higher-level d escriptions of the software\nthen do not get updated. Maintenance programmers having to d eal with these systems\nhave become part historian, part detective, and part clairv oyant (Corby, 1989).\nCareful working procedures and management attention could prevent such a\nsituation from occurring. But even then we are not sure that t he right type of\ndocumentation will result. Two issues deserve our attentio n in this respect:\n/AF A design rationale is often missing. Programmers and design ers tend to\ndocument their ﬁnal decisions, not the rationale for those d ecisions and\nthe alternatives rejected. Maintenance programmers have t o reconstruct this\nrationale and may easily make the wrong decisions.\n/AF In trying to comprehend a piece of software, programmers oft en operate in\nan opportunistic mode. Based on their programming knowledg e, in terms\nof programming plans and other stereotyped solutions to pro blems, they\nhypothesize a reasonable structure. Problems arise if the c ode does not meet\nthese assumptions.\nFinally, the noun ‘maintenance’ in itself has a negative con notation. Maintaining\nsoftware is considered a second-rate job. Maintenance work is viewed as unchallenging\nand unrewarding. Preferably, new and inexperienced progra mmers are assigned to the\nmaintenance group, possibly under the guidance of an experi enced person. The more\nexperienced people are to be found working on initial softwa re development. In the\nstructure of the organization, maintenance personnel rank s lower, both ﬁnancially\nand organizationally, than programmers working on the deve lopment of new systems.\nThis tends to affect morale. Maintenance programmers are of ten not happy with\ntheir circumstances and try to change jobs as fast as possibl e. The high turnover of\n14.3. REVERSE ENGINEERING AND REFACTORING 467\nmaintenance programmers precludes them from becoming sufﬁ ciently familiar with\nthe software to be maintained", "token_count": 512, "start_token": 270270, "end_token": 270782, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 586, "text": ". The high turnover of\n14.3. REVERSE ENGINEERING AND REFACTORING 467\nmaintenance programmers precludes them from becoming sufﬁ ciently familiar with\nthe software to be maintained which in turn hampers future ma intenance.\nIt would be far better to have a more positive attitude toward s maintenance.\nMaintaining software is a very difﬁcult job. The job content of a maintenance\nprogrammer is more demanding than the job content of a develo pment programmer.\nThe programs are usually written by other people, people who can often not be\nconsulted because they have left the ﬁrm or are entangled in t he development of\nnew systems. When making changes in an existing system, one i s bound by the very\nstructure of that system. There is generally a strong time pr essure on maintenance\npersonnel. Maintenance work requires more skills and knowl edge than development\ndoes. It is simply more difﬁcult (Chapin, 1987).\nThe maintenance group is of vital importance. It is they who k eep things going.\nIt is their job to ensure that the software keeps pace with the ever-changing reality.\nCompared to software development, software maintenance ha s more impact on the\nwell-being of an organization.\n14.3 Reverse Engineering and Refactoring\nWhat we’re doing now with reverse engineering is Archeology . We’re trying to gain an\nunderstanding of existing systems by examining ancient art ifacts and piecing together the\nsoftware equivalent of broken clay pots. Then we look to rest ructuring and reengineering\nto save the clay.\n(Chikofsky, 1990)\nIt is fashionable in our trade to coin new terms once in a while and offer them as\na panacea to the software crisis. One of the magical terms is reverse engineering .\nIt comes under different guises and means altogether differ ent things to different\npeople. In the discussion below we will use the terminology f rom (Chikofsky and\nCross II, 1990). The different terms are illustrated in ﬁgur e 14.5.\nChikofsky deﬁnes reverse engineering as ’the process of ana lyzing a subject system\nto\n– identify the system’s components and their interrelation ships and\n– create representations of the system", "token_count": 512, "start_token": 270732, "end_token": 271244, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 587, "text": "5.\nChikofsky deﬁnes reverse engineering as ’the process of ana lyzing a subject system\nto\n– identify the system’s components and their interrelation ships and\n– create representations of the system in another form or at a higher level of\nabstraction.’\nAccording to this deﬁnition, reverse engineering only conc erns inspection of a\nsystem. Adaptations of a system and any form of restructurin g, such as changing\ngotos into structured control constructs, do not fall withi n the strict deﬁnition of\nreverse engineering. Reverse engineering is akin to the rec onstruction of a lost\nblueprint. Retiling the bathroom or the addition of a new bed room is an altogether\ndifferent affair. If this distinction is not carefully made , the meaning of the term reverse\nengineering dilutes too much and it reduces to a fancy synony m for maintenance.\n468 SOFTWARE MAINTENANCE\nFigure 14.5 Reverse engineering and related notions ( Source: E.J. Chikofsky & J.H. Cross\nII, Reverse engineering and design recovery , IEEE Software 7, 1 (1990) pp 13--18, 1990 IEEE. )\nThe above deﬁnition still leaves open the question whether o r not the resulting\ndescription is at a higher level of abstraction. To emphasiz e the distinction, Chikofsky\nuses the notions of design recovery and redocumentation, respectively.\nRedocumentation concerns the derivation of a semantically -equivalent description\nat the same level of abstraction. Examples of redocumentati on are the transformation\nof a badly-indented program into one having a neat lay-out or the construction of a\nset of ﬂowcharts for a given program.\nDesign recovery concerns the derivation of a semantically- equivalent description\nat a higher level of abstraction. Some people limit the term r everse engineering to\nefforts that result in higher level descriptions and thus eq uate the term to what we\nhave termed design recovery.\nNote that a 100% functional equivalence is difﬁcult to achie ve in reverse\nengineering. The person carrying out the process (the reeng ineer) may encounter\nerrors in the original system and may want to correct those. S uch errors may be deeply\n14.3. REVERSE ENGINEERING", "token_count": 512, "start_token": 271194, "end_token": 271706, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 588, "text": "\nengineering. The person carrying out the process (the reeng ineer) may encounter\nerrors in the original system and may want to correct those. S uch errors may be deeply\n14.3. REVERSE ENGINEERING AND REFACTORING 469\nhidden in the original system and become much more troubleso me in the reverse\nengineered system. The programming language may be incompl etely deﬁned and its\nimplementation may depend on certain machine characterist ics. Data equivalence\nmay be difﬁcult to achieve because of typing issues, approxi mations, data conversions,\netc. In practice, it seems sensible to solve this issue by agr eeing on some acceptance\ntest for the reengineered system, thereby relaxing the 100% functional equivalence\nrequirement.\nObviously, reverse engineering is often done in circumstan ces where the tar-\nget system is adapted as well. Two important subclasses are restructuring and\nreengineering.\nRestructuring concerns the transformation of a system from one representation\nto another, at the same level of abstraction. The functional ity of the system does\nnot change. The transformation of spaghetti-code to struct ured code is a form of\nrestructuring. The redesign of a system (possibly after a de sign recovery step) is\nanother example of restructuring. In agile methods, restru cturing the code to improve\nits design is an explicit process step. There, it is known as refactoring. Refactoring is\ndiscussed in section 14.3.1.\nRefactoring is a white-box method, in that it involves inspe ction of and changes\nto the code. It is also possible to modernize a system without touching the code. For\nexample, a legacy system may be given a modern user interface . The old, text-based\ninterface is then wrapped to yield, for example, a graphical user interface or a client\nrunning in a Web browser. This is a black box method. The code o f the old system is\nnot inspected. The input and output are simply redirected to the wrapper. Usability\nis increased, although the capabilities of the new type of in terface are often not fully\nexploited. A similar black box technique can be used to switc h to another database, or\nintegrate systems through intermediate XML documents. A", "token_count": 512, "start_token": 271656, "end_token": 272168, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 589, "text": " increased, although the capabilities of the new type of in terface are often not fully\nexploited. A similar black box technique can be used to switc h to another database, or\nintegrate systems through intermediate XML documents. A th ird black box wrapping\ntechnique is applied at the level of components, where both b usiness logic and data\nare wrapped and next accessed through an interface as if it we re, say, a JavaBean.\nThese wrapping techniques do not change the platform on whic h the software\nis running. If a platform change is involved in the restructu ring effort of a legacy\nsystem, this is known as migration. Migration to another platform is often done\nin conjunction with value-adding activities such as a chang e of interface, or code\nimprovements.\nRestructuring is sometimes done in conjunction with effort s to convert existing\nsoftware into reusable building blocks. Such reclamation e fforts may well have higher\n(indirect) payoffs than the mere savings in maintenance exp enditure for the particular\nsystem being restructured, especially if the effort concer ns a family of similar systems.\nThe latter is often done in combination with domain engineer ing and the development\nof a (reusable) architecture or framework.\nWith reengineering, also called renovation, real changes are made to the system.\nThe reverse engineering step is followed by a traditional fo rward engineering step in\nwhich the required changes are incorporated.\nEach of the above transformations starts from a given descri ption of the system\n470 SOFTWARE MAINTENANCE\nto be transformed. In most cases this will be the program code , which may or may\nnot be adequately documented. However, it is also possible t o, say, restructure an\nexisting design or to reconstruct a requirements speciﬁcat ion for a given design. For\nthese transformations too, the term reverse engineering ap plies.\nBoth reverse engineering and restructuring can be done manu ally, but it is a\nrather tiresome affair. Quite a number of tools have been dev eloped to support these\nprocesses. These tools are discussed in section 14.3.3. The re are, however, some\ninherent limitations as to how much can be achieved automati cally. These limitations\nare discussed in section 14.3.2.\n14.3.1 Refactoring\nThe modern name for restructuring is refactoring. Ref", "token_count": 512, "start_token": 272118, "end_token": 272630, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 590, "text": "\ninherent limitations as to how much can be achieved automati cally. These limitations\nare discussed in section 14.3.2.\n14.3.1 Refactoring\nThe modern name for restructuring is refactoring. Refactoring has become popular\nas one of the practices from XP (see section 3.2.4). Of course , programmers have\napplied the technique in some form since the beginning of pro gramming.2. Quite\noften, refactoring activities are not explicitly planned, and occur somewhat unnoticed\nin the daily work of software developers. In XP and other agil e methods, they are an\nexplicit method step.\nThere are both arguments for and against refactoring. The cl assic engineering\nrule ”if it aint’t broken don’t ﬁx it” is a compelling argumen t against refactoring. On\nthe other hand, the second law of software evolution tells us that software becomes\nincreasingly complex over time. So we are forced to apply ref actoring to keep the\nsoftware maintainable. The arguments pro and con are both va lid. It depends on the\nphase the software is in which argument is the decisive one. D uring the evolution\nstage, when knowledge about the system is still around, refa ctoring is a viable option.\nDuring the servicing stage, knowledge will have vaporized t o some extent, and\nrefactoring then may well introduce more problems than it so lves. During that stage,\none may decide for example to add a wrapper, and not touch the s oftware anymore.\nRefactoring is applied when the structure of the software is of substandard quality.\nFowler (1999) used the term bad smells to indicate occurrences of substandard code\nquality. Fowler (1999) lists the following 22 bad smells 3 :\n/AF Long Method A method that is too long.\n/AF Large Class A class that is too big, in terms of instance variables or meth ods.\n/AF Primitive Obsession The use of primitives, such as numbers, instead of small\nclasses such as Dollar.\n2 My earliest recall of a refactoring activity goes back to 197 0. I was at that time fulﬁlling my\ncompulsory military service. I couldn’t properly ﬁre a gun, so I got assigned to the army’s computer", "token_count": 512, "start_token": 272580, "end_token": 273092, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 591, "text": "oring activity goes back to 197 0. I was at that time fulﬁlling my\ncompulsory military service. I couldn’t properly ﬁre a gun, so I got assigned to the army’s computer center\nas a programmer. A couple of weeks before I got demobilized, I ﬁnished my last FORTRAN program. To\nﬁll up the time, I decided to improve it a bit: improve the stru cture, remove redundant goto’s, and the like.\nConﬁguration control was unheard of at the time and I only ret ained the last copy of the source code. By\nthe time I left the army, I had introduced some faults, and I co uld not make the program work anymore.\nThey were probably glad I left, but not this way.\n3 Fowler also gives detailed instructions on how to improve th e bad code.\n14.3. REVERSE ENGINEERING AND REFACTORING 471\n/AF Long Parameter List A parameter list that is too long.\n/AF Data Clumps Groups of data items that are often used together, such as the\nheight, width and color of a graphical object. If you remove o ne of the items,\nthe rest doesn’t make sense any more.\n/AF Switch Statements The use of type codes instead of polymorphism. This results\nin case statements all over the code\n/AF Temporary Field A class has a variable which is only used in some circum-\nstances.\n/AF Refused Bequest A subclass which does not support all of the methods or data\nit inherits.\n/AF Alternative Classes with Different Interfaces Methods that do the same things\nbut have different interfaces. For example, methods DisplayRectangle next to\nDisplayCircle.\n/AF Parallel Inheritance Hierarchies Two class hierarchies exist, and if one of them\nhas to be extended, so has the other.\n/AF Lazy Class A class that isn’t doing all that much. This might be the resul t of a\nprevious refactoring operation.\n/AF Data Class A class that holds data, but little else.\n/AF Duplicate Code According to Fowler (1999), this is ”number one in the stink\nparade”.\n/AF Speculative Generality Code has been created", "token_count": 512, "start_token": 273042, "end_token": 273554, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 592, "text": " Class A class that holds data, but little else.\n/AF Duplicate Code According to Fowler (1999), this is ”number one in the stink\nparade”.\n/AF Speculative Generality Code has been created for which you anticipate some\nfuture need. But this future is unknown.\n/AF Message Chains An object asks for an object from another object, which in\nturn asks for an object from yet another object, and so on.\n/AF Middle Man A class delegates most of its tasks to other classes. Delegat ion is\nOK, but too much delegation is not.\n/AF Feature Envy A method is more tightly coupled to, i.e. interested in, othe r\nclasses than the class where it is located.\n/AF Inappropriate Intimacy Two classes are coupled too tightly.\n/AF Divergent Change The same class needs to be changed for different reasons,\ne.g. each time a new database is added, and each time the user i nterface\nchanges.\n472 SOFTWARE MAINTENANCE\n/AF Shotgun Surgery This is the opposite of the Divergent Change smell: for every\nchange, many classes have to be changed.\n/AF Incomplete Library Class A library doesn’t offer all the functionality needed\nfor the task at hand.\n/AF Comments Comments are bad if they compensate for low-quality code.\nThis is quite a long list, and somewhat hard to go through manu ally in each and every\nrefactoring situation. M ¨ antyl ¨ a et al. (2003) gives a usef ul categorization of these bad\nsmells into seven broad categories; see ﬁgure 14.6. These ca tegories give handles as\nto the kind of situation one should look for when refactoring code.\nCategory Bad smells\nBloaters Long Method, Large Class, Primitive Obsession,\nLong Parameter List, Data Clumps\nObject-Oriented Abusers Switch Statements, Temporary Fie ld, Refused\nBequest, Alternative Classes with Different Inter-\nfaces, Parallel Inheritance Hierarchies\nChange Preventers Divergent Change, Shotgun Surgery\nDispensables Lazy Class, Data Class, Duplicate Code, Specu la-\ntive Generality\nEncapsulators Message Chains, Middle Man\nCouplers Feature Envy, Inapprorp", "token_count": 512, "start_token": 273504, "end_token": 274016, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 593, "text": ", Shotgun Surgery\nDispensables Lazy Class, Data Class, Duplicate Code, Specu la-\ntive Generality\nEncapsulators Message Chains, Middle Man\nCouplers Feature Envy, Inapprorpiate Intimacy\nOthers Incomplete Library Class, Comments\nFigure 14.6 Categories of bad smells\nThe ﬁrst category, the Bloaters denote situations in which something has grown\ntoo large to handle effectively. The Primitive Obsession is placed there, because the\nfunctionality to handle the primitives has to be placed in so me other class, which\nmay then grow too large. The Object-Oriented Abusers denote situations where\nthe possibilities of object orientation are not fully explo ited. The Change Preventers\nhinder further evolution of the software. The Dispensables represent things that can\nbe removed. The Encapsulators deal with data communication. The two smells in\nthis category are opposite: decreasing one will increase th e other. The Couplers\nrepresent situations where coupling is too high. The Others category ﬁnally contains\nthe smells that do not ﬁt another category.\nBad smells not only occur at the code level. At the design leve l, the evolution\nof system through successive releases may provide valuable information about bad\n14.3. REVERSE ENGINEERING AND REFACTORING 473\nsmells. For example, if certain classes often change, or cla sses get introduced in one\nversion, disappear in the next, and then reappear again, suc h merits closer inspection.\nFowler (1999) states that ”no set of metrics rivals informed human intuition”. On\nthe other hand, several of the metrics deﬁned in section 12.1 do relate to a number\nof the bad smells listed above. For example, a high value for M cCabe’s cyclomatic\ncomplexity could indicate the Switch Statement bad smell, w hile a high value for the\nCoupling Between Object Classes (CBO) metric could indicat e a Feature Envy bad\nsmell. Metrics thus may augment human intuition in the searc h for bad smells.\n14.3.2 Inherent Limitations\nIf you pass an unstructured, unmodular mess through one of th ese restructuring systems,\nyou end up with at best, a structured, un", "token_count": 512, "start_token": 273966, "end_token": 274478, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 594, "text": "arc h for bad smells.\n14.3.2 Inherent Limitations\nIf you pass an unstructured, unmodular mess through one of th ese restructuring systems,\nyou end up with at best, a structured, unmodular mess.\n(Wendel, 1986)\nReverse engineering will mostly not be limited to redocumen tation in a narrow sense.\nWe will often be inclined to ask why certain things are being d one the way they are\ndone, what the meaning is of a certain code fragment, and the l ike. We must therefore\ninvestigate how programmers go about studying program text . The relevance of these\nissues shows from results of a study into maintenance activi ties (Fjelstad and Hamlen,\n1979), conﬁrmed by Yu and Chen (2006):\n/AF maintenance programmers study the original program code ab out one and a\nhalf times as long as its documentation;\n/AF maintenance programmers spend as much time reading the code as they do\nimplementing a change.\nInsights into the discovery process which takes place durin g maintenance activities\nwill give us the necessary insight to put various developmen ts regarding reverse\nengineering and refactoring into perspective.\nIn forward engineering activities we usually proceed from h igh-level abstractions\nto low-level implementations. Information gets lost in the successive steps involved in\nthis process. If we want to reverse the route, this informati on must be reconstructed.\nThe object we start with, a piece of source code in general, us ually offers insufﬁcient\nclues for a full reconstruction.\nThe programmer uses various sources of information in his di scovery process.\nFor example, if the design documentation is available, that documentation will reveal\nsomething about the structure of the system. A characterist ic situation in practice is\nthat the source code is the only reliable source of informati on. So this source code\nhas to be studied in order to discover the underlying abstrac tions. The question is\nhow the programmer goes about doing this.\nSeveral theories have been developed to describe this compr ehension process.\nCommon to these theories is that expert programmers may draw on a vast number of\nknowledge chunks. These knowledge chunks are called in when software is developed.\n474 SOFTWARE MAINTENANCE\nWithin the realm of programming, it is postulated that exper ts know of program", "token_count": 512, "start_token": 274428, "end_token": 274940, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 595, "text": " is that expert programmers may draw on a vast number of\nknowledge chunks. These knowledge chunks are called in when software is developed.\n474 SOFTWARE MAINTENANCE\nWithin the realm of programming, it is postulated that exper ts know of program-\nming plans or beacons. A programming plan is a program fragment that corresponds\nto a stereotypical action. For example, to compute the sum of a series of numbers, a\nprogrammer uses the ‘running total loop plan’. In this plan, some counter is initialized\nto zero and incremented with the next value of a series in the b ody of a loop. A\nbeacon is a key feature that typically indicates the presence of a pa rticular structure\nor operation. Beacons seem to be very diagnostic of program m eaning. For example,\nthe kernel idea or central operation in a sorting program is a swap operation. If we\nare presented with a program that contains a swap operation, our immediate reaction\nwould then be that it concerns some sorting program.\nThis type of program comprehension process occurs when stud ying existing\nsoftware. Meaningful units are isolated from the ‘ﬂat’ sour ce text. Knowledge from\nhuman memory is called in during this process. The more knowl edge the reader has\nabout programming or the application domain, the more succe ssful this process will\nbe. The better the source code maps onto knowledge already av ailable to the reader,\nthe more effective this process will be.\nDuring the comprehension process, the reader forms hypothe ses and checks these\nhypotheses with the actual text. Well-structured programs and proper documentation\nease this process. If application domain concepts map onto w ell-delineated program\nunits then the program text will be more easily understood. I f the structure of a\nprogram shows no relation with the structure of the applicat ion domain, or the reader\ncannot discern this structure, then understanding of the pr ogram text is seriously\nhampered.\nAs a side remark we note that there are two extreme strategies for studying\nprogram text:\n– the as-needed strategy, and\n– the systematic strategy.\nIn the as-needed strategy, program text is read from beginni ng to end like a piece of\nprose and hypotheses are formulated on the basis of local inf ormation. Inexperienced\nprogrammers in particular tend to fall back onto this str", "token_count": 512, "start_token": 274890, "end_token": 275402, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 596, "text": "-needed strategy, program text is read from beginni ng to end like a piece of\nprose and hypotheses are formulated on the basis of local inf ormation. Inexperienced\nprogrammers in particular tend to fall back onto this strate gy. In the systematic\nstrategy, an overall understanding of the system is formed b y a systematic top-down\nstudy of the program text. The systematic approach gives a be tter insight into causal\nrelations between program components.\nThese causal relations play an important role when implemen ting changes. So-\ncalled delocalized plans, in which conceptually related pi eces of code are located\nin program parts that are physically wide apart, may serious ly hamper maintenance\nactivities. Excessive use of inheritance increases the use of delocalized plans. If our\nunderstanding is based on local clues only, modiﬁcations ma y easily result in so-\ncalled ripple-effects, i.e. changes that are locally corre ct but lead to new problems at\ndifferent, unforeseen places. Use of the as-needed strateg y increases the probability\nof ripple effects.\n14.3. REVERSE ENGINEERING AND REFACTORING 475\nDuring the comprehension process the programmer uses knowl edge that has its\norigin outside the program text proper. To illustrate this p henomenon, consider the\nprogram text from ﬁgure 14.7.\nfor i:= 1 to n do\nfor j:= 1 to n do\nif A[j, i] then\nfor k:= 1 to n do\nif A[i, k] then A[j, k]:= true endif\nenddo\nendif\nenddo\nenddo\nFigure 14.7 Warshall’s algorithm to compute the transitive closure of a graph\nThe program fragment of ﬁgure 14.7 manipulates a boolean mat rix A. Before this\nfragment is executed the matrix will have a certain value. Th e matrix is traversed in\na rather complicated way (potentially, each element is visi ted n times) and once in a\nwhile an element of the array is set to true. But what does this fragment mean? What\ndoes it do?\nAn expert will ‘recognize’ Warshall’s algorithm. Warshall ’s algorithm computes\n", "token_count": 512, "start_token": 275352, "end_token": 275864, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 597, "text": " element of the array is set to true. But what does this fragment mean? What\ndoes it do?\nAn expert will ‘recognize’ Warshall’s algorithm. Warshall ’s algorithm computes\nthe transitive closure of a relation (graph). The notions ‘t ransitive closure’, ‘relation’\nand ‘graph’ have a precise meaning within a certain knowledg e domain. If you don’t\nknow the meaning of these notions, you haven’t made any progr ess in understanding\nthe algorithm either.\nAt yet another level of abstraction the meaning of this fragm ent could be described\nas follows. Suppose we start with a collection of cities. The relation /BT states, for each\npair of cities /CX and /CY , whether there is a direct rail connection between cities /CX and\n/CY . The code fragment of ﬁgure 14.7 computes whether there is a c onnection at all\n(either direct or indirect) between each pair of cities.\nWarshall’s algorithm has many applications. If you know the algorithm, you will\nrecognize the fragment reproduced in ﬁgure 14.7. If you don’ t know the algorithm,\nyou will not discover the meaning of this fragment either.\nAs a second example, consider the code fragment of ﬁgure 14.8 , adapted from\n(Biggerstaff, 1989). The fragment will not mean much to you. Procedure and variable\nnames are meaningless. A meaningful interpretation of this fragment is next to\nimpossible.\nThe same code fragment is given in ﬁgure 14.9, though with mea ningful names.\nFrom that version you may grasp that the routine has somethin g to do with window\nmanagement. The border of the current window is depicted in a lighter shade while\n476 SOFTWARE MAINTENANCE\nprocedure A(var x: w);\nbegin b(y, n1);\nb(x, n2);\nm(w[x]);\ny:= x;\nr(p[x])\nend;\nFigure 14.8 An incomprehensible code fragment\nthe border of another window gets highlighted. The cursor is positioned in the now\nhighlighted window and the process of that window is restart ed. If we add", "token_count": 512, "start_token": 275814, "end_token": 276326, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 598, "text": "p[x])\nend;\nFigure 14.8 An incomprehensible code fragment\nthe border of another window gets highlighted. The cursor is positioned in the now\nhighlighted window and the process of that window is restart ed. If we add a few\ncomments to the routine, its text becomes fairly easy to inte rpret. Meaningful names\nand comments together provide for an informal semantics of t his code which sufﬁce\nfor a proper understanding.\nThis informal semantics goes much further than building loc al knowledge of the\nmeaning of a component. Developers use naming conventions a lso to ﬁnd their way\naround in a large system. Organizations often prescribe nam ing conventions precisely\nfor this reason. When design and architecture documentatio n is not updated, these\nnaming conventions serve as a proxy for that documentation.\nprocedure change\nwindow(var nw: window);\nbegin border(current window, no highlight);\nborder(nw, highlight);\nmove\ncursor(w[nw]);\ncurrent window:= nw;\nresume(process[nw])\nend;\nFigure 14.9 Code fragment with meaningful names\nCommon to these two examples as well as the altimeter anecdot e from section 14.2\nis that we need outside information for a proper interpretation of the code fragmen ts.\nThe outside information concerns concepts from a certain kn owledge domain or\na design rationale that was only present in the head of the pro grammer.\nThe window management example is illustrative for yet anoth er reason. Tools\nmanipulate sequences of symbols. In principle, tools do not have knowledge of\nthe (external) meaning of the symbols being manipulated. In particular, a reverse\nengineering tool has no knowledge of ‘windows’, ‘cursor’ an d the like. These notions\n14.3. REVERSE ENGINEERING AND REFACTORING 477\nderive their meaning from the application domain, not from t he program text itself.\nFrom the tool point of view, the texts of ﬁgures 14.8 and 14.9 a re equally meaningful.\nThe above observations have repercussions for the degree to which tools can\nsupport the reverse engineering and restructuring process . Such tools cannot turn a\nbadly-designed system into a good one. They cannot infer kno wledge from a source\ntext which is not already contained", "token_count": 512, "start_token": 276276, "end_token": 276788, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 599, "text": " repercussions for the degree to which tools can\nsupport the reverse engineering and restructuring process . Such tools cannot turn a\nbadly-designed system into a good one. They cannot infer kno wledge from a source\ntext which is not already contained in that text without call ing in external knowledge\nas an aid. In particular, completely automatic design recov ery is not feasible. You\ncan’t make a pig out of a sausage.\n14.3.3 Tools\nDuring the reverse engineering process, the programmer bui lds an understanding of\nwhat the software is trying to accomplish and why things are d one the way they are\ndone. Several classes of tools may support the task of progra m understanding:\n/AF Tools to ease perceptual processes involved in program unde rstanding (refor-\nmatters). Tools may for example produce a neat lay-out in whi ch nested\ninstructions are indented and blank lines are put between su ccessive methods.\nMore advanced tools print procedure names in a larger font or generate page\nheaders which contain the name of the component, its version number, creation\ndate, and the like.\n/AF Tools to gain insight into the static structure of programs. For example,\ntools that generate tables of contents and cross-reference listings help to\ntrace the use of program elements. Browsers provide powerfu l interactive\ncapabilities for inspecting the static structure of progra ms. Hypertext systems\nprovide mechanisms to extend the traditional ﬂat organizat ion of text by their\ncapabilities for linking non-sequential chunks of informa tion. If system-related\ninformation is kept in a hypertext form, this opens up new pos sibilities for\ninteractive, dynamic inspection of that information. Code analyzers may be\nused to identify potential trouble spots by computing softw are complexity\nmetrics, highlighting ‘dead code’, or indicating question able coding practices\nor bad smells. Finally, tools may generate a graphical image of a program text in\nthe form of a control graph or a calling hierarchy. Tools may a nalyze the surface\nstructure of large systems, e.g. by considering variable na mes, and cluster parts\nthat seem to be highly related. The result of this clustering provides a ﬁrst guess\nat a restructuring for the system.\n/AF Tools that inspect the version history of a system (see also s e", "token_count": 512, "start_token": 276738, "end_token": 277250, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 600, "text": " and cluster parts\nthat seem to be highly related. The result of this clustering provides a ﬁrst guess\nat a restructuring for the system.\n/AF Tools that inspect the version history of a system (see also s ection 14.4).\nThese tools may for example highlight components that have b een changed\nvery often, indicating candidates for reengineering. Tool s that identify pairs\nof components that have often changed together but are not lo gically related\nmay indicate weak spots in the software architecture.\n478 SOFTWARE MAINTENANCE\n/AF Tools to gain insight into the dynamic behavior of programs. Next to traditional\ntext-oriented debugging systems there are systems which pr ovide graphical\ncapabilities to monitor program execution, e.g. to animate data structures or\nthe execution ﬂow.\nNote that these tools provide support for maintenance tasks in general (alongside\ntools such as test coverage monitors, which keep track of pro gram paths executed\nby a given set of test data, and source comparators, which ide ntify changes between\nprogram versions). With respect to reverse engineering, th e above tools may be\nclassiﬁed as redocumentation tools. By far the majority of r everse engineering tools\nfalls into this category.\nTools which result in a description at a higher level of abstr action (design recovery\ntools) have some inherent limitations, as argued in the prev ious section. Tools for\ndesign recovery need a model of the application domain in whi ch the concepts from\nthat domain are modeled in an explicit way, together with the ir mutual dependencies\nand interrelations. Completely automatic design recovery is not feasible for the\nforeseeable future. Concepts from an application domain us ually carry an informal\nsemantics. Tools for design recovery may, in a dialog with th e human user, search for\npatterns, make suggestions, indicate relations between co mponents, etc. Such a tool\nmay be termed a ‘maintenance apprentice’.\nMany tools exist for restructuring program code. The histor y of these restructuring\ntools goes all the way back to the late 1960s. In 1966, B ¨ ohm an d Jacopini (1966)\npublished a seminal paper in which it was shown that gotos are not necessary for\ncreating programs. The roots of restructuring tools like Re coder (Bush, 1985) can\nbe traced to the constructive proof", "token_count": 512, "start_token": 277200, "end_token": 277712, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 601, "text": " Jacopini (1966)\npublished a seminal paper in which it was shown that gotos are not necessary for\ncreating programs. The roots of restructuring tools like Re coder (Bush, 1985) can\nbe traced to the constructive proof given in B ¨ ohm and Jacopi ni’s paper. Recoder\nstructures the control ﬂow of Cobol programs. There is a wide choice of such Cobol\nrestructuring tools.\nRestructuring tools can be very valuable -- a well-structur ed program is usually\neasier to read and understand. A study reported by Gibson and Senn (1989) provides\nevidence that structural differences do affect maintenanc e performance. Speciﬁcally,\nit was found that eliminating gotos and redundancy appears t o decrease both the time\nrequired to perform maintenance and the frequency of ripple effects.\nYet, the merit of restructuring tools is limited. They will n ot transform a ﬂawed\ndesign into a good one.\n14.4 Software Evolution Revisited\nLehman and Belady studied the evolution of software systems and formulated their\nwell-known laws of software evolution. Empirical studies h ave given general support\nfor these laws.\nApparently, there is quite a bit of regularity in the evoluti on of software. We\ncan use this insight and try to predict the future evolution of a speciﬁc system by\nlooking at the actual evolution of that system till now. We then base our next actio n\n14.4. SOFTWARE EVOLUTION REVISITED 479\non information from the past. We may for example decide which components to\nreengineer by looking at components that changed a lot in the recent past. The\nassumption then is that components that changed a lot in the r ecent past, are likely\nto change in the near future too. G ˆ\nırba et al. (2004) used the term yesterday’s weather to\ncharacterize this idea: if we have no further information, w e may guess that today’s\nweather will be like yesterday’s.\nGˆ\nırba and Ducasse (2006) distinguish two types of analysis of evolutionary\ndata: version-centered analysis and history-centered analysis . In version-centered\nanalysis, differences between successive versions of a sys tem are studied. The results", "token_count": 512, "start_token": 277662, "end_token": 278174, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 602, "text": "\nırba and Ducasse (2006) distinguish two types of analysis of evolutionary\ndata: version-centered analysis and history-centered analysis . In version-centered\nanalysis, differences between successive versions of a sys tem are studied. The results\nare typically depicted in a ﬁgure with time (i.e. successive versions) along one axis\nand the relevant aspects of the system on another. For exampl e, we may consider\nthe relative size of the different components of a system ove r time, as illustrated in\nﬁgure 14.10 (adapted from (G ˆ\nırba and Ducasse, 2006)).\n1 2 3 4 5 versions\nB\nC\nD\nA components\nFigure 14.10 Size versus version\nEach rectangle in ﬁgure 14.10 denotes a component. The width and height of\na rectangle each stand for an attribute of that component. Th e width may for\ninstance denote the number of classes of a component, while t he height denotes\nits number of interfaces. Figure 14.10 tells us that compone nt A is stable and small,\n480 SOFTWARE MAINTENANCE\nwhile component D is stable and big. Component C shows a stead y growth from one\nversion to the next, and component B exhibits some ripple eff ects in versions 2 and\n3, and is stable since then.\nIn a history-centered analysis, a particular viewpoint is c hosen, and the evolution\nof a system is depicted with respect to that viewpoint. For ex ample, ﬁgure 14.11\nshows how often different components are changed together. Each node denotes\na component, and the thickness of the edges denotes how often two connected\ncomponents are changed together (so-called co-changes). A thicker edge between\ncomponents indicates more frequent co-changes. The latter information may for\ninstance be derived from the versioning database.\nworkflow/paint\nworkflow/figs\nutil/tools\nutil/figs\nworkflow/main\nFigure 14.11 Components that change together\nFrom ﬁgure 14.11 we learn that components /util/ﬁgs and /util/tools are\nchanged together frequently. The same holds for components /util/tools and /work-\nﬂow/paint . The names of the components suggest that components /util/ﬁgs and", "token_count": 512, "start_token": 278124, "end_token": 278636, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 603, "text": "gs and /util/tools are\nchanged together frequently. The same holds for components /util/tools and /work-\nﬂow/paint . The names of the components suggest that components /util/ﬁgs and\n/util/tools are structurally related, while /util/tools and /workﬂow/paint are struc-\nturally unrelated. From this additional information, we mi ght infer that the interaction\nbetween components /util/tools and /workﬂow/paint deserves our attention. Alter-\nnatively, we may label the components with the (external) fe atures they participate\nin, and the view then shows whether changes frequently affec t different features.\nA version-centered analysis depicts the version informati on as-is. It is up to the\nuser to detect any pattern. In ﬁgure 14.10, it is the user who h as to detect growing\nor shrinking components; the picture just presents the fact s. In a history-centered\n14.5. ORGANIZATIONAL AND MANAGERIAL ISSUES 481\nanalysis, some hypothesis guides the representation, and t he patterns are then encoded\nin the representation, as in ﬁgure 14.11.\n14.5 Organizational and Managerial Issues\nThe duties of maintenance management are not different from those of other\norganizational functions, and software development in par ticular. In chapter 2 we\nidentiﬁed ﬁve entities that require continuous attention o f management:\n– time, i.e. progress towards goals;\n– information, in particular the integrity of the complete s et of documents,\nincluding change requests;\n– organization of the team, including coordination of activ ities;\n– quality of the product and process;\n– money, i.e. cost of the project.\nIn this section we address these issues from a maintenance pe rspective. We pay\nparticular attention to issues that pose speciﬁc problems a nd challenges to mainte-\nnance. These issues are: the organization of maintenance ac tivities, major differences\nbetween development and maintenance, the control of mainte nance tasks, and quality\nassessment.\n14.5.1 Organization of Maintenance Activities\nThe primary question to be addressed here is whether or not so ftware maintenance\nshould be assigned to a", "token_count": 512, "start_token": 278586, "end_token": 279098, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 604, "text": " and maintenance, the control of mainte nance tasks, and quality\nassessment.\n14.5.1 Organization of Maintenance Activities\nThe primary question to be addressed here is whether or not so ftware maintenance\nshould be assigned to a separate organizational unit. The fo llowing discussion is largely\nbased on an insightful study of different forms of systems st aff departmentalization\npresented in (Swanson and Beath, 1990). The authors of this a rticle explore the\nstrengths and weaknesses of three alternative bases for sta ff departmentalization. The\nthree organizational forms with their focal strengths and w eaknesses are listed in\nﬁgure 14.12. We will sketch the W- and A-Type organizations a nd discuss the L-type\norganization with its pros and cons more elaborately.\nTraditionally, departmentalization in software developm ent tended to be accord-\ning to work type (a W-Type scheme). In such a scheme, people an alyze user needs,\nor design systems, or implement them, or test them, etc. Even though they cooperate\nin a team, each team member has quite separate responsibilit ies and roles.\nIn a W-Type scheme, work assignments may originate from both development\nand maintenance projects. For example, a designer may be inv olved in the design of a\n(sub)system in the context of some development project or in the design of a change\nto an existing system. Likewise, a programmer may implement an algorithm for a new\nsystem or realize changes in an operational program.\n482 SOFTWARE MAINTENANCE\nW-Type Departmentalization by work type (analysis versus program ming)\nFocal strength : development and specialization of programming\nknowledge and skills\nFocal weakness : costs of coordination between systems analysts and\nprogrammers\nA-Type Departmentalization by application domain (application g roup A\nversus application group B)\nFocal strength : development and specialization of application knowl-\nedge\nFocal weakness : costs of coordination and integration among appli-\ncation groups\nL-Type Departmentalization by life-cycle phase (development ver sus main-\ntenance)\nFocal strength : development and specialization of service orientation\nand maintenance skills\nFocal weakness : costs of coordination between development and\nmaintenance units\nFigure 14.12 Trade-offs between alternative organization al forms ( Source:", "token_count": 512, "start_token": 279048, "end_token": 279560, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 605, "text": "-\ntenance)\nFocal strength : development and specialization of service orientation\nand maintenance skills\nFocal weakness : costs of coordination between development and\nmaintenance units\nFigure 14.12 Trade-offs between alternative organization al forms ( Source: E.B. Swanson\n& C.M. Beath, Departmentalization in software development and maintenance , Communications of\nthe ACM 33, 6 (1990) pp 658-667. Reproduced by permission of the Associa tion for Computing\nMachinery, Inc. )\nNote that the development of new systems does not occur in a va cuum. Designers\nof new systems will reuse existing designs and must take into account constraints\nimposed by existing systems. Programmers involved in devel opment projects have\nto deal with interfaces to existing software, existing data bases, etc. In the W-Type\nscheme, the distinction between development and maintenan ce work is primarily a\ndistinction between different origins of the work assignment.\nA second form of departmentalization is one according to app lication areas,\nthe A-Type scheme. Nowadays, computerized applications ha ve extended to almost\nall corners of the enterprise. Systems have become more dive rsiﬁed. Application\ndomain expertise has become increasingly important for suc cessful implementation\nof information systems. Deep knowledge of an application do main is a valuable but\nscarce resource. Nurturing of this expertise amongst staff is one way to increase quality\nand productivity in both development and maintenance. In la rger organizations, we\nmay therefore ﬁnd units with particular expertise in certai n application domains, like\nﬁnancial systems, ofﬁce automation, or real-time process c ontrol.\nFinally, we may departmentalize according to life-cycle ph ases, as is done\nin the L-Type scheme. In particular, we may distinguish betw een development\n14.5. ORGANIZATIONAL AND MANAGERIAL ISSUES 483\nand maintenance. With an increasing portfolio of systems to be maintained and\nthe increasing business need of keeping the growing base of i nformation systems\nworking satisfactorily, the division of development and ma intenance into separate\norganizational units is found more often.\nSeparating development and maintenance has both advantage s and disadvantages.\nThe major advantages are:\n/AF Clear accountability: we may clearly separate the cost", "token_count": 512, "start_token": 279510, "end_token": 280022, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 606, "text": " division of development and ma intenance into separate\norganizational units is found more often.\nSeparating development and maintenance has both advantage s and disadvantages.\nThe major advantages are:\n/AF Clear accountability: we may clearly separate the cost and e ffort involved in\nmaintenance activities from investments in new developmen ts. If personnel are\ninvolved in both types of work, they have some freedom in char ging their\ntime. It is then more difﬁcult to measure and predict the ‘rea l’ cost of software\nmaintenance.\n/AF Intermittent demands of maintenance make it difﬁcult to pre dict and control\nprogress of new system development. If people do both mainte nance work and\ndevelopment, some control can be exercised by speciﬁcally a llocating certain\nperiods of time as maintenance periods. For instance, the ﬁr st week of each\ncalendar month may be set aside for maintenance. But even the n, maintenance\nproblems are rather unpredictable and some need immediate a ttention. Many\na schedule slippage is due to the maintenance drain.\n/AF A separation of maintenance and development facilitates an d motivates the\nmaintenance organization to conduct a meaningful acceptan ce test before the\nsystem is taken into production. If such an acceptance test i s not conducted\nexplicitly, maintenance may be confronted with low-qualit y software or systems\nwhich still need a ‘ﬁnishing touch’ which the development te am has left undone\nfor lack of time.\n/AF By specializing on maintenance tasks, a higher quality of us er service can\nbe realized. By their very nature, development groups are fo cused on system\ndelivery, whereas maintenance people are service-oriente d and ﬁnd pride in\nsatisfying user requests. We will further elaborate upon th is issue in section\n14.5.2.\n/AF By concentrating on the systems to be maintained, a higher le vel of productivity\nis achieved. Maintenance work requires speciﬁc skills of wh ich a more optimal\nuse can be made in a separate organization. If people are invo lved in both\ndevelopment and maintenance, more staff have to be allocate d to maintenance\nand the familiarity with any particular system is spread mor e thinly.\nOn the other hand, the strict separation of development", "token_count": 512, "start_token": 279972, "end_token": 280484, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 607, "text": " organization. If people are invo lved in both\ndevelopment and maintenance, more staff have to be allocate d to maintenance\nand the familiarity with any particular system is spread mor e thinly.\nOn the other hand, the strict separation of development and m aintenance has certain\ndisadvantages as well:\n/AF Demotivation of personnel because of status differences, w ith consequential\ndegradation of quality and productivity. Managerial attit udes and traditional\ncareer paths are the main causes for these motivational prob lems. Conversely,\n484 SOFTWARE MAINTENANCE\nproper managerial attention to maintenance work goes a larg e way towards\nalleviating the morale problem. For example, an organizati on may decide to\nhire new people into development only and explicitly consid er a transfer to\nmaintenance as a promotion. (Most organizations do exactly the opposite.)\n/AF Loss of knowledge about the system (with respect to both its d esign and the\napplication domain knowledge incorporated) when the syste m is transferred\nfrom development to maintenance. Various strategies can mi tigate against\nthis loss. For example, a future maintainer of a system may sp end some time\nwith the development team, a developer may stay with mainten ance until the\nmaintainers have become sufﬁciently acquainted with the sy stem, or a designer\nmay instruct the maintainers about the design of a system.\n/AF Coordination costs between development and maintenance, e specially when\nthe new system replaces an existing one.\n/AF Increased cost of system acceptance by the maintenance orga nization. If\nthe system is explicitly carried over from development, cer tain quality and\ndocumentation criteria must be met. Within an A-type organi zation these\nrequirements can often be relaxed a bit, or their fulﬁllment is postponed. It\nis by no means clear though that this really incurs an increas e in cost. In the\nlong run it may well be cheaper to only accept systems which pa ss a proper\nmaintenance acceptance test.\n/AF Possible duplication of communication channels to the user organization.\nBased on an analysis of existing departmentalizations and t he resulting list of strengths\nand weaknesses, Swanson and Beath express a slight preferen ce for having develop-\nment and maintenance as separate organizational units. We c oncur with that. Careful\nprocedures could", "token_count": 512, "start_token": 280434, "end_token": 280946, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 608, "text": "alizations and t he resulting list of strengths\nand weaknesses, Swanson and Beath express a slight preferen ce for having develop-\nment and maintenance as separate organizational units. We c oncur with that. Careful\nprocedures could be devised that overcome some or all of the d isadvantages listed.\nWe should stress that personnel demotivation is a real issue in many organizations. It\ndeserves serious management attention.\nCombinations of departmentalization types are also possib le. In particular, com-\nbinations of A-type and L-type departmentalizations are qu ite common. So, within\nthe maintenance organization, smaller groups may speciali ze in some application\ndomain, i.e. a speciﬁc collection of information systems. T his may be termed the\nL-A-scheme. Conversely, in an A-L-scheme a small maintenan ce unit is found within\na group that specializes in a certain application area. The L -A-scheme is more likely\nto exhibit the advantages of the L-scheme than the A-L-schem e does.\nToo much specialization is a lurking danger though. A system should never\nbecome someone’s private property. A variation of the rever se Peter principle applies\nhere: people rise within an organization to a level at which t hey become indispensable.\nJob rotation is one way to avoid people from becoming too much entrenched in the\npeculiarities of a system. There is a trade-off though, sinc e such a step also means\nthat in-depth knowledge of a system is sacriﬁced.\n14.5. ORGANIZATIONAL AND MANAGERIAL ISSUES 485\n14.5.2 Software Maintenance from a Service Perspective\nSoftware maintenance organizations need to realize that th ey are in the customer service\nbusiness.\n(Pigoski, 1996)\nSoftware development results in a product, a piece of softwa re. Software maintenance\ncan be seen as providing a service. There are notable differe nces between products and\nservices, which mean that the quality of products and servic es is judged differently.\nAs a consequence, the quality of software development and so ftware maintenance\nis also judged differently and maintenance organizations s hould pay attention to\nservice-speciﬁc quality aspects.\nApparently, this is not widely recognized yet.", "token_count": 512, "start_token": 280896, "end_token": 281408, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 609, "text": "As a consequence, the quality of software development and so ftware maintenance\nis also judged differently and maintenance organizations s hould pay attention to\nservice-speciﬁc quality aspects.\nApparently, this is not widely recognized yet. Within the so ftware maintenance\ndomain, the focus is still on product aspects. The ﬁnal phase s of software development\nsupposedly concern the delivery of an operations manual, in stalling the software,\nhandling change requests and ﬁxing bugs. In practice, the ro le of an IT department is\nmuch broader during the deployment stage, as is illustrated by the ubiquitous help\ndesk.\nThis is conﬁrmed by St ˚ alhane et al. (1997) who report on a sur vey to ﬁnd those\naspects of software quality that customers consider most im portant. The main insight\nto be gained from their study is the strong emphasis customer s place on service\nquality. The top ﬁve factors found in their study are: servic e responsiveness, service\ncapacity, product reliability, service efﬁciency, and pro duct functionality. They also\nquote an interesting result from a quality study in the telec ommunications domain.\nTo the question ‘Would you recommend others to buy from this c ompany?’, a\n100% yes was obtained from the category of users that had comp lained and got a\nsatisfactory result. For the category that had not complain ed, this percentage was\n87%. Apparently, it is more important to get a satisfactory s ervice than to have no\nproblems at all.\nThe main differences between products and services are as fo llows:\n/AF Services are intangible, products are tangible. This is considered the most\nbasic difference between products and services. Services - - being beneﬁts\nor activities -- cannot be seen, felt, tasted, or touched, un like products.\nConsequently, services cannot be counted, stored, patente d, readily displayed,\nor communicated, and pricing is more difﬁcult.\n/AF Because services are created by activities, and activities are performed by\nhumans, services tend to be more heterogeneous than products. Customer\nsatisfaction depends on employee actions during the servic e delivery. Service\nquality depends on factors which are dif�", "token_count": 512, "start_token": 281358, "end_token": 281870, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 610, "text": " are created by activities, and activities are performed by\nhumans, services tend to be more heterogeneous than products. Customer\nsatisfaction depends on employee actions during the servic e delivery. Service\nquality depends on factors which are difﬁcult to control, su ch as the ability of\ncustomers to articulate their needs, the ability and willin gness of personnel to\nsatisfy those needs, the presence or absence of other custom ers, and the level\nof demand for the service. These complicating factors make i t hard to know\nwhether the service was delivered according to plan or speci ﬁcation.\n486 SOFTWARE MAINTENANCE\n/AF Services are produced and consumed simultaneously, whereas production and\nconsumption of products can be separated. For example, a car can be produced\nﬁrst, sold a few months later, and then be consumed over a peri od of several\nyears. For services, production and consumption has to take place in parallel.\nThe production of the service creates the set of beneﬁts, who se consumption\ncannot be postponed. For example, a restaurant service -- pr eparing a meal and\nserving the customer -- by and large has to be produced while t he customer\nis receiving the service. As a consequence, customers parti cipate in and affect\nthe transaction, customers may affect each other, employee s affect the service\noutcome, and centralization and mass production are difﬁcu lt.\n/AF Services are perishable, products are not. Services cannot be saved or stored.\nThey cannot be returned or resold, and it is difﬁcult to synch ronize supply and\ndemand.\nThe difference between products and services is not clear-c ut. Often, services are\naugmented with physical products to make them more tangible . For example, luggage\ntags may be provided with a travel insurance. In the same way, products are augmented\nwith add-on services, such as a guarantee, to improve the qua lity perception of the\nbuyer. In the service marketing literature, a product--ser vice continuum is used to\nindicate that there is no clear boundary between products an d services. This product-\n-service continuum has pure products at one end, pure servic es at the other, and\nproduct--service mixtures in between. Figure 14.13 shows s", "token_count": 512, "start_token": 281820, "end_token": 282332, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 611, "text": "icate that there is no clear boundary between products an d services. This product-\n-service continuum has pure products at one end, pure servic es at the other, and\nproduct--service mixtures in between. Figure 14.13 shows s ome example products\nand services along this continuum.\nFigure 14.13 The product--service continuum ( Source: L.L. Berry & A. Parasuraman ,\nMarketing Services: Competing Through Quality, 1991, The Free Press )\nAs this ﬁgure shows, products and services can be intertwine d. In the case of\nfast-food, both the product, the food, and the service, quic k delivery, are essential to\n14.5. ORGANIZATIONAL AND MANAGERIAL ISSUES 487\nthe customer. The quality of such a product--service mix is j udged on both product\nand service aspects: does the food taste good and is it served quickly.\nLet us return to the software engineering domain. A major dif ference between\nsoftware development and software maintenance is the fact t hat software development\nresults in a product, whereas software maintenance results in a service being delivered\nto the customer. Software maintenance has more service-lik e aspects than software\ndevelopment, because the value of software maintenance lie s in activities that result\nin beneﬁts for the customers, such as corrected faults and ne w features. Contrast\nthis with software development, where the development acti vities themselves do not\nprovide beneﬁts to the customer. It is the resulting softwar e system that provides\nthose beneﬁts.\nAs noted, the difference between products and services is no t clear-cut. Con-\nsequently, this goes for software development and software maintenance as well.\nFigure 14.14 shows the product--service continuum with exa mples from the software\nengineering domain.\nFigure 14.14 The product--service continuum for software d evelopment and mainte-\nnance\nService marketeers often use the gap model to illustrate how differences between\nperceived service delivery and expected service may come ab out. This gap model is\ndepicted in ﬁgure 14.15. Service quality is improved if thos e gaps are closed. The\ndifference between the perceived quality and the expected q uality (gap 5) is caused\nby four other gaps. These four gaps,", "token_count": 512, "start_token": 282282, "end_token": 282794, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 612, "text": "��gure 14.15. Service quality is improved if thos e gaps are closed. The\ndifference between the perceived quality and the expected q uality (gap 5) is caused\nby four other gaps. These four gaps, and suggested solutions for bridging them, are:\nGap 1 The expected service as perceived by the service provid er\ndiffers from the service as expected by the customer. In the ﬁ eld of software\nmaintenance, this difference is often caused by an insufﬁci ent relationship\nfocus of the service provider. For example, a maintenance de partment may\naim to satisfy certain availability constraints such as 99% availability, while\nthe actual customer concern is with maximum downtime.\n488 SOFTWARE MAINTENANCE\nFigure 14.15 The gaps model of service quality ( Reprinted with permission from A.\nParasuraman, V.A. Zeithaml & L.L. Berry , A Conceptual Model of Service Quality and its\nImplication for Future Research, in Journal of Marketing 49, Fall 1985, pp. 41-50. Published\nby the American Marketing Association. )\nIt is important for a maintenance organization to translate customer service\nexpectations into clear service agreements. Preferably, t he maintenance service\ncommitments are speciﬁed in a contract -- the Service Level Agreement --\nwhich speciﬁes, amongst other things, the services themsel ves, the levels of\nservice (i.e. how fast and how reliably will the service be de livered), what\nhappens if the service provider does not reach the agreed upo n service levels,\nwhen and how the customer will receive reports regarding the services actually\ndelivered, when and how the service level agreement will be r eviewed, and so\non.\nGap 2 The service speciﬁcation differs from the expected ser vice as perceived by the\nservice provider. This may arise if the (internal) service d esigns and standards\n14.5. ORGANIZATIONAL AND MANAGERIAL ISSUES 489\ndo not match the service requirements as perceived by the ser vice provider.\nFor example, the customer expects a quick restart of the syst em, while the\nstandard procedure of the maintenance organization is focu sed on analyzing\nthe reason for the crash.\nThe maintenance activities as speciﬁed", "token_count": 512, "start_token": 282744, "end_token": 283256, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 613, "text": ".\nFor example, the customer expects a quick restart of the syst em, while the\nstandard procedure of the maintenance organization is focu sed on analyzing\nthe reason for the crash.\nThe maintenance activities as speciﬁed in the service level agreement have to be\nplanned. This includes the planning of the activities thems elves, the transfer of\nthe results to the customer, the planning of releases, the es timation of resources\nneeded, the scheduling of maintenance activities, and the i dentiﬁcation of\npossible risks. Explicitly basing the planning of maintena nce activities on the\ncommitments as agreed with the customer helps to close this g ap.\nGap 3 The actual service delivery differs from the speciﬁed s ervices. This is often\ncaused by deﬁciencies in human resource policies, failures to match demand\nand supply, and customers not fulﬁlling their role. For exam ple, customers\nmay bypass the helpdesk by phoning the maintainer of their sy stem directly,\nthereby hindering a proper incident management process.\nThe service level agreement states which maintenance activ ities are to be\ncarried out, and how fast, reliably, etc. this should be done . In order to be able\nto report on the performance of the maintenance organizatio n in this respect,\ninformation about the actual maintenance activities must b e gathered. This\ninformation can be used to monitor maintenance activities a nd take corrective\nactions if necessary.\nFor example, when the customer reports a bug, information ab out the bug\nitself (originator, type, etc.) is recorded, as well as the r eporting time, the\ntime when corrective action was started and ended, and the ti me when the\nbug was reported as ﬁxed. If these data indicate that the aver age downtime\nof a system exceeds the level as speciﬁed in the service level agreement,\nthe maintenance organization might assign more maintenanc e staff to this\nsystem, put maintenance staff on point-duty at the customer site, renegotiate\nthe agreed upon service level, or take other action to realig n agreement and\nreality.\nBy keeping a strict eye upon the performance of the maintenan ce organization\nand adjusting the maintenance planning or renegotiating th e commitments\nwith the customer when required, gap 3 is", "token_count": 512, "start_token": 283206, "end_token": 283718, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 614, "text": " take other action to realig n agreement and\nreality.\nBy keeping a strict eye upon the performance of the maintenan ce organization\nand adjusting the maintenance planning or renegotiating th e commitments\nwith the customer when required, gap 3 is narrowed.\nGap 4 Communication about the service does not match the actu al service delivery.\nThis may be caused by ineffective management of customer exp ectations,\npromising too much, or ineffective horizontal communicati on. For example, a\ncustomer is not informed about the repair of a bug he reported .\nAn important instrument to help close this gap is event manag ement. Event\nmanagement concerns the management of events that cause or m ight cause\nthe maintenance activities carried out to deviate from the l evels as promised\n490 SOFTWARE MAINTENANCE\nin the service level agreement. An event is either a change re quest, such as a\nuser request for a new feature, or an incident. Incidents are software bugs and\nother hazards that the maintenance organization has promis ed to deal with,\nsuch as, say, a server being down.\nThe main purpose of event management is to manage all those ev ents. To do\nso, an event management library system is employed, often in the form of\na ‘helpdesk system’. The event management library system pr ovides for the\nstorage, update, and retrieval of event records, and the sha ring and transfer\nof event records between parties involved. This event manag ement library\nsystem supports the communication with the customer about m aintenance\nservices delivered. It is also a highly valuable ‘memory’ fo r the maintainers:\nthey may use the event library to search for similar incident s, to see why\ncertain components were changed before, etc. 4\nSince the ﬁfth gap is caused by the four other gaps, perceived service quality can be\nimproved by closing those ﬁrst four gaps, thus bringing the p erceived quality in line\nwith the expected quality. Since software maintenance orga nizations are essentially\nservice providers, they need to consider the above issues. T hey need to manage their\nproduct -- software maintenance -- as a service in order to be able to deliver high\nquality.\n14.5.3 Control of Maintenance Tasks\nCareful control of the product is necessary during software development. The vast\namount of information has to be", "token_count": 512, "start_token": 283668, "end_token": 284180, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 615, "text": " software maintenance -- as a service in order to be able to deliver high\nquality.\n14.5.3 Control of Maintenance Tasks\nCareful control of the product is necessary during software development. The vast\namount of information has to be kept under control. Document ation must be kept\nconsistent and up-to-date. An appropriate scheme for doing so is provided by the\nset of procedures that make up conﬁguration control; see cha pter 4. Conﬁguration\ncontrol pays particular attention to the handling of change requests. Since handling\nchange requests is what maintenance is all about, conﬁgurat ion control is of vital\nimportance during maintenance.\nEffective maintenance depends on following a rigorous meth odology, not only\nwith respect to the implementation of changes agreed upon, b ut also with respect to\nthe way change is controlled. Following IEEE Standard 1219, we suggest the following\norderly, well-documented process for controlling changes during maintenance:\n1. Identify and classify change requests Each change request (CR) is given a\nunique identiﬁcation number and is classiﬁed into one of the maintenance\ncategories (corrective, adaptive, perfective, preventiv e). The CR is analyzed to\ndecide whether it will be accepted, rejected, or needs furth er evaluation. This\nanalysis also results in a ﬁrst cost estimate. The CR is ﬁnall y prioritized and\nscheduled for implementation.\n4 Note that the focus of the event management library system di ffers somewhat from that of conﬁguration\nmanagement as discussed in the next section. Conﬁguration m anagement emphasizes the internal use of\ninformation about change requests and the like. Our descrip tion of event management focuses on the\nexternal use of essentially the same information. In practice, the tw o processes may well be combined.\n14.5. ORGANIZATIONAL AND MANAGERIAL ISSUES 491\n2. Analysis of change requests This step starts with an analysis of the CR to\ndetermine its impact on the system, the organization, and po ssible interfacing\nsystems. Several alternative solutions to implement the CR may be devised,\nincluding their cost and schedule. The results of the analys is are documented\nin a report. Based on this report, a decision is made whether o", "token_count": 512, "start_token": 284130, "end_token": 284642, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 616, "text": " ssible interfacing\nsystems. Several alternative solutions to implement the CR may be devised,\nincluding their cost and schedule. The results of the analys is are documented\nin a report. Based on this report, a decision is made whether o r not the CR\nwill be implemented. The authority for this decision is usua lly assigned to the\nconﬁguration control board; see also chapter 4.\n3. Implement the change This involves the design, implementation and testing of\nthe change. The output of this step is a new version of the syst em, fully tested,\nand well documented.\nThe above steps indicate a maintenance model in which each ch ange request is\ncarefully analyzed and, if (and only if) the request is appro ved, its implementation\nis carried out in a disciplined, orderly way, including a pro per update of the\ndocumentation. This control scheme ﬁts in well with the iterative-enhancement\nmodel of software maintenance; see ﬁgure 14.16. The essence of the iterative-\nenhancement model is that the set of documents is modiﬁed sta rting with the\nhighest-level document affected by the changes, propagati ng the changes down\nthrough the full set of documents. For example, if a change re quest necessitates a\ndesign change, then the design is changed ﬁrst. Only as a cons equence of the design\nchange will the code be adapted.\nFigure 14.16 Iterative-enhancement model of software main tenance ( Source: V.R.\nBasili, Viewing maintenance as reuse-oriented software de velopment, IEEE Software 7, 1 (1990)\n19--25, 1990 IEEE. )\n492 SOFTWARE MAINTENANCE\nReality is often different. Figure 14.17 depicts the so-cal led quick-ﬁx model of\nsoftware maintenance. In the quick-ﬁx model, you take the so urce code, make the\nnecessary changes to the code and recompile the system to obt ain a new version. The\nsource-code documentation and other higher-level documen ts get updated after the\ncode has been ﬁxed, and usually only if time permits.\nFigure 14.17 Quick-ﬁx model of software maintenance ( Source: V.R. Basili,", "token_count": 512, "start_token": 284592, "end_token": 285104, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 617, "text": "level documen ts get updated after the\ncode has been ﬁxed, and usually only if time permits.\nFigure 14.17 Quick-ﬁx model of software maintenance ( Source: V.R. Basili, Viewing\nmaintenance as reuse-oriented software development , IEEE Software 7, 1 (1990) 19--25, 1990\nIEEE.)\nIn the latter scheme, patches are made upon patches and the st ructure of the\nsystem degrades rather quickly. Because of the resulting in crease in system complexity\nand inconsistency of documents, future maintenance become s much more difﬁcult. To\nbe realistic, the quick-ﬁx model cannot be completely circu mvented. In an emergency\nsituation there is but one thing that matters: getting the sy stem up and running again\nas fast as possible. Where possible though, the quick-ﬁx mod el should be avoided. If\nit is used at all, preventive maintenance activities should be scheduled to repair the\nstructural damage done.\nIn a normal, non-emergency situation, change requests are o ften bundled into\nreleases. The user then does not get a new version after each and every c hange has\nbeen realized, but after a certain number of change requests has been handled, or after\na certain time frame. Three common ways of deciding on the con tents and timing of\nthe next release are:\n/AF ﬁxed staff and variable schedule. In this scheme, there is a ﬁ xed number of\npeople available for the maintenance work. The next release date is ﬁxed in\nadvance. Often, the release dates are scheduled at ﬁxed time intervals, say every\nsix months. The next release will contain all changes that ha ve been handled\nwithin the agreed time frame. So the next release is always on time. There also\n14.5. ORGANIZATIONAL AND MANAGERIAL ISSUES 493\nis some ﬂexibility as to the contents of the next release, sin ce the maintainers\nand the customer do not ﬁx the contents in advance.\n/AF variable staff and ﬁxed schedule. Here, a release date is ﬁxe d in advance. The\nportfolio of change requests to be handled in this release is also negotiated and\nﬁ", "token_count": 512, "start_token": 285054, "end_token": 285566, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 618, "text": " advance.\n/AF variable staff and ﬁxed schedule. Here, a release date is ﬁxe d in advance. The\nportfolio of change requests to be handled in this release is also negotiated and\nﬁxed in advance. Next, the number of people needed to impleme nt the changes\nwithin the ﬁxed time frame is decided. On the way, some renego tiation of both\nthe contents and the schedule is possible. An advantage of th is scheme is that\nchange requests are assigned clear priorities and that comm unication with the\ncustomer about the contents of the next release is enforced.\n/AF variable staff and variable schedule. As in the previous sch eme, the portfolio\nof change requests to be handled in the next release is negoti ated and ﬁxed\nin advance. Then, the cost and schedule for this release are n egotiated, and\nthe number of maintainers required to achieve it is determin ed. This scheme\nrequires more planning and oversight than the other two sche mes. It is also\nlikely to better accommodate the customer. As with ordinary development,\nschedule slippages and contents renegotiation are not unco mmon in this\nscheme.\n14.5.4 Quality Issues\nChanging software impairs its structure. By a conscious app lication of software quality\nassurance procedures during maintenance, we may limit the n egative effects. If we\nknow the software quality factors that affect maintenance e ffort and cost, we may\nmeasure those factors and take preventive actions accordin gly. In particular, such\nmetrics can be used to guide decisions as to when to start a maj or overhaul of\ncomponents or complete systems.\nQuality control issues get quite some attention during soft ware development.\nSoftware quality assurance however should broaden its scop e to maintenance as\nwell. The implementation of changes during maintenance req uires the same level of\nquality assurance as development work. The ingredients of s oftware quality assurance\nprocedures, as discussed in chapter 6, apply equally well to software maintenance.\nSoftware quality assurance can be backed up by measurements that quantify\nquality aspects. With respect to maintenance, we may focus o n measures which\nspeciﬁcally relate to maintenance effort, such as counting defects reported, change\nrequests issued, effort spent on incorporating changes, co mplexity metrics, etc.", "token_count": 512, "start_token": 285516, "end_token": 286028, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 619, "text": " respect to maintenance, we may focus o n measures which\nspeciﬁcally relate to maintenance effort, such as counting defects reported, change\nrequests issued, effort spent on incorporating changes, co mplexity metrics, etc.\nRelationships between such measures can then be sought. Obs erved trends can\nbe used to initiate actions, such as:\n/AF If maintenance efforts correlate well with complexity metr ics like Henri and\nKafura’s Information Flow or McCabe’s cyclomatic complexi ty (see chapter 12),\nthen these complexity metrics may be used to trigger prevent ive maintenance.\nVarious studies have indeed found such correlations.\n494 SOFTWARE MAINTENANCE\n/AF If certain modules require frequent changes or much effort t o realize changes,\nthen a re-design of such modules should be given serious cons ideration.\n/AF Metrics can be used to spot bad smells, and initiate refactor ing.\nA particularly relevant issue during maintenance is to deci de when to reengineer. At a\ncertain point in time, evolving an old system becomes next to impossible and a major\nreengineering effort is required or the system enters the se rvicing stage. There are\nno hard ﬁgures on which to decide this, but certain system cha racteristics certainly\nindicate system degradation:\n/AF Frequent system failures;\n/AF Code over seven years old;\n/AF Overly-complex program structure and logic ﬂow;\n/AF Code written for previous generation hardware;\n/AF Running in emulation mode;\n/AF Very large modules or subroutines;\n/AF Excessive resource requirements;\n/AF Hard-coded parameters that are subject to change;\n/AF Difﬁculty in keeping maintenance personnel;\n/AF Seriously deﬁcient documentation;\n/AF Missing or incomplete design speciﬁcations.\nThe greater the number of such characteristics present, the greater the potential for\nredesign.\nImprovements in software maintenance requires insight int o factors that determine\nmaintenance cost and effort. Software metrics provide such insight. To measure is to\nknow. By carefully collecting and interpreting maintenanc e data, we may discover\nthe major cost drivers of software maintenance and initiate actions to improve both\nquality and productivity.\n14.6 Summary\nSoftware maintenance encompasses all modi�", "token_count": 512, "start_token": 285978, "end_token": 286490, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 620, "text": " to\nknow. By carefully collecting and interpreting maintenanc e data, we may discover\nthe major cost drivers of software maintenance and initiate actions to improve both\nquality and productivity.\n14.6 Summary\nSoftware maintenance encompasses all modiﬁcations to a sof tware product after\ndelivery. The following breakdown of maintenance activiti es is usually made:\nCorrective maintenance concerns the correction of faults.\nAdaptive maintenance deals with adapting software to changes in the environment.\n14.7. FURTHER READING 495\nPerfective maintenance mainly deals with accommodating new or changed user\nrequirements.\nPreventive maintenance concerns activities aimed at increasing a system’s maintai n-\nability.\n‘Real’ maintenance, the correction of faults, consumes app roximately 25% of mainte-\nnance effort. By far the larger part of software maintenance concerns the evolution\nof software. This evolution is inescapable. Software model s part of reality. Reality\nchanges, and so does the software that models it.\nMajor causes of maintenance problems were discussed in sect ion 14.2: the exis-\ntence of a vast amount of unstructured code, insufﬁcient kno wledge about the\nsystem or application domain on the part of maintenance prog rammers, insufﬁcient\ndocumentation, and the bad image of the software maintenanc e department.\nSome of these problems are accidental and can be remedied by p roper actions.\nThrough a better organization and management of software ma intenance, substantial\nquality and productivity improvements can be realized. The se issues were discussed\nin section 14.5. Obviously, improved maintenance should st art with improved devel-\nopment. Opportunities to improve the development process a re a major topic in most\nchapters of this book.\nA particularly relevant issue for software maintenance is t hat of reverse engineer-\ning, the process of reconstructing a lost blueprint. Before changes can be realized, the\nmaintainer has to gain an understanding of the system. Since the majority of opera-\ntional code is unstructured and undocumented, this is a majo r problem. Section 14.3\naddresses reverse engineering, its limitations, and tools to support it.\nThe fundamental problem is that maintenance will remain a bi g issue. Because of\nthe changes made to software, its structure degrades", "token_count": 512, "start_token": 286440, "end_token": 286952, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 621, "text": "o r problem. Section 14.3\naddresses reverse engineering, its limitations, and tools to support it.\nThe fundamental problem is that maintenance will remain a bi g issue. Because of\nthe changes made to software, its structure degrades. Speci ﬁc attention to preventive\nmaintenance activities aimed at improving system structur e are needed from time to\ntime to ﬁght system entropy.\nSoftware maintenance used to be a rather neglected topic in t he software\nengineering literature. Like programmers, researchers ar e more attracted to developing\nnew, fancy methods and tools for software development. This situation has changed.\nMajor journals regularly feature articles on software main tenance, there is an annual\nIEEE Conference on Software Maintenance (since 1985), and t he journal Software\nMaintenance and Evolution: Research and Practice (launched 1989) is wholly devoted to it.\n14.7 Further Reading\n(Pigoski, 1996) is a text book wholly devoted to software mai ntenance. Lientz\nand Swanson (1980) is a seminal booklet on software maintena nce. It introduces the\nwidely-known categories of maintenance tasks and provides data on their distribution.\nMore recent data on the distribution of maintenance tasks ar e given in (Nosek and\nPalvia, 1990), (Dekleva, 1992) and (Sousa and Mozeira, 1998 ). Chapin et al. (2001)\ngives a new classiﬁcation of maintenance categories, inclu ding a separate category\n496 SOFTWARE MAINTENANCE\nfor user support. The maintenance life cycle stages are disc ussed in (Burch and\nKung, 1997) and (Kung and Hsu, 1998). The distinction betwee n an evolution stage\nand a servicing stage stems from (Bennett and Rajlich, 2000) . The distribution of\ncode-related maintenance activities is discussed in (Yu an d Chen, 2006). The practice\nof software maintenance is discussed in (Singer, 1998) and ( Tan and Gable, 1998).\nThe various types of reverse engineering are discussed in (C hikofsky and Cross II,\n1990). The 100% functional equivalence issue in reverse eng ineering is discussed\nin (Bennett, 1998). Reverse engineering tools are discusse d in (Biggerstaff et al.,\n1994), (Jarzabek and Wang, 1998) and", "token_count": 512, "start_token": 286902, "end_token": 287414, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 622, "text": "% functional equivalence issue in reverse eng ineering is discussed\nin (Bennett, 1998). Reverse engineering tools are discusse d in (Biggerstaff et al.,\n1994), (Jarzabek and Wang, 1998) and (Bellay and Gall, 1998) . Fowler (1999) is the\nstandard text for refactorinig. Mens and Tourw ´ e (2004) pro vide a survey of software\nrefactoring. Migration is discussed in (Rahgozar and Oroum chian, 2003) and (Bisbal\net al., 1999). Programming plans and beacons were originall y proposed in (Soloway\nand Ehrlich, 1984) and (Brooks, 1983). Research addressing the role of these concepts\nin program comprehension processes is described in (von May rhauser and Vans, 1995)\nand (von Mayrhauser et al., 1997). LaToza et al. (2006) discu sses developer work\nhabits, including code comprehension, during development and evolution. Example\ntools to help software maintenance include (Singer et al., 2 005) (support for browsing\nthrough software), (Rysselberghe and Demeyer, 2004) (visu alize change history) and\n(Ducasse et al., 2006) (visualization of distribution of sy stem properties).\nGˆ\nırba and Ducasse (2006) provide an overview of types of softw are evolution\nanalysis. The distinction between version-centered and hi story-centered analysis is\nmade in that article. G ˆ\nırba et al. (2004) discusses the ‘yesterday’s weather’ appr oach\nto reverse engineering. Fischer and Gall (2004) and Greevy e t al. (2006) discuss\nhistory-centered analysis.\nPossible organizations of maintenance activities as well a s their major advantages\nand disadvantages are discussed in (Swanson and Beath, 1990 ). Yeh and Jeng (2002)\ndiscuss the inﬂuence of departmentalization on software ma intenance. The service\nperspective on software maintenance is discussed in (Niess ink and van Vliet, 1999).\nThe translation hereof into a Capability Maturity Model aim ed at maintenance\nprocesses is described in (Niessink and van Vliet, 1998a).\nThe IEEE Process model", "token_count": 512, "start_token": 287364, "end_token": 287876, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 623, "text": "ess ink and van Vliet, 1999).\nThe translation hereof into a Capability Maturity Model aim ed at maintenance\nprocesses is described in (Niessink and van Vliet, 1998a).\nThe IEEE Process model for software maintenance is describe d in (IEEE1219,\n1992). The iterative-enhancement and quick-ﬁx models of so ftware maintenance are\ndiscussed in (Basili, 1990). Approaches to scheduling rele ases are the topic of (Stark\nand Oman, 1997).\nThe cost of software maintenance, and empirical relations b etween quality aspects\nand cost are the topic of (Banker et al., 1993), (Kemerer and S laughter, 1997), (Henry\nand Cain, 1997) and (Niessink and van Vliet, 1997). Indicato rs of system degradation\nare given in (Martin and Osborne, 1983).\nExercises\n1. Deﬁne the following terms: corrective maintenance, adap tive maintenance,\nperfective maintenance, and preventive maintenance.\n14.7. FURTHER READING 497\n2. Discuss the major causes of software maintenance problem s.\n3. What is reverse engineering?\n4. What is refactoring?\n5. Characterize the evolution and servicing stage of softwa re maintenance.\n6. What is the difference between design recovery and redocu mentation?\n7. Characterize the version-oriented analysis and history -centered analysis of\nsoftware evolution data.\n8. Why does corrective maintenance have more service-like a spects than\nproduct-like aspects?\n9. Discuss the iterative-enhancement and quick-ﬁx models o f software mainte-\nnance.\n10. Discuss the major impediments to fully-automated desig n recovery.\n11. Discuss advantages of software conﬁguration control su pport during software\nmaintenance.\n12. Discuss the possible structure and role of an acceptance test by the mainte-\nnance organization prior to the release of a system.\n13. /DI An alternative classiﬁcation of maintenance and developme nt activities is\nas follows:\n/AF Functional maintenance = corrective maintenance /B7 adaptive mainte-\nnance /B7 non-functional perfective maintenance (i.e. improving qu ality)\n/B", "token_count": 512, "start_token": 287826, "end_token": 288338, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 624, "text": " and developme nt activities is\nas follows:\n/AF Functional maintenance = corrective maintenance /B7 adaptive mainte-\nnance /B7 non-functional perfective maintenance (i.e. improving qu ality)\n/B7 replacement of a system by a functional equivalent.\n/AF Functional development = functional perfective maintenan ce (i.e. adding\nnew features) /B7 development of new systems.\nCould this classiﬁcation provide us with a better picture of the real maintenance\neffort? See also (Krogstie, 1994).\n14. /DI Assess opportunities of knowledge-based support for softw are maintenance\n(see (Devanbu et al., 1991) for a very interesting applicati on of such ideas).\n15. /DI Give a primary classiﬁcation of your maintenance organizat ion as W-, A-,\nor L-Type (see ﬁgure 14.12). What are the major strengths and weaknesses\nof your particular organization?\n16. /DI Does your organization collect quantitative data on mainte nance activities?\nIf so, what type of data, and how are they used to guide and impr ove the\n498 SOFTWARE MAINTENANCE\nmaintenance process? If not, how is maintenance planned and controlled?\n17. /DJ Study the technical documentation of a system whose develop ment you\nhave been involved in. Does the documentation capture the de sign rationale?\nIn what ways does it support comprehension of the system? In h indsight,\ncan you suggest ways to improve the documentation for the pur pose of\nmaintenance?\n18. /DI Discuss the impact of component reuse on maintainability.\n19. /DI Discuss the possible contribution of object-oriented soft ware development\nto software maintenance.\n20. /DI Can you think of reasons why a 10% change in a program of 200 LOC\nwould take more effort than a 20% change in a program of 100 LOC ?\n15\nSoftware Tools\nLEARNING OBJECTIVES\n/AF To be able to distinguish various dimensions along which too ls can be classiﬁed\n/AF To be aware of the major trends in (collections of) software t ools\n/AF To appreciate the role of tools in the software development p rocess\n500 SOFTWARE TOOLS\nSoftware development is generally supported by tools, rang ing from tools\nsupport", "token_count": 512, "start_token": 288288, "end_token": 288800, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 625, "text": " the major trends in (collections of) software t ools\n/AF To appreciate the role of tools in the software development p rocess\n500 SOFTWARE TOOLS\nSoftware development is generally supported by tools, rang ing from tools\nsupporting a single activity to integrated environments su pporting a complete\ndevelopment process. In this chapter we discuss the main cla sses of software\ndevelopment tools and their role in the development process .\nThe demand for software grows faster than the increase in sof tware development\nproductivity and available manpower. The result is an ever- increasing shortage of\npersonnel; we are less and less able to satisfy the quest for s oftware. To turn the tide,\nwe must look for techniques that result in signiﬁcant produc tivity gains.\nOne of the most obvious routes to pursue is automation itself . We may use the\ncomputer as a tool in the production of software. In the past, all sorts of things were\nautomated, save software development itself. Programmers knew better than that.\nWe have long been accustomed to employ the computer as a tool f or the\nimplementation of software. To this end, programmers have a vast array of tools at\ntheir disposal, such as compilers, linkers and loaders. Als o during testing, tools like\ntest drivers and test harnesses have been used for a long time . The development of\ntools to support earlier phases of the software life cycle is more recent. One example\nof the latter is software to aid the drawing and validation of UML diagrams.\nThe use of software tools may have a positive effect on both th e productivity\nof the people involved and the quality of the product being de veloped. Tools may\nsupport checking conformance to standards. Tools may help t o quantify the degree\nof testing. Tools may support progress tracking. And so on.\nThe application of tools in the software development proces s is referred to\nas Computer Aided Software Engineering (CASE). Apart from the traditional\nimplementation and test tools, CASE has a relatively short h istory. The ﬁrst tools to\nsupport design activities appeared in the early 1980s. Toda y, the number of CASE\nproducts is overwhelming.\nAs the number of available CASE products proliferates, it be comes expedient\nto classify them. One way of doing so is according to the bread th of support they\noffer.", "token_count": 512, "start_token": 288750, "end_token": 289262, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 626, "text": "oda y, the number of CASE\nproducts is overwhelming.\nAs the number of available CASE products proliferates, it be comes expedient\nto classify them. One way of doing so is according to the bread th of support they\noffer. Figure 15.1 gives a classiﬁcation of CASE products al ong this dimension. Some\nproducts support a speciﬁc task in the software development process. Others support\nthe entire software process. The former are called tools, the latter environments. In\nbetween these two extremes it is useful to identify CASE prod ucts that support a\nlimited set of activities, such as those which comprise the a nalysis and design stages.\nSuch a coherent set of tools with a limited scope is referred t o as a workbench.\nEnvironments can be further classiﬁed according to the mech anism that ties\ntogether the individual tools that make up the environment. In a toolkit, tools\nare generally not well integrated. The support offered is in dependent of a speciﬁc\nprogramming language or development paradigm. A toolkit me rely offers a set of useful\nbuilding blocks. A language-centered environment contains tools speciﬁcally suited\nfor the support of software development in a speciﬁc program ming language. Such\nan environment may be hand-crafted or generated from a gramm atical description of\n501\nCASE product supports\nTool One task\nWorkbench Limited set of activities\nEnvironment Entire software process\nToolkit\nLanguage-centered environment\nIntegrated environment\nProcess-centered environment\nFigure 15.1 Classiﬁcation of CASE products\nthe language. In the latter case, the environment tends to fo cus on the manipulation\nof program structures.\nThe essence of integrated and process-centered environments is the sharing of\ninformation between the tools that make up the environment. Integrated environments\nfocus on the resulting product. The heart of an integrated en vironment is a data\nrepository, containing a wealth of information on the produ ct to be developed, from\nrequirements up to running code. Process-centered environ ments focus on sharing a\ndescription of the software development process.\nObviously, classifying actual CASE products according to t his framework is not\nalways easy. For example, many environments that span the co mplete life cycle\nevolved from workbenches that supported either", "token_count": 512, "start_token": 289212, "end_token": 289724, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 627, "text": "\ndescription of the software development process.\nObviously, classifying actual CASE products according to t his framework is not\nalways easy. For example, many environments that span the co mplete life cycle\nevolved from workbenches that supported either front-end a ctivities (analysis and\nglobal design) or back-end activities (implementation and test). These environments\ntend to contain tools speciﬁcally geared at supporting task s from the corresponding\npart of the life cycle, augmented by a more general support fo r the other phases (such\nas for editing, text processing, or database access).\nThe framework of ﬁgure 15.1 classiﬁes CASE products accordi ng to the parts of\nthe life cycle they support. Figure 15.2 lists a number of dim ensions along which\nCASE products can be classiﬁed. Using all of these dimension s to classify a CASE\nproduct yields a faceted classiﬁcation scheme, which provi des more information and\nis more ﬂexible than the one-dimensional framework of ﬁgure 15.1.\nNo development method is suited for all classes of problems. Likewise, there is no\nCASE product for all problem classes. Speciﬁc properties of a given class of problems\nwill impact the tools for that class. An important property o f embedded systems is\nthat the software is often developed on some host machine whi ch is different from\nthe ultimate target machine. Speciﬁc tools will be required for the development of\nsuch systems, for instance tools that allow us to test the sof tware on the host machine.\n502 SOFTWARE TOOLS\nDimension Typical values\nBreadth of support Tool, workbench, or environment\nClass of problem Embedded, business, real-time, . . .\nSize of system Small, medium, or large\nUser scale Individual, family, city, or state\nNumber of sites 1, /BQ /BD\nProcess scale Product, people, or product-and-people\nProcess support None, ﬁxed, or variable\nExecution paradigm State machine, Petri net, production rules, procedures, . . .\nFigure 15.2 Faceted classiﬁcation structure for CASE produ cts\nFor many business applications, the human--computer inter action plays a prom", "token_count": 512, "start_token": 289674, "end_token": 290186, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 628, "text": " State machine, Petri net, production rules, procedures, . . .\nFigure 15.2 Faceted classiﬁcation structure for CASE produ cts\nFor many business applications, the human--computer inter action plays a promi-\nnent role, while the requirements analysis of such systems t ends to be problematic.\nA development environment for such systems had better conta in tools that support\nthose aspects (analyst workbench, prototyping facilities , and facilities to generate\nscreen layouts).\nAs a ﬁnal example, when developing real-time software, it wo uld be preferable to\nhave tools that allow us to analyze system performance at an e arly stage.\nA second dimension relates the set of tools to the size of the s ystem to be\ndeveloped. In practice, it shows that tool usage increases w ith problem size. For a\nsmall project, we may conﬁne ourselves to a simple conﬁgurat ion control system,\nsimple test tools, and a shared database system to store docu ments. In a medium-sized\nproject, more advanced support could be used, such as a struc tured database with\nobjects like design documentation, test plans, or code comp onents. Certain relations\nbetween objects, such as A uses B, or A implements B, could be m aintained. For a\nmedium-sized project, the toolset would also include tools to support management\ntasks, for example to create CPM or PERT charts. For a large pr oject, we may require\nthat the tools be mutually compatible. The toolset for a larg e project will generally\nalso impose more constraints on their users.\nThe user scale refers to the number of users the product suppo rts. Not surprisingly,\nthe user-scale dimension is closely related to the system si ze dimension. Larger\nsystems require larger development teams, don’t they? Usin g a sociological paradigm,\npossible values along the user-scale dimension are called i ndividual, family, city\nand state. Some products support the individual developer. These products are\ndominated by issues of software construction. The emphasis is on tools that support\nsoftware construction: editors, debuggers, compilers, et c. CASE products that offer\nconﬁguration management and system build facilities can be classiﬁed as belonging\n", "token_count": 512, "start_token": 290136, "end_token": 290648, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 629, "text": ". The emphasis is on tools that support\nsoftware construction: editors, debuggers, compilers, et c. CASE products that offer\nconﬁguration management and system build facilities can be classiﬁed as belonging\nto the family model of software development environments. I n the family model, a\n503\ngreat deal of freedom is left to the individual developer, wh ile a number of rules are\nagreed upon to regulate critical interactions between deve lopers.\nThis model is not appropriate any more if projects get really big. Larger\npopulations require more complicated rules and restrictio ns on individual freedom.\nWithin my family, a few simple rules sufﬁce (Jasper and Marie ke take turns in washing\ndishes), and adjustments and local deviations are easily es tablished (Jasper has a party\ntoday and asks Marieke to take over). Within a large company, policies have to be\nmore strictly obeyed and cooperation between individuals i s enforced (like in a city).\nLikewise, toolsets to support the development of large syst ems should enforce the\nproper cooperation between individual developers.\nA state may be viewed as a collection of cities. A company may b e viewed as a\ncollection of projects. In the state model, the main concern is with commonality and\nstandardization, to allow developers to switch between pro jects, to be able to reuse\ncode, designs, test plans, etc.\nIf development is done at more than one site, we need tools to f acilitate\ncollaboration and coordination. On one hand, tools like tho se for conﬁguration\nmanagement and requirements management need to provide sup port to coordinate\ndevelopment work at multiple sites. On the other hand, tools from the realm of\nComputer-Supported Cooperative Work (CSCW) could be part o f the tool suite.\nThis dimension is also closely related to the user-scale and system size dimension,\nsince larger projects tend to be distributed over multiple s ites; see also chapter ??.\nThe process scale speciﬁes whether the CASE product support s code production\nactivities, people activities, or both. CASE products focu sing on code production\nconcentrate on support for the evolution of software. They c ontain tools to write,\ncompile, test, debug, and conﬁgure code. These are all activ", "token_count": 512, "start_token": 290598, "end_token": 291110, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 630, "text": ". CASE products focu sing on code production\nconcentrate on support for the evolution of software. They c ontain tools to write,\ncompile, test, debug, and conﬁgure code. These are all activ ities done by a computer.\nOther CASE products concentrate on personnel interactions , such as the scheduling\nof review meetings. Still others do both. Values along this a xis may be termed\nproduct, people, and product-and-people.\nCASE products may or may not support the development process. If the develop-\nment process is supported, some tools do so on the basis of a pr edeﬁned model of the\nprocess. Others allow the user to deﬁne his own process model . If the CASE product\nsupports the development process, it may employ various int ernal means to guide the\nexecution (or enactment) of the development process, such a s state machines, Petri\nnets, production rules, or procedures.\nThe various approaches to collections of software tools are addressed in sections\n15.1 to 15.4, using the simple classiﬁcation scheme of ﬁgure 15.1. Toolkits are\ndiscussed in section 15.1. UNIX is a prime example from this c ategory. Section 15.2\ndiscusses language-centered environments. This encompas ses both environments\ncreated manually around some given programming language, a nd environments gen-\nerated from a grammatical description of the program struct ures being manipulated. In\nboth cases, the support offered mostly concerns the individ ual programmer. Section\n15.3 and 15.4 discuss integrated and process-centered envi ronments, respectively.\nSince most workbenches may be viewed as trimmed-down integr ated environments,\n504 SOFTWARE TOOLS\nworkbenches are discussed in section 15.3 as well.\nThe discussion below is fairly global in nature. We will skim over details of\nindividual tools. Our aim is to sketch discernible trends in this area and to have a\ncritical look at the possible role of tools in the software de velopment process.\n15.1 Toolkits\nWith a toolkit, developers are supported by a rather loosely -coupled collection of\ntools, each of which serves a speciﬁc, well-deﬁned", "token_count": 512, "start_token": 291060, "end_token": 291572, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 631, "text": " process.\n15.1 Toolkits\nWith a toolkit, developers are supported by a rather loosely -coupled collection of\ntools, each of which serves a speciﬁc, well-deﬁned, task. Th e analogy with a carpenter\nis obvious. His toolkit contains hammers, screwdrivers, a s aw, and the like. These\ntools each serve a speciﬁc task. However, they are not ‘integ rated’ in the way a drill\nand its attachments are.\nThe prime example of a toolkit environment is UNIX. UNIX may b e viewed as\na general support environment, not aimed at one speciﬁc prog ramming language,\ndevelopment method, or process model. UNIX offers a number o f very convenient,\nyet very simple, building blocks with which more complicate d things can be\nrealized (Kernighan and Mashey, 1981):\n/AF The ﬁle system is a tree. The leafs of this tree are the ﬁles, wh ile inner nodes\ncorrespond to directories. A speciﬁc ﬁle can be addressed ab solutely or relative\nto the current directory. The addressing is through a pathna me, analogous to\nthe selection of method names in Java. Directories are ﬁles t oo, though the user\ncannot change their contents.\n/AF Files have a very simple structure. A ﬁle is but a sequence of c haracters (bytes).\nSo there are no physical or logical records, there is no disti nction between\nrandom access ﬁles and sequential access ﬁles, and there are no ﬁle types.\nAn I/O device is a ﬁle too; if it is opened, it automatically ac tivates a program\nwhich handles the trafﬁc with that device. In this way, a user may write\nprograms without knowing (or, indeed, without having to kno w) where the\ninput comes from or where the output goes to.\n/AF All system programs (and most user programs) assume that inp ut comes from\nthe user’s terminal, while the output is again written to tha t terminal. The user\ncan easily redirect both input and output. Through a call of t", "token_count": 512, "start_token": 291522, "end_token": 292034, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 632, "text": " system programs (and most user programs) assume that inp ut comes from\nthe user’s terminal, while the output is again written to tha t terminal. The user\ncan easily redirect both input and output. Through a call of t he form\nprog /BO in /BQ out\ninput is read from ﬁle in, while output is written to ﬁle out. The program itself\nneed not be changed.\n/AF UNIX offers its users a very large set of small, useful, progr ams. To name but\na few: wc counts the number of lines, words and characters in ﬁles, lpr prints\nﬁles, grep does pattern matching.\n15.2. LANGUAGE-CENTERED ENVIRONMENTS 505\n/AF UNIX programs can easily be combined to form larger programs . If the output\nof one program is to serve as input to another program, they ca n be connected\nthrough a pipe, denoted by ‘ /CY ’:\nls /CY pr\nmakes a list of all ﬁle names and subsequently prints that lis t. There is no need\nfor an auxiliary ﬁle to store intermediate results.\nIn this way, users are led to try to reach their goals by gluing existing components\ntogether, rather than writing a program from scratch. A disa dvantage of UNIX is\nthat there is little consistency in interfaces and the choic e of command names. For\ndifferent programs, the ‘ -k’ option, say, may well mean something rather different.\nTo stop a dialogue, you may try kill, stop, quit, end, leave, and a few others. If you\nget tired, CTRL-c is likely to work too.\nThe average UNIX user knows only a fairly limited subset of th e available\ncommands and tools (Fischer, 1986). It is quite likely that, after a while, a workable\nset of commands will be known and used, and then the learning p rocess stops.\nInevitably, the facilities offered under UNIX are far from o ptimally used.\nIn UNIX, the different tools have minimal knowledge of the ob jects they\nmanipulate. Various integrated and process-centered envi ronments have been built\non top of UNIX. They make use of", "token_count": 512, "start_token": 291984, "end_token": 292496, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 633, "text": " used.\nIn UNIX, the different tools have minimal knowledge of the ob jects they\nmanipulate. Various integrated and process-centered envi ronments have been built\non top of UNIX. They make use of the attractive features of UNI X, but try to\novercome its disadvantages by imposing more structure.\nBesides tools that support the individual programmer, UNIX also offers support\nfor programming-in-the-large, through conﬁguration mana gement and system build\nfacilities like SCCS and Make. These will be discussed in sec tion 15.3.2.\n15.2 Language-Centered Environments\nNowadays, most software is developed interactively, chang es are made interactively,\nand programs are tested and executed interactively. Much re search in the area of\nlanguage-centered environments is aimed at developing a co llection of useful, user-\nfriendly, effective tools for this type of activity. Since m ost of these environments\nfocus on supporting programming tasks, this type of environ ment is often called a\nprogramming environment . To emphasize their graphic capabilities to manipulate\nprogram constructs, they are sometimes called visual programming environments .\nEnvironments that are built around a speciﬁc programming la nguage exploit the\nfact that a program entails more than a mere sequence of chara cters. Programs have a\nclear structure. This structure can be used to make the editi ng process more effective,\nto handle debugging in a structured way, and the like. Knowle dge of properties of the\nobjects to be manipulated can be built into the tools and subs equently used by these\ntools. Well-known early examples of language-centered env ironments are Interlisp\nand the Smalltalk-80 environment.\n506 SOFTWARE TOOLS\nPresent-day language-centered environments generally co me with a host of com-\nponents that considerably ease software development. Exam ples of such environments\ninclude Microsoft Studio .NET and Eclipse. The support offe red ranges from a set\nof API’s for generating user interfaces (such as Swing), to f acilities for handling\npersistence (EJB) or create web applications (Ajax). The ri chness of features comes\nwith a price: a rather long learning curve.\n15.3 Integrated Environments and Workbenches\nThis section is devoted to CASE products that support", "token_count": 512, "start_token": 292446, "end_token": 292958, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 634, "text": ") or create web applications (Ajax). The ri chness of features comes\nwith a price: a rather long learning curve.\n15.3 Integrated Environments and Workbenches\nThis section is devoted to CASE products that support (parts of) the software\ndevelopment process. Depending on the scope of the set of too ls available, such\nan environment is called an Analyst WorkBench (AWB), a Progr ammer WorkBench\n(PWB), a Management WorkBench (MWB), or an Integrated Proje ct Support Envi-\nronment (IPSE); see also ﬁgure 15.3. The acronym CASE (Compu ter-Aided Software\nEngineering) is often used to indicate any type of tool suppo rt in the software devel-\nopment process. The qualiﬁed terms Upper-CASE and Lower-CA SE refer to tool\nsupport during the analysis--design and implementation-- test phases, respectively.\nIn the ideal case, the choice of a speciﬁc set of tools will be m ade as follows. First,\na certain approach to the software development process is se lected. Next, techniques\nare selected that support the various phases in that develop ment process. As a last\nstep, tools are selected that support those techniques. Som e steps in the development\nprocess may not be supported by well-deﬁned techniques. Som e techniques may not\nbe supported by tools. Thus, a typical development environm ent will have a pyramid\nshape as in ﬁgure 15.4.\nIn practice, we often ﬁnd the reverse conical form: a barely- developed model of\nthe development process, few well-deﬁned techniques, and a lot of tools. In this way,\nthe beneﬁts of the tools will be limited at best. To paraphras e the situation: for many\na CASE, there is a lot of Computer-Aided, and precious little Software Engineering.\nThe different tool sets identiﬁed above are discussed in the subsections to follow.\n15.3.1 Analyst WorkBenches\nAnalyst workbenches serve to support the activities in the e arly phases of software\ndevelopment: requirements engineering and (global) desig n. In these phases, analysis\nand design data is gathered. Often, a graphical", "token_count": 512, "start_token": 292908, "end_token": 293420, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 635, "text": "Benches\nAnalyst workbenches serve to support the activities in the e arly phases of software\ndevelopment: requirements engineering and (global) desig n. In these phases, analysis\nand design data is gathered. Often, a graphical image of the s ystem is made,\nfor instance in the form of a set of UML diagrams. From a practi cal point of\nview, important problems concern the drawing and redrawing of those diagrams\nand guarding the consistency and completeness of the data ga thered. AWB tools\nspeciﬁcally address these points.\nThe kernel of an AWB is a database in which the information gat hered is stored.\nThe structure of the database can be rather free, or it can be d erived from the\ntechniques supported. The AWB will also contain tools to sup port the following\ntypes of activity:\n15.3. INTEGRATED ENVIRONMENTS AND WORKBENCHES 507\nFigure 15.3 Scope of tool sets\nFigure 15.4 Support in a typical development environment\n508 SOFTWARE TOOLS\n/AF Drawing, changing and manipulation of pictures. This may va ry from simple\ndrawing programs that have no knowledge of the pictures’ sem antics, to\nprograms that have an elaborate knowledge of the semantics o f the drawing\ntechnique in question. As far as the latter is concerned, we m ay think of\nautomatic generation of pointers to subpictures, the autom atic reconﬁguration\nof pictures to circumvent intersecting lines, and the like. If the drawing\ntechnique has been sufﬁciently formalized, the user suppor t can be comparable\nto that offered by a syntax-directed editor for programming languages.\n/AF Analysis of data produced, as regards consistency and compl eteness. The\npossibilities of doing this are strongly dependent upon the degree to which the\ndrawing technique itself imposes strict rules. There is a ch oice as to when this\nchecking takes place. If the user is immediately notiﬁed whe n an error is made,\nthere is little chance for errors to cascade. On the other han d, the freedom\nto ‘play’ during the exploratory development stages is also limited. If checking\nis done at a later stage, the user may continue on the wrong tra ck for quite\n", "token_count": 512, "start_token": 293370, "end_token": 293882, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 636, "text": ". On the other han d, the freedom\nto ‘play’ during the exploratory development stages is also limited. If checking\nis done at a later stage, the user may continue on the wrong tra ck for quite\na while before detection, and it then becomes more difﬁcult t o identify the\nproper error messages.\n/AF Managing information. A prime example is managing requirem ents. A simple\nway is to store them in a plain text document. More advanced to ols allow\nfor maintaining relations between requirements, tracing r equirements to design\ndocuments, detecting and handling conﬂicts, and the like.\n/AF Generating reports and documentation. It is important to be able to adapt\nthe precise form of reports and documentation to the require ments of the\nuser. For instance, internal standards of some organizatio n may enforce certain\nreport formats. It should be possible to conﬁgure the tools t o adhere to these\nstandards.\nFurther tools of an AWB may support, amongst others, prototy ping, the generation\nof user interfaces, or the generation of executable code. Po st et al. (1998) found that\nusers perceive two types of (Upper-CASE) tool: those that ar e good at supporting\nanalysis and design tasks and those that are good at code gene ration and prototyping.\nApparently, the tools tend to emphasize one of these uses.\n15.3.2 Programmer Workbenches\nA programmer workbench consists of a set of tools to support t he implementa-\ntion and test phases of software development. The term origi nated in the UNIX\nworld (Dolotta et al., 1978). The support offered by UNIX mai nly concerns these\ntypes of activity. Many programming environments construc ted around a certain\nprogramming language also support these phases in particul ar. In a PWB, we ﬁnd\ntools to support, amongst others:\n– editing and analysis of programs;\n15.3. INTEGRATED ENVIRONMENTS AND WORKBENCHES 509\n– debugging;\n– generation of test data;\n– simulation;\n– test coverage determination.\nThe tools that support teamwork on large projects deserve ou r special attention. In a\ntypical environment, a group of programmers will be working on the", "token_count": 512, "start_token": 293832, "end_token": 294344, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 637, "text": ";\n– generation of test data;\n– simulation;\n– test coverage determination.\nThe tools that support teamwork on large projects deserve ou r special attention. In a\ntypical environment, a group of programmers will be working on the same system.\nThe system will have many components, developed, tested, an d changed by different\npeople. During the evolution of the system, different versi ons of components will\nresult. Automatic support for the control of such a set of com ponents, both technically\nand organizationally, is a sheer necessity.\nOne of the early systems for conﬁguration control is the Sour ce Code Control\nSystem (SCCS), originally developed for IBM OS and best know n from UNIX. SCCS\nenables the user to keep track of modiﬁcations in ﬁles (which may contain such\ndiverse things as program code, documentation, or test sets ). The system enables the\nuser to generate any version of the system. New versions can b e generated without\nold versions being lost. Important aspects of SCCS are:\n– no separate copies of versions are kept: only the modiﬁcati ons (so-called deltas)\nto previous versions are stored;\n– access to ﬁles is protected: only authorized users can make changes;\n– each ﬁle is identiﬁed by author, version number, and date an d time of\nmodiﬁcation;\n– the system asks the user for information on the reason for a c hange, which\nchange is made, where, and by whom.\nFigure 15.5 illustrates the main operations provided by SCC S. Within SCCS, all\ninformation is kept in so-called s-ﬁles . The operation create creates the s-ﬁle for the\nﬁrst time. If the original ﬁle is named prog, then the SCCS ﬁle is named s.prog.\nThe operation get yields a read-only copy of the ﬁle requested. This read-only copy\ncan be used for compiling, printing, and the like. It is not intended to be edited.\nThe operation edit retrieves a copy to be edited. SCCS takes care of protection i n\nthe sense that only one person can be editing", "token_count": 512, "start_token": 294294, "end_token": 294806, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 638, "text": " be used for compiling, printing, and the like. It is not intended to be edited.\nThe operation edit retrieves a copy to be edited. SCCS takes care of protection i n\nthe sense that only one person can be editing a ﬁle at one time. Finally, the delta\noperation stores the revised version of the ﬁle edited.\nVersions of SCCS ﬁles are numbered, 1.1, 1.2, 1.3, 2.1, etc. T he number to the\nleft of the period is the major version number (release numbe r). The number to the\nright of the period is the minor version number. The ﬁrst vers ion is numbered 1.1.\nBy default, get and edit retrieve the latest version of a ﬁle, while delta results in an\nincrease of the minor version number. If an older version is r equired or the major\nversion number is to be increased, this must be speciﬁed expl icitly.\n510 SOFTWARE TOOLS\nFigure 15.5 Main operations of SCCS\nThe above scheme results in a linear sequence of versions. SC CS also provides\nthe possibility of creating branches ( forks), as illustrated in ﬁgure 15.6. For example,\nstarting from version 1.2 we may create versions 1.3, 1.4, et c to represent normal\ndevelopment of a system component, and versions 1.2.1.1, 1. 2.1.2, etc to represent\nbug ﬁxes in version 1.2. In SCCS, the merging of development p aths must be done\nmanually.\nWhen different versions of the same system are maintained in this way, the need\nto automate the construction of new executable versions ari ses. Make is a tool that\ndoes this (Feldman, 1978). Make uses a description of the var ious components of a\nsystem and their mutual dependencies. When generating a new executable system,\nMake inspects the date and time of the latest changes to compo nents and only\nrecompiles components when needed (i.e. components that ha ve been changed since\nthe last compilation). A tool like Make not only saves machin e time, but also ensures\nthat the most recent version of each component is used.\nThe basic functionality of con�", "token_count": 512, "start_token": 294756, "end_token": 295268, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 639, "text": ".e. components that ha ve been changed since\nthe last compilation). A tool like Make not only saves machin e time, but also ensures\nthat the most recent version of each component is used.\nThe basic functionality of conﬁguration control systems ha s not fundamentally\nchanged since the development of SCCS in the early 1970s. Rat her than keeping\na copy of each version, SCCS and similar systems only keep tra ck of what has\nchanged from the previous version (the so-called deltas). N owadays, disk storage is\nnot an issue anymore, and many software conﬁguration system s use simple zip-like\ncompression instead of deltas. Additional features offere d in present-day systems are\nmainly directed at increasing the ﬂexibility and usability of such systems:\n15.3. INTEGRATED ENVIRONMENTS AND WORKBENCHES 511\nFigure 15.6 Forking and merging of development paths\n/AF The ability to symbolically tag ﬁle versions. If the repair o f some bug requires\nchanges in a number of modules, each of these revised modules may be given\nthe same tag, say bug27. In a subsequent build of the system, this tag bug27\nmay then be used to reference ﬁle versions in which this bug ha s been taken\ncare of. This frees the user from the need to remember that the bug concerns\nversion 1.12 of module A, 1.3.1.7 of module B, etc.\n/AF The ability to automatically merge branches. This is by no me ans a fool-proof\noperation and should be used with care. The possibility of me rging branches\nhinges on the availability of appropriate merge tools. If ch anges are made in\ndisjoint parts of a ﬁle, merge tools can generally merge thes e changes fully\nautomatically.\n/AF Flexible support for multiple developers working on the sam e system. In SCCS,\nonly one person can be editing a ﬁle at a time. This rather rest rictive scheme is\nknown as reserved checkout . It may unnecessarily restrict the work in a team.\nFor example, one developer may check out a ﬁle he is not going t o work on until\nnext week. However, the fact that he did so prevents", "token_count": 512, "start_token": 295218, "end_token": 295730, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 640, "text": " as reserved checkout . It may unnecessarily restrict the work in a team.\nFor example, one developer may check out a ﬁle he is not going t o work on until\nnext week. However, the fact that he did so prevents other dev elopers from\nworking on that ﬁle during this week. In another model, known as unreserved\ncheckout, each developer has a working copy of a ﬁle. After a while, one\ndeveloper writes back his updated copy of that ﬁle, and other developers will\nbe notiﬁed if they want to do the same. These other developers will then, one\nby one, have to merge their changes with the already updated c opy.\n/AF Management of workspaces. Checked-out ﬁles are put in a workspace. This\nmay be as simple as the home directory of a developer, or be mor e complex and\nbe supported by additional tooling. For instance, next to th e ﬁles a developer is\nabout to change, depending ﬁles that are needed to compile an d test changes\nmay be automatically downloaded as well.\n512 SOFTWARE TOOLS\n/AF Support for communication within a development team. For ex ample, if one\ndeveloper checks out a ﬁle someone else is already working on , he may be given\na notiﬁcation of this, so that the developers can start a dial og and coordinate\ntheir activities. The latter type of support connects the pu re archival function\nof conﬁguration control systems with the communication and coordination\nfunctions of workﬂow management systems.\nLanguage-centered environments as discussed in section 15 .2 support the individual\ndeveloper. These environments are dominated by issues of so ftware construction. The\nemphasis is on tools that support software construction: ed itors, debuggers, compilers,\netc. Toolsets that offer conﬁguration management and syste m build facilities like those\noffered by SCCS and Make can be classiﬁed as belonging to the f amily model of\nsoftware development environments: a great deal of freedom is left to the individual\ndevelopers, while a number of rules are agreed upon to regula te critical interactions\nbetween developers.\nMost programmer workbenches offer this family type of suppo rt. For example", "token_count": 512, "start_token": 295680, "end_token": 296192, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 641, "text": " a great deal of freedom is left to the individual\ndevelopers, while a number of rules are agreed upon to regula te critical interactions\nbetween developers.\nMost programmer workbenches offer this family type of suppo rt. For example,\nMake assumes that ﬁles whose names end in .c are C source ﬁles. Members of the\ndevelopment family follow this rule and may even have agreed upon further naming\nconventions. The development environment however has no wa y of enforcing those\nrules. It is up to management to make sure that the rules are fo llowed.\n15.3.3 Management WorkBenches\nA management workbench contains tools that assist the manag er during planning and\ncontrol of a software development project. Example tools in an MWB include:\nConﬁguration control Besides the control of software components as discussed in\nthe previous section, we may also think of the control of othe r project-speciﬁc\ninformation, like design and analysis data, or documentati on. An essential aspect\nof this type of conﬁguration control concerns the control of change requests.\nChanges are proposed, assessed, approved or rejected, give n a priority and cost\nestimate, planned, and executed. The corresponding proced ures are described in a\nconﬁguration control plan. The administration and workﬂow of those change requests\nmay well be supported through a tool. See also chapter 4.\nWork assignment Given a number of components, their mutual dependencies, an d\nresources needed (both people and hardware), tools can be us ed to determine critical\npaths in the network of tasks, and work packages may be assign ed accordingly. This\nis a central feature of process-centered environments; see section 15.4.\nCost estimation Various quantitative cost-estimation models have been dev eloped.\nThese models yield cost estimates, based on project charact eristics. Tools have been\ndeveloped that assist in gathering quantitative project da ta, calibrating cost-estimation\nmodels based on these data, and making cost estimates for new projects.\n15.4. PROCESS-CENTERED ENVIRONMENTS 513\n15.3.4 Integrated Project Support Environments\nAn Integrated Project Support Environment is meant to suppo rt all phases of the\nsoftware life cycle. Thus, such an environment has to contai n the various tools as\n", "token_count": 512, "start_token": 296142, "end_token": 296654, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 642, "text": " 513\n15.3.4 Integrated Project Support Environments\nAn Integrated Project Support Environment is meant to suppo rt all phases of the\nsoftware life cycle. Thus, such an environment has to contai n the various tools as\ndiscussed in the previous sections. Environments that span the complete life cycle\nusually emphasize the support of either front-end activiti es (analysis and global design\n-- Upper-CASE) or back-end activities (implementation and testing -- Lower-CASE).\nThey then contain tools speciﬁcally geared at supporting ta sks from the corresponding\npart of the life cycle, augmented by a more general support fo r the other phases (such\nas for editing, text processing, or database access).\nWhen developing an IPSE, we may strive for either a strong or a weak integration\nof its tools. A strong integration, as realized in the langua ge-centered environments\ndiscussed in section 15.2, has both advantages (like better control capabilities) and\ndisadvantages. One disadvantage is that such an IPSE tends t o be less ﬂexible. If the\ntools are not integrated, as in UNIX, there is more ﬂexibilit y. On the other hand, a\nmore stringent management control is then needed.\nWe may also look for intermediate forms. For example, all obj ects may be stored\nin the UNIX ﬁle system, controlled by SCCS, and the relations hips between objects\nmay be represented using a relational database system.\nThe heart of an integrated environment is the data repositor y, containing the\ninformation shared between the tools that make up the enviro nment. The constraints\nimposed on the structure of this repository mirror the degre e to which the tools\nare integrated. A stricter integration of tools allows for a stricter deﬁnition of the\nstructure of the data they share, and vice versa.\n15.4 Process-Centered Environments\nIn a process-centered software engineering environment (P SEE), a description of the\nsoftware development process is shared by the tools that mak e up the environment.\nNot surprisingly, developments in process-centered envir onments are closely tied\nto developments in process modeling, and vice versa. For exa mple, the kinds of\ndescription used in process modeling (state transition dia grams, Petri nets,", "token_count": 512, "start_token": 296604, "end_token": 297116, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 643, "text": ", developments in process-centered envir onments are closely tied\nto developments in process modeling, and vice versa. For exa mple, the kinds of\ndescription used in process modeling (state transition dia grams, Petri nets, and the\nlike) are also the formalisms used in PSEEs. Process modelin g is discussed in section\n3.6.\nLike an integrated environment, a process-centered enviro nment may cover the\ncomplete life cycle. Like an IPSE, a PSEE tends to be geared to wards supporting tasks\nfrom a speciﬁc part of the software development life cycle. S ince back-end activities\n(implementation and testing) are somewhat easier to struct ure and formalize, work in\nprocess modeling and PSEEs has concentrated on modeling and supporting back-end\nactivities, consequently.\nFigure 15.7 gives a model of the process of conducting a code r eview. The\nnotation is that of Petri nets. In section 3.6, this same ﬁgur e was used to explain the\n514 SOFTWARE TOOLS\nrole of different formalisms in process modeling. Here, we w ill use it to discuss its\nrole in a process-centered software engineering environme nt.\nFigure 15.7 Petri net view of the review process\nIf the developer indicates that some piece of code is ready fo r review, the\nenvironment is notiﬁed and comes into a state as indicated in ﬁgure 15.7. Parallel\nto the coding activity, management schedules a review meeti ng. Once this is done,\nthe place 1 labeled review scheduled is marked. The support environment then\n‘knows’ that the review can be held and may offer support for d oing so. In this way,\nthe environment guides the developers and other participan ts through the steps of\nthe review process, alerts them when certain actions are req uired, maintains status\ninformation of code products and other pieces of informatio n, etc. Thus, PSEEs\nprovide support for software development by automating rou tine tasks, invoking\nappropriate development tools, and enforcing rules and pra ctices.\nFormal models of a software process are rigid. In practice, t his rigidity is a\nhindrance, since there will always be exceptions. For examp le, the minutes of a review", "token_count": 512, "start_token": 297066, "end_token": 297578, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 644, "text": " enforcing rules and pra ctices.\nFormal models of a software process are rigid. In practice, t his rigidity is a\nhindrance, since there will always be exceptions. For examp le, the minutes of a review\nmeeting might get lost, management may decide to skip a certa in review meeting,\na review meeting may have to be rescheduled because some part icipant got ill, etc.\nThe Petri model of ﬁgure 15.7 can not cope with these situatio ns. A number of them\ncan be accommodated by making the model more complex. But the model will never\ncover all situations. There is thus a need to be able to interv ene. Some PSEEs, for\nexample, offer means to update process models on the ﬂy. A ful ly satisfactory solution\nis difﬁcult to ﬁnd, and the rigidity of formal models is likel y to continue to conﬂict\nwith the requirements of ﬂexibility in process support.\nThis holds the more where it supports the early stages of soft ware development.\nA designer or requirements engineer is not helped by an envir onment that dictates\n1 See section 3.6 for the terminology of Petri nets.\n15.5. SUMMARY 515\nthe detailed order of process steps to be taken. Broadly spea king, we may distin-\nguish two types of activity: the unstructured, creative, an d cooperative activities\nthat characterize the early stages of software development ; and the repetitive and\nstructured activities that characterize the later stages. A similar dichotomy may be\nobserved in PSEEs. PSEEs focusing on the early stages have mu ch in common with\ngroupware and Computer Supported Cooperative Work (CSCW) s ystems. These\nPSEEs support coordination of activities, such as access to and sharing of information,\nand cooperation activities, such as communication between people and scheduling\nmeetings. This type of support is becoming increasingly imp ortant in present-day\nmultisite development; see also chapter ??. PSEEs focusing on the later stages have\nmuch in common with workﬂow management and conﬁguration con trol systems.\nPresent-day conﬁguration control systems not only offer th e basic versioning and\naccess", "token_count": 512, "start_token": 297528, "end_token": 298040, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 645, "text": " the later stages have\nmuch in common with workﬂow management and conﬁguration con trol systems.\nPresent-day conﬁguration control systems not only offer th e basic versioning and\naccess capabilities known from systems like SCCS (see secti on 15.3.2) but they also\noffer ways to deﬁne and enact software conﬁguration tasks an d policies. Some even\nclaim that conﬁguration management tools are the ‘real’ PSE Es (Conradi et al., 1998).\n15.5 Summary\nDevelopments in the area of (integrated) collections of too ls move very fast. For\nmany a facet of the software development process, good tools are available. In\nthis chapter, we have discussed the major developments as re gards computer-aided\nsoftware engineering (CASE). We have done so using a simple, one-dimensional\nclassiﬁcation of CASE products, which expresses the parts o f the life cycle they\nsupport:\n/AF a tool supports one speciﬁc task;\n/AF a workbench supports a limited set of activities, such as those which com prise\nthe implementation and testing stages;\n/AF an environment supports the entire process.\nWe have further classiﬁed environments according to the mec hanism that ties together\nthe tools that make up the environment:\n/AF In a toolkit, the tools are generally not so well integrated. A toolkit me rely\noffers a set of useful building blocks. UNIX is a prime exampl e of this.\n/AF A language-centered environment contains tools speciﬁcally aimed at support-\ning software development in a speciﬁc programming language .\n/AF An integrated environment contains tools that share information about the\nresulting product. This information is stored in a data repo sitory, and the tools\nread and write this repository.\n516 SOFTWARE TOOLS\n/AF A process-centered environment contains tools that share a description of the\nsoftware-development process.\nThough environments are supposed to cover the entire life cy cle, they tend to\nemphasize certain parts of the process. They then contain to ols speciﬁcally geared at\nsupporting tasks from that part of the process, augmented by a more", "token_count": 512, "start_token": 297990, "end_token": 298502, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 646, "text": " cover the entire life cy cle, they tend to\nemphasize certain parts of the process. They then contain to ols speciﬁcally geared at\nsupporting tasks from that part of the process, augmented by a more general, and often\nlimited, support for the other parts. For example, language -centered environments\ntend to focus on the implementation and testing stages.\nOne of the major impediments to the widespread use of tools is their rigidity.\nSoftware tools are driven by formal models of what can and can not be done. A tool\nfor requirements engineering is likely to enforce certain r ules of well-formedness on\nthe diagrams it handles. A tool to support the testing proces s is likely to prescribe a\ncertain order of process steps. The requirements engineer, though, may well want to\nplay with ill-formed diagrams for a while. Likewise, the tes ter may want to deviate\nfrom the pre-established order of steps if circumstances re quire this. The tension\nbetween the demands for ﬂexibility of tool users and those fo r formality of tool\nbuilders is one of the major challenging research themes in t his area.\nIn a retrospective of PSEE research, Cugola and Ghezzi (1998 ) refer to this tension\nas the minimalist versus maximalist approach. In a maximali st approach, the goal is\nto model all possible situations. A minimalist approach fol lows a more lightweight\napproach, and acknowledges that humans play a decisive role in the decision process.\nA further corollary is that tools should support cooperatio n rather than automation.\nAn interesting open question is whether tools really help. S tudies of tool adoption\nand usage show mixed results. Some conclude that tools offer real improvements,\nwhile others conclude that users have not found tools to be he lpful. There are\ndeﬁnitely certain impediments to tool adoption. Tools cost money, sometimes a lot\nof money. There also is a learning curve for tool users. Final ly, there is quite a gulf\nbetween the state of the art as reported in this chapter and th e state of the practice.\nFor many an organizational problem, automation seems to be t he panacea.\nLikewise, the use of tools is often seen as panacea for our pro blems in software\nengineering: CASE as prosthesis. Tools, though, remain mer e tools. Within the", "token_count": 512, "start_token": 298452, "end_token": 298964, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 647, "text": " problem, automation seems to be t he panacea.\nLikewise, the use of tools is often seen as panacea for our pro blems in software\nengineering: CASE as prosthesis. Tools, though, remain mer e tools. Within the\nsoftware development process, other factors play a role as w ell. If the tools do not\nﬁt the procedures used within your organization, they are li kely to have a far from\noptimal effect. Also, tools cannot make up for an ineffectiv e development method or\nbadly-qualiﬁed personnel. Good people deliver good produc ts and mediocre people\ndeliver mediocre products, irrespective of the tools they u se.\n15.6 Further Reading\nAn early taxonomy of CASE products is given in (Dart et al., 19 87). Fuggetta (1993)\nextended this framework with a category ’process-centered environments’. The latter\nclassiﬁcation is used in this chapter. Additional dimensio ns for classifying CASE\n15.6. FURTHER READING 517\nproducts are given in (Lott, 1993). The sociological paradi gm (individual, family,\netc.) for the user scale stems from (Perry and Kaiser, 1991).\nBarstow et al. (1984) is a collection of seminal articles on p rogramming envi-\nronments, including the UNIX toolkit approach and early lan guage-centered envi-\nronments like Interlisp. The Source Code Control System (SC CS) is described in\n(Rochkind, 1975). The state of the art in conﬁguration manag ement is reﬂected in\n(Estublier et al., 2005). Building tools have not changed mu ch since Make (Feldman,\n1978). A recent development in this area in the Java world is A nt (Serrano and\nCiordia, 2004).\nIn the 1980s, tool research focused on creating integrated e nvironments. (Tah-\nvanainen and Smolander, 1990) is an annotated bibliography of articles on software\nengineering environments from that period. Subsequent res earch in the area of tools\nfocused on PSEEs. The state of the art in this area is reﬂected in (Fuggetta and Wolf,\n1996) and", "token_count": 512, "start_token": 298914, "end_token": 299426, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 648, "text": "engineering environments from that period. Subsequent res earch in the area of tools\nfocused on PSEEs. The state of the art in this area is reﬂected in (Fuggetta and Wolf,\n1996) and (Ambriola et al., 1997). The case for more ﬂexibili ty in software engineer-\ning environments is made in (Jankowski, 1994), (Cugola et al ., 1996), (Jarzabek and\nHuang, 1998) and (Cugola and Ghezzi, 1998).\nTool integration issues are addressed in (Sharon and Bell, 1 995). Tools assessment\nis the topic of (Software, 1996b). Studies of tool adoption a nd usage can be found in\n(Iivari, 1996) and (Post et al., 1998).\nExercises\n1. What does the acronym CASE stand for?\n2. Deﬁne the following terms:\n– tool,\n– workbench,\n– environment.\n3. What are the main distinguishing features of:\n– a toolkit,\n– a language-centered environment,\n– an integrated environment, and\n– a process-centered environment.\n4. What is the difference between Upper-CASE and Lower-CASE ?\n5. What is the basic functionality of a tool for conﬁguration management?\n6. Discuss the fundamental tension between formality and in formality in tools.\n518 SOFTWARE TOOLS\n7. Why is the user scale an important issue when considering t he adoption of\ntools?\n8. /DI Defend the statement that conﬁguration management tools ar e the only\n‘real’ process-centered environments (see (Conradi et al. , 1998)).\n9. /DJ For the development environment you are currently working i n, prepare a\nlist of:\n– utilities you use on a regular basis;\n– utilities you use infrequently or vaguely know about.\nNext compare these lists with the manuals describing the env ironment. What\npercentage of the environment’s functionality do you reall y need?\n10. /DJ Select and evaluate some commercial UML modeling tool using the criteria\ngiven in (Zucconi, 1989) or (Baram and Steinberg, 1989).\n11. /DI Discuss the possible role of automatic support for con�", "token_count": 512, "start_token": 299376, "end_token": 299888, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 649, "text": " /DJ Select and evaluate some commercial UML modeling tool using the criteria\ngiven in (Zucconi, 1989) or (Baram and Steinberg, 1989).\n11. /DI Discuss the possible role of automatic support for conﬁgura tion control in\nthe management of artifacts other than source code modules.\n12. /DI One of the claims of CASE-tool providers is that CASE will dra matically\nimprove productivity. At the same time though, customers se em to be\ndisappointed with CASE and take a cautionary stand. Can you t hink of\nreasons for this discrepancy?\n13. /DI Why is tool integration such an important issue?\nPart III: Advanced Topics\nIn this third part, we discuss a number of additional important issues concerning large-scale software \ndevelopment.\nChapter 16 addresses issues that have to do with human factors that are relevant for the development \nof interactive systems. The approach taken in this chapter can be summarized as ’The user interface \nis the system’.\nThe next three chapters deal with software reuse. Chapter 17 gives a broad overview of the topic and \nthe other two chapters zoom in on specific forms of software reuse. Chapter 18 deals with component-based \nsoftware engineering (CBSE). In CBSE, we try to compose systems out of ready-made building blocks, \nmuch like a car is composed out of ready-made building blocks. Chapter 19 deals with service orientation. \nA service can be seen as a component that is searched for and discovered dynamically.\nFinally, Chapter 20 deals with global software development. Nowadays, software development often is \nnot done by a collocated team. Rather, members of a team are scattered around the globe. This has \nrepercussions for the way development projects are managed and executed.\nChapter 16. User Interface Design\nWith Gerrit C. van der Veer, Open University, Heerlen, The Netherlands\nLEARNING OBJECTIVES\n• To be aware of different architectural styles for interactive systems\n• To appreciate the role of different types of expertise in user interface design\n• To be aware of the role of various models in user interface design\n• To understand that a user interface entails considerably more than what is represented on the \nscreen\n• To recognize the differences between a user-centered approach to the design of interactive \nsystems and other requirements engineering approaches\nNOTE\nSoftware systems are", "token_count": 512, "start_token": 299838, "end_token": 300350, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 650, "text": " To understand that a user interface entails considerably more than what is represented on the \nscreen\n• To recognize the differences between a user-centered approach to the design of interactive \nsystems and other requirements engineering approaches\nNOTE\nSoftware systems are used by humans. Cognitive issues are a major determinant of the effectiveness \nwith which users go about their work. W hy is one system more understandable than another? W hy is system \nX more ’user-friendly’ than system Y? In the past, the user interface was often only addressed after \nthe system had been fully designed. However, the user interface concerns more than the size and placement\n\nof buttons and pull-down menus. This chapter addresses issues about the human factors that are relevant \nto the development of interactive systems.\nToday, user needs are recognized to be important in designing interactive computer systems, but as \nrecently as 1980, they received little emphasis. Grudin (1991)\nW e can’t worry about these user interface issues now. W e haven’ t even gotten this thing to work yet! \n(Mulligan et al., 1991)\nA system in which the interaction occurs at a level which is understandable to the user will be accepted \nfaster than a system where it is not. A system which is available at irregular intervals or gives \nincomprehensible error messages, is likely to meet resistance. A 1992 survey found that 48% of the \ncode of applications was devoted to the user interface, and about 50% of the development time was devoted \nto implementing that part of the application (Myers and Rosson, 1992). Often, the user interface is \none of the most critical factors as regards the success or failure of a computerized system. Yet, most \nsoftware engineers know fairly little about this aspect of our trade.\nUsers judge the quality of a software system by the degree in which it helps them to accomplish their \ntasks and by the sheer joy they have in using it. This judgment is to a large extent determined by \nthe quality of the user interface. Good user interfaces contribute to a system’s quality in the following \nways (Bias and Mayhew, 1994):\n• Increased efficiency: If the system fits the way its users work and if it has a good ergonomic \ndesign, users can perform their tasks efficiently. They do not lose time struggling with the", "token_count": 512, "start_token": 300300, "end_token": 300812, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 651, "text": " (Bias and Mayhew, 1994):\n• Increased efficiency: If the system fits the way its users work and if it has a good ergonomic \ndesign, users can perform their tasks efficiently. They do not lose time struggling with the \nfunctionality and its appearance on the screen.\n• Improved productivity: A good interface does not distract the user, but rather allows him to \nconcentrate on the task to be done.\n• Reduced errors: Many so-called ’ human errors’ can be attributed to poor user interface quality. \nAvoiding inconsistencies, ambiguities, and so on, reduces user errors.\n• Reduced training: A poor user interface hampers learning. A well-designed user interface \nencourages its users to create proper models and reinforces learning, thus reducing training \ntime.\n• Improved acceptance: Users prefer systems whose interface is we 11-designed. Such systems make \ninformation easy to find and provide the information in a form which is easy to use.\nIn a technical sense, the user interface often comprises one or more layers in the architecture of \na system. Section 16.1 discusses two well-known architectural styles that highlight the place and role \nof the user interface in interactive systems. A common denominator of these and other schemes is that \nthey separate the functionality of the system from the interaction with the user. In a similar vein, \nmany software engineering methods also separate the design of the functionality from the design of \nthe user interface. The design of the user interface then reduces to a mere design of the screen layout, \nmenu structure, size and color of buttons, format of help and error messages, etc. User interface design \nthen becomes an activity that is only started after the requirements engineering phase has finished. \nIt is often done by software engineers who have little specialized knowledge of user interface design.\n\nSoftware engineers are inclined to model the user interface after the structure of the implementation \nmechanism, rather than the structure of the task domain. For instance, a structure-based editor may\nforce you to input ^ 10 2 in order to obtain 102, simply because the former is easier for the system\nto recognize. This resembles the interface to early pocket calculators, where the stack mechanism used \ninternally shows itself in the user interface. Similarly, user documentation often follows \nimplementation patterns and error messages are phrased in terms that reflect", "token_count": 512, "start_token": 300762, "end_token": 301274, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 652, "text": "to recognize. This resembles the interface to early pocket calculators, where the stack mechanism used \ninternally shows itself in the user interface. Similarly, user documentation often follows \nimplementation patterns and error messages are phrased in terms that reflect the implementation rather \nthan the user tasks.\nIn this chapter we advocate a rather different approach. This approach may be summarized as ’The user \ninterface is the system’. This broader view of the concept user interface and the disciplines that \nare relevant while developing user interfaces are discussed in Section 16.2. Within the approach \ndiscussed, the design of the user interface replaces what we used to call requirements engineering. \nThe approach is inspired by the observation that the usability of a system is not only determined by \nits perceptual appearance in the form of menus, buttons, etc. The user of an interactive system has \nto accomplish certain tasks. Within the task domain, e. g. sending electronic mail or preparing documents, \nthese tasks have a certain structure. The human-computer interaction (HCI) then should have the same \nstructure, as far as this can be accomplished. Discovering an adequate structuring of the task domain \nis considered part of user interface design. This discovery process and its translation into user \ninterface representations requires specific expertise, expertise that most software engineers do not \npossess. Section 16. 5 discusses this eclectic approach to user interface design. Its main activities \n- task analysis, interface specification, and evaluation - are discussed in Sections 16.6 to 16. 8.\nIn order to develop a better understanding of what is involved in designing user interfaces, it is \nnecessary to take a closer look at the role of the user in operating a complex device such as a computer. \nTwo types of model bear upon the interplay between a human and the computer: the user’s mental model \nand the conceptual model.\nUsers create a model of the system they use. Based on education, knowledge of the system or application \ndomain, knowledge of other systems, general world knowledge, and so on, the user constructs a model, \na knowledge structure, of that system. This is called the mental model. During interaction with the \nsystem, this mental model is used to plan actions and predict and interpret system reactions. The mental \nmodel reflects the user’s understanding of what the system contains, how it works,", "token_count": 512, "start_token": 301224, "end_token": 301736, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 653, "text": " called the mental model. During interaction with the \nsystem, this mental model is used to plan actions and predict and interpret system reactions. The mental \nmodel reflects the user’s understanding of what the system contains, how it works, and why it works \nthe way it does. The mental model is initially determined through metacommunication, such as training \nand documentation. It evolves over time as the user acquires a better understanding of the system. \nThe user’s mental model need not be, and often is not, accurate in technical terms. It may contain \nmisunderstandings and omissions.\nThe conceptual model is the technically accurate model of the computer system created by designers \nand teachers for their purposes. It is a consistent and complete representation of the system as far \nas user-relevant characteristics are involved. The conceptual model reflects itself in the system’s \nreaction to user actions.\nThe central question in human-computer interaction is how to attune the user’s mental model and the \nconceptual model as well as possible. When this is achieved to a higher degree, an interactive system\n\nbecomes easier to learn and easier to use. Where the models conflict, the user gets confused, makes \nerrors, and gets frustrated. A good design starts with a conceptual model derived from an analysis \nof the intended users and their tasks. The conceptual model should result in a system and training \nmaterials which are consistent with the conceptual model. This, in turn, should be designed such that \nit induces adequate mental models in the users.\nSection 16. 4 discusses various models that play a role in HCI. As well as the aforementioned mental \nand conceptual models, attention is given to a model of human information processing. When interacting \nwith a system, be it a car or a library information system, the user processes information. Limitations \nand properties of human information processing have their effect on the interaction. Knowledge of how \nhumans process information may help us to develop systems that users can better cope with.\nThere are many factors that impact human-computer interaction. In this chapter, we just scratch the \nsurface. Important topics not discussed include the socio-economic context of human-computer \ninteraction, input and output media and their ergonomics, and workplace ergonomics. Section 16. 10 \ncontains some pointers to relevant literature", "token_count": 512, "start_token": 301686, "end_token": 302198, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 654, "text": "surface. Important topics not discussed include the socio-economic context of human-computer \ninteraction, input and output media and their ergonomics, and workplace ergonomics. Section 16. 10 \ncontains some pointers to relevant literature.\n16.1. WHERE IS THE USER INTERFACE?\nA computerized library system includes a component to search the library’s database for certain titles. \nThis component includes code to implement its function as well as code to handle the interaction with \nthe user. In the old days, these pieces of code tended to be entangled, resulting in one large, monolithic \npiece of software.\nIn 1983, a workshop on user interface management systems took place at Seeheim in West Germany (Pfaff, \n1985). At this workshop, a model was proposed which separates the application proper from the user \ninterface. This model has become known as the Seeheim model.\nThe Seeheim model (see Figure 16.1) describes the user interface as the outer layer of the system. \nThis outer layer is an agent responsible for the actual interaction between the user and the application. \nIt, in turn, consists of two layers:\n• the presentation, i.e. the perceptible aspects including screen design and keyboard layout;\n• the dialog, i.e. the syntax of the interaction including metacomnunication (help functions, \nerror messages, and state information). If the machine is said to apply a model of its human \npartner in the dialog, e. g. by choosing the user’ s native language for command names, this \nmodel is also located in the dialog layer.\nThis conceptualization of the user interface does not include the application semantics, or \n’ functionality’. In the Seeheim model, the tasks the user can ask the machine to perform are located \nin another layer, the application interface. Figure 16.1 shows the separation of concerns into three \nparts. For efficiency reasons, an extra connection is drawn between the application and the display. \nIn this way, large volumes of output data may skip the dialog layer.\n\nFigure 16.1. The Seeheim model\nThe Seeheim model provides some very relevant advantages. For example, we may provide the same outer \nlayer to different applications. W e may apply the same look and feel to a text editor, a spreadsheet, \nand", "token_count": 512, "start_token": 302148, "end_token": 302660, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 655, "text": " Seeheim model\nThe Seeheim model provides some very relevant advantages. For example, we may provide the same outer \nlayer to different applications. W e may apply the same look and feel to a text editor, a spreadsheet, \nand so on, as in Microsoft products. In this way, the user does not have to learn different dialog \nlanguages for different applications. Conversely, we may provide a single application to be implemented \nbehind several different outer layers, so as to allow different companies to adopt the same application \nwith their own corporate interface style.\nIn both these cases, it is assumed that the changes are likely to occur in the interface part of the \nsystem, while the application part remains largely unaffected. Alternatively, we may assume that the \nfunctionality of the system will change. W e then look for an architecture in which parts of the system \ncan be modified independently of each other. A first decomposition of an interactive system along these \nlines is depicted in Figure 16. 2. Each component in this decomposition handles part of the application, \ntogether with its presentation and dialog. In a next step, we may refine this architecture such that \nthe input or output device of each component may be replaced. The result of this is shown in Figure \n16.3. This result is in fact the Model-View-Controller (MVC) paradigm used in Smalltalk. It is also \nthe archetypal example of a design pattern; see Section 12.5. The dialog and application together \nconstitute the model part of a component. In MVC, the output and input are called view and controller, \nrespectively.\n\nFigure 16.2. A part-whole decomposition of interactive systems\npresentation \ndialog \napplication part\npresentation \ndialog \napplication part\npresentation \ndialog \napplication part\nBoth the Seeheim model and M VC decompose an interactive system according to quality arguments pertaining \nto flexibility. The primary concern in the Seeheim model is with changes in the user interface, while \nthe primary concern of M VC is with changes in the functionality. This difference in emphasis is not \nsurprising if we consider the environments in which these models were developed: the Seeheim model \nby a group of specialists in computer graphics and M VC in an exploratory Smalltalk software development \nenvironment. Both models have their", "token_count": 512, "start_token": 302610, "end_token": 303122, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 656, "text": " not \nsurprising if we consider the environments in which these models were developed: the Seeheim model \nby a group of specialists in computer graphics and M VC in an exploratory Smalltalk software development \nenvironment. Both models have their advantages and disadvantages. The project at hand and its quality \nrequirements should guide the design team in selecting an appropriate separation of concerns between \nthe functionality proper and the part which handles communication with the user.\n\nFigure 16.3. The Model - View - Controller paradigm for interactive \nsystems\nIn many applications, the user interface part is running on one machine, the client, while the \napplication proper is running on another, the server. This of course also holds for Web applications, \nwhere the user interface is in the browser. On one hand, there has been a tendency towards ’ thin clients, \nwhere only the user interface is located at the client side, while all processing takes place at the \nserver side. However, in circumstances where one is not always connected to the Internet, e.g. with \nmobile devices, one would still like to continue work, and restore data once the connection is \nre-established. This gives rise to more data manipulation at the client side and, thus, ’fatter’ clients \n(Jazayeri, 2007). The separation between user interface and application, then, is not the same as that \nbetween browser and server application.\n\n16.2. WHAT IS THE USER INTERFACE?\nThe concept ’ user interface’ has several meanings. It may denote the layout of the screen, ’ windows’, \nor a shell or layer in the architecture of a system or the application. Each of these meanings denotes \na designer’ s point of view. Alternatively, the user interface can be defined from the point of view \nof the intended user of a system. In most cases, users do not make a distinction between layers in \nan architecture and they often do not even have a clear view of the difference between hardware and \nsoftware. For most users an information system as a whole is a tool to perform certain tasks. To them, \nthe user interface is the system.\nIn this chapter, we use the term user interface to denote all aspects of an information system that \nare relevant to a user. This includes not only everything that a user can perceive or experience (", "token_count": 512, "start_token": 303072, "end_token": 303584, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 657, "text": " \nthe user interface is the system.\nIn this chapter, we use the term user interface to denote all aspects of an information system that \nare relevant to a user. This includes not only everything that a user can perceive or experience (as \nfar as it has a meaning), but also aspects of internal structure and processes as far as the user should \nbe aware of them. For example, car salesmen sometimes try to impress their customers and mention the \nhorse-power of each and every car in their shop. Most customers probably do not know how to interpret \nthose figures. They are not really interested in them either. A Rolls-Royce dealer knows this. His \nanswer to a question about the horse-power of one of his cars would simply be: ’Enough’. The same holds \nfor many aspects of the internal structure of an information system. On the other hand, the user of \na suite of programs including a text editor, a spreadsheet, and a graphics editor should know that \na clipboard is a memory structure whose contents remain unchanged until overwritten.\nW e define the user interface in this broad sense as the user virtual machine (UVM). The UVM  includes \nboth hardware and software. It includes the workstation or device (gadget) with which the user is in \nphysical contact as well as everything that is ’ behind’ it, such as a network and remote data collections. \nIn this chapter, we take the whole UVM , including the application semantics, as the subject of (user \ninterface) design.\nIn many cases, several groups of users have to be distinguished with respect to their tasks. As an \nexample, consider an ATM. One type of user consists of people, bank clients, who put a card into the \nmachine to perform some financial transaction. Other users are specially trained people who maintain \nthe machine and supply it with a stock of cash. Their role is in ATM maintenance. Lawyers constitute \na third category of users of ATM machines. They have to argue in favor of (or against) a bank to show \nthat a transaction has been fraudulent, using a log or another type of transaction trace that is \nmaintained by the system. Each of these three user categories represents a different role in relation \nto the use of the ATM. For each of these roles, the system has a different meaning; each", "token_count": 512, "start_token": 303534, "end_token": 304046, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 658, "text": " type of transaction trace that is \nmaintained by the system. Each of these three user categories represents a different role in relation \nto the use of the ATM. For each of these roles, the system has a different meaning; each role has to \nbe aware of different processes and internal structures. Consequently, each has a different interface. \nIf we are going to design these interfaces, however, we have to design all of them, and, moreover, \nwe have to design the relation between them. In other words, within the task domain of the ATM, we \nhave to design a set of related UVMs, with respect to the tasks that are part of the various roles.\nNot only will several groups of users have different interfaces to the same application, but sometimes \na single user will have different interfaces to one and the same application as well. This is the case \nin particular when a user is accessing a system through different devices, such as a mobile phone and \na laptop. Not only do these devices have different characteristics, such as the size of the screen\n\nand the number of buttons available, but the user is likely to be in a different mood as well: in a \nhurry and with a lot of distracting noise around him when working via the mobile phone, while in a \nmore quiet environment when working on his laptop. Conceptually, this is not different from the \nmulti-role situation sketched above. Technically, the multi-device user situation poses its own set \nof challenges (Seffah et al., 2004).\nW e may look at the user interface from different viewpoints:\n• how to design all that is relevant to the user (the design aspect)\n• what does the user need to understand (the human side)\nIn principle these aspects have to be combined, otherwise the user will not understand the system’s \nfeatures. The next section is concerned with the human side. Later sections focus on the design aspects \nof the user interface.\n16.3. HUMAN FACTORS IN HUMAN-COMPUTER INTERACTION\nAttention to the user interface is often located in the later phases of the software life cycle. The \ndesign approach we elaborate in this chapter, however, requires attention to the human user (or to \nthe different user roles) from the very start of the design process. The various design activities \nare carried out in", "token_count": 512, "start_token": 303996, "end_token": 304508, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 659, "text": " cycle. The \ndesign approach we elaborate in this chapter, however, requires attention to the human user (or to \nthe different user roles) from the very start of the design process. The various design activities \nare carried out in parallel and in interaction with each other, even though a large design team may \nallocate to specialists the tasks of analyzing, specifying, and evaluating user interface aspects. \nThe design of the user interface consists of a complex of activities, all of which are intended to \nfocus on the human side of the system.\nThe human side cannot be covered by a single discipline or a single technique. There are at least three \nrelevant disciplines: the humanities, artistic design, and ergonomics.\n16.3.1. Humanities\nIn this view we pay attention to people based on psychological approaches (how do humans perceive, \nlearn, remember, think, and feel), and to organization and culture (how do people work together and \nhow does the work situation affect the people’ s work). Relevant disciplines are cognitive psychology, \nanthropology, and ethnography. These disciplines provide a theoretical base and associated techniques \nfor collecting information on people’s work as well as techniques for assessing newly designed tools \nand procedures. Designers of the virtual machine or user interface need some insight into the theories \nand experience with techniques from these disciplines. For example, in specifying what should be \nrepresented at a control panel, one may have to consider that less information makes it easier for \nthe user to identify indications of process irregularity (the psychological phenomenon of attention \nand distraction). On the other hand, if less of the relevant information is displayed, the user may \nhave to remember more, and psychology teaches us that human working memory has a very limited capacity.\n\n16.3.2. Artistic Design\nCreative and performing artists in very different fields have developed knowledge on how to convey \nmeaning to their public. Graphical artists know how shapes, colors, and spatial arrangements affect \nthe viewer. Consequently, their expertise teaches interface designers how to draw the attention of \nusers to important elements of the interface. For example, colors should be used sparingly in order \nnot to devalue their possible meaning. Well-chosen use of colors helps to show important relations \nbetween elements on the screen and supports users searching for relevant structures in information. \nDesign companies", "token_count": 512, "start_token": 304458, "end_token": 304970, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 660, "text": " should be used sparingly in order \nnot to devalue their possible meaning. Well-chosen use of colors helps to show important relations \nbetween elements on the screen and supports users searching for relevant structures in information. \nDesign companies nowadays employ graphical artists to participate in the design of representational \naspects of user interfaces.\nComplex systems often need a representation of complex processes, where several flows of activity \ninfluence each other. Examples of this type of work situation are the team monitoring a complex chemical \nprocess and the cockpit crew flying an intercontinental passenger airplane. In such situations, users \nneed to understand complex relations over time. The representation of the relevant processes and their \nrelations over time is far from trivial. Representing in an understandable way what is going on and \nhow the relations change over time is only part of the question. Frequently, such complex processes \nare safety critical, which means that the human supervisor needs to make the right decision very soon \nafter some abnormal phenomenon occurs, so immediate detection of an event as well as immediate \nunderstanding of the total complex of states and process details is needed. Experts in theater direction \nturn out to have knowledge of just this type of situation. This type of interface may be compared with \na theater show, where an optimal direction of the action helps to make the audience aware of the complex \nof intentions of the author and the cast (Laurel, 1990, 1993). Consequently, theater sciences are another \nsource for designing interfaces to complex processes.\nAnother type of artistic expertise that turns out to be very relevant for interface design is \ncinematography. Film design has resulted in systematic knowledge of the representation of dynamics \nand processes over time (May and Barnard, 1995). For example, there are special mechanisms to represent \nthe suggestion of causality between processes and events. If it is possible to graphically represent \nthe causing process with a directional movement, the resulting event or state should be shown in a \nlocation that is in the same direction. For example, in an electronic commerce system, buying an object \nmay be represented by dragging that object to a shopping cart. If the direction of this movement is \nto the right of the screen, the resulting change in the balance should also be shown to the right.\nIn the same way there are ’ laws’ for representing continuity in time. In a movie, the representation", "token_count": 512, "start_token": 304920, "end_token": 305432, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 661, "text": " this movement is \nto the right of the screen, the resulting change in the balance should also be shown to the right.\nIn the same way there are ’ laws’ for representing continuity in time. In a movie, the representation \nof a continuing meeting between two partners can best be achieved by ensuring that the camera viewpoints \ndo not cross the line that connects the location points of the two partners. As soon as this line is \ncrossed, the audience will interpret this as a jump in time. This type of expertise helps the design \nof animated representations of processes and so on.\nIn general, artists are able to design attractive solutions, to develop a distinctive style for a line \nof products or for a company, and to relate the design to the professional status of the user. There \nare, however, tradeoffs to be made. For example, artistic design sometimes conflicts with ergonomics. \nWhen strolling through a consumer electronics shop you will find artistic variants of mobile phones,\n\ncoffee machines, and audio systems where the designer seems to have paid a tribute to artistic shape \nand color, while making the device less intuitive and less easy to use, from the point of view of fitting \nthe relevant buttons to the size of the human hand. A similar fate may befall a user interface of an \ninformation system.\n16.3.3. Ergonomics\nErgonomics is concerned with the relation between human characteristics and artifacts. Ergonomics \ndevelops methods and techniques to allow adaptation between humans and artifacts (whether physical \ntools, complex systems, organizations, or procedures). In classical ergonomics, the main concern is \nanthropometries (statistics of human measures, including muscle power and attributes of human \nperception). During the past 25 years, cognitive ergonomics developed as a field that focuses mainly \non characteristics of human information processing in interaction with information systems. Cognitive \nergonomics is increasingly considered to be the core view for managing user interface design. A cognitive \nergonomist is frequently found to be the leader of the design team as far as the virtual machine is \nconcerned.\nFor beginning users, the human-computer conversation is often very embarrassing. The real beginner \nis a novice in using a specific computer program. He might even be a novice in computer use in general. \nSometimes he is also relatively new to", "token_count": 512, "start_token": 305382, "end_token": 305894, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 662, "text": "For beginning users, the human-computer conversation is often very embarrassing. The real beginner \nis a novice in using a specific computer program. He might even be a novice in computer use in general. \nSometimes he is also relatively new to the domain of the primary task (the office work for which he \nwill use the PC or the monitoring of the chemical process for which the computer console is the front \nend). In such a situation, problems quickly reach a level at which an expert is asked for help and \nthe user tends to blame the program or the system for his failure to use the new facility.\nThere seems to be a straightforward remedy for this dilemma: start by educating the user in the task \ndomain, next teach him everything about the facility, and only thereafter allow him access to the \ncomputer. This, however, is only a theoretical possibility. Users will insist on using the computer \nfrom the outset, if they intend ever to use it, and introducing a task domain without giving actual \nexperience with the system that is designed for the task is bad education. So the cure must be found \nin another direction. The designer of the system must start from a detailed ’model of the user’ and \na ’ model of the task’ . If he knows that the user is a novice both on the task domain and on the system, \nhe will have to include options for learning both these areas at the same time.\nIn general, the system designer will try to apply cognitive ergonomic knowledge and adapt the interface \nto the intended task rather than vice versa. The system should be made transparent (unobtrusive) as \nfar as anything but the intended task is concerned. This should facilitate the user’ s double task: \nto delegate tasks to the system and to learn how to interact with the system. However, in many cases \nthis cannot be accomplished completely in one direction and a solution has to be found by adapting \nthe human user to the artifact, i.e. by teaching and training the user or by selecting users that are \nable to work with the artifacts. Adapting the user to the artifacts requires a strong motive, though. \nConstraints of available technology, economic aspects, and safety arguments may contribute to a decision \nin this direction. A mobile phone has only a few keys and a fairly small screen. Instead of designing \nan ’", "token_count": 512, "start_token": 305844, "end_token": 306356, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 663, "text": " though. \nConstraints of available technology, economic aspects, and safety arguments may contribute to a decision \nin this direction. A mobile phone has only a few keys and a fairly small screen. Instead of designing \nan ’ intuitive’ airplane cockpit that would allow an average adult to fly without more than a brief\n\nseries of lessons, analogous to driving a car, most airlines prefer to thoroughly select and train \ntheir pilots.\nCognitive ergonomics developed when information technology started to be applied by people whose \nexpertise was not in the domains of computer science or computer programming. The first ideas in this \nfield were elaborated more or less simultaneously in different parts of the world, and in communities \nthat used different languages, which resulted in several schools with rather specific characteristics. \nMuch of the early work in the US and Canada, for instance, is based on applying cognitive ergonomics \nto actual design problems. Also, success stories (such as the development of the Xerox Star) were, \nafter the fact, interpreted in terms of ergonomic design concepts (Smith et al., 1982). Carroll (1990) \ndescribes this as ’ the theory is in the artifact’. Conversely, European work in the field of cognitive \nergonomics has concentrated on the development of models: models of computer users, models of \nhuman-computer interaction, models of task structures, and so on. By now, these differences are fading \naway, but a lot of important sources still require some understanding of their cultural background.\n16.4. THE ROLE OF MODELS IN HUMAN-COMPUTER  \nINTERACTION\nThe concept of a model has an important place in the literature on human-computer interaction and \ncognitive ergonomics. Models represent relevant characteristics of a part of reality that we need to \nunderstand. At the same time, models are abstract: they represent only what is needed, thus helping \nus to find our way in complex situations. W e need to be aware of differences between types of model, \nthough, and of the inconsistent use of names for the various types of model. First, we discuss the \ndifference between internal and external models in human-computer interaction.\nInternal models are models ’for execution’. Internal models use an agent (a human or a machine) who \nmakes a decision based on the behavior of", "token_count": 512, "start_token": 306306, "end_token": 306818, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 664, "text": " \ndifference between internal and external models in human-computer interaction.\nInternal models are models ’for execution’. Internal models use an agent (a human or a machine) who \nmakes a decision based on the behavior of the model. If the agent is human, this model is termed a \nmental model in psychology. Humans apply these models whenever they have to interact with complex systems. \nW e discuss mental models in Section 16.4.2.\nIf the agent is a machine, the internal model is a program or a knowledge system. For example, a user \ninterface may retain a model of the user. In that case the literature mostly speaks of a user model: \na model of the user that is used by the interface. The model could help the interface to react differently \nto different users or, alternatively, to adjust to the current user depending on the machine’ s \nunderstanding of that user’ s current goals or level of understanding. User models of this type may \nbe designed to learn from user behavior and are commonly used in so-called intelligent user interfaces. \nA third type of internal model in machines is a model of the task domain, which enables the user and \nthe system to collaborate in solving problems about the task. The latter type of internal model leads \nto systems that can reason, critique user solutions, provide diagnosis, or suggest user actions. User \nmodels are not discussed further in this book.\nExternal models are used for communication and, hence, are first of all represented in some type of \nformalism (which could also be a graphical representation such as a Petri net or flow diagram). The\n\nformalism should be chosen in relation to what is being modeled, as well as to the goal of the \ncommunication. In designing user interfaces, there are several domains where external models are needed. \nDesigners need to understand some relevant aspects of the user, especially human information processing. \nCognitive psychology provides such types of knowledge, hence in Section 16. 4.1 we briefly discuss a \nrecent variant of the model of human information processing, only mentioning those aspects that are \nrelevant when designing for users of computers. Another type of model is used in the various types \nof design activity. These external models help designers to document their decisions, to backtrack \nwhen one design decision overrules another, and to communicate the result of", "token_count": 512, "start_token": 306768, "end_token": 307280, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 665, "text": " for users of computers. Another type of model is used in the various types \nof design activity. These external models help designers to document their decisions, to backtrack \nwhen one design decision overrules another, and to communicate the result of one design phase to people \nresponsible for another phase (e. g. to communicate a view of the task to a colleague responsible for \nusability evaluation). In Section 16.4.3, we give some examples of external models used in various \ndesign activities. These models are the HCI-oriented counterparts of the requirements representation \nformats discussed in Chapter 9.\nSome types of model, such as task knowledge models, refer to aspects that are both internal and external. \nTask knowledge is originally to be found in the memory of human beings, in documents about the work \ndomain, and in the actual situation of the work environment. These are internal models, applied while \ndoing the work. Designers need to understand this knowledge and apply it as the base of their design, \nhence they need to perform task analysis and model the task knowledge. This is an external model for \nuse in design. Task models and task modeling are treated in Section 16.6.\n16.4.1. A Model of Human Information Processing\nThe model of human information processing is an example of an external model. W e only briefly mention \nsome notions that need to be understood in analyzing human-computer interaction. W e focus on human \nperception, memory, and the processing of information in relation to the input and output of the human \nin interaction with an outside system. Figure 16. 4 depicts this model. In textbooks on psychology, \na figure such as this is often adorned with formulae that allow calculation of the speed of processing, \nthe effect of learning, etc.\n\nFigure 16.4. A model of human information processing\nIn modern cognitive psychology, perception (the input of human information processing) is considered \nto proceed through a number of phases:\n1. Edge detection: the large amount of unstructured information that bombards our senses is \nautomatically and quickly structured, e.g. into phonemes (hearing) or a ’ 2. 5-D sketch’ based \non movement, color, and location (vision).\n2. Gestalt formation: a small number of understandable structures (such as a triangle,", "token_count": 512, "start_token": 307230, "end_token": 307742, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 666, "text": "emes (hearing) or a ’ 2. 5-D sketch’ based \non movement, color, and location (vision).\n2. Gestalt formation: a small number of understandable structures (such as a triangle, a word, \nand a tactile shape) known as ’gestalts’ are formed, based on similarities detected in the \nsketch, on spatial relations and on simplicity.\n3. Combination: the gestalts are combined into groups of segments that seem to belong together: \nan object consisting of triangles, cubes and cylinders; a spoken utterance consisting of a \nseries of words.\n4. Recognition: the group of segments is recognized as, for example, a picture of a horse or a \nspoken sentence.\nThe processing in the later phases is done less and less automatically. People are aware of gestalt \nformation and combination when any problem arises, for example because of irregularity or exceptional \nsituations such as ’ impossible’ figures. Recognition leads to conscious perception.\nThe whole series of phases takes a fraction of a second. It takes more time when a problem occurs because \nof an unexpected or distorted stimulus. It takes less time when the type of stimulus is familiar. So \nwe may train our computer users to perceive important signals quickly and we may design our signals \nfor easy and quick detection and discrimination. Psychologists and ergonomists know when a signal is \neasy to detect, what color combinations are slow to be detected, and what sounds are easy to discriminate.\n\nThe output of human beings is movement. People make gestures, manipulate tools, speak, or use a \ncombination of these. For computer use, manipulation of keys, mouse or touch-screen, and speaking into \nmicrophones are common examples of output. According to modern psychology, all those types of output \nare monitored by a central processing mechanism in the human. This central executive decides on the \nmeaning of the output (say yes, move the mouse to a certain location, press the return key) but leaves \nthe actual execution to motor processes that, in normal cases, are running ’ unattended’ , i. e. the actual \nexecution is not consciously controlled. Only in case of problems is attention needed. For example, \nif the location to be pointed to on the screen is in an awkward position, if a", "token_count": 512, "start_token": 307692, "end_token": 308204, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 667, "text": "’ , i. e. the actual \nexecution is not consciously controlled. Only in case of problems is attention needed. For example, \nif the location to be pointed to on the screen is in an awkward position, if a key is not functioning \nproperly, or if the room is so noisy that the person cannot properly hear his own spoken command. So \nwe should design for human movements and human measures. It pays to ask an ergonomist about the most \nergonomic design of buttons and dials.\nThe central executive unit of human information processing is modeled as an instance that performs \nproductions of the form if condition then action, where the condition in most cases relates \nto some perceived input or to some knowledge available from memory. The action is a command to the \nmotor system, with attributes derived from working memory. The central executive unit has a very limited \ncapacity. First of all, only a very small number of processes can be performed simultaneously. Secondly, \nthe knowledge that is needed in testing the condition as well as the knowledge that is processed on \nbehalf of the motor output has to be available in working memory. Most of the time, we may consider \nthe limitations to result in the execution of one process at a time and, consequently, in causing \ncompeting processes to be scheduled for sequential execution based on perceived priority. For example, \nwhen a driver approaches a crossroads, the talk with his passenger will be temporarily interrupted \nand only resumed when the driving decisions have been made. The amount of available resources has to \nbe taken into account when designing systems. For example, humans cannot cope with several error messages \neach of which requires an immediate decision, especially if each requires complex error diagnosis to \nbe performed before reaction is feasible.\nWorking memory is another relevant concept in the model. Modern psychology presumes there is only one \nmemory structure, long-term memory, that contains knowledge that is permanently stored. Any stimulus \nthat reaches the central executive unit leads to the activation of an element in long-term memory. \nThe activated elements together form the current working memory. The capacity of the set of activated \nelements is very limited. The average capacity of the human information processor is 5 -9 elements. \nIf new elements are activated, other elements lose their activation status and, hence, are no longer \nimmediately available to the central", "token_count": 512, "start_token": 308154, "end_token": 308666, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 668, "text": "\nelements is very limited. The average capacity of the human information processor is 5 -9 elements. \nIf new elements are activated, other elements lose their activation status and, hence, are no longer \nimmediately available to the central executive. In other words, they are not in working memory any \nmore.\nLong-term memory is highly structured. One important type of relation concerns semantic relations \nbetween concepts, such as part-of, member-of, and specialization-generalization. In fact, each piece \nof knowledge can be considered a concept defined by its relation to other elements. Such a piece of \nknowledge is often called a chunk. It is assumed that working memory has a capacity of 5 -9 chunks. \nAn expert in some task domain is someone who has available well-chosen chunks in that domain, so that \nhe is able to expand any chunk into relevant relations, but only when needed for making decisions and \nderiving an answer to a problem. If not needed, an expert will not expand the chunk that has been triggered \nby the recognition phase of perception or by the production based on a stimulus. For example, the sequence \nof digits ’ 85884’ could occupy five entries in working memory. However, if it is your mother’ s telephone\n\nnumber, it is encoded as such and occupies only one entry. When the number has to be dialed, this single \nentry is expanded to a series of digits again. Entries in working memory can thus be viewed as labels \ndenoting some unit of information, such as a digit, your mother’ s telephone number, or the routine \nquicksort. In this way an expert can cope with a situation even with the restrictions on the capacity \nof working memory.\nThe structures in long-term memory are the basis for solving problems in a domain and for expertise. \nWhen working with a system, people develop a suitable knowledge structure for performing their tasks. \nIf they are able to understand the system as much as they need (we defined this as the virtual machine \nin Section 16. 2), they may develop a coherent and useful structure in long-term memory. As far as this \nstructure can be considered a model of the system, we consider it to be the mental model of the system.\n16.4.2. Mental Models of Information Systems\nMental models are structures", "token_count": 512, "start_token": 308616, "end_token": 309128, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 669, "text": "term memory. As far as this \nstructure can be considered a model of the system, we consider it to be the mental model of the system.\n16.4.2. Mental Models of Information Systems\nMental models are structures in long-term memory. They consist of elements and relations between those \nelements. They represent relevant knowledge structures analogous to physical, organizational, and \nprocedural structures in the world. These mental models become ’ instantiated’ when activated by an \nactual need, e. g. when one needs to make a decision related to an element of this knowledge. The activated \nmental model is, to a certain extent, run or executed in order to predict how the structure in the \nworld that is represented by the mental model would behave in relation to the current situation and \nin reaction to the possible actions of the person. In the terminology introduced before, mental models \nare internal models.\nWhen working with complex systems, where part of the relevant structure and processes of the system \ncannot be perceived by a human being or cannot be completely monitored, a mental model is needed to \nbehave optimally in relation to the system. Hence, people develop mental models of such situations \nand systems. If the system is a computer system, there are four functions of using the system that \nrequire the activation of a mental model:\n• When planning the use of the technology, users will apply their knowledge (i.e. their mental \nmodel) to find out for what part of their task the system could be used and the conditions \nfor its use. Users will determine what they need to do beforehand, when they would like to \nperform actions and take decisions during the use of the system, and when they would abort \nexecution or reconsider use.\nSuppose I want to use our library information system to search for literature on mental models \nof computer systems. I may decide to search by author name. First, I must find one or a few \ncandidate authors.\n• During execution of a task with a system, there is a continuous need for fine-tuning of user \nactions towards system events. The mental model is applied to monitoring the collaboration \nand reconsidering decisions taken during the planning stage.\n\nIf the result of my search action is not satisfactory, I may decide to look up alternative \nauthor names or switch to a keyword", "token_count": 512, "start_token": 309078, "end_token": 309590, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 670, "text": " The mental model is applied to monitoring the collaboration \nand reconsidering decisions taken during the planning stage.\n\nIf the result of my search action is not satisfactory, I may decide to look up alternative \nauthor names or switch to a keyword search. If the keywords used by the system are keywords \nlisted in the titles of publications, there is quite a chance that relevant literature is not \nfound by a search using the keywords mental model. I may then consider other keywords \nas well, such as human-computer interaction.\n• If the system has performed some tasks for the user and produced output, there is the need \nto evaluate the results, to understand when to stop, and to understand the value of the results \nin relation to the intended task. The mental model of the system is needed to evaluate the \nsystem’s actions and output, and to translate these to the goals and needs of the user.\nSome of the literature sources found may have titles that indicate a relation between mental \nmodels and learning, while others relate mental models to personality factors. I may decide \nto keep only those titles that relate mental models to HCI, since the others are probably not \nrelevant.\n• Modern computer systems are frequently not working in isolation and more processes may be going \non than those initiated by current use. The user has to cope with unexpected system events, \nand needs to interpret the system’ s behavior in relation to the intended task as well as to \nthe state of the system and the network of related systems. For this interpretation, users \nneed an adequate mental model of the system and its relation to the current task.\nI may accept a slow response to my query knowing that the answer is quite long and network \ntraffic during office hours is heavy.\nMental models as developed by users of a system are always just models. They abstract from aspects \nthe user considers not relevant and they have to be usable for a human information processor with his \nrestricted resources and capacities. Consequently, we observe some general restrictions in the \nqualities of human mental models of computer systems. Norman (1983) has shown that mental models of \nsystems of the complexity of a computer application have the following general characteristics:\n• They are incomplete and users are generally aware of the fact that they do not really know \nall details of the system, even if relevant. They will know, if they are experts", "token_count": 512, "start_token": 309540, "end_token": 310052, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 671, "text": " complexity of a computer application have the following general characteristics:\n• They are incomplete and users are generally aware of the fact that they do not really know \nall details of the system, even if relevant. They will know, if they are experts, where details \ncan be found.\n• They can only partly be ’ run’, because of the nature of human knowledge representation. I may \nknow how to express a global replacement in my text editor (i.e., I know the start and end \nsituation) without knowing how the intended effect is obtained.\n• They are unstable. They change over time, both because of users using different systems and \nspoiling the knowledge of the previously applied system and because of new experiences, even \nif the user has been considered a guru on this system for the past ten years.\n• They have vague boundaries. People tend to mix characteristics of their word processor with \naspects of the operating system and, hence, are prone to occasionally make fatal errors based \non well-prepared decisions.\n• They are parsimonious. People like to maintain models that are not too complex and try to stick \nto enough basic knowledge to be able to apply the model for the majority of their tasks. If\n\nsomething uncommon has to be done they accept having to do some extra operations, even if they \nknow there should be a simpler solution for those exceptions.\n• They have characteristics of superstitions that help people feel comfortable in situations \nwhich they know they do not really understand. An example is the experienced user who changes \nback to his root directory before switching off his machine or before logging out. He knows \nperfectly well there is no real need for this, but he prefers to behave in a nice and systematic \nway and hopes the machine will behave nicely and systematically in return.\nDesigners of user interfaces should understand the types of mental structures users tend to develop. \nThere are techniques for acquiring information about an individual user’ s mental models, as well as \nabout the generic mental structures of groups of users. Psychological techniques can be applied and, \nin the design of new types of system, it is worthwhile to apply some expert help in assessing the knowledge \nstructures that may be needed for the system, as well as those that may be expected to be developed \nby users. If the knowledge needed differs from the mental models developed in actual", "token_count": 512, "start_token": 310002, "end_token": 310514, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 672, "text": " worthwhile to apply some expert help in assessing the knowledge \nstructures that may be needed for the system, as well as those that may be expected to be developed \nby users. If the knowledge needed differs from the mental models developed in actual use, there is \na problem and designers should ask for expert help before the design results in an implementation that \ndoes not accord with the users’ models.\n16.4.3. Conceptual Models in User Interface Design\nA central part of user interface design is the stepwise-refined specification of the system as far \nas it is relevant for the user. This includes the knowledge the user needs in order to operate the \nsystem, the definition of the dialog between user and system, and the functionality that the system \nprovides to the user. All that is specified in the design process is obviously also explicitly modeled, \nin order to make sure imple mentation does not result in a system that differs from the one intended. \nIn cognitive ergonomics, all that is modeled about the system as far as relevant to its different sets \nof users is called the conceptual model of the system (Norman, 1983).\nFormal design modeling techniques have been developed in order to communicate in design teams, to \ndocument design decisions, to be able to backtrack on specifications, and to calculate the effects \nof design specifications. Some techniques model the user’s knowledge (so-called competence models), \nothers focus on the interaction process (so-called process models), and others do both. Reisner’s \nPsychological BNF (Reisner, 1981) is an example of a competence model. In this model, the set of valid \nuser dialogs is defined using a context-free grammar. Process models may model time aspects of \ninteraction, as in the Keystroke model (Card et al., 1983) which gives performance predictions of \nlow-level user actions. Task Action Grammar (TAG) (Payne and Green, 1989) is an example of a combined \nmodel. It allows the calculation of indexes for learning (the time needed to acquire knowledge) and \nfor ease of use (mental load, or the time needed for the user’s part of executing a command).\nMoran (1981) was one of the first to structure the conceptual model into components, somewhat akin \nto the Seeheim model.", "token_count": 512, "start_token": 310464, "end_token": 310976, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 673, "text": " use (mental load, or the time needed for the user’s part of executing a command).\nMoran (1981) was one of the first to structure the conceptual model into components, somewhat akin \nto the Seeheim model. Even though, at that time, command dialogs were the only type of interactive \nuser interface available to the general public, his Command Language Grammar (CLG) still provides a \nremarkably complete view of the types of design decision to be made during user interface design. \nAdditionally, Moran was the first to state that a conceptual model can be looked upon from three different \nviewpoints:\n\n• The psychological view considers the specification as the definition of all that a user should \nunderstand and know about the new system.\n• The linguistic view describes the interaction between human and system in all aspects that \nare relevant for both participants in the dialog.\n• The design view specifies all that needs to be decided about the system from the point of view \nof the user interface design.\nMoran distinguishes six levels in the conceptual model, structured in three components. Each level \ndetails concepts from a higher level, from the specific point of view of the current level. The formalism \nthat Moran proposes (the actual grammar) would nowadays be replaced by more sophisticated notations, \nbut the architectural concepts show the relevance of analyzing design decisions from different \nviewpoints and at the same time investigating the relationships between these viewpoints:\na. Conceptual component. This component concerns design decisions at the level of functionality: \nwhat will the system do for the users.\na. 1 Task level. At this level we describe the task domain in relation to the system: which \ntasks can be delegated to the machine, which tasks have to be done by the user in relation \nto this (preparation, decisions in between one machine task and the next, etc.). A \nrepresentation at this level concerns tasks and task-related objects as seen from the eyes \nof the user, not detailing anything about the system, such as ’print a letter on office \nstationery’ or ’ store a copy’ .\na. 2 Semantic level. Semantics in the sense of CLG concern the system’ s functionality in relation \nto the tasks that can be delegated. At this level, task delegation is specified in relation \nto the system", "token_count": 512, "start_token": 310926, "end_token": 311438, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 674, "text": "\na. 2 Semantic level. Semantics in the sense of CLG concern the system’ s functionality in relation \nto the tasks that can be delegated. At this level, task delegation is specified in relation \nto the system. The system objects are described with their attributes and relevant states, \nand the operations on these objects as a result of task delegation are specified. For example, \nthere may be an object letter with an attribute print date and an operation to store \na copy in another object called printed letters with attributes list of printed \nletters and date of last storage operation.\nIn terms of the Seeheim model, this level describes the application interface.\nb. Communication component. This component describes the dialog of the Seeheim model.\nb. 1 Syntax level. This level describes the dialog style, such as menus, form-filling, commands, \nor answering questions, by specifying the lexicographical structure of the user and system \nactions. For example, to store a letter, the user has to indicate the letter to be stored, \nthen the storage location, then the storage command, and, finally, an end-of-command \nindication.\nb. 2 Keystroke level. The physical actions of the user and the system are specified at this \nlevel, such as clicking the mouse buttons, pointing, typing, dragging, blinking the cursor, \nand issuing beeping signals.\n\nc. Material component. At this level, Moran refers to the domain of classical ergonomics, \nincluding perceptual aspects of the interface, as well as relevant aspects of the hardware. \nThe presentation aspect of the Seeheim model is located at the spatial layout level.\nc. 1 Spatial layout level. The screen design, for example, the shape, color, and size of icons \nand characters on the screen, and the size of buttons, is specified at this level. This level \nis also intended to cover sound and tactile aspects of the interface (such as tactile mouse \nfeedback) not covered by the hardware.\nc. 2 Apparatus level. At this level, Moran suggests we specify the shape of buttons and the \npower needed to press them, as well as other relevant hardware aspects.\nMoran s CLG provides a fairly complete specification model for the user interface or UVM . The actual \ngrammar representation is no longer relevant, but the layers", "token_count": 512, "start_token": 311388, "end_token": 311900, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 675, "text": "\npower needed to press them, as well as other relevant hardware aspects.\nMoran s CLG provides a fairly complete specification model for the user interface or UVM . The actual \ngrammar representation is no longer relevant, but the layers and their relations are important, and \nthe design models discussed in the next section cover most of them: task models relate to Moran’s task \nlevel and the UVM  specifications include the semantic level, the communication component, and parts \nof the spatial layout level.\n16.5. THE DESIGN OF INTERACTIVE SYSTEMS\nThe concept user interface in this chapter denotes the complete UVM , the user’ s virtual machine. \nTraditional user interface design mainly concerns the situation of a single user and a monolithic system. \nIn current applications, computers are mostly part of a network, and users are collaborating, or at \nleast communicating, with others through networks. Consequently, the UVM  should include all aspects \nof communication between users as far as this communication is routed through the system. It should \nalso include aspects of distributed computing and networking as far as this is relevant for the user, \nsuch as access, structural, and time aspects of remote sources of data and computing. For example, \nwhen using a Web browser, it is relevant to understand mechanisms of caching and of refreshing or \nreloading a page, both in terms of the content that may have changed since the previous loading operation \nand in terms of the time needed for operations to complete.\nThese newer types of application bring another dimension of complexity into view. People are \ncollaborating in various ways mediated by information technology. Collaboration via systems requires \nspecial aspects of functionality. It requires facilities for the integration of actions originating \nfrom different users on shared objects and environments, facilities to manage and coordinate the \ncollaboration, and communication functionality. Such systems are often denoted as groupware. Modern \nuser interface design techniques cater for both the situation of the classical single user system and \ngroupware. W e expect this distinction to disappear in the near future.\nThere are several classes of stakeholder in system development (see also Chapter 9). These include, \nat least, the clients, i. e. the people or organizations that pay for the design or acquisition of systems, \nand the users, i. e. the people or groups that apply the systems as", "token_count": 512, "start_token": 311850, "end_token": 312362, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 676, "text": " 9). These include, \nat least, the clients, i. e. the people or organizations that pay for the design or acquisition of systems, \nand the users, i. e. the people or groups that apply the systems as part of their daily work, often \nreferred to as the end users. Throughout the process of design, these two classes of stakeholders have \nto be distinguished, since they may well have different goals for the system, different (and possibly\n\neven contradictory) knowledge about the task domain, and different views on what is an optimal or \nacceptable system. This does not mean that in certain situations these classes will not overlap. But \neven if this is the case, individual people may well turn out to have contradictory views on the system \nthey need. In many situations there will be additional classes of stakeholders to cater for, such as \npeople who are involved in maintaining the system, and people who need traces or logs of the system \nto monitor cases of failure or abuse, such as lawyers.\nIn relation to these different classes of stakeholders, designers are in a situation of potential \npolitical stress. Clients and users may have contradictory inputs into the specification of the system. \nMoreover, the financial and temporal constraints on the amount of effort to be invested in designing \nthe different aspects of the system (such as specifying functionality and user interface, implementation \nand testing) tend to counteract the designers’ ambitions to sufficiently take care of the users’ needs.\nMaking a distinction between classes of stakeholders does not solve the problem of user diversity. \nIn complex systems design, we are confronted with different end users playing different roles, as well \nas end-user groups that have knowledge or a view on the task domain that need not be equivalent to \nthe (average or aggregated) knowledge and views of the individuals.\n16.5.1. Design as an Activity Structure\nViewing design as a structure of interrelated activities, we need a process model. The model we use \nwill be familiar to readers of this book: it is a cyclical process with phases devoted to analysis, \nspecification, and evaluation. Figure 16. 5 depicts this process model.\nFigure 16.5. A process model for user interface design\nAnalysis: Since the system to be developed will feature in a task situation, we start with task analysis. \nW e further structure this activity into the development", "token_count": 512, "start_token": 312312, "end_token": 312824, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 677, "text": " this process model.\nFigure 16.5. A process model for user interface design\nAnalysis: Since the system to be developed will feature in a task situation, we start with task analysis. \nW e further structure this activity into the development of two models: task model 1, which models the \ncurrent task situation, and task model 2, which models the task domain of the future situation, where \nthe system to be developed will be used, including changes in the organization of people and work\n\nprocedures. The relationship between task models 1 and 2 reflects the change in the structure and \norganization of the task world as caused by the implementation of the system to be developed. As such, \nthe difference is relevant both for the client and the user.\nThe development of task model 2 from task model 1 uses knowledge of current inadequacies and problems \nconcerning the existing task situation, needs for change as articulated by the clients, and insight \ninto current technological developments. Section 16.6 discusses task analysis.\nSpecification: The specification of the system to be designed is based on task model 2. It has to be \nmodeled in all details that are relevant to the users, including cooperation technology and \nuser-relevant system structure and network characteristics. Differences between the specification of \nthe new system (the user’s virtual machine or UVM) and task model 2 must be considered explicitly and \nlead to design iteration. Specifying the UVM  is elaborated in Section 16.7.\nEvaluation: The specification of the new system incurs many design decisions that have to be considered \nin relation to the system’s prospective use. For some design decisions, guidelines and standards might \nbe used as checklists. In other situations, formal evaluation may be applied, using formal modeling \ntools that provide an indication of the complexity of use or learning effort required. For many design \ndecisions, however, evaluation requires confronting the future user with relevant aspects of the \nintended system. Some kind of prototyping is a good way to confront the user with the solution proposed. \nA prototype allows experimentation with selected elements or aspects of the UVM . It enables imitation \nof (aspects of) the presentation interface, it enables the user to express himself in (fragments of) \nthe interaction language, and it can be used to simulate aspects of the functionality, including \norgan", "token_count": 512, "start_token": 312774, "end_token": 313286, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 678, "text": " enables imitation \nof (aspects of) the presentation interface, it enables the user to express himself in (fragments of) \nthe interaction language, and it can be used to simulate aspects of the functionality, including \norganizational and structural characteristics of the intended task structure. W e discuss some \nevaluation techniques in Section 16.8.\nFigure 16. 5 is similar to Figure 9. 1. This is not surprising. The design of an interactive system as \ndiscussed in this chapter is very akin to the requirements engineering activity discussed in Chapter\n9. The terminology is slightly different and reflects the user-centered stance taken in this chapter. \nFor example, ’elicitation’ sounds more passive than ’analysis’. ’Evaluation’ entails more than \n’validation’ ; it includes usability testing as well. Finally, we treat the user and the task domain \nas one entity from which requirements are elicited. In the approach advocated here, the user is observed \nwithin the task domain.\n16.5.2. Design as Multi-Disciplinary Collaboration\nThe main problem with the design activities discussed in the previous section is that different methods \nmay provide conflicting viewpoints and goals. A psychological focus on individual users and their \ncapacities tends to lead to Taylorism, neglecting the reality of a multitude of goals and methods in \nany task domain. On the other hand, sociological and ethnographical approaches towards groupware design \ntend to omit analysis of individual knowledge and needs. Still, both extremes provide unique \ncontributions.\n\nIn order to design for people, we have to take into account both sides of the coin: the individual \nusers and clients of the system, and the structure and organization of the group for which the system \nis intended. W e need to know the individuals’ knowledge and views on the task, on applying the technology, \nand the relation between using technology and task-relevant user characteristics (expertise, knowledge, \nand skills). With respect to the group, we need to know its structure and dynamics, the phenomenon \nof ’ group knowledge’ and work practice and culture. These aspects are needed in order to acquire insight \ninto both existing and projected task situations where (new) cooperation technology is introduced. \nBoth types of insight are also needed in relation to design", "token_count": 512, "start_token": 313236, "end_token": 313748, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 679, "text": " group knowledge’ and work practice and culture. These aspects are needed in order to acquire insight \ninto both existing and projected task situations where (new) cooperation technology is introduced. \nBoth types of insight are also needed in relation to design decisions, for functionality and for the \nuser interface. Consequently, in prototyping and field-testing, we need insight into the acceptance \nand use by individuals and the effect of the new design on group processes and complex task dynamics.\nFor example, in a traditional bank setting, the client and the bank employee are on different sides \nof a counter. The bank employee is probably using a computer, but the client cannot see the screen, \nand does not know what the clerk is doing. In a service-oriented bank setting, the clerk and client \nmay be looking at the screen together. They are together searching for a solution to the client’s question. \nThis overturns the existing culture of the bank and an ethnographer may be asked to observe what this \nnew setup brings about.\nThe general framework for our approach to user interface design is depicted in Figure 16.6. It is a \nrefinement of Figure 16. 5, emphasizing the specialties involved in carrying out different activities. \nTask model 1 is based on knowledge of single users (psychological variables, task-related variables, \nknowledge, and skills) and on complex phenomena in the task situation (roles, official and actual \nprocedures, variation in strategies, and variation in the application of procedures). The integration \nof this insight in a model often does not provide a single (or a single best) decomposition of tasks \nand a unique structure of relationships between people, activities, and environments. The model often \nshows alternative ways to perform a certain task, role-specific and situation-specific methods and \nprocedures, and a variety of alternative assignments of subtasks to people. For example, the joint \nproblem-solving approach to the bank counter, sketched out above, cannot be applied to the drive-in \ncounter of the bank. The drive-in counter requires a different approach and a different user interface.\nFrom this, and because of client requirements, compromises often have to be made in defining task model\n2, the new task situation for which the technology has to be designed. This process includes the \ninterpretation of problems in the current task situation,", "token_count": 512, "start_token": 313698, "end_token": 314210, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 680, "text": " this, and because of client requirements, compromises often have to be made in defining task model\n2, the new task situation for which the technology has to be designed. This process includes the \ninterpretation of problems in the current task situation, negotiation with the client regarding his \nconditions, and the resources available for design (including both financial impacts and time \nconstraints). Ultimately, decisions have to be made about complex aspects, such as re-arranging the \nbalance of power and the possibilities for users in various roles to exercise control.\n\nFigure 16.6. Structure of design team activities\nAgain, when detailed design decisions are being considered, early evaluation needs to include analytical \nmethods (formal evaluation and cognitive walkthrough techniques) in combination with usability testing \nwhere users in different roles are studied both in the sense of traditional individual measures and \nin the sense of ethnographic interaction analysis.\n16.6. TASK ANALYSIS\nAnalyzing a complex system means analyzing the world in which the system functions, the context of \nuse, which comprises (according to standards such as (ISO 9241, 1996)):\n• the users;\n• the tasks;\n• the equipment (hardware, software, and materials);\n• the social environment;\n• the physical environment.\nIf we design systems for the context of use, we must take these different aspects of the task world \ninto consideration. In traditional literature on task analysis from the HCI mainstream, the focus is\n\nmostly on users, tasks, and software. Design approaches for groupware and computer-supported \ncollaborative work (CSCW), on the other hand, often focus on analyzing the world first of all from \nthe point of view of the (physical and social) environment. Recent approaches to task modeling include \nsome aspects that belong to both categories, but it still looks as if one has to, by and large, opt \nfor one view or the other. Section 16.6.1 presents task analysis approaches from the classical HCI \ntradition and distinguishes different phases in task analysis. Section 16. 6. 2 presents an ethnographic \npoint of view, as frequently applied to the design of CSCW systems, where phases in the analysis process \nare hardly considered.\nJordan (1996), though originally working from an ethnographic approach and focusing on groupware \napplications,", "token_count": 512, "start_token": 314160, "end_token": 314672, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 681, "text": " view, as frequently applied to the design of CSCW systems, where phases in the analysis process \nare hardly considered.\nJordan (1996), though originally working from an ethnographic approach and focusing on groupware \napplications, provides a view on analyzing knowledge of the task world that is broad enough to cover \nmost of the context of use as now defined by ISO 9241 (1996). W e illustrate Jordan’ s view in Section \n16. 6.3. The groupware task analysis (GTA) framework of modeling task knowledge combines approaches \nfrom both HCI and CSCW design. GTA is described in Section 16.6.4.\n16.6.1. Task Analysis in HCI Design\nClassical HCI features a variety of notions regarding task analysis. Task analysis can mean different \nactivities:\n• analyzing a current task situation,\n• envisioning a task situation for which information technology is to be designed, or\n• specifying the semantics of the information technology to be designed.\nMany HCI task analysis methods combine more than one of these activities and relate them to actual \ndesign stages. Others do not bother about the distinction. For example, goals, operators, methods, \nand selection rules (GOMS, see (Card et al., 1983)) can be applied for any or a combination of the \nabove activities.\nIn many cases, the design of a new system is triggered by an existing task situation. Either the current \nway of performing tasks is not considered optimal, or the availability of new technology is expected \nto allow an improvement over current methods. A systematic analysis of the current situation may help \nformulate requirements and allow later evaluation of the design. In all cases where a current version \nof the task situation exists, it pays to model this. Task models of this type pretend to describe the \nsituation as it can be found in real life, by asking or observing people who know the situation (see \n(Johnson, 1989)). Task model 1 is often considered to be generic, indicating the belief that different \nexpert users have at their disposal basically the same task knowledge.\nMany design methods in HCI that start with task modeling are structured in a number of phases. After \ndescribing a current situation (in task model 1), the method requires a re-design of the task structure \nin order to include technological solutions for problems and technological answers", "token_count": 512, "start_token": 314622, "end_token": 315134, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 682, "text": " start with task modeling are structured in a number of phases. After \ndescribing a current situation (in task model 1), the method requires a re-design of the task structure \nin order to include technological solutions for problems and technological answers to requirements. \nTask model 2 is in general formulated and structured in the same way as task model 1. However, it is \nnot considered a descriptive model of users’ knowledge, though in some cases it may be applied as a \nprescriptive model of the knowledge an expert user of the new technology should possess.\n\nA third type of modeling activity focuses on the technology to be designed. This may be considered \npart of task model 2. However, some HCI approaches distinguish specific design activities which focus \non the technology (e.g. see (Tauber, 1990)). This part of the design activity is focused on a detailed \ndescription of the system as far as it is of direct relevance to the end user, i. e. the UVM . W e separate \nthe design of the UVM  from the design of the new task situation as a whole, mainly because the UVM  \nmodels the detailed solution in terms of technology, whereas task model 2 focuses on the task structure \nand work organization. In actual design, iteration is needed between the specification of these two \nmodels. This should be an explicit activity, making the implications of each obvious in its consequences \nfor the other. Specifying the UVM  is treated in more detail in Section 16.7.\nHCI task models represent a restricted point of view. All HCI task modeling is rather narrowly focused, \nmainly considering individual people’s tasks. Most HCI approaches are based on cognitive psychology. \nJohnson (1989) refers to knowledge structures in long-term memory. Tauber (1990) refers to ’knowledge \nof competent users’. HCI approaches focus on the knowledge of individuals who are knowledgeable or \nexpert in the task domain, whether this domain already exists (task model 1) or still has to be \nre-structured by introducing new technology (task model 2 and the UVM).\nAs a consequence of their origin, HCI task models seldom provide an insight into complex organizational \naspects, situational conditions for task performance, or complex relationships between tasks of \nindividuals with different roles. Business processes and business goals (such", "token_count": 512, "start_token": 315084, "end_token": 315596, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 683, "text": "As a consequence of their origin, HCI task models seldom provide an insight into complex organizational \naspects, situational conditions for task performance, or complex relationships between tasks of \nindividuals with different roles. Business processes and business goals (such as the service focus \nof a modern bank counter, which may be found in a business reengineering project) are seldom part of \nthe knowledge of individual workers and, consequently, are seldom related to the goals and processes \nfound in HCI task modeling.\nTask analysis assumes there are tasks to analyze. Many current Web applications, though, are \ninformation-centric. The value of such systems is in the information they provide (Wikipedia, Amazon, com \nand so on), and to a much lesser extent in the tasks they offer to the user. The key operation is searching. \nThe developers seek to make searching simpler by organizing the information in a logical way, by \nproviding navigation schemes, and so on (Nerurkar, 2001). The challenge for such applications is to \ninduce the users to provide ever more information. This is another example of crowdsourcing, as already \nmentioned in Chapter 1.\n16.6.2. Analysis Approaches for Collaborative Work\nCSCW work stresses the importance of situational aspects, group phenomena and organizational structure \nand procedures. Shapiro (1996) even goes so far as to state that HCI has failed in the case of task \nanalysis for cooperative work situations, since generic individual knowledge of the total complex task \ndomain does not exist. The CSCW literature strongly advocates ethnographic methods.\nEthnographers study a task domain (or community of practice) by becoming a participant observer, if \npossible with the status of an apprentice. The ethnographer observes the world ’ through the eyes of \nthe aboriginal’ and at the same time is aware of his status as an outside observer whose final goal \nis to understand and describe for a certain purpose and a certain audience (in the case of CSCW, a \ndesign project). Ethnographers start their observation purposely without a conceptual framework\n\nregarding characteristics of task knowledge, but, instead, may choose to focus on activities, \nenvironments, people, or objects. The choice of focus is itself based on prior ethnographic observations, \nwhich illustrates the bootstrapping character of knowledge elicitation in ethno-methodology. Methods \n", "token_count": 512, "start_token": 315546, "end_token": 316058, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 684, "text": " focus on activities, \nenvironments, people, or objects. The choice of focus is itself based on prior ethnographic observations, \nwhich illustrates the bootstrapping character of knowledge elicitation in ethno-methodology. Methods \nof data collection nowadays start with video recordings of relevant phenomena (the relevance of which, \nagain, can only be inferred from prior observation) followed by systematic transaction analysis, where \ninter-observer agreement serves to improve the reliability of interpretation. Knowledge of individual \nworkers in the task domain may be collected as far as it seems to be relevant, but it is in no sense \na priori considered the main source and is never considered indicative of generic task knowledge.\nThe ethnographic approach is unique in its attention to all relevant phenomena in the task domain that \ncannot be verbalized explicitly by (all) experts (see (Nardi, 1995)). The approach attends to knowledge \nand intentions that are specific for some actors only, to conflicting goals, to cultural aspects that \nare not perceived by the actors in the culture, to temporal changes in beliefs, to situational factors \nthat are triggers or conditions for strategies, and to non-physical objects such as messages, stories, \nsignatures and symbols, of which the actors may not be aware while interacting.\nEthno-methodology covers the methods of collecting information that might serve as a basis for \ndeveloping task model 1 (and no more than this since ethno-methodology only covers information on the \ncurrent state of a task domain). However, the methodology for the collection of data and its structuring \ninto a complete task domain description is often rather special and difficult to follow in detail. \nThe general impression is that CSCW design methods skip the explicit construction of task models 1 \nand 2 and, after collecting sufficient information on the community of practice, immediately embark \non specifying the UVM , based on deep knowledge of the current task situation that is not formalized. \nThis may cause two types of problem. Firstly, the relationship between specifications for design and \nanalysis of the current task world might depend more on intuition than on systematic design decisions. \nSecondly, skipping the development of task model 2 may lead to conservatism with respect to \norganizational and structural aspects of the work for which a system is to be (re)designed.\n16.6.3. Sources of Knowledge and Collection Methods\nCollect", "token_count": 512, "start_token": 316008, "end_token": 316520, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 685, "text": " the development of task model 2 may lead to conservatism with respect to \norganizational and structural aspects of the work for which a system is to be (re)designed.\n16.6.3. Sources of Knowledge and Collection Methods\nCollecting task knowledge to analyze the current situation of a complex system has to start by \nidentifying the relevant knowledge sources. In this respect, we refer to a framework derived from (Jordan, \n1996), see Figure 16. 7. The two dimensions of this framework denote where the knowledge resides and \nhow it can be communicated. For example, A stands for the explicit knowledge of an individual, while \nD stands for the implicit knowledge of a group.\n\nFigure 16.7. Dimensions of knowledge for complex task domains\nSources of Knowledge\nLevels of communicability\nindividual group\nexplicit\nimplicit\nA c\nB 0\nJordan’ s framework has been applied in actual design processes for large industrial and government \ninteractive systems. W e may expand the two factors distinguished from dichotomies to continuous \ndimensions to obtain a two-dimensional framework for analyzing the relevant sources of knowledge in \nthe context of use. This framework provides a map of knowledge sources that helps us to identify the \ndifferent techniques that we might need in order to collect information and structure this information \ninto a model of the task world.\nTo gather task knowledge in cell A, psychological methods may be used: interviews, questionnaires, \nthink-aloud protocols, and (single-person-oriented) observations. For knowledge in cell B, \nobservations of task behavior must be complemented by hermeneutic methods to interpret mental \nrepresentations (see (Veer, 1990)). For the knowledge referred to in cell C, the obvious methods concern \nthe study of artifacts such as documents and archives. In fact all these methods are to be found in \nclassical HCI task analysis approaches and, for that matter, the requirements elicitation techniques \ndiscussed in Chapter 9.\nThe knowledge indicated in cell D is unique in that it requires ethnographic methods such as interaction \nanalysis. Moreover, this knowledge may be in conflict with what can be learned from the other sources. \nFirst of all, explicit individual knowledge often turns out to be abstract with respect to observable \nbehavior and to ignore the situation in which task behavior is exhibited. Secondly, explicit group \nknowledge", "token_count": 512, "start_token": 316470, "end_token": 316982, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 686, "text": " what can be learned from the other sources. \nFirst of all, explicit individual knowledge often turns out to be abstract with respect to observable \nbehavior and to ignore the situation in which task behavior is exhibited. Secondly, explicit group \nknowledge such as expressed in official rules and time schedules is often in conflict with actual group \nbehavior, and for good reasons. Official procedures do not always work in practice and the literal \napplication of them is sometimes used as apolitical weapon in labor conflicts, or as a legal alternative \nto a strike. In all cases of discrepancy between sources of task knowledge, ethnographic methods will \nreveal unique and relevant additional information that has to be explicitly represented in task model \n1.\nThe allocation of methods to knowledge sources should not be taken too strictly. The knowledge sources \noften cannot be located completely in single cells of Jordan’ s conceptual map. The main conclusion \nis that we need different methods in a complementary sense, as we need information from different \nknowledge sources.\n\n16.6.4. An Integrated Approach to Task Analysis: GTA\nGroupware Task Analysis (GTA) is an attempt to integrate the merits from the most important classical \nHCI approaches with the ethnographic methods applied for CSCW (see (Veer and van Welie, 2003)). GTA \ncontains a collection of concepts and their relations (a conceptual framework) that allows analysis \nand representation of all relevant notions regarding human work and task situations as dealt with in \nthe different theories.\nThe framework is intended to structure task models 1 and 2, and, hence, to guide the choice of techniques \nfor information collection in the case of task model 1. For task model 2, design decisions have to \nbe made, based on problems and conflicts that are present in task model 1 and the requirement \nspecification.\nTask models for complex situations are composed of different aspects. Each describes the task world \nfrom a different viewpoint and each relates to the others. The three viewpoints are:\n• Agents, often people, either individually or in groups. Agents are considered in relation to \nthe task world. Hence, we make a distinction between agents as actors and the roles they play. \nMoreover, we need the concept of organization of agents. Actors have to be described with \nrelevant characteristics (e.g. for human actors, the language they speak, their amount of \ntyping", "token_count": 512, "start_token": 316932, "end_token": 317444, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 687, "text": " the roles they play. \nMoreover, we need the concept of organization of agents. Actors have to be described with \nrelevant characteristics (e.g. for human actors, the language they speak, their amount of \ntyping skill, or their experience with Microsoft Windows). Roles indicate classes of actors \nto whom certain subsets of tasks are allocated. By definition, roles are generic for the task \nworld. More than one actor may perform the same role and a single actor may have several roles \nat the same time. Organization refers to the relation between actors and roles in respect to \ntask allocation. Delegating and mandating responsibilities from one role to another is part \nof the organization.\nFor example, an office may have agents such as 'a secretary’, ’the typing pool’, and ’ the \nanswering machine’. A possible role is ’ answer a telephone call’. Sometimes it is not relevant \nto know which agent performs a certain role: it is not important who answers a telephone call, \nas long as it is answered.\n• Work, in both its structural and dynamic aspects. W e take task as the basic concept. A task \nhas a goal as an attribute. W e make a distinction between tasks and actions. Tasks can be \nidentified at various levels of complexity. The unit level of tasks needs special attention. \nW e need to make a distinction between\no the unit task: the lowest task level that people want to consider in referring to \ntheir work\no the basic task (after (Tauber, 1990)): the unit level of task delegation that is \ndefined by the tool that is used, for example a single command in a command-driven \ncomputer application.\nUnit tasks are often role-related. Unit tasks and basic tasks may be decomposed further into \n(user) actions and (system) events, but these cannot really be understood without a frame of\n\nreference created by the corresponding task, i. e. actions derive their meaning from the task. \nFor instance, hitting a return key has a different meaning depending on whether it ends a command \nor confirms the specification of a numerical input value.\nThe task structure is often at least partially hierarchical. On the other hand, performance \non certain tasks may influence the procedures for other tasks (possibly with other roles \n", "token_count": 512, "start_token": 317394, "end_token": 317906, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 688, "text": " a command \nor confirms the specification of a numerical input value.\nThe task structure is often at least partially hierarchical. On the other hand, performance \non certain tasks may influence the procedures for other tasks (possibly with other roles \ninvolved). For example, the secretary has to deliver the mail on time and may have to interrupt \nother tasks to be able to do so. Therefore we also need to understand task flow and data flow \nover time as well as the relationship between several concurrent flows.\n• Situation. Analyzing a task world from the viewpoint of the situation means detecting and \ndescribing the environment (physical, conceptual, and social) and the objects in the \nenvironment. Each thing that is relevant to the work in a certain situation is an object in \nthe sense of task analysis. Objects may be physical things, or conceptual (non-material) things \nsuch as messages, gestures, passwords, stories, or signatures. The task environment is the \ncurrent situation for the performance of a certain task. It includes actors with roles as well \nas conditions for task performance The history of past relevant events in the task situation \nis part of the actual environment if this features in conditions for task execution.\n16.7. SPECIFICATION OF THE USER INTERFACE DETAILS\nSpecifying details of the user interface means elaborating all aspects of the machine that are relevant \nfor the user, hence the concept of a user virtual machine (UVM). When there are several types of user \nfor the system, we need to specify several separate UVMs, since each user role is defined by another \nsubset of tasks. As suggested by the Seeheim model, we need to consider the representation, the dialog, \nand the application, each in relation to the type of user (the role) on which we are focusing. The \napplication proper, i.e. the functionality of the system, is the first aspect. It defines what the \nuser can do with the system (cf. Moran s semantic level). Techniques for specifying the functionality \nare dealt with in Chapter 9.\nThe other activities in relation to the specification of the UVM  concern the interaction between the \nuser and the system, with its two aspects:\n• the dialog (corresponding to the dialog layer in the Seeheim model, and the syntax and keystroke \nlevel in Moran’s CLG), and", "token_count": 512, "start_token": 317856, "end_token": 318368, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 689, "text": " between the \nuser and the system, with its two aspects:\n• the dialog (corresponding to the dialog layer in the Seeheim model, and the syntax and keystroke \nlevel in Moran’s CLG), and\n• the presentation interface (corresponding to the presentation layer in the Seeheim model, and \nMoran’s spatial layout level).\nThe three components of the UVM  lead to three specifications that are strongly related. The dialog \nand the presentation are two sides of the coin of user-system interaction, and both express, each in \nits own way, the semantics and functionality of the system.\n\n16.7.1. Dialog\nThe dialog in modern user interfaces is frequently a combination of several dialog styles, such as \ncommand language, menu choice, answering of questions generated by the interface, fill-in-the-blanks \nforms, and direct manipulation of interface objects. For an overview of the various styles, and options \nfor using them in different situations depending on task and user characteristic, see (Mayhew, 1992) \nand (Shneiderman and Plaisant, 2004). Dialog styles may often be seen as implementations of different \ndialog metaphors:\n• In a command language or natural language, the user and the interface * speak’ to each other. \nLegal dialogs obey a certain grammar. The user feels in control as long as he understands what \nis possible and remembers the right terminology. The user does not perform a task directly \nbut is rather obliged to persuade the system to perform it.\n• When the user has to choose from a menu, click on an icon, fill in labeled slots in a form \non the screen, or answer questions from the interface, the interface provides a structure where \nthe user is prompted to react by selecting an option. The user does not have to remember too \nmany options. On the other hand, he may not feel totally in control of the dialog.\n• In a direct-manipulation-type interface, the user moves in a ’ space’ and, by acting in the \nspace, shows the computer what he needs, whether the space is a two-dimensional screen where \nhe may drag and drop icons, a 3-D virtual reality environment, or something in between\n(’ augmented-reality interfaces’). The direct manipulation style", "token_count": 512, "start_token": 318318, "end_token": 318830, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 690, "text": " what he needs, whether the space is a two-dimensional screen where \nhe may drag and drop icons, a 3-D virtual reality environment, or something in between\n(’ augmented-reality interfaces’). The direct manipulation style provides the user with a sense \nof direct engagement. It feels as if the user is in direct contact with the objects from the \ntask domain.\nIt makes sense to relate the metaphor to the actual task domain. For example, a space can be specified \nas a desktop, or a virtual library, depending on whether the task domain concerns the management of \ndocuments or a search for objects.\nIn specifying the dialog further, the syntax of the interaction has to be specified in detail, including \nthe sequence of user actions. For example, in both Windows and the Macintosh interface, the user has \nto indicate the object first and then the operation. The reverse is true in the UNIX command language. \nAlso, the lexicon has to be specified. This includes deciding on the verbal labels for objects and \noperations, the iconic representations, the gestures (such as a cross or a series of connected up and \ndown strokes to indicate rubbing out on a drawing pad), and sounds. The lexicon includes both the symbols \nthat the user can use in communicating with the machine and the symbols the machine will output to \nthe user.\nThere are various modeling techniques for specifying the dialog. An example dialog specification \ntechnique is User Action Notation (UAN, see (Hix and Hartson, 1993)) which combines the specification \nof functionality with dialog details. UAN is relatively easy to use, especially since the actual \nformalism may to a large extent be tailored to the designer’s needs without losing the benefits of \na formal model. UAN provides a representation of the specification of the UVM  with separate columns \nto specify user actions, interface actions, interface states, and connections to underlying system \nevents. Each of these columns is filled in with the amount of detail the designer needs at a certain\n\nmoment. Later on, any item may be refined. For example, the designer may specify a user action en ter \npincode and later on specify a detailed interaction enter pincode where he elaborates details \nof inputting each digit, erasing a wrong keystroke, and what the interface should show on the screen", "token_count": 512, "start_token": 318780, "end_token": 319292, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 691, "text": " a user action en ter \npincode and later on specify a detailed interaction enter pincode where he elaborates details \nof inputting each digit, erasing a wrong keystroke, and what the interface should show on the screen \nat each point in time.\n16.7.2. Representation\nThis aspect of the UVM  contains the details of the interface that determine the perceptible aspects. \nThe lexicon indicated in the previous section includes all interface elements. Their representation \nconcerns their shape, color, contrast, pitch, loudness, size, etc. Representation also concerns all \naspects of screen design, such as the size of windows, the speed of movement displayed, and the timbre \nof generated sounds. The representation aspect may need the assistance of artists or at least specialists \nwho understand the laws of graphical representation, sound representation, and animation.\nThis part of design is the one for which no general formal representation models have been developed. \nSketches, video clips, and verbal descriptions of what one intends to have represented are commonly \nused, and frequent communication between the designer and the implementor is needed. Artists may have \nvery useful ideas but may propose very convincing solutions that change the essence of the intended \nspecification.\n16.8. EVALUATION\nEvaluation is needed whenever decisions are made in the course of the design process. This will be \nthe case during both analysis and specification. Evaluating analysis decisions is mostly related to \nthe phase where the future task world is envisioned. During the process of developing detail \nspecifications of the UVM , many decisions have to be made that relate technical details to aspects \nof usability.\nEvaluation does not solve problems, it merely points to them. A valid diagnosis often requires several \ncomplementary techniques as well as expertise. Evaluation is done by presenting design decisions such \nthat questions can be answered. Sometimes the questions may be answered in an unbiased way by the designer \nhimself (e.g. if indexes can be calculated in a straightforward way), but in many cases there is a \nneed to include others in the evaluation process, either specialists in design or humanities, or \nstakeholders in the design.\n16.8.1. Evaluation of Analysis Decisions\nDuring the early development of task model 2 there is not enough detail to develop a prototype.", "token_count": 512, "start_token": 319242, "end_token": 319754, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 692, "text": " process, either specialists in design or humanities, or \nstakeholders in the design.\n16.8.1. Evaluation of Analysis Decisions\nDuring the early development of task model 2 there is not enough detail to develop a prototype. However, \nscenarios can be developed regarding the future task world, and it can be modeled with the help of \nformalisms. Both scenarios and formalisms offer opportunities to apply evaluation techniques.\n\nIn scenario-based evaluation, scenarios will be developed concerning those parts of task model 2 that \nconcern a change in comparison to the current situation. In this phase of the design, it is worthwhile \nto represent not only the new use of technology, but also the situational aspects of this use and the \norganizational consequences. Developing a scenario means describing a process of using the intended \nsystem in an actual situation and organizational setting. The scenario may be described verbally, but \na video representation is often used because that may show more relevant situational details, even \nthough the technology may be represented in a way that reveals no details (for example, a laptop may \nbe represented by a sheet of paper if the details of the screens have not yet been decided).\nIn order to evaluate a scenario, a ’claims analysis’ can be performed. Apart from the designer and \nthe constructor of the scenario, (future) users, representatives of the client, and other relevant \nstakeholders may participate in the claims analysis. It often makes sense not to choose only \nrepresentatives who have a positive attitude towards the intended change but also to include people \nwho are afraid of the future developments or who have a pronounced opinion on the possible negative \neffects of future implementation. For each aspect of the task delegation to the new system that is \nan explicit change from the current system, the participants of the claims analysis try to identify:\n• to what extent the change is providing a solution in the intended direction, and\n• what the positive and negative side effects of the change are.\nAnother way to evaluate a scenario is to ask a group of stakeholders to act out the written scenario \nand videotape the performance, possibly collecting several takes where people change roles and where \nthe non-believers, in particular, get a chance to show where things may go wrong. Analyses of this \ntype will show not only the possible success of the envisioned changes but also the potential", "token_count": 512, "start_token": 319704, "end_token": 320216, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 693, "text": " where people change roles and where \nthe non-believers, in particular, get a chance to show where things may go wrong. Analyses of this \ntype will show not only the possible success of the envisioned changes but also the potential problems. \nThe latter, in particular, are the basis for reconsidering decisions and for developing measures to \ncounteract unwanted side-effects. The scenarios that are acted by stakeholders, in particular, often \nreveal possible changes in the design that may provide a breakthrough.\nFormal evaluation techniques allows specific questions to be answered. For example, hierarchical task \nanalysis (HTA) (Kirwan and Ainsworth, 1992) describes the task domain as a hierarchical structure of \ntasks and subtasks with a complete representation of the procedural structures of the decomposition. \nHTA formal evaluation may consider the length of a sequence of subtasks, given the relevant conditions. \nThe same type of formalism allows an evaluation of possible modular procedures (similar subtrees that \noccur in different places and the aspects of consistency between their execution), which is indicative \nof the amount of learning involved for understanding the new task domain.\n16.8.2. Evaluation of UVM Specifications\nAs soon as details of the UVM  have been specified, other representations may be used for evaluation, \neven though it may still be worthwhile to analyze scenarios. At this stage in the design, scenarios \nare often elaborated and executed with the help of mock-up representations or simulations of the intended \nsystem, especially if hardware aspects in relation to the physical work conditions are expected to \nmatter. The simulations concern the size, weight, and perceptible aspects of the intended UVM , even\n\nif the interactive aspects have not yet been specified. Many evaluation techniques from classical \nergonomics may be applied as well (Corlett and Clark, 1995).\nFormal evaluation will certainly play an important role for the UVM . Many formalisms have been developed \nwith certain usability aspects explicitly in mind. For example, TAG allows us to measure ease of learning \nand use by indexing the complexity of rules and the number of features to be considered during each \ncommand to the machine; UAN representations allow systematic reasoning about dialog specification \ndetails.\nDetailed specification of the UVM  permits other evaluation techniques as well, in particular heuristic \nevaluation and cognitive walkthrough. In both", "token_count": 512, "start_token": 320166, "end_token": 320678, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 694, "text": " \ncommand to the machine; UAN representations allow systematic reasoning about dialog specification \ndetails.\nDetailed specification of the UVM  permits other evaluation techniques as well, in particular heuristic \nevaluation and cognitive walkthrough. In both cases, it is useful to employ experts in user interface \ndesign who have not been part of the team that developed the specification. Experienced designers know \nthe criteria applied in these techniques and will have considered them during their decisions. Only \nsomebody for whom the design is new can have an unbiased view concerning these criteria. A last type \nof evaluation technique, user testing and observation, requires future users to be involved and a working \nprototype. Obviously, a prototype may also be the basis for heuristic evaluation and a cognitive \nwalkthrough.\nHeuristic evaluation is based on some definition of usability. Usability is a complex of aspects such \nas ease of use, ease of learning, ease of recall after a period of not using a system (known as \nre-learnability), affection, help, likeability, etc. Approaches toward heuristic evaluation provide \nchecklists of characteristics of the user interface or UVM  that describe the different usability aspects. \nSuch a checklist may also be applied as a guideline for making design decisions. Checklists exist in \ndifferent forms, and often include a technique for calculating usability indexes. Each item may be \nchecked when applicable and, additionally, each item that is diagnosed as non-optimal may give rise \nto design changes. Example items from such a checklist are (Shneiderman and Plaisant, 2004; Nielsen, \n1993):\n• Use a simple and natural dialog Humans can only pay attention to a few things at a time. Therefore, \ndialogs should not contain information that is irrelevant or rarely needed. Information should \nappear in a logical and natural order to ease comprehension.\n• Speak the user’ s language A dialog is easier to understand if it uses concepts and phrases \nthat are familiar to the user. The dialog should not be expressed in computer-oriented terms, \nbut in terms from the task domain.\n• Minimize memory load The user should not have to remember information from one part of the \ndialog to another. Long command sequences, menus with a large number of entries, and uncertainty \nabout ’where we are’ hamper interaction. There must be easy", "token_count": 512, "start_token": 320628, "end_token": 321140, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 695, "text": " should not have to remember information from one part of the \ndialog to another. Long command sequences, menus with a large number of entries, and uncertainty \nabout ’where we are’ hamper interaction. There must be easy ways to find out what to do next, \nhow to retrace steps, and get instructions for use.\n• Be consistent Users should not have to wonder whether different words or actions mean the same \nthing. Metaphors should be chosen carefully, so as not to confuse the user.\n• Provide feedback The system should keep the user informed of what is going on. If certain \nprocesses take a while, the user should not be left in the dark. A moving widget informs the \nuser that the system is doing something; a percentage-done indicator informs him about the \nprogress towards the goal.\n\n• Provide clearly marked exits Users make mistakes, activate the wrong function, follow the wrong \nthread. There must be an easy way to leave such an unwanted state.\n• Provide shortcuts Novice users may be presented with an extensive question-answer dialog. It \ngives them a safe feeling and helps them to learn the system. Experts are hindered by a tedious \nstep-by-step dialog and the system should provide shortcuts to accommodate them.\n• Give good error messages Error messages should be explained in plain language. They should \nnot refer to the internals of the system. Error messages should precisely state the problem \nand, if possible, suggest a solution.\nItems from such a checklist should be used with care, though. Design involves tradeoffs between \nconflicting goals. Consider for example the two function-key layouts in Figure 16. 8. Interface designers \nmight prefer the star as the best design. It is a symmetric design, consistent with directional \nindicators on a compass. Yet, studies have shown that the inverted ’ T’ is the most useful configuration. \nWith the index finger on the cursor-left key and the ring finger on the cursor-right key, the middle \nfinger can efficiently cover the cursor-up and cursor-down keys. Designers of computer games seem to \nhave known this for quite a while.\nFigure 16.8. Two possible cursor key arrangements\n- ►\nCognitive walkthroughs focus solely on the cognitive aspects of the dialog. The technique can be applied \nearly in the specification phase", "token_count": 512, "start_token": 321090, "end_token": 321602, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 696, "text": "have known this for quite a while.\nFigure 16.8. Two possible cursor key arrangements\n- ►\nCognitive walkthroughs focus solely on the cognitive aspects of the dialog. The technique can be applied \nearly in the specification phase and it helps to detect failures that would otherwise make the system \nincomprehensible for users. Like heuristic evaluation, it requires only a small number of expert \ncolleagues who are confronted with the specification of the dialog and the content of the representation. \nScreen design need not have finished yet, but the information representation (wording, icons) of the \nscreen must be known. The technique requires a specification of scenarios of normal, faultless dialog \nexamples. A scenario might for example read as follows: ’when checking in you have to put your credit \ncard in the slot; the machine will ask you to enter your pin code: you type ... ’ . Based on a specification \nof this type, the start state is described to the evaluator, along with all information on the task \nas the user would know it, and the background of the user (education and systems experience). The \nevaluator is asked to answer a small set of questions about the next move. After these have been answered,\n\nthe intended move is described with the resulting state of the interface, after which the evaluator \nis again asked the same set of questions.\nAn example of such a set of questions is:\n• What should the user do now?\n• Based on what knowledge or information would the user do this?\n• What would the user expect to be the next step of the system?\nTechniques such as this quickly expose any invalid expectations of user knowledge and understanding \nand any lack of relevant information at the interface. Additionally, they show inconsistencies in the \ninterface information as well as inconsistencies in dialog conventions.\n16.8.3. Evaluation of Prototypes\nThe proof of the pudding is in the eating. An evaluation should, at some point, be carried out with \nreal users. As soon as a mock-up or simulation is available, users can be asked to perform tasks. W e \nare then asking users to ’ play a scenario’ even if we do not mention this explicitly. As soon as details \nof the dialog have been established, a more interactive type of testing is possible.\nEvaluation by", "token_count": 512, "start_token": 321552, "end_token": 322064, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 697, "text": " \nare then asking users to ’ play a scenario’ even if we do not mention this explicitly. As soon as details \nof the dialog have been established, a more interactive type of testing is possible.\nEvaluation by the user is often based on a prototype implementation of the system. In early phases \nof detail design, the prototype will often not represent the total UVM . A single aspect of the task \nto be delegated, one instance of the dialog and representation with hardly any real functionality \navailable, may be enough to detect problems early on. Several types of user testing may be done. Users \nmay be provided with tasks or allowed to explore. Observations during the interaction, complemented \nwith subsequent discussions with the user, may reveal problems and misunderstandings. In addition, \nuser performance may be measured, for example, the time to complete a task or the frequency of errors. \nUsers may be asked for their subjective understanding of the system; standardized measurement techniques \nare commercially available, focusing on subjective learnability, ease of use, and mental load.\nISO 9241 (1996) defines usability in terms of efficiency, effectiveness, and satisfaction. Usability \nevaluation of prototypes (and systems) is usually based on more specific definitions of usability \ncharacteristics, such as those defined in (Shneiderman and Plaisant, 2004; Nielsen, 1993). Figure 16. 9 \ngives an overview of these usability characteristics. They have an almost one-to-one correspondence \nwith the user interface quality factors as listed in the introduction to this chapter. For each of \nthe usability characteristics, a number of (indirect) metrics exist. These metrics are gathered by \nobserving users at work and by asking subjective questions.\n\nFigure 16.9. Usability characteristics according to ISO 9241, \nShneiderman and Plaisant (2004) and Nielsen (1993)\nISO 9241 Shneiderman Nielsen\nEfficiency Speed of performance Efficiency\nTime to learn Learnability\nEffectiveness Retention over time Memorability\nRate ol errors by users Errors/Safety\nSatisfaction Subjective satisfaction Satisfaction\n16.9. SUMMARY\nThe user interface of a system is important. About half of the code of an interactive system is devoted \nto the user interface. Consequently, about half of the time and effort is spent on that interface as \nwell.", "token_count": 512, "start_token": 322014, "end_token": 322526, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 698, "text": " SUMMARY\nThe user interface of a system is important. About half of the code of an interactive system is devoted \nto the user interface. Consequently, about half of the time and effort is spent on that interface as \nwell. The quality of the user interface is a critical success factor. Good user interfaces increase \nthe efficiency and productivity of their users, reduce errors and training time, and improve user \nacceptance.\nIn a technical sense, the user interface of a system often consists of two components or layers:\n• a presentation component that handles the perceptible aspects of the interface, including \nscreen design and keyboard layout;\n• a dialog component that handles the syntax of the interaction, including metacom-munication \nsuch as help functions and error messages.\nAs a result of this limited view of what a user interface is, it is often designed rather independently \nof the system’ s functionality. The design of the user interface is then seen as a separate activity, \nnot in the mainstream requirements-engineering-design-implementation-testing phases. Chances are then \nthat it does not get the attention it deserves.\nIn this chapter, we take a different stance. In the approach we sketch, the design of the interface \nand the design of the functionality go hand in hand. A provocative heading could have been ’The user \ninterface is the system’. There are two main reasons for taking this broader view of what a user interface\n• The system, and hence its interface, should help the user perform certain tasks. The user \ninterface should therefore reflect the structure of the task domain. The design of tasks and \nthe design of the corresponding user interface influence each other and should be part of the \nsame cyclical process. Like quality, the user interface is not a supplement.\n\n• The dialog and representation alone do not provide sufficient information to the user. In order \nto be able to work with a system, the user sometimes needs to know 'what is going on behind \nthe screen’.\nWhen thinking about user interface design, it is important to make a distinction between the user’s \nmental model, the user virtual machine, and the conceptual model.\nThe mental model is a model in human memory. It is the user’s model of the system he uses. It is based \non education, knowledge of other systems, knowledge of the", "token_count": 512, "start_token": 322476, "end_token": 322988, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 699, "text": " user virtual machine, and the conceptual model.\nThe mental model is a model in human memory. It is the user’s model of the system he uses. It is based \non education, knowledge of other systems, knowledge of the application domain, general knowledge about \nthe world, etc. The mental model is used during interaction with the system, to plan actions and interpret \nsystem reactions. The mental model is often incomplete and inconsistent.\nThe user virtual machine (UVM) includes everything the user should know about the system in order to \nuse it. It includes aspects ranging from the physical outlook of the computer and connected devices \nto the style of interaction and the form and content of the information exchange.\nThe conceptual model is the explicit model of the system created by designers and teachers. It is a \nconsistent and complete representation of the system as far as relevant for the users. The conceptual \nmodel shows itself in the interface. If there is only one class of users, the user virtual machine \nand the conceptual model are the same. If there is more than one class of users (such as ATM clients, \nATM maintainers, and lawyers), or the user uses more than one device, there is one UVM  for each class, \nand the conceptual model is the union of those UVMs.\nThe central issue in human-computer interaction is to attune the user’s mental model and the conceptual \nmodel as closely as possible. When this is achieved, the system becomes easier to learn and easier \nto use. When the models conflict, the user gets confused and starts making errors. Good design starts \nwith the derivation of a conceptual model from an analysis of users and their tasks. This conceptual \nmodel is then built into the system (the UVM) in such a way that it induces adequate mental models \nin the users.\nThe design of a user interface involves different disciplines. Psychologists know how humans perceive, \nlearn, remember, think, and feel, how people work together, and how the work situation affects work. \nCognitive psychology, anthropology and ethnography provide techniques for collecting information on \nhow people work. Artists know how to design attractive things that function effectively. Cognitive \nergonomics is concerned with the characteristics of human information processing in interaction with \ninformation systems. Design teams for interactive systems may thus contain quite a variety of expertise \nalongside", "token_count": 512, "start_token": 322938, "end_token": 323450, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 700, "text": " know how to design attractive things that function effectively. Cognitive \nergonomics is concerned with the characteristics of human information processing in interaction with \ninformation systems. Design teams for interactive systems may thus contain quite a variety of expertise \nalongside software engineering.\n16.10. FURTHER READING\nThere is a growing collection of books on user interface design. Well-known textbooks are (Shneiderman \nand Plaisant, 2004) and (Sharp et al., 2007). Newman and Lamming (1995) and (Dix et al., 1998) cover \nmost aspects of design, and are, at the same time introductory, i. e. they do not require too much\n\nbackground on the subject. Moran and Carroll (1996) consider the design process from the point of view \nof management and provide techniques to monitor the design space and design decisions.\nThe classical HCI approaches to task analysis are best exemplified in (Johnson and Johnson, 1991). \nAdditional insight into methods of task knowledge elicitation may be found in (Sebillotte, 1988). \nGeneral task analysis representation techniques are discussed in detail in (Kirwan and Ainsworth, 1992). \nJordan and Henderson (1995) give a detailed account of ethnographic methods and techniques from the \nbackground of CSCW and groupware design.\nFor an overview of modeling techniques and examples see (Haan et al., 1991). Task Action Grammar (TAG) \nis discussed in (Payne and Green, 1989), User Action Notation (UAN) in (Hix and Hartson, 1993), and \nGroupware Task Analysis (GTA) in (Veer and van Welie, 2003).\nA classical collection of user interface guidelines can be found in (Smith and Mosier, 1986). Two volumes \nthat consider dialog styles in detail are (Shneiderman and Plaisant, 2004) and (Mayhew, 1992). A view \non details of representation and dialog design from an artistic point of view is presented in (Laurel, \n1993). Representation aspects, as well as hardware aspects, are discussed in detail in (Corlett and \nClark, 1995).\nNielsen and Mack (1994), (Jordan et al., 1996), and Lindgaard (1994) provide collections of evaluation \ntechniques for various stages in design. Carroll (1995) discusses scenario evaluation techniques, as \n", "token_count": 512, "start_token": 323400, "end_token": 323912, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 701, "text": ", 1995).\nNielsen and Mack (1994), (Jordan et al., 1996), and Lindgaard (1994) provide collections of evaluation \ntechniques for various stages in design. Carroll (1995) discusses scenario evaluation techniques, as \nwell as the application of scenarios to other design phases.\n16.10.1. Exercises\n1. Define the following terms: mental model, conceptual model, and user virtual machine.\n2. Discuss the differences between the Seeheim model and M VC.\n3. Describe the role of cognitive ergonomics in user interface design.\n4. Sketch a model of human information processing.\n5. What is the difference between working memory and long-term memory?\n6. In which ways is the user s mental model activated while using a computer system?\n7. Describe the constituents of Command Language Grammar (CLG).\n8. Discuss the differences between single-user systems and groupware with respect to task \nanalysis.\n9. Discuss the following user interface evaluation methods:\no scenario-based evaluation: \no heuristic evaluation; \no cognitive walkthrough.\nro\n10. ~  Study the desktop metaphor as it is commonly used in user interfaces for PCs and workstations. \nCan you spot places where the metaphor breaks down or may even lead you astray?\n11. ^  Try to answer the following questions from the manual of your favorite word processor:\no How do I swap two paragraphs?\n\no How do I include the text of some other document at a given position? \no How do I let the page numbering start at 0 rather than 1? \no How do I align a picture at the top or bottom of the page?\nAssess whether the user documentation is organized by the functionality offered or whether \nit addresses typical tasks faced by its users.\n12. ^  Discuss the requirements for online help facilities for a word processor.\n13. ^Augment the waterfall model such that user interface issues are dealt with at appropriate \nphases.\n14. ^D iscuss the pros and cons of the following approaches to user interface development:\no discussing manually constructed usage scenarios with prospective users; \no prototyping screen displays and iteratively enhancing them;\no developing the user interface after the functional parts of the system are complete \nand accepted by the users; \no formally describing and analyzing the user interface prior", "token_count": 512, "start_token": 323862, "end_token": 324374, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 702, "text": " prospective users; \no prototyping screen displays and iteratively enhancing them;\no developing the user interface after the functional parts of the system are complete \nand accepted by the users; \no formally describing and analyzing the user interface prior to or concurrent with \nsystem design.\n\nChapter 17. Software Reusability\nLEARNING OBJECTIVES\n• To appreciate various dimensions along which approaches to reuse may be classified\n• To be aware of a number of composition-based and generation-based reuse techniques\n• To see how reuse can be incorporated into the software life cycle\n• To recognize the relation between reuse and various other software engineering concepts and \ntechniques\n• To understand the major factors that impede successful reuse\nNOTE\nIf we estimate the programmer population at three million people, and furthermore assume that each \nprogrammer writes 2 000 lines of code per year, 6 000 million lines of code are produced each year. \nThere is bound to be a lot of redundancy in them. Reuse of software or other artifacts that are produced \nin the course of a software development project, may lead to considerable productivity improvements \nand, consequently, cost savings. This chapter gives an overview of reuse issues. Chapters 18 and 2? \ndiscuss two reuse technologies in more details: components and services.\nMeanwhile Daedalus, tired of Crete and of his long absence from home, was filled with longing for his \nown country, but he was shut in by the sea. Then he said: ’The king may block my way by land or across \nthe ocean, but the sky, surely, is open, and that is how we shall go. Minos may possess all the rest, \nbut he does not possess the air. ’ With these words, he set his mind to sciences never explored before, \nand altered the laws of nature. He laid down a row of feathers, beginning with tiny ones, and gradually \nincreasing their length, so that the edge seemed to slope upwards. In the same way, the pipe which \nshepherds used to play is built up from reeds, each slightly longer than the last. Then he fastened \nthe feathers together in the middle with thread, and at the bottom with wax; when he had arranged them \nin this way, he bent them round into a gentle curve, to look like real birds’ wings.\nOvid: Metamorphoses, VIII", "token_count": 512, "start_token": 324324, "end_token": 324836, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 703, "text": " the middle with thread, and at the bottom with wax; when he had arranged them \nin this way, he bent them round into a gentle curve, to look like real birds’ wings.\nOvid: Metamorphoses, VIII, 183 - 194.\nDaedalus deserves a place in the mythology of software engineering. In King Minos’ days, software did \nnot exist; and yet the problems and notions which we still find in today’s software engineering existed. \nOne example is the construction of complex systems. Daedalus certainly has a track record in that field. \nHe successfully managed a project that can stand a comparison with today’ s software development projects \nthe construction of the Labyrinth at Knossos.\nAfter a while, Daedalus wanted to leave Crete, as narrated above in Ovid’ s words. King Minos, however, \ndid not want to let him go. W e know how the story continues: Daedalus flies with his son Icarus from \nCrete. Despite his father’s warnings, Icarus flies higher and higher. He gets too close to the sun \nand the wax on his wings melts. Icarus falls into the sea and drowns. Daedalus safely reaches the mainland \nof Italy.\n\nDaedalus’ construction is interesting from the point of view of reuse. The fact that it concerns hardware \nrather than software is not important here. What concerns us in the present framework is the application \nof certain principles in the construction:\n• reuse of components: Daedalus used real feathers;\n• reuse of design: he imitated real wings;\n• glue to connect the various components: at that time, people used wax to glue things together. \nThe quality of the glue has a great impact on the reliability of the end product.\nThrough a justified and determined application of these principles, a successful and ambitious project \n(Daedalus’ flight to Italy) was realized. An effort to storm heaven with insufficient technology turned \ninto a disaster (Icarus’ fall into the sea).\nW e make a small jump in history, to the end of the 1970s. The software crisis has been rampant for \nmany years. The demand for new applications far surpasses the ability of the collective workforce in \nour field. This gap between demand and supply is still growing. Software reuse", "token_count": 512, "start_token": 324786, "end_token": 325298, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 704, "text": " end of the 1970s. The software crisis has been rampant for \nmany years. The demand for new applications far surpasses the ability of the collective workforce in \nour field. This gap between demand and supply is still growing. Software reuse is one of the paths \nbeing explored in order to achieve a significant increase in software productivity.\nWhy code well-known computations over and over again? Cannot reliability and productivity be drastically \nincreased by using existing high-quality software components?\nIt sounds too good to be true. But it isn’t that simple. The use of existing software components requires \nstandardization of naming and interfaces. The idea of gluing components together is not directly \ntransferable to software.\nIs software reuse a myth or can it really be achieved? In the following sections, we give an overview \nof the developments, opportunities, and expectations of software reusability. A tentative conclusion \nis that we should not expect miracles. By patiently developing a sound reuse technology, a lot of progress \nis possible. There is no philosopher’ s stone. There are, however, a great number of different \ndevelopments that may reinforce and supplement one another.\nThe modern view does not restrict the notion of software reuse to component reuse. Design information \ncan be reused also, as can other forms of knowledge gathered during software construction.\nSoftware reuse is closely related to software architecture. A software architecture provides a context \nfor the development of reusable building blocks. Conversely, a software architecture provides a skeleton \ninto which building blocks can be incorporated. Attention to architectural issues is a prime software \nreuse success factor. A new style of software development, emphasizing component reuse within an \narchitectural framework, is emerging. It is known as Component-Based Software Engineering (CBSE). \nDevelopments in interface technology such as provided by middleware interface description languages \nprovide additional leverage for CBSE. Components that are dynamically discovered and deployed are called \nservices. These two specific reuse technologies are discussed more extensively in Chapters 18 and Jj).\nClosely coupled to software reuse is software flexibility. Software is continuously adapting to changed \ncircumstances. In developing the next release of a system, we would like to reuse as much as possible\n\nfrom the present release. This is sometimes considered to be software reuse. Flexibility aspects have \nbeen extensively discussed in previous chapters, notably Chapters 6 and", "token_count": 512, "start_token": 325248, "end_token": 325760, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 705, "text": " developing the next release of a system, we would like to reuse as much as possible\n\nfrom the present release. This is sometimes considered to be software reuse. Flexibility aspects have \nbeen extensively discussed in previous chapters, notably Chapters 6 and _11, albeit not explicitly in \nthe context of reusability.\nVarious aspects of software reuse are discussed in Sections 17. 1 to 17. 4. Section 17. 1 discusses the \nmain dimensions along which reuse approaches can be distinguished. Section 17. 2 elaborates upon one \nof these dimensions, the type of product to be reused. Section 17. 3 discusses another of these dimensions, \nnamely the various process models incorporating reuse. Specific tools and techniques to support reuse \nare the topic of Section 17. 4. Section 17. 5 addresses the perspectives of software reuse. In particular, \na domain-oriented, evolutionary approach is advocated. Finally, non-technical aspects of software reuse \nare addressed in Section 17.6.\n17.1. REUSE DIMENSIONS\nSoftware reuse has many dimensions or facets. The main dimensions along which approaches to software \nreuse can be distinguished are listed in Table 17.1. W e discuss each of these dimensions in turn, by \nhighlighting essential characteristics of extreme positions along the axes. Most reuse systems, however, \nexhibit a mixture of these characteristics. For example, a typical reuse system may use a combination \nof a compositional and a generative approach.\nTable 17.1. Reuse dimensions\nDimension |  Description\nSubstance |components, concepts, procedures\nscope |horizontal or vertical\napproach jplanned, systematic or ad hoc, opportunistic\ntechnique jcompositional or generative\nusage jblack-box, as-is or white-box, modified\nproduct jcode, object, design (architecture), text,...\nThe first dimension along which approaches to reuse may differ concerns the substance, the essence \nof the things that are reused. Most often, the things being reused are components. A component can \nbe any piece of program text: a procedure, a module, an object-oriented class, etc. Components can \nbe generic (data structures, such as binary trees or lists, widgets for graphical user interfaces, \nor sorting routines) or domain-specific. A point of recurring concern when reusing components is their \nquality,", "token_count": 512, "start_token": 325710, "end_token": 326222, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 706, "text": ". Components can \nbe generic (data structures, such as binary trees or lists, widgets for graphical user interfaces, \nor sorting routines) or domain-specific. A point of recurring concern when reusing components is their \nquality, in particular their reliability. Instead of encapsulating a chunk of knowledge as a component \nin some programming language, we may also describe it at a more abstract level, for example as a generic \nalgorithm, or a concept. Finally, rather than reusing product elements, we may also reuse process \nelements, such as procedures on how to carry out an inspection or how to prototype. To be able to do \nso, these process elements have to be formally captured, for example in a process model.\n\nThe scope of software reuse can be horizontal or vertical. In horizontal reuse, components are generic. \nThey can be used across a variety of domains. A library of mathematical subroutines or GUI widgets \nis a typical example of horizontal reuse. In vertical reuse, components within a particular application \ndomain are sought for. This often involves a thorough domain analysis to make sure that the components \ndo reflect the essential concepts of the domain. The choice of a particular domain incurs a challenging \ntradeoff: if the domain is narrow, components can be made to fit precisely and the pay-off is high \nwhen these components are reused. On the other hand, the chance that these components can be reused \noutside this narrow domain is fairly small. The reverse holds for large domains.\nSoftware reuse may be undertaken in a planned, systematic way or it may be done in an ad hoc, opportunistic \nfashion. Planned reuse involves substantial changes in the way software is developed. Extra effort \nis needed to develop, test, and document reusable software. Specific process steps must be introduced \nto investigate opportunities to reuse existing components. The economics of software development change, \nsince costs and benefits relate to more than just the present project. Planned reuse requires a \nconsiderable investment up front. For a while, extra effort is needed to develop reusable components. \nOnly at a later stage can the benefits be reaped. With the opportunistic approach, individuals reuse \ncomponents when and if they happen to know of their existence, and when and if these components happen \nto fit. In this approach, components are not developed with reuse in mind. Populating a library with \n", "token_count": 512, "start_token": 326172, "end_token": 326684, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 707, "text": ", individuals reuse \ncomponents when and if they happen to know of their existence, and when and if these components happen \nto fit. In this approach, components are not developed with reuse in mind. Populating a library with \na large enough number of reusable components is often a problem when using the opportunistic approach. \nIn the process-model perspective, the planned and opportunistic approaches to reuse are known as \nsoftware development for reuse and software development with reuse, respectively.\nIn a composition-based technology, reuse is achieved by (partly) composing a new system from existing \ncomponents. The building blocks used are passive fragments that are copied from an existing base. \nRetrieval of suitable components is a major issue here. In a generation-based technology, it is much \nmore difficult to identify the components that are being reused. Rather, the knowledge reused (usually \ndomain-specific) is to be found in a program that generates some other program. In a generation-based \ntechnology, reusable patterns are an active element used to generate the target system. Prime examples \nof these two technologies are subroutine libraries and application generators, respectively.\nIn a black-box reuse approach, elements are reused as-is: they are not modified to fit the application \nin which they are going to be incorporated. Often, the person reusing the component does not know the \ninternals of the element. Commercial off-the-shelf (COTS) components are a prime example of this \napproach. Quality and the legal aspects of such components are critical issues. In awhite-box approach, \nelements can be modified before they are incorporated. White-box reuse is most often done in combination \nwith an opportunistic approach. Black-box reuse is ’ safer’ in that components reused as-is usually \nhave fewer faults than components that are changed before being reused.\nFinally, we may categorize reuse approaches according to the type of product that is reused: source \ncode, design, architecture, object, text, and so on. Most often, some form of source code is the reuse \nproduct. There is a strong trend to capture reusable design knowledge in the form of design patterns \nand software architectures: see Chapter 11. Text is a quite different kind of reusable product, for \ninstance in the form of pieces of documentation. The ’ user manual�", "token_count": 512, "start_token": 326634, "end_token": 327146, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 708, "text": " trend to capture reusable design knowledge in the form of design patterns \nand software architectures: see Chapter 11. Text is a quite different kind of reusable product, for \ninstance in the form of pieces of documentation. The ’ user manual’ of a modern airplane, for example, \neasily runs to thousands of pages. Quite likely, each airplane is unique in some aspects and so is\n\nits documentation. By developing reusable pieces of documentation, the user manual can be constructed \nby assembling it from a huge number of documentation fragments.\n17.2. REUSE OF INTERMEDIATE PRODUCTS\nLibraries with ready-to-use pieces of code, such as those for numerical or statistical computations, \nhave been with us for a long time and their use is widespread. This form of software reuse is not \nnecessarily suited for other domains. In other domains we may be better off reusing ’ skeleton’ components, \ni. e. components in which some details have not been filled in yet. In an environment in which the same \ntype of software is developed over and over again, these skeletons may be molded in a reusable design.\nA similar technique is to reuse the architecture of a software system, as is found in the construction \nof compilers, for example. These are all examples of composition-based reuse techniques.\nBy incorporating domain knowledge in supporting software, we arrive at the area of application \ngenerators and fourth-generation languages. These are examples of generation-based reuse techniques.\n17.2.1. Libraries of Software Components\nNo one in his right mind will think of writing a routine to compute a cosine. If it is not built into \nthe language already, there is bound to be a library routine COS. By investigating the question of \nwhy the reuse of mathematical functions is so easy, we come across a number of stumbling blocks that \nhamper the reuse of software components in other domains:\n• a well-developed field, with a standardized terminology: ’cosine’ means the same to all of \nus;\n• a small interface: we need exactly one number to compute a cosine;\n• a standardized data format: a real number may be represented in fixed point, floating point, \nor double precision, and that’s about all.\nReuse of subroutines works best in an application domain that is well disclosed", "token_count": 512, "start_token": 327096, "end_token": 327608, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 709, "text": " a standardized data format: a real number may be represented in fixed point, floating point, \nor double precision, and that’s about all.\nReuse of subroutines works best in an application domain that is well disclosed, one whose notions \nare clear and where the data to be used is in some standardized format.\nThe modern history of software reuse starts with Mcllroy (1968), who envisaged a bright future for \na software component technology at the NATO software engineering conference. In his view, it should \nbe possible to assemble larger components and systems from a vast number of ready-to-use building blocks, \nmuch like hardware systems are assembled using standard components. W e haven’ t got there yet. In order \nfor large-scale reuse of software components to become feasible, we first have to solve the following \nproblems:\n• Searching: W e have to search for the right component in a database of available components, \nwhich is only possible if we have proper methods available to describe components. If you do \nnot know how to specify what you are looking for, there is little chance you will find it.\n\n• Understanding: To decide whether some component is usable, we need a precise and sufficiently \ncomplete understanding of what the component does.\n• Adaptation: The component selected may not exactly fit the problem at hand. Tinkering with \nthe code is not satisfactory and is, in any case, only justified if it is thoroughly understood.\n• Composition: A system is wired from many components. How do we glue the components together? \nWe return to this topic in Section 17.4.1 and, more extensively, in Chapter 18.\nTo ease the searching process, hardware components are usually classified in a multilevel hierarchy. \nSince the naming conventions in that field have been standardized, people are able to traverse the \nhierarchy. At the lowest level, alternative descriptions of components are given, such as a natural \nlanguage description, logic schema, and timing information, which describe different aspects of the \ncomponents. These alternative descriptions further improve the user’s understanding of these \ncomponents.\nSeveral efforts have been made to classify software components in a hierarchical fashion as well. One \nsuch effort is described in (Booch, 1987). In his taxonomy (see Figure 17. 1), a component is first \n", "token_count": 512, "start_token": 327558, "end_token": 328070, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 710, "text": "onents.\nSeveral efforts have been made to classify software components in a hierarchical fashion as well. One \nsuch effort is described in (Booch, 1987). In his taxonomy (see Figure 17. 1), a component is first \ndescribed by the abstraction it embodies. Secondly, components are described by their time and space \nbehavior, for instance, whether or not objects are static in size or handle their own memory management.\nFigure 17.1. Part of a taxonomy of reusable software components\n• structures • monolithic • stacks\n• strings\n• queues\n• ...\n• polylithic • lists\n• trees\n• graphs\n• tools • utilities\n• filters\n«...\nThe retrieval problem for software components is very similar to that for textual sources in an ordinary \nlibrary. Quite a number of classification, or indexing, techniques have been developed for the latter \ntype of problem. Figure 17. 2 identifies the main indexing techniques.\n\nFigure 17.2. Main indexing techniques\nindexing\ncontrolled uncontrolled\nclassification keywords\n/ \\\nenumeration facets\nAn indexing scheme is either controlled or uncontrolled. In a controlled indexing scheme, classifiers \nare chosen from a finite set of terms. This set of terms may be predefined and immutable. It may also \nchange over time, though only in a controlled way. With controlled indexing, a list of synonyms is \noften provided to make both searching and indexing more flexible. In an uncontrolled indexing scheme, \nthere is no restriction on the number of terms. Uncontrolled indexing is mostly done by extracting \nterms from the entity to be indexed. For example, the terms that occur most frequently can be taken \nas index terms. An advantage of uncontrolled indexing is that it can be done automatically. A \ndisadvantage is that semantic knowledge is lost.\nIn controlled indexing, one option is simply to use a list of keywords. This list is not ordered and \nthere are no relations between the keywords. An advantage of this scheme is that it is easy to extend \nthe set of index terms. In a classification scheme, on the other hand, the set of index terms is structured \nin some way. One way of doing so is through some enumerated hierarchical structure, as in Figures 17. 1 \nand 17. 2.  The power of a hierarchical scheme is its structure. This same", "token_count": 512, "start_token": 328020, "end_token": 328532, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 711, "text": " of index terms is structured \nin some way. One way of doing so is through some enumerated hierarchical structure, as in Figures 17. 1 \nand 17. 2.  The power of a hierarchical scheme is its structure. This same structure, however, is also \na weakness.\nAn enumerated scheme offers one specific view on the structure of a domain. Figure 17. 1 offers one \nsuch view on the domain of generic data structures. Figure 17. 3 offers an alternative view on that \nsame domain. In the latter scheme, the structural relationships between elements of a compound data \nstructure have been used to set up the taxonomy. For example, there is a 1 - 1 relationship between \nelements of a linear structure such as a list or queue. The taxonomies in Figures 17. 1 and 17. 3 both \nseem to be reasonable. Each of them can be used effectively, provided the user knows how the hierarchy \nis organized.\n\nFigure 17.3. An alternative component hierarchy\nstructures 0 -0 sets\n1-1 stacks\nqueues\nlists\n1  -n trees\nn-m graphs\nThis phenomenon holds for component hierarchies in general. If you do not know how the hierarchy is \norganized, there is little chance that you will be able to find the component you were looking for.\nStrictly enumerative schemes use a predefined hierarchy and force you to search for a node that best \nfits the component to be classified. Though cross-references to other nodes can be included, the \nresulting network soon becomes fairly complicated. Facetted classification has certain advantages over \nthe enumerative classification used in the examples of Figures 17. 1 and 17. 3.  A faceted classification \nscheme uses a number of different characteristics, or facets, to describe each component. For example, \ncomponents in a UNIX environment could be classified according to the action they embody, the object \nthey manipulate, the data structure used, and the system they are part of. Classifying a component \nis then a matter of choosing an n-tuple which best fits that component.\nThe essence of an indexing technique is to capture the relevant information of the entities to be \nclassified. This requires knowledge of the kind of questions users will pose, as well as knowledge \nof the users’  search behavior. This is difficult,", "token_count": 512, "start_token": 328482, "end_token": 328994, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 712, "text": " an indexing technique is to capture the relevant information of the entities to be \nclassified. This requires knowledge of the kind of questions users will pose, as well as knowledge \nof the users’  search behavior. This is difficult, which makes the development of an indexing language \na far from trivial undertaking. Librarians know this. Software engineers responsible for a library \nof reusable components should know this too. Any user of the Internet will have experienced that finding \nsomething that exactly fits your needs is a very difficult task.\nThe examples contained in Figures 17.1 and 17. 3 are somewhat misleading, in that the components found \nat the leaf nodes of the hierarchy embody abstractions that are all too well known. In other domains, \nthere will be less mutual understanding as regards primitive concepts and their naming. Therefore, \nsetting up a usable taxonomy, i. e. defining an indexing language, is likely to be much more difficult \nin other domains.\nOnce a set of candidate components has been found, we need to evaluate these components for their \nsuitability in the current reuse situation. The main types of information useful for such an evaluation \nare:\n• Quality information, for example, a rating for each ISO 9126 quality characteristic (see \nChapter 6)\n\n• Administrative information, such as the name and address of the developer, the component’s \nmodification history, and information on the price of reuse\n• Documentation about what the component does and details about the internals of the component \n(if it may be adapted)\n• Interface information (most often about the types of parameters)\n• Test information, to help with testing the component in the reuse situation, such as a set \nof test cases with the associated expected results.\nValuable quality information is also provided by comments about the reuse history of the component: \nsuccessful experiences,^ critical notes about circumstances in which reuse was found to be less \nsuccessful, and so on.\nJ Be careful though. The software that caused the Ariane 5 disaster was reused from the Ariane 4 and \nnever caused any problems there (Lions, 1996); see also Section 1. 4.1.  This phenomenon may be termed \nthe antidecomposition property of software reuse: if a component has been successfully used in some \nenvironment, this does not imply that it can be successfully reused in some other", "token_count": 512, "start_token": 328944, "end_token": 329456, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 713, "text": " 1. 4.1.  This phenomenon may be termed \nthe antidecomposition property of software reuse: if a component has been successfully used in some \nenvironment, this does not imply that it can be successfully reused in some other environment.\nOne further observation that can be made about the reuse of components regards their granularity. The \nlarger a component is, the larger the pay-off will be once it is reused. On the other hand, the reusability \nof a component decreases as its size grows, because larger components tend to put larger constraints \non their environment. This is analogous to Fisher’s fundamental theorem of biology: the more an organism \nis adapted to some given environment, the less suited it is for some other environment.\nSome actual experiences suggest that practical, useful component libraries will not contain a huge \nnumber of components. For example, Prieto-Diaz (1991a) reports that the asset collection of GTE went \nfrom 190 in 1988 to 128 in 1990. Poulin (1999) asserts that the best libraries range from 30 components \nto, in rare cases, as many as 250 components. For that reason, the classification and retrieval of \ncomponents is often not the main impediment to a successful reuse program. Rather, filling the library \nwith the right components is the real issue. This aspect will be taken up again in Section 17.5.\nMore detailed technical characteristics of components, their forms, their development and composition, \nare discussed in Chapter 18.\n17.2.2. Templates\nIn the preceding section, we silently assumed library components to be ready-to-use pieces of code. \nThe applicability of a component can be increased by leaving certain details unspecified. Templates \nor skeletons are ’unfinished’  components. By instantiating them, i.e. by filling in the holes, a \n(re)usable component results.\nAn example of a possible template is a procedure that implements the quicksort algorithm. Details such \nas the bounds of the array to be sorted, the type of the array elements, and the relational operator \nused to compare array elements, are not important for the essence of the algorithm.\n\nAs more and more details are left open, a template can be applied more generally. However, there is \na price to be paid. The cost of obtaining a complete application", "token_count": 512, "start_token": 329406, "end_token": 329918, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 714, "text": " elements, are not important for the essence of the algorithm.\n\nAs more and more details are left open, a template can be applied more generally. However, there is \na price to be paid. The cost of obtaining a complete application is likely to increase in proportion \nto the number of holes to be filled in.\nTemplates need not be constrained to just subroutines. It is realistic to think of a template that \ncan be instantiated into a full program for a very specific application domain. Such templates are \ncalled application generators and are discussed in Section 17.2.4.\n17.2.3. Reuse of Architecture\nFor each problem, we must look for an architecture which best fits that problem. An inappropriate \narchitecture can never be the basis for a good system. The situation becomes rather different if a \nproblem recurs over and over again in different variants. If a useful standard architecture exists \nfor a particular type of problem, it can be applied in all future variants.\nA prime area within computer science where a software architecture is routinely reused is in building \ncompilers. Most compilers are built out of the same components: a lexical analyzer, a parser, a symbol \ntable, a code generator, and a few others. There exist certain well-defined types of parser, such as \nLL(1) or LALR(l) parsers. There is a large body of theory about how compilers function and this theory \nis known to the people building compilers. In this way, a generally accepted standard architecture \nfor compilers has evolved. Obviously, it has never been proved that this is the only, or best, way \nto build a compiler. But it constitutes a sound and well-known method of attacking problems in a \nnotoriously difficult domain.\nLarge-scale reuse of architecture is still seldom found in other areas. The main reason is that a similar \nbody of shared, crystallized knowledge just does not yet exist for most domains. We may, however, observe \nthat this situation is changing rapidly. In many fields, people are explicitly building such a body \nof knowledge and molding it into the form of a software architecture. It may be called a domain-specific \nsoftware architecture (DSSA), a product-line architecture (in which case the architecture provides \nthe basis for a family of similar systems),", "token_count": 512, "start_token": 329868, "end_token": 330380, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 715, "text": " molding it into the form of a software architecture. It may be called a domain-specific \nsoftware architecture (DSSA), a product-line architecture (in which case the architecture provides \nthe basis for a family of similar systems), or an application framework (if the emphasis is on the \nrapid generation of an application from existing building blocks); see also Chapter 11.\n17.2.4. Application Generators and Fourth-Generation  \nLanguages\nApplication generators write programs. An application generator has a fair amount of application-domain \nknowledge. Usually, the application domain is quite narrow. In order to obtain a program, one obviously \nneeds a specification of that program. Once the specification is available, the program is generated \nautomatically.\nThe principle being used is the same as that behind a generic package or template: the actual program \nto be generated is already built into the application generator. Instantiation of an actual program\n\nis done by filling in a number of details. The difference is that the size of the code delivered is \nmuch bigger with an application generator than with a template. Also, the details are generally provided \nat a higher level of abstraction, in terms of concepts and notions drawn from the application domain.\nAn application generator can be employed in each domain with a structure such that complicated operations \nwithin that domain can be largely automated. One example is the production of graphical summaries from \na database. So-called compiler compilers are another typical example of application generators: given \na grammar (i.e. the details) of some programming language, a parser for that language is produced.\nFourth-generation languages or very-high-level languages (VHLLs) are often mentioned in the same breath \nwith application generators. Fourth-generation languages offer programming constructs at a much higher \nlevel than third-generation programming languages. Model-driven development/architecture (MDD/MDA) \nmay be seen as the ultimate form of this: see also Section 3. 4.\nExpressions from a given application domain can be directly phrased in the corresponding \nfourth-generation language. Consequently, the fourth-generation language must have knowledge of that \napplication domain. This generally means that fourth-generation languages are only suited for one \nspecific, limited, domain.\nThere is no fundamental difference between fourth-generation languages and application generators. \n", "token_count": 512, "start_token": 330330, "end_token": 330842, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 716, "text": "generation language must have knowledge of that \napplication domain. This generally means that fourth-generation languages are only suited for one \nspecific, limited, domain.\nThere is no fundamental difference between fourth-generation languages and application generators. \nWhen one wants to stress the generative capabilities of a system, the term application generator is \nmostly applied. The term fourth-generation language highlights the high-level programming constructs \nbeing offered. For many such systems, the terms are used interchangeably.\nApplication generators and fourth-generation languages potentially offer a number of cost savings, \nsince implementation details need not be bothered with: less code is written, the software is more \ncomprehensible, there are fewer errors, and the software is easier to maintain. In practice, this theory \noften does not come up to expectations. For one thing, the user may want something which is not offered \nby the system. In that case, a piece of handwritten code must be added to the software being generated \nautomatically. By doing this, one of the main advantages of using fourth-generation languages, easily \ncomprehensible programs at a high level of abstraction, is lost.\n17.3. REUSE AND THE SOFTWARE LIFE CYCLE\nReuse affects the way we develop software. We may distinguish two main process models incorporating \nreuse:\n• software development with reuse, and\n• software development for reuse.\nBoth these approaches to reuse may be combined with any of the software life cycle models discussed \nearlier. Also, combinations of the ’with’  and ’for’  reuse models are possible.\n\nThe software-development-with-reuse model may be termed a passive approach to reuse. It presupposes \na repository with a number of reusable assets. At some point during the development process, this \nrepository is searched for reusable assets. If they are found, they are evaluated for their suitability \nin the situation at hand and, if the evaluation yields a positive answer, the reusable assets are \nincorporated. The process does not actively seek to extend the repository. As a side effect of the \npresent project, we may add elements to the repository, but no extra effort is spent in doing so. For \ninstance, we do not put in extra effort to test the component more thoroughly, to document it more \nelaborately, or to develop", "token_count": 512, "start_token": 330792, "end_token": 331304, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 717, "text": " we may add elements to the repository, but no extra effort is spent in doing so. For \ninstance, we do not put in extra effort to test the component more thoroughly, to document it more \nelaborately, or to develop a more general interface to it. From a reuse perspective, the \nsoftware-development-with-reuse approach is an opportunistic approach.\nA pure software-development-with-reuse model is routinely applied in, e. g. circumstances where we need \nsome mathematical routine. If our project requires some numerical interpolation routine, we search \na mathematical library. We may find some routine which uses Gaussian interpolation, fits our needs, \nand decide to incorporate it. Most likely, the project will not result in a new interpolation routine \nto be included in the library.\nDevelopment with reuse is most often applied at the component level. It has its main impact, therefore, \nduring the architectural design stage when the global decomposition into components is decided upon. \nWe search the repository for suitable candidates, evaluate them, and possibly include them in our \narchitecture. This is a cyclical process, since we may decide to adjust the architecture because of \ncharacteristics of the components found. The resulting process model is depicted in Figure 17. 4.  The \nmodel includes some further communication links between later phases of the software development life \ncycle and the repository. These reflect less far-reaching adaptations to the process model. For example, \nthe repository may contain test cases that can be retrieved and used when testing the system, or we \nmay be able to add our own test results to the repository.\nThe software-development-for-reuse process model constitutes an active approach to reuse. Rather than \nmerely searching an existing base, we develop reusable assets. The software-development-for-reuse \napproach is thus a planned approach to reuse. Again, this approach most often involves reusable \ncomponents, and we illustrate the approach by considering that situation. During architectural design, \nextra effort is now spent to make components more general, more reusable. These components are then \nincorporated into the repository, together with any information that might be of help at a later stage, \nwhen searching for or retrieving components. Software-development-for-reuse thus incurs extra costs \nto the present project. These extra costs are", "token_count": 512, "start_token": 331254, "end_token": 331766, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 718, "text": " the repository, together with any information that might be of help at a later stage, \nwhen searching for or retrieving components. Software-development-for-reuse thus incurs extra costs \nto the present project. These extra costs are only paid back when a subsequent project reuses the \ncomponents.\nSoftware-development-for-reuse process models (see Figure 17. 5) may differ with respect to the point \nin time at which components are made reusable and incorporated in the repository. In one extreme form, \nreusable components are extracted from the system after it has been developed. This may be termed the \na posteriori approach. In an a priori software-development-for-reuse approach, reusable components \nare developed before the system in which they are to be used. The latter approach has become known \nas the software factory approach.\n\nFigure 17.4. Software-development-with-reuse process model\nrequirements engineering\nr \\\nrepository\ndetail*d desin\nf\nimplementation V\ntesting r\narchitectural design\ndesign architecture\nsearch components evaluate components\nIf the architecture is developed for one specific problem, chances are that peculiarities of that \nsituation creep into the architecture. As a result, components identified might fit the present \nsituation very well, but they might not fit a similar future situation. The extra effort spent to make \nthese components reusable then might not pay off. To prevent this, development for reuse generally \ninvolves a different requirements engineering process as well. Rather than only considering the present \nsituation, the requirements for a family of similar systems are taken into account. So, instead of \ndevising an architecture for the library of our own department, we may decide to develop an architecture \nwhich fits the other departments of our university as well. We may even decide to develop an architecture \nfor scientific libraries in general. This more general requirements engineering process is known as \ndomain engineering. The resulting architecture is also termed a product-line architecture; see also \nSection 18.4.\n\nFigure 17.5. Software-development-for-reuse process model\nA disadvantage of the model depicted in Figure 17. 5 is that the development of components and the \ndevelopment of applications are intertwined. This may lead to tensions. For example, a manager \nresponsible for the delivery of an application may be", "token_count": 512, "start_token": 331716, "end_token": 332228, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 719, "text": "\nA disadvantage of the model depicted in Figure 17. 5 is that the development of components and the \ndevelopment of applications are intertwined. This may lead to tensions. For example, a manager \nresponsible for the delivery of an application may be reluctant to spend resources on developing reusable \ncomponents. An alternative form of the software-development-for-reuse model therefore is to have \nseparate life cycle processes for the development of reusable components and the development of \napplications. This latter form is discussed in Section 18.3.\n\n17.4. REUSE TOOLS AND TECHNIQUES\nIn this section, we consider a few concepts, methods and techniques that have a positive impact on \nsoftware reuse. In doing so, we reconsider the approaches discussed in the previous section, thus \nestablishing a relation between the reusable software assets discussed in the previous section and \nthe notions discussed here.\n17.4.1. From Module Interconnection Language to Architecture \nDescription Language\nThe relation between different modules of a system can be formally expressed in a module interconnection \nlanguage (MIL). A MIL is an important tool when designing and maintaining large systems consisting \nof many different modules. A MIL description is a formal description of the global structure of a software \nsystem. It can be used to verify the integrity of the system automatically. It can also be used to \ncheck whether the various modules conform to the agreed interfaces.\nFigure 17.6 contains a small fragment of (hypothetical) MIL code to illustrate the general flavor. \nThe example concerns the structure of a Key Word In Context (KWIC) index program using abstract data \ntypes (see (Parnas, 1972) for the description of this problem and its solutions). For each component, \nit specifies what the component provides to its environment and what it requires from its environment. \nThe overall result is a complete ’uses’  structure of the system. For each component, one or more \nimplementations are also indicated. The composition given at the end of the description selects a number \nof building blocks defined previously.\nMILs originated as a consequence of the separation between programming-in-the-small and \nprogramming-in-the-large. The essential ideas behind the development of MILs are:\n• A separate language for system design: A MIL is not a programming language.", "token_count": 512, "start_token": 332178, "end_token": 332690, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 720, "text": " the separation between programming-in-the-small and \nprogramming-in-the-large. The essential ideas behind the development of MILs are:\n• A separate language for system design: A MIL is not a programming language. Rather, it describes \ndesirable properties of modules that are to become part of the system being considered.\n• Static type-checking between different modules: This automatically guarantees that different \nmodules obey the interface. An interface can only be changed after the corresponding change \nhas been realized in the design.\n• Design and binding of modules in one description: In the early days of programming-in-the-large \nthe various modules of a system were assembled by hand. Using a MIL, it is done automatically.\n• Version control: Keeping track of the different versions of (parts of) a system during \ndevelopment and maintenance requires a disciplined approach.\nA number of different MILs have been developed. The basic concepts, however, are the same:\n• resources: everything that can have a name in a programming language (constants, types, \nvariables, and procedures) and can be made available by a module for use in another module:\n\nFigure 17.6. Partial MIL description of a KWIC-index system\n\nsystem kwic\nprovide kwic_system\nmodule control-mod\nprovide procedure control \nrequire input-procs, output-procs \nImplementation CONTROL \nend control .mod\nmodule inputjnod\nprovide package input-procs Is\nend input_proca \nrequire store_procs \nImplementation INPUT1 .. Java \nImplementation INPUT2 .. Pascal \nend inputunod\nmodule store-mod\nprovide package store_procs Is \nprocedure InitStore \nprocedure PutCharacter(r, w, c, d) \nprocedure CloseStore \nprocedure Lines \nprocedure Words(r) \nprocedure Characters(r, w) \nprocedure Character(r, w, c) \nend store_procs \nImplementation STORE1 .. Java \nImplementation ST0RE2 .. Pascal \nend store-mod\nCOMPOSITION\nKWIC.SYSTEMJ. = [CONTROL, INPUT2. ST0RE2,  SHIFT2", "token_count": 512, "start_token": 332640, "end_token": 333152, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 721, "text": " .. Java \nImplementation ST0RE2 .. Pascal \nend store-mod\nCOMPOSITION\nKWIC.SYSTEMJ. = [CONTROL, INPUT2. ST0RE2,  SHIFT2, S0RT2, \n0UTPUT2] \nend kwic\n\n• modules: make resources available or use them;\n• systems: groups of modules which together perform a well-defined task. To the outside world, \na system can be viewed as a single module.\nThe coupling between modules can be modeled as a graph: the nodes of the graph denote modules while \nthe (directed) edges denote the ’  uses’  relation. Depending on the sophistication of the MIL, this graph \ncan be a tree, an acyclic directed graph, or a directed graph without any restrictions.\nTo describe the architecture of a system, we need more than is generally provided by a MIL. MILs emphasize \ncomponents and uses relations between components. In particular, MILs neither treat connectors as \nfirst-class citizens nor describe the architectural configuration (topology) of the system. MILs have \nevolved into architecture description languages (ADLs) that express the latter aspects also.\nFigure 17. 7 contains part of a (hypothetical) ADL-description of the same KWIC-index program using \nabstract data types. It defines Store as a component with an abstract data type interface. It also \nlists the various methods, with their signatures, that make up this interface. The main program, kwic, \nis a component too. Its interface is defined to be of type filter; both its input and output are \nstreams of characters. The implementation part of kwic lists all components and connectors as instances \nof certain types of component or connector. Furthermore, all connections are made explicit, so that \nthe topology of the system is completely specified. For example, a procedure call connector has two \nends: a defining end and a calling end. The defining end of P in Figure 17. 7 is connected to the routine \nPutchar of module Store, while its calling end is connected to the output routine of module Input.\nMILs and ADLs generally have the same limitations: they only engage themselves in the syntax of \ninterfaces. Whether the resources passed on are meaningful or not", "token_count": 512, "start_token": 333102, "end_token": 333614, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 722, "text": " while its calling end is connected to the output routine of module Input.\nMILs and ADLs generally have the same limitations: they only engage themselves in the syntax of \ninterfaces. Whether the resources passed on are meaningful or not cannot be assessed.\nWith respect to the previous section we may note that MILs and ADLs fit in well with forms of reuse \nwhere design plays an essential role.\n17.4.2. Middleware\nIn the object-oriented paradigm, it is often stated that two objects, a client and a server, have agreed \nupon some contract, whereby the client object is allowed to request certain services from the server \nobject. A natural next step is to isolate the contents of this contract, or interface, from both client \nand server. This is essentially what happens in the Common Object Request Broker Architecture, CORBA. J \nCORBA has been developed by the Object Management Group (OMG), a multivendor effort to standardize \nobject-oriented distributed computing. JavaBeans and Microsoft’s COM and .NET are similar solutions \nto the problem of connecting components with a very long wire.\n1  CORBA, ORB, Object Request Broker, OMG-IDL, CORBAservices and CORBAfacilities are trademarks of the \nObject Management Group.\n\nFigure 17.7. Partial ADL description of a KWIC-index system\nsystem kwic\ninterface is type filter\nplayer input is Streamln \nplayer output Is Streamln \nend Interface \nimplementation is\nuses Inp instance component Input \nuses Sto instance component Store \nuses Shi instance component Shift \nuses Sor instance component Sort \nuses Out instance component Output \nuses P Instance connector ProcedureCal1 \nuses Q instance connector ProcedureCal1\nconnect input to Inp.in\nconnect output to Out.out\nconnect Inp.out to P.caller\nconnect Store.Putchar to P.definer\nconnect Out.in to Q.caller\nconnect Sor.Ith to Q.definer\nend implementation o\nend kwic\ncomponent Store\nInterface is type ADT\nplayer InitStore is RoutineDef signature (  - * >  void) \nplayer PutCharacter is RoutineDef signature \ntint x int x int x char — void) \nplayer CloseStore is R", "token_count": 512, "start_token": 333564, "end_token": 334076, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 723, "text": " type ADT\nplayer InitStore is RoutineDef signature (  - * >  void) \nplayer PutCharacter is RoutineDef signature \ntint x int x int x char — void) \nplayer CloseStore is RoutineDef signature (  — void) \nplayer Lines is RoutineDef signature (  — int) \nplayer Words is RoutineDef signature (int -» int) \nplayer Characters Is RoutineDef sign attire (int x int int) \nplayer Character Is RoutineDef signature \n(int x int x int char) \nend Interface \nimplementation Is \nvariant ST0RE2 \nend Store\n\nFigure 17.8. Partial IDL description of a KWIC-index system\nBOdUl* KWIC)\ninterface Store\n(▼Old InitStore;\nvoid PutCharacter (In int 1. in int w. in int c. in char d);  \nvoid Closestore?\nInt Lines;\nInt Words {in int 1)?\nint Characters (in int 1. in int w);\nchar Character (in int 1, in int w, in int c);\nI\ninterface Input ... \ninterface Shift ... \ninterface Sort ...\nCORBA interfaces are expressed in the Interface Definition Language (IDL). Figure 17. 8' contains part \nof such an interface definition for the KWIC index program using abstract data types. IDL is a strongly \ntyped language; it is not case-sensitive; and its syntax resembles that of C++. The interface construct \ncollects operations that form a natural group. Typically, the operations of one abstract data type \nconstitute such a group. For each operation, the result type is given, followed by the operation names, \nand finally the parameters. A result type of Void indicates that no value is returned. Parameters \nare prefixed by either in, out, or inout, denoting an input, output, or input-output parameter.\nJ Reserved words are printed in bold for legibility.\nNote the similarity between the texts of Figures 17.6,  17. 7 and 17. 8.  Each of these figures expresses \ninterfaces of components, though with a slightly different syntax and for slightly different purposes.\nMiddleware primarily shields underlying technology such as hardware, the operating system, and the \nnetwork. It", "token_count": 512, "start_token": 334026, "end_token": 334538, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 724, "text": ". 8.  Each of these figures expresses \ninterfaces of components, though with a slightly different syntax and for slightly different purposes.\nMiddleware primarily shields underlying technology such as hardware, the operating system, and the \nnetwork. It is a bridging technology. A key driver of middleware is to realize interoperability between \nindependently developed pieces of a software system. It is often used as an integration technology \nin enterprise information systems. Component models on the other hand emphasize achieving certain \nquality properties for a collection of components that together make up a system. Component models \ngenerally focus on the conventions that components running on top of the middleware must satisfy. Some \ntypes of middleware can thus be part of a component model. The Corba Component Model (CCM) is a very \nrelaxed component model. It imposes few constraints on top of its request-response type of interaction. \nOther component models offer a lot more, though. Component models are discussed in Section 18.2.\n\n17.5. PERSPECTIVES OF SOFTWARE REUSE\nUseful abstractions are discovered, not invented.\nJohnson and Foote (1988)\nIn any reuse technology, the building blocks being reused, whether in the form of subroutines, templates, \ntransformations, or problem solutions known to the designers, correspond to crystallized pieces of \nknowledge, which can be used in circumstances other than the ones for which they were envisaged \noriginally.\nA central question in all the reuse technologies discussed above is how to exploit some given set of \nreusable building blocks. This is most paramount in various projects in the area of component libraries, \nwhere the main goal is to provide ways of retrieving a useable component for the task at hand.\nAlternatively, we may look at software reusability from an entirely different angle: what building \nblocks do we need in order to be able to use them in different applications?\nReuse is not the same as reusability. Reuse of software is only profitable if the software is indeed \nreusable. The second approach addresses the question of how to identify a useful, i. e. reusable, \ncollection of components in an organized way. Such a collection of reusable components is tied to a \ncertain application domain.\nWhen trying to identify a reusable set of components, the main question is to decide which components \nare needed", "token_count": 512, "start_token": 334488, "end_token": 335000, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 725, "text": ", \ncollection of components in an organized way. Such a collection of reusable components is tied to a \ncertain application domain.\nWhen trying to identify a reusable set of components, the main question is to decide which components \nare needed. A reusable component is to be valued, not for the trivial reason that it offers relief \nfrom implementing the functionality yourself, but for offering a piece of the right domain knowledge, \nthe very functionality you need, gained through much experience and an obsessive desire to find the \nright abstractions.\nComponents should reflect the primitive notions of the application domain. In order to be able to \nidentify a proper set of primitives for a given domain, considerable experience with software \ndevelopment for that domain is needed. While this experience is being built up, the proper set of \nprimitives will slowly evolve.\nActual implementation of those primitives is of secondary importance. A collection of primitives for \na given domain defines an interface that can be used when developing different programs in that domain. \nThe ideas, concepts, and structures that play an important role in the application domain have to be \npresent in the interface. Reuse of that interface is more important than reuse of its implementation. \nThe interface structures the software. It offers a focal point in designing software for that application \narea.\nIn (Sikkel and van Vliet, 1988), such a collection of primitives is called a domain-oriented virtual \nmachine (DOVM). A domain is a ’  sphere or field of activity or influence’.  A domain is defined by consensus \nand its essence is the shared understanding of some community. It is characterized by a collection\n\nof common notions that show a certain coherence, while the same notions do not exist or do not show \nthat coherence outside the domain. Domains can be taken more or less broadly. Example domains are, \nfor instance:\n• accounting software,\n• accounting software for multinationals,\n• accounting software for multinationals, developed by Soft Ltd.\nAll accounting software will incorporate such notions as ’ledger and ’balance’.  Accounting software \nfor multinationals will have some notions in common that do not exist in accounting systems for the \ngrocery store or the milkman, such as provisions for cross-border cash flow. Representation of notions \nin software developed by", "token_count": 512, "start_token": 334950, "end_token": 335462, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 726, "text": "\nfor multinationals will have some notions in common that do not exist in accounting systems for the \ngrocery store or the milkman, such as provisions for cross-border cash flow. Representation of notions \nin software developed by Soft Ltd. will differ from those of other firms because of the use of different \nmethodologies or conventions.\nThe essential point is that certain notions play an important role in the domain in question. Those \nnotions also play a role in the software for that domain. If we want to attain reuse within a given \ndomain, these domain-specific notions are important. These notions have certain semantics which are \nfixed within the domain, and are known to people working in that domain. These semantically primitive \nnotions should be our main focus in trying to achieve reusability.\nFor most domains, it is not immediately clear which primitives are the right ones. It is very much \na matter of trial and error. By and by, the proper set of primitives show themselves. As a domain develops, \nwe may distinguish various stages:\n• At the start, there is no clear set of notions and all software is written from scratch. \nExperience slowly builds up, while we learn from previous mistakes.\n• At the second stage, similar problems are being recognized and solved in a similar way. The \nfirst semantic primitives are recognized. By trial and error, we find out which primitives \nare useful and which are not.\n• At the third stage, the domain is ripe for reuse. A reasonable amount of software has been \ndeveloped, the set of concepts has stabilized, there are standard solutions for standard \nproblems.\n• Finally, the domain has been fully explored. Software development for the domain can largely \nbe automated. We do not program in the domain any more. Instead, we use a standard interface \nformed by the semantic primitives of the domain.\nMost reuse occurs at the last stage, by which time it is not recognized as such. A long time ago, computers \nwere programmed in assembly language. In high-level languages, we ’  just write down what we want’  and \nthe compiler makes this into a ’real’  program. This is generally not seen as reuse any more. A similar \nphenomenon occurs in the transition from a third-generation language to a fourth-generation language.", "token_count": 512, "start_token": 335412, "end_token": 335924, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 727, "text": " \nthe compiler makes this into a ’real’  program. This is generally not seen as reuse any more. A similar \nphenomenon occurs in the transition from a third-generation language to a fourth-generation language.\nFrom the reusability point of view, the above classification is one of a normal, natural, evolution \nof a domain. The various stages are categorized by reuse at qualitatively different levels:\n• at the first stage, there is no reuse:\n\n• at the second stage, reuse is ad hoc;\n• at the third stage, reuse is structured. Existing components are reused in an organized way \nwhen new software is being developed;\n• at the fourth stage, reuse is institutionalized and automated. Human effort is restricted to \nthe upper levels of abstraction.\nWithin a given domain, an informal language is used. In this informal domain language, the same thing \ncan be phrased in quite different ways, using concepts that are not sharply defined. Yet, informal \nlanguage is understandable, because the concepts refer to a universe of discourse that both speaker \nand listener share.\nConcepts in a formal language do not refer to experience or everyday knowledge. They merely have a \nmeaning in some formal system. A virtual machine is such a formal system and its language is a formal \nlanguage.\nTo formalize a domain is to construct a formal (domain) language that mimics an existing informal \nlanguage. We then have to choose from the different semantic primitives that exist informally. Sometimes \nalso, it is convenient to add new primitives that fit neatly within the formalized domain.\nAs an example of the latter, consider the domain of computerized typesetting. Part of formatting a \ndocument concerns assembling words into lines and lines into paragraphs. The sequence of words making \nup a paragraph must be broken into lines such that the result is typographically pleasing. Knuth and \nPlass (1981) describe this problem in terms of ’boxes’,  ’glue’,  and ’penalties’.  Words are contained \nin boxes, which have a certain width. White space between words is phrased in terms of glue, which \nmay shrink or stretch. A nominal amount of white space between adjacent words is preferred and a penalty \nof 0 is associated with this nominal spacing. Putting words closer together (shr", "token_count": 512, "start_token": 335874, "end_token": 336386, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 728, "text": " space between words is phrased in terms of glue, which \nmay shrink or stretch. A nominal amount of white space between adjacent words is preferred and a penalty \nof 0 is associated with this nominal spacing. Putting words closer together (shrinking the glue), or \nwider apart (stretching the glue), incurs a non-negative penalty. The more this glue is stretched or \nshrunk, the higher the penalty. The penalty associated with formatting a complete paragraph in some \ngiven way then is the sum of the penalties associated with the inter-word spacing within that formatted \nparagraph. The problem may now be rephrased as: break the paragraph into lines such that the total \npenalty is minimal. (Note that penalties may also be associated with other typographically \nless-desirable properties, such as hyphenation.) The notions ’box’,  ’glue’,  and’penalty’  give a neat \nformalization to certain aspects of typography. They also lead to an efficient solution for the above \nproblem, using a dynamic programming technique.\nIn practice, formalizing is not a one-shot activity. Rather, it is an iterative process. The formalized \nversion does not exactly describe the informal language. It fixes one possible interpretation. If we \nstudy its semantics, it may have some undesirable aspects. In due course, an acceptable compromise \nis reached between those who use the language (in higher domains) and those who implement it (in lower \ndomains). Once the formal domain language is fixed, it also affects the informal domain language. People \nworking within the domain start to use the primitives of the formal language.\nIt is now clear that it is, in general, not wise to go directly from stage one (no reuse) to stage \nthree (structured reuse). Formalization has much in common with standardization. It has a solidifying \neffect on the semantic primitives of the domain. Our notion of these primitives changes, because we\n\ndo not any longer consider them as coming from the intuitive universe of discourse, but as being based \non the underlying formalism. A crucial question, namely whether we formalized the right semantic \nprimitives, then becomes harder to answer.\nStage two (ad hoc reuse) is crucial. In this stage, we get insight into the application", "token_count": 512, "start_token": 336336, "end_token": 336848, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 729, "text": "on the underlying formalism. A crucial question, namely whether we formalized the right semantic \nprimitives, then becomes harder to answer.\nStage two (ad hoc reuse) is crucial. In this stage, we get insight into the application domain and \ndiscover useful semantic primitives. This experience, both in working with the primitives and in \nimplementing them, is of vital importance for the formalization of the domain in the right way.\nThe above discussion suggests an evolutionary approach to reuse. To start with, potentially reusable \nbuilding blocks can be extracted from existing software products. While gaining experience with the \nreuse of these building blocks, better insight is obtained and better abstractions of concepts and \nmechanisms from the application domain are discovered. The library of reusable building blocks thus \nevolves and stabilizes over time.\nThis evolutionary process can be structured and guided through domain analysis, a process in which \ninformation used in developing software for a particular domain is identified, captured, structured, \nand organized for further reuse. Domain analysts and domain experts may use a variety of sources when \nmodeling a domain, including expert knowledge, existing implementations and documentation. They extract \nand abstract the relevant information and encapsulate them in reusable building blocks.\nDomain analysis often results not only in a collection of reusable building blocks. It also yields \na reusable architecture for that domain: the domain-specific software architecture, product-line \narchitecture, or application framework mentioned in Section 17.2.3.  To increase the reusability of \nthese building blocks across different operating systems, networks, and so on, they are put on top \nof some middleware platform.\n17.6. NON-TECHNICAL ASPECTS OF SOFTWARE REUSE\nThe problem is not lack of technology but unwillingness to address the most important issues influencing \nsoftware reuse: managerial, economic, legal, cultural, and social.\nPrieto-Diaz (1991b)\nMyth #1: Software reuse is a technical problem.\nTracz (1988)\nUntil now, we have discussed only the technical aspects of software reuse. Software engineering is \nnot only concerned with technical aspects but with people and other environmental aspects as well.\nBy being embedded within a society, the field of software engineering will also be influenced by that \nsociety. Software reuse in the US is likely to be different from software", "token_count": 512, "start_token": 336798, "end_token": 337310, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 730, "text": " concerned with technical aspects but with people and other environmental aspects as well.\nBy being embedded within a society, the field of software engineering will also be influenced by that \nsociety. Software reuse in the US is likely to be different from software reuse in Japan or Europe. \nBecause of cultural differences and different economic structures, it is not a priori clear that, say, \nthe Toshiba approach to reuse can be copied by Europeans, with the same results.\n\nThough our discussion so far has concerned the technical aspects of software reuse, it is not complete \nwithout a few words on non-technical issues. These nontechnical issues are intimately intertwined with \nthe more technical ones. Various practitioners in the field of software reuse have argued that the \ntechnology needed for software reuse is available, but that the main problems inhibiting a prosperous \nreuse industry are non-technical in nature.\nSuccessful reuse programs share the following characteristics:\n• Unconditional and extensive management support. A reuse program requires changes in the way \nsoftware is developed. Management commitment is essential for making such changes work. In \nparticular, building a base of reusable assets requires an initial investment which may not \npay off for some time.\n• Establishment of an organizational support structure. The organization must provide the \ninitiative for the reuse program, funding, and policies. A separate body is needed to assess \npotential candidates for inclusion in the reuse library. A librarian is needed to maintain \nthe library.\n• Incremental program implementation. A first catalog with potential reusable assets can be built \nat a relatively low cost. Positive experiences with such an initial library will raise awareness \nand provide the necessary incentives (and funding) to expand the library, devise a \nclassification scheme, etc.\n• Significant success, both financial and organizational. Raytheon for example reports a 50% \nincrease in productivity over a period of several years.\n• Compulsory or highly incentivized. Programmers suffer from the *  not invented here* syndrome. \nBy creating an environment that values both the creation of reusable software and the reuse \nof software, an atmosphere is established in which reuse may become a success.\n• Domain analysis was conducted either consciously or unconsciously. Domain analysis identifies \nthe concepts and mechanisms underlying some well-understood domain. This way, the really useful \nconcepts are captured in reusable resources.", "token_count": 512, "start_token": 337260, "end_token": 337772, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 731, "text": " reuse may become a success.\n• Domain analysis was conducted either consciously or unconsciously. Domain analysis identifies \nthe concepts and mechanisms underlying some well-understood domain. This way, the really useful \nconcepts are captured in reusable resources.\n• Explicit attention to architectural issues, such as a common architecture across a product \nline.\nSome of the non-technical aspects are discussed in the subsections below.\n17.6.1. Economics\nReuse is a long term investment.\nTracz (1990)\nReuse does not come for free. In a traditional development environment, products are tailored to the \nsituation at hand. Similar situations are likely to require slightly different products or product \ncomponents. For a software component to become reusable, it has to be generalized from the situation \nat hand, thoroughly documented and tested, incorporated in a library and classification scheme, and \nmaintained as a separate entity. This requires an initial investment, which only starts to pay off\n\nafter a certain period of time. One of the real dangers for a software reuse program is that it gets \ntrapped in a devil’s loop of the kind depicted in Figure 17. 9.\nFigure 17.9. Software reuse devil's loop\nThe major factors that determine the cost of a reusable building block are:\n• the initial development cost of that component,\n• the direct and indirect costs of including the component in a library, and\n• the cost of (possibly) adapting the component and incorporating it into the system under \ndevelopment.\nIt is obvious that the development of a reusable component is more costly than the development of a \nnonreusable component with the same functionality. Estimates of this extra cost vary from 50% to 100% \n(see also Section 7. 1. 5 on the C0C0M0 2 cost estimation model). It depends on the usage frequency of \nthe component whether its development eventually pays off.\nMore immediate returns on investment can be obtained if the reuse program starts small, with an initial \nlibrary whose members are extracted from existing products. Expansion of the program can then be \njustified on the basis of positive early experiences. But even then, non-project-specific funds must \nbe allocated to the reuse program.\n\nThe economic consequences of software reuse go beyond cost savings in production and maintenance. The \nnature of the software development process itself changes. Software becomes a", "token_count": 512, "start_token": 337722, "end_token": 338234, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 732, "text": " then, non-project-specific funds must \nbe allocated to the reuse program.\n\nThe economic consequences of software reuse go beyond cost savings in production and maintenance. The \nnature of the software development process itself changes. Software becomes a capital good. High initial \ncosts are coupled with returns over a longer time period. The production of software thus becomes a \ncapital-intensive process (Wegner, 1984). The production of non-reusable software, on the other hand, \nis a labor-intensive process. Many man-months are spent, but the profits are reaped as soon as the \nproject is finished.\nWhereas labor-intensive software production tends to concentrate on finishing the project at hand on \ntime and within budget, capital-intensive software production takes into account long-term business \nconcerns such as the collective workers’  knowledge and the collection of reusable assets. The software \nfactory paradigm discussed earlier in this chapter as well as the various approaches emphasizing the \narchitecture of a software system fit this view of the software development organization.\n17.6.2. Management\nMyth #9: Software reuse will just happen.\nTracz (1988)\nGetting software reuse off the ground cannot depend on spontaneity. Rather, software production ought \nto be organized so that reuse is promoted. In Chapter 3,  we noted that the traditional waterfall model \ntends to impede software reuse. In the waterfall model, emphasis is placed on measuring and controlling \nproject progress. The product quality with respect to reusability is hard to measure. There is no real \nincentive to pursue reusability, since the primary (and often the only) goal is to finish the current \nproject within time and budget. There is no motivation to make the next project look good. Consequently, \nsoftware reusability tends to have a low priority.\nIf reuse is not a clear objective of our software development process, it is bound to remain accidental. \nProgrammers tinker with code they have written before if and when they happen to notice similarities \nbetween successive problems. This unplanned approach to reuse is also known as code scavenging or code \nsalvaging. This is distinct from the process of reusing software that was designed to be reused. In \nthe life cycle perspective, this shows up as the difference between software-development-with-reuse \n", "token_count": 512, "start_token": 338184, "end_token": 338696, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 733, "text": " or code \nsalvaging. This is distinct from the process of reusing software that was designed to be reused. In \nthe life cycle perspective, this shows up as the difference between software-development-with-reuse \nand software-development-for-reuse.\nIn software-development-for-reuse, software reuse has been incorporated in the software development \nprocess. In this process model, reusable assets are actively sought. The concepts and mechanisms \nunderlying some domain are identified and captured in reusable resources. The focus of software \nmanagement then shifts from the delivery of individual products to maintaining and nurturing a rich \ncollection of reusable artifacts. Some of the successful reuse programs, such as those reported in \n(Prieto-Diaz, 1991b), have followed this approach.\nThe library of reusable assets itself needs to be managed. An organizational infrastructure must be \ncreated which makes the library accessible (through documentation and classification schemes), assesses \ncandidates for inclusion in the library, maintains and updates the library, etc. A separate\n\norganizational role, the librarian, may be created for this purpose. Its tasks resemble that of a \ndatabase administrator.\nOne type of reuse only mentioned in passing is reuse of good people. Expert designers are worth their \nweight in gold. Every average programmer is capable of writing a complicated, large program. In order \nto obtain a better, smaller, more elegant, radically new solution for that same problem, we need a \nperson who has bright ideas from time to time.\nA major problem in our field is that managers are rated higher than programmers or designers. If you \nare really good, you will sooner or later, but usually sooner, rise in the hierarchy and become part \nof the management. According to (Brooks, 1987), there is only one way to counteract this phenomenon. \nTo ensure that bright people remain system designers, we need a dual ranking scheme, one in which good \ndesigners have the same job prospects as good managers. Once again: the software process must be \nreconsidered as one of growing both people and the base of reusable assets (Curtis, 1989).\n17.6.3. Psychology of Programmers\nReusing other people* s code would prove that I don’t care about my work. I would no more reuse code \nthan Hemingway would reuse other authors’", "token_count": 512, "start_token": 338646, "end_token": 339158, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 734, "text": "\n17.6.3. Psychology of Programmers\nReusing other people* s code would prove that I don’t care about my work. I would no more reuse code \nthan Hemingway would reuse other authors’  paragraphs.\nCox (1990)\nSoftware reuse means that programmers have to adapt, incorporate, or rejuvenate software written by \nother programmers. There are two important psychological aspects to this process:\n• Are programmers willing to do so?\n• Are they capable of doing so?\nThe first aspect is often mentioned as a major stumbling-block to establishing a positive attitude \ntowards software reuse. Barnes and Bollinger (1991) phrase this problem of image as follows: ’Anyone \nwho has ever gone to an auto salvage yard to pick up a spare part for his old car ’  ’  knows’  ’  what reuse \nis. ’\nMany authors suggest a solution to this problem that is both simple and effective: change the programming \nculture. The experiences at Raytheon and other places suggest that it is indeed possible, given the \nright incentives and, more importantly, a management attitude that pays attention to longer-term goals \nand developers’  expectations about the nature of their work.\nResearch into the comprehensibility of software, such as reported in (Soloway and Ehrlich, 1984), shows \nthat programmers use certain standard schemes in standard situations. Experienced programmers tend \nto get confused when a known problem has been tackled using (to them) non-standard solutions. As a \nconsequence, the reusability of components is likely to be increased if the components embody \nabstractions the programmers are familiar with. Domain analysis addresses the same issues by trying \nto identify the notions that are shared by experts in a particular domain.\n\nOne side-effect of the use of standard designs and standard components is the increased \ncomprehensibility of the resulting software. Once all programmers get used to the same house style, \nall programs read as if they were written by one team. Any team can understand and adapt a program \nwritten by another team. This effect is stronger if we are able to explicitly name these larger constructs, \nas is done with design patterns and architectural styles.\n17.7. SUMMARY\nReuse projects vary considerably in a number of dimensions:\n• The thing to", "token_count": 512, "start_token": 339108, "end_token": 339620, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 735, "text": " is stronger if we are able to explicitly name these larger constructs, \nas is done with design patterns and architectural styles.\n17.7. SUMMARY\nReuse projects vary considerably in a number of dimensions:\n• The thing to be reused may be a concrete component such as a piece of code or a software \narchitecture, a more abstract concept, or even a process element such as a procedure to handle \nchange requests.\n• The scope of reuse may be horizontal or vertical. In horizontal reuse, components are generic. \nIn vertical reuse, they are domain-specific.\n• The approach to reuse may be planned or opportunistic. In planned reuse, software is designed \nto be reused. In opportunistic reuse, software is reused haphazardly, if and when we happen \nto know of its existence, if and when it happens to fit the current situation. Planned reuse \nis software development for reuse, opportunistic reuse is software development with reuse.\n• Reuse may be compositional or generative. A composition-based technology aims at incorporating \nexisting components into software to be newly developed. In a generation-based technology, \nthe knowledge reused is to be found in some program that generates some other program.\n• Reuse may be black-box or white-box. In black-box reuse, elements are reused as-is. Inwhite-box \nreuse, they may be adapted to fit the situation at hand.\nClassification schemes for reusable elements resemble those for textual sources in an ordinary library. \nThey vary from a simple Key Word In Context approach to fully automated keyword retrieval from existing \ndocumentation, and may even involve elaborate knowledge of the application domain. With respect to \nretrieval, systems may employ an extensive thesaurus to relate similar terms or offer browsing \nfacilities to inspect ’similar’  components.\nSoftware reusability is an objective, rather than a field. It emerged as an issue within software \nengineering, not because of its appeal as a scientific issue per se, but driven by the expected gain \nin software development productivity.\nThe history of software reuse starts in 1968. At the first software engineering conference, Mcllroy \nalready envisaged a bright future for a software component technology, somewhat similar to that for \nhardware components. The first conference specifically devoted to software reuse was held in 1983 (ITT, ", "token_count": 512, "start_token": 339570, "end_token": 340082, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 736, "text": " first software engineering conference, Mcllroy \nalready envisaged a bright future for a software component technology, somewhat similar to that for \nhardware components. The first conference specifically devoted to software reuse was held in 1983 (ITT, \n1983). Since then, the topic has received increased attention. Over the years, a shift in research \nfocus can be observed from domain-independent technical issues, such as classification techniques and \ncomponent libraries, to domain-specific content issues, such as architectural frameworks and domain \nanalysis.\n\nA central question in all reuse technologies discussed is how to exploit some set of reusable building \nblocks. As argued in Section 17.5,  an equally important question is which building blocks are needed \nto start with. Answering the latter question requires a much deeper understanding of the software design \nprocess than we currently have.\nSuccessful reuse programs share a number of characteristics:\n• unconditional and extensive management support,\n• an organizational support structure,\n• incremental program implementation,\n• significant success, both financial and organizational,\n• compulsory or highly incentivized,\n• domain analysis conducted either consciously or unconsciously,\n• explicit attention to architectural issues.\nReuse is not a magic word with which the productivity of the software development process can be \nsubstantially increased at a stroke. But we do have a sufficient number of departure-points for further \nimprovements to get a remunerative reuse technology off the ground. Foremost amongst these are the \nattention to non-technical issues involved in software reuse and an evolutionary approach in conjunction \nwith a conscientious effort to model limited application domains.\n17.8. FURTHER READING\nThe modern history of software reuse starts at the first NATO software engineering conference (Mcllroy, \n1968). The first conference specifically devoted to software reuse was held in 1983 (ITT, 1983). \n(Biggerstaff and Perlis, 1989) and (Freeman, 1987) are well-known collections of articles on software \nreuse. (Karlsson, 1995) is a good textbook on the subject. It is the result of an Esprit project called \nREBOOT. Amongst other things, it describes the software-development-with-reuse and \nsoftware-development-for-reuse process models. (Reifer, 1997) and (Mili et al.,  2002) are other \ntextbooks on", "token_count": 512, "start_token": 340032, "end_token": 340544, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 737, "text": " things, it describes the software-development-with-reuse and \nsoftware-development-for-reuse process models. (Reifer, 1997) and (Mili et al.,  2002) are other \ntextbooks on software reuse. Frakes and Kang (2005) discuss the status of software reuse research.\nThe various reuse dimensions are discussed in (Prieto-Diaz, 1993). A survey of methods for classifying \nreusable software components is given in (Frakes and Gandel, 1990). Advice on when to choose black-box \nreuse or white-box reuse is given in (Ravichandran and Rothenberger, 2003). Selby (2005) discusses \nfault characteristics of black-box versus white-box reuse. The application of faceted classification \nto software reuse is described in (Prieto-Diaz, 1991a).\n(Prieto-Diaz and Neighbors, 1986) gives an overview of Module Interconnection Languages. (Medvidovic \nand Taylor, 1997) gives an overview of major types of Architecture Description Languages. CORBA is \ndescribed in (Siegel, 1995). (Emmerich et al.,  2007) give an excellent overview of research on middleware \nReferences for component-based software engineering are given at the end of Chapter 18.\nThe non-technical nature of software reuse is discussed in (Tracz, 1988) and (Fafchamps, 1994). Software \nreuse success factors are discussed in (Prieto-Diaz, 1991b), (Rine and Sonnemann, 1998), (Fichman and\n\nKemerer, 2001), (Morisio et al.,  2002a), and (Rothenberger et al.,  2003). Models to quantify reuse \nlevels, maturity, costs and benefits are discussed in (Frakes and Terry, 1996). The Raytheon approach \nto software reuse is described in (Lanergan and Grasso, 1984). Experiences with successful reuse \nprograms are collected in (Schaeffer et al.,  1993), (Software, 1994b), and (JSS, 1995b).\n17.8.1. Exercises\n1. What is the difference between composition-based reuse and generation-based reuse?\n2. What is a faceted classification scheme?\n3. What is the difference between horizontal and vertical reuse?", "token_count": 512, "start_token": 340494, "end_token": 341006, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 738, "text": ".8.1. Exercises\n1. What is the difference between composition-based reuse and generation-based reuse?\n2. What is a faceted classification scheme?\n3. What is the difference between horizontal and vertical reuse?\n4. Describe the software-development-with-reuse process model. Where does it differ from the \nsoftware-development-for-reuse process model?\n5. Discuss the main differences between module interconnection languages (MILs) and architecture \ndescription languages (ADLs). How do these differences relate to software reuse?\n6. How does CORBA promote reuse?\n7. To what extent do you consider a domain-independent library of reusable software components \na realistic option?\n8. ^  For a domain with which you are familiar, identify a set of potentially reusable software \ncomponents and devise a classification scheme for them. Consider both a hierarchical and a \nfaceted classification scheme and assess their merits with respect to ease of classification \nand search, and extensibility.\n9. ^  For the same domain, assess its maturity level and that of the components identified. Can \nyou relate the maturity level of components to their perceived reusability?\n10. ^  Devise a managerial setting and a software development process model for a component-based \nsoftware factory.\n11. ^  Assess one or more of the following domains and determine the extent and kind of reuse \nthat has been achieved:\no window management systems; \no (2D) computer graphics; \no user-interface development systems; \no office automation; \no salary administration; \no hypertext systems.\n12. ^ F o r  the domains studied in Exercise 11, is there any relation between the reuse level \nachieved and (de facto or de jure) standardization within the domain? Can you discern any \ninfluence of standardization on reuse, or vice versa?\n13. ^Discuss possible merits of knowledge-based approaches to software reusability.\n\n14. ^  From your own past in software development, make an inventory of:\no components developed by yourself which you reused more than once, and \no components developed by others and reused by you.\nTo what extent does the ’  not-invented-here’  syndrome apply to your situation? Is reuse in your", "token_count": 512, "start_token": 340956, "end_token": 341468, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 739, "text": " yourself which you reused more than once, and \no components developed by others and reused by you.\nTo what extent does the ’  not-invented-here’  syndrome apply to your situation? Is reuse in your \nsituation accidental or deliberate? Were the components designed for reuse or was it, rather, \na form of code scavenging?\n15. ^Suppose you developed a routine to determine the inverse of a matrix. The routine is to \nbe incorporated in a library of reusable components. Which aspects of this routine should be \ndocumented in order that others may determine the suitability of the routine for their \napplication?\n16. ^ I n  developing abstract data types (ADTs), we try to strictly separate (and hide) \nimplementation concerns from the users of those ADTs. To what extent could these implementation \nconcerns be relevant to the person reusing them?\n\nChapter 18. Component-Based Software \nEngineering\nWith Michel Chaudron, Technische Universiteit Eindhoven, The Netherlands, and Ivica Crnkovic, \nMalardalen University, Sweden\nLEARNING OBJECTIVES\n• To understand the essentials of component-based software engineering\n• To know the main characteristics of components and component models\n• To be aware of software development processes for component-based systems\n• To be aware of the mutual relations between software architecture and component models\nNOTE\nIn component-based software engineering (CBSE), systems are assembled from existing components. In \nCBSE, there are independent development processes for components and for systems built out of components. \nComposing a system out of components is only possible if those components conform to the same set of \nstandards, also known as their component model. Component models differ in the way they handle quality \nproperties. Component models influence software architecture, and vice versa.\nChapter 17 gave a general discussion of software reuse. In this chapter, we focus on a specific type \nof reuse, that of components. A component is a building block for software, much like an LCD screen \nis a building block for a mobile phone and a rubber tire is a building block for a car. The idea behind \ncomponent-based software engineering (CBSE) is to assemble systems out of existing, independently \ndeveloped, components. CBSE entails more than the mere reuse of components, though.", "token_count": 512, "start_token": 341418, "end_token": 341930, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 740, "text": " is a building block for a car. The idea behind \ncomponent-based software engineering (CBSE) is to assemble systems out of existing, independently \ndeveloped, components. CBSE entails more than the mere reuse of components, though. It also aims to \nincrease the flexibility of systems through improved modularization.\nThe idea of separating the manufacturing of parts and the assemblage of those parts into a product \nwas pioneered around 1800 in the production of rifles. This idea has fundamentally changed the \nhardware-manufacturing business. In this chapter, we discuss how to apply the same idea to the production \nof software. The production of software parts - the components - is separated from the assemblage \nof those parts into applications. As a consequence, there will be two separate development processes, \none for components and one for applications. These processes are not independent. Applications need \ncertain components and components had better be used in applications. So there are dependencies between \nthe two development processes. These development processes and their dependencies are discussed in \nSection 18.3.\nLEGO is often taken as an example of a component-based approach. LEGO is a set of building blocks in \na large variety of shapes and colors. LEGO is sold in boxes that contain a number of blocks that can \nbe composed to make up toys such as cars, trains or airplanes. In order to enable their composition, \nall LEGO blocks provide small cylindrical stubs on the top and complementary holes on the bottom of\n\nthe shape. The conformance of the blocks to this convention ensures that blocks, possibly from different \nLEGO boxes, can be combined. Moreover, they can be combined into constructions other than the \nconstruction suggested by the manufacturer. Hence, LEGO blocks have the characteristic that they are \neasily composable and are generic. These are characteristics that we also look for in software \ncomponents.\nThere are however, many more toys that consist of building blocks that can be assembled. Take, for \nexample, Meccano and traditional jigsaw puzzles. While each of these can be combined with blocks of \nthe same type (Meccano - Meccano, LEGO-LEGO, etc.), they cannot be combined with blocks of another \ntype (e.g. Meccano - LEGO).  This illustrates that composability of building blocks is related to the \nconformance", "token_count": 512, "start_token": 341880, "end_token": 342392, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 741, "text": " Meccano, LEGO-LEGO, etc.), they cannot be combined with blocks of another \ntype (e.g. Meccano - LEGO).  This illustrates that composability of building blocks is related to the \nconformance to a set of conventions. This set of conventions is called a component model. Component \nmodels and components are discussed in Section 18.2.\nComponents are to become parts of bigger systems. As such, they have to fit the architecture of those \nsystems. One possibility is to first design the architecture and then search for components that fit \nthe architecture. A second possibility is to design an architecture of a family of (similar) systems \nand develop components that fit a variety of products within that family. A third possibility is to \nuse a bottom-up approach in which the architecture is made to fit the available components. These \ndifferent architectural approaches are discussed in Section 18.4.\nA warning about terminology is warranted. In CBSE, the word ’component’  has a more specific meaning \nthan its meaning in Standard English. Whereas ’  component’  in general means ’  part’,  in CBSE a ’  component’ \nis ’a piece of software that conforms to the rules of a particular software component model’.  The \ncomponent model used in one system may be very different from that used in another system. As a result, \nthe notion of component differs between different types of domain. In the literature, the component \nmodel assumed is often implicit. Furthermore, in earlier chapters of this book we used the term \n’component’  in its general sense of ’part’  or ’constituent’.\nCBSE is not a goal in itself, but a means to an end. CBSE is aimed at contributing to the realization \nof the business goals of an organization. The main motivations for applying CBSE are the topic of Section \n18. 1.\n18.1. WHY COMPONENT-BASED SOFTWARE ENGINEERING?\nIt is not the strongest of the species that survive, nor the most intelligent, but the ones most \nresponsive to change.\nCharles Darwin\nCBSE contributes to the following business goals:\n• CBSE increases the quality of software, especially its evolvability and maintainability. This \nhold", "token_count": 512, "start_token": 342342, "end_token": 342854, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 742, "text": " most intelligent, but the ones most \nresponsive to change.\nCharles Darwin\nCBSE contributes to the following business goals:\n• CBSE increases the quality of software, especially its evolvability and maintainability. This \nholds for both the quality of individual components and for the quality of the architecture \nof systems built in a component-based way.\n\n• CBSE increases the productivity of software development (more software per dollar).\n• CBSE shortens the development time, and thus time to market, of software.\nWe explain these benefits in a bit more detail.\nCBSE leads to a higher quality of individual software components in the following ways:\n• CBSE requires us to make the dependencies of components explicit. This reduces programming \nerrors that occur as a result of unknown or undocumented dependencies. Also, testing can be \nperformed more effectively if dependencies are explicit.\n• The more often a component is (re)used, the more likely it is that errors are found and removed. \nErrors may be uncovered during execution of a component or through the testing that is done \nbefore a component is integrated into a system.\n• Before components are offered to other parties on a commercial basis, they must be tested \nthoroughly. Otherwise, the company that offers this component will lose its credibility and \ngo out of business quickly.\n• Components must be we 11-documented, otherwise parties other than the creator of the component \nhave great difficulty in using the component.\nDeveloping software in a component-based way requires a discipline of strict modularization. The strict \nmodularization limits the domino effect of changes in the system. Hence, the effort needed to change \na component-based system is likely to be less than the effort needed when the same changes are made \nto a system that is not modularized according to a component-based design discipline. This property \nimproves maintainability. When subsystems are strictly modularized, it becomes easier to change parts \nto support new features. This improves the ability of the system to evolve.\nCBSE increases productivity through the reuse of building blocks that have been developed in earlier \nefforts or by other parties. In order for this to enhance productivity, the acquisition and integration \nof a component should of course be cheaper than developing that component from scratch. This general \ncharacteristic of software reuse has been discussed in Chapter 17.", "token_count": 512, "start_token": 342804, "end_token": 343316, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 743, "text": " or by other parties. In order for this to enhance productivity, the acquisition and integration \nof a component should of course be cheaper than developing that component from scratch. This general \ncharacteristic of software reuse has been discussed in Chapter 17.\nThe size of professional software systems is in the order of millions of lines of code. The time needed \nto realize such software systems may span several years. CBSE contributes to reducing the development \ntime of software by using existing components rather than developing components from scratch. Another \nway in which CBSE may reduce development time is by enabling concurrent development of components. \nConcurrent development of components is easier if components have minimal mutual dependencies, i.e. \nwhen components are loosely coupled. Any dependencies that do exist between components must be specified \nexplicitly. Hence, in CBSE, components are designed and specified in such a way that they can be \nconstructed independently of, and concurrently with, other components.\n18.2. COMPONENT MODELS AND COMPONENTS\nIn the introduction to this chapter, we made an analogy with LEGO and Meccano and noticed that composing \nbuilding blocks is feasible only if they conform to the same set of conventions.\n\nIn the world of engineering, the conventions for components are chosen such that they can be used for \nconstructing systems with certain properties. For example, a racing car requires parts that are \nlightweight and aerodynamic in order to obtain an overall system that is fast. An army tank requires \nparts that are tough in order to make a robust system.\nSoftware components encapsulate functionality in a form that conforms to a set of conventions. These \nconventions ensure composability and determine the properties of systems that can be built using a \nparticular type of components. Rather than physical properties, such as weight and shape, software \ncomponents are required to have properties such as computational efficiency, resource efficiency, and \nreliability. These characteristics are captured in the following definition.\nA component model defines standards for:\n• properties that individual components must satisfy, and\n• methods, and possibly mechanisms, for composing components.\nInformally, a component model defines the types of building block and the recipe for putting these \nbuilding blocks together. This definition stresses a generic constraint: components are composable.\nA component is a building block that conforms to a component model\nThe key aspect of this definition is", "token_count": 512, "start_token": 343266, "end_token": 343778, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 744, "text": " types of building block and the recipe for putting these \nbuilding blocks together. This definition stresses a generic constraint: components are composable.\nA component is a building block that conforms to a component model\nThe key aspect of this definition is composability. For software, composability may be achieved by \nusing explicit interfaces for defining what is offered as well as what is required by a piece of software \nand by defining the manner in which a component can communicate with other pieces of software. Whereas \ncomposability is a necessary technical requirement, genericity is a desirable requirement from a \nbusiness perspective. A generic component can be used more often and hence has greater potential for \ngenerating revenue. The genericity characteristic implies certain technical characteristics. For \ninstance, components with lower coupling generally have fewer dependencies on their environment and, \nhence, can be applied in a wider context. The following definition of a component is more specific \nto software.\nA software component:\n• implements some functionality,\n• has explicit dependencies through provided and required interfaces,\n• communicates through its interfaces only, and\n• has a structure and behavior which conform to an encompassing software component model;  notably \nthis applies to the interfaces and patterns of communication of the component.\nWhereas a component model defines a standard, a component technology is the collection of implementation \nartifacts that realize this standard.\nA software component technology is the implementation of a component model by means of:\n• standards and guidelines for the implementation and execution of software components, and\n\n• executable software that supports the implementation, assembly, deployment, and execution of \ncomponents.\nThere are many examples of software component technologies. A large number of component models is \noriented towards business information systems. These include Enterprise JavaBeans (EJB) (Burke and \nMonson-Haefel, 2006), C0M+ (Box, 1997), .NET (Chappell, 2006), and the CORBA-Component Model (CCM). \nOther component models are oriented towards embedded systems: the Robocop component model (Muskens \net al.,  2005) for consumer electronics and the SaveCCM (Akerholm et al.,  2007) for automotive systems. \nEach of these technologies embodies some underlying component model. Let’s look at the .NET component \ntechnology as an example. Implementation support for .  NET is provided by the", "token_count": 512, "start_token": 343728, "end_token": 344240, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 745, "text": "holm et al.,  2007) for automotive systems. \nEach of these technologies embodies some underlying component model. Let’s look at the .NET component \ntechnology as an example. Implementation support for .  NET is provided by the Visual Studio .  NET toolset \nwhich includes dedicated editors and compilers. Run-time support is provided by a run-time execution \nplatform (called the common language run-time, CLR) that runs on top of the regular operating system.\nThe composability requirement for components entails the standardization of interfaces and interaction. \nThese conditions may be sufficient to ensure composability at the implementation level of the component. \nHowever, much more can be said about properties that are generally desired from software components, \nsuch as component granularity, encapsulation, cohesion, or testability. These additional properties \nare related to general aspects of the design and development of components and are discussed in Chapter \n12-\nAlthough the definition of a component model allows a lot of freedom, in practice there is a lot of \ncommonality amongst component models. Comparing component technologies shows that they standardize \nconventions that cover multiple stages of the development of components. In the next subsection we \ndiscuss how the standards defined by component models are related to different development stages of \na component.\n18.2.1. Component Forms in Component Models\nWhen we look at the life cycle of a component, it passes through the following global stages, depicted \nin Figure 18. 1:  development, packaging, distribution, deployment, and execution. In the development \nstage, the design, specification, implementation, and meta data of components is constructed. In the \npackaging stage, all information that is needed for trading and deployment of the component \nimplementation is grouped into a single package. The distribution stage deals with searching, retrieval, \nand transportation of components. The deployment stage addresses issues related to the integration \nof component implementations in an executable system on some target platform. Finally, the execution \nstage deals with executing and possibly upgrading components.\n\nFigure 18.1. Stages of a component life cycle\nAcross these different stages of their life cycle, components are represented in different forms. In \nthe development stage, components may be represented by means of a design or specification language, \nsuch as a set of UML diagrams, and as a set of source-code and configuration", "token_count": 512, "start_token": 344190, "end_token": 344702, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 746, "text": " cycle, components are represented in different forms. In \nthe development stage, components may be represented by means of a design or specification language, \nsuch as a set of UML diagrams, and as a set of source-code and configuration files, such as a directory \nwith .c and .h files for C or a set of class files in case of Java, that together can be turned into \nexecutable code. In the packaging stage, the files that together form a component are bundled into \na single unit, for example in a compressed file. In the distribution stage, packaged components are \nrepresented in a format that can be transmitted across a network or stored on some physical carrier \nsuch as a disk or memory stick. This may be standardized by a component model but, in general, \ndistribution formats are from the area of distributed systems - nowadays, mostly Internet standards. \nAt the deployment stage, components are unpackaged in a form that can be installed onto a target machine. \nIn the execution stage, components take the form of blocks of code and data in the memory of a processor \nand cause a set of actions on this processor. All these forms are different views on, or manifestations \nof, what is logically a single building block.\nCheesman and Daniels (2000) introduce convenient terminology for denoting the different forms of \ncomponents. Figure 18. 2 shows the distinction between different forms of components that they introduced \nand the relations between them. Figure 18. 3 shows how these different forms relate to different stages \nof development.\nThe component specification describes properties that are, or should be, realized by the corresponding \ncomponent implementation. Many different properties may be included in a specification. A component \nspecification typically includes the following important properties:\n• functionality (what a component does),\n• behavior (the order of actions a component performs),\n• interaction potential (the ways according to which a component can interact with other \nsoftware),\n• quality properties such as performance and reliability.\n\nFigure 18.2. Characterization of component forms\nFigure 18.3. Forms of a component at different stages of the life cycle\nOf course, these properties should be specified in a complete, precise, and verifiable way.\n\nThe interface of a component is defined in the design stage and continues to play an important role \nin execution time. A component interface defines the actions through which", "token_count": 512, "start_token": 344652, "end_token": 345164, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 747, "text": " these properties should be specified in a complete, precise, and verifiable way.\n\nThe interface of a component is defined in the design stage and continues to play an important role \nin execution time. A component interface defines the actions through which components may communicate \nwith each other. Interfaces are offered by one component in order to be used by other components. The \ncomponent that offers an interface is responsible for realizing the actions of the interface. The \ncomponent that uses the actions of an interface only needs to know what the action achieves, not how \nit is achieved. In this sense, users of an interface are shielded from the machinery that is used to \nimplement it. This shielding is a means of abstraction - details about the realization are omitted. \nAs a result of this abstraction, different implementations of an interface may be used to realize some \naction without users of the interface being aware of it. This is, of course, the basic idea of information \nhiding, as discussed in Chapter 12.\nA typical use of this property of interfaces is to replace a component by a newer version (see Figure\n18. 4). This figure shows that component P can be replaced by component P’if P’realizes the same \ninterface Ix. Component Rthat uses interface Ixneed not be changed. The component that offers an \ninterface is called the provider of that interface; the component that uses the interface is called \nthe requirer of the interface.\nFigure 18.4. Component P can be replaced by component P1  if P1  realizes\nthe same interface Ix\nf|  component\nprovided interface \nY  required interface\nThe purpose and scope of a component specification differ from the purpose and scope of a component \ninterface. The most important difference is that specifications define a realization contract, while \ninterfaces describe usage contracts. During development of a component, the specification is a \nprescription of what the implementation should realize. As such, the specification may include the \ndefinition of interfaces. Once the implementation of a component is finished, a specification describes \nwhat architects and developers who wish to use a component may want to know about it. Here, the \nspecification is used to understand the component.\nA component specification and an interface also differ in scope: if a component has multiple interfaces, \nthese are all listed as part of the specification. The scope of a", "token_count": 512, "start_token": 345114, "end_token": 345626, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 748, "text": ". Here, the \nspecification is used to understand the component.\nA component specification and an interface also differ in scope: if a component has multiple interfaces, \nthese are all listed as part of the specification. The scope of a specification is the component as \na whole. As such it needs to specify the way in which the interfaces of a component relate to each \nother.\nA component implementation is a realization of a component specification. There has been some discussion \non how strict the hiding of internals of components should be. The black-box requirement for components \nhas been criticized as being too strong a constraint. For the purpose of tailorability or testability,\n\ncomponents should disclose more of their internals. Several variants of black box have been proposed; \nthey differ in the degree to which the internals of components can be inspected and changed by parties \nother than its developer:\n• Black-box component: only the specification and the contract of the component are available \nto the user or integrator of a component.\n• Glass-box component: the internals of the component may be inspected but not modified. The \nimplementation can thus add information to the specification of the component.\n• Grey-box component: part of the internals of a component may be inspected and limited extension \nor modification is possible; e. g. only certain methods may be defined or redefined by the user \nor integrator.\n• White-box: the component is open to both inspection and modification by its user or integrator.\nA component package is a unit of distribution. A package contains the implementation of a component, \nrelevant data files, meta-data about the component, and meta data about the package. The meta-data \nof a package contains a table of contents of the files in the package. It may be compressed to improve \ndownload time, and encrypted and certified to improve security. It can be compared to the way a ZIP \nfile can be used to package a collection of files into a single unit.\nFinally, the component instance consists of the executable code and associated data in the target machine \nThe relation between a component implementation and a component instance is like the relation between \na class and an object. The component instance will form part of the execution architecture of the running \nsystem. The execution architecture determines the performance of a system by defining the mapping of \nfunction", "token_count": 512, "start_token": 345576, "end_token": 346088, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 749, "text": " a component instance is like the relation between \na class and an object. The component instance will form part of the execution architecture of the running \nsystem. The execution architecture determines the performance of a system by defining the mapping of \nfunctionality onto run-time entities (such as processes and resources) in a system. The component \ninstance has to conform to conventions that are dictated for this purpose by the software architecture.\n18.2.2. Architecture and Component Models\nSince the mid 1990s, software architecture has been recognized as an important intermediate artifact \nof software engineering projects. The goal of a software architecture is to define the key principles \nand guidelines for developing a software system such that the resulting system and process meets its \nfunctional and quality requirements (see Chapter 11).\nThe functional requirements can be achieved by defining a functional decomposition of a system. \nFunctionality behaves relatively nicely in an additive manner: to increase the functionality of a system \nwe just add a new subsystem. Achieving the quality properties of a system is often more difficult. \nOne complicating factor is that quality properties do not have the additive property, but are the \ncollective result of interaction by all parts of a system. The performance of a system is not ’handled’ \nby one component; it is ’everywhere’.  In order to achieve some set of quality properties, all parts \nof a system must adhere to certain principles. Since quality is to a large extent determined by the \nsoftware architecture (see Chapter 11), component-based software engineering requires that attention \nbe paid to the software architecture.\n\nTo successfully develop systems in a component-based manner, an architectural plan needs to be in place< \")\nthat organizes how components fit together and how, once assembled, a system meets its quality \nrequirements. In an ideal case, the development of a system is driven by an architecture that is developed \nup front. Based on this architecture, a component model is selected or a dedicated component model \nis developed such that the rules of the component model match those of the architecture. Examples of \ndedicated component models are the Koala model (Ommering et al.,  2000) developed for meeting resource \nconstraints in consumer devices, and the SaveCCM (Akerholm et al.,  2007) model developed for meeting \ndependability requirements in the automotive", "token_count": 512, "start_token": 346038, "end_token": 346550, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 750, "text": "Ommering et al.,  2000) developed for meeting resource \nconstraints in consumer devices, and the SaveCCM (Akerholm et al.,  2007) model developed for meeting \ndependability requirements in the automotive domain. As these examples illustrate, dedicated component \nmodels are developed in domains that have rather specific quality requirements.\nDeveloping a proprietary component model takes a lot of effort. Therefore, a practical alternative \nis to select the architecture and component model in concert. To this end, a set of candidate \narchitectures and a set of candidate component models are selected. The choice of a particular component \nmodel limits the possible architectures that can be realized. If a component model is not an ideal \nmatch with the target architecture, then some additional work is needed to provide extra features or \neliminate (or hide) superfluous features. So, an architecture constrains the possible component models \nand a component model constrains the possible architectures. Typical issues that are the subject of \narchitectural decisions which may influence the choice between a custom architecture and custom \ncomponent model versus a commercial component model are: security mechanisms, transaction mechanisms, \nand scheduling policies. Typically, policies for such issues are hard-wired into commercial component \nmodels, but can be tailored when designing a custom component model.\nThere are different approaches to dividing the responsibility for managing quality properties between \ncomponents and the execution platform. The different types of approach are characterized by the \nreference architectures shown in Figure 18. 5.  The grey areas in this figure denote the locations where \nlogic resides that handles quality properties of the system. These reference architectures talk about \nquality properties in general. An instance of the architecture could be concerned with performance, \nsecurity, reliability. There are two main dimensions in which these approaches differ in managing \nquality properties:\n• The party that manages the property: Either the property is endogenous (that is, it is handled \nby the component) or it is exogenous (that is, it is handled by the system).\n• The scope of management of the property: A property is managed on a percollaboration basis \nor on a system-wide scale.\n\nFigure 18.5. Management of quality, or extra-functional properties \n(EFP)\nEndogenous EFP \nmanagement\n-o >\nDE*=S]Pat", "token_count": 512, "start_token": 346500, "end_token": 347012, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 751, "text": "\nor on a system-wide scale.\n\nFigure 18.5. Management of quality, or extra-functional properties \n(EFP)\nEndogenous EFP \nmanagement\n-o >\nDE*=S]Patent\nExogenous EFP \nmanagement\nConpcrort E*ei*«n PMtfMti\n]-------CO ---------(c-FO—  |\nCig y KEwcyiooPl^Dmi\nEFP Managed per collaboration EFP Managed systemwide\nMany component models provide no specific facilities for managing quality properties. The way a property \nis handled is, in that case, left to the designers of the system; as a result, a property may not be \nmanaged at all (approach A, in Figure 18.5). This approach makes it possible to include policies for \nmanaging quality properties that are optimized towards a specific system and can also cater for adopting \nmultiple policies in one system. This heterogeneity may be particularly useful when commercial \noff-the-shelf (COTS) components need to be integrated. On the other hand, the fact that such policies \nare not standardized may be a source of architectural mismatch between components.\nThe compatibility of components can be improved if the component model provides standardized facilities \nfor managing quality properties (approach B in Figure 18.5). In this approach, there is a mechanism \nin the component execution platform that contains policies for managing quality properties for \nindividual components as well as for quality properties involving multiple components. The ability \nto negotiate the manner in which quality properties are handled requires that the components themselves \nhave some knowledge about how the quality properties affect their functioning. This is a form of \nreflection.\nA third approach is that the components should be designed such that they address only functional aspects \nand no quality properties. Consequently, in the execution environment these components are surrounded \nby a container. This container contains the knowledge on how to manage quality properties. Containers \ncan either be connected to containers of other components (approach C in Figure 18. 5) or they can interact \nwith a mechanism in the component execution platform that manages quality properties on a system-wide \nscale (approach D in Figure 18. 5). Approach C manages interaction between two components. In approach \nD, the scope of the management can be global across the system.\n\nThe container", "token_count": 512, "start_token": 346962, "end_token": 347474, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 752, "text": " quality properties on a system-wide \nscale (approach D in Figure 18. 5). Approach C manages interaction between two components. In approach \nD, the scope of the management can be global across the system.\n\nThe container approach is a way of realizing separation of concerns in which components concentrate \non functional aspects and containers concentrate on quality aspects. In this way, components become \nmore generic because no modification is required to integrate them into systems that may employ different \npolicies for managing quality properties. Since in this approach components do not address quality \nproperties, they are simpler and smaller, and hence cheaper to implement or integrate.\nAs well as the differences discussed above, component models also have a number of features in common. \nAn overview of these common features is given in Table 18.1.  The features common to component models \nare:\nTable 18.1. Common features of component models\nInfrastructure\nInstantiation\nBinding\nCommunication\nDiscovery\nAnnouncement of capabilities\nComponent and application development support\nLanguage independence\nPlatform independence\nAnalysis support\nSupport for upgrading and extension \nSupport for quality properties\n• Infrastructure All component models provide an infrastructure: mechanisms for component \ninstantiation, binding, communication, distribution of components over hardware, announcing \ncapabilities of components and discovery of desired components. These mechanisms are needed \nto create a composition of components that can cooperate in performing a certain task.\n• Instantiation A component instance is the instantiation of an executable component at a \nspecific location in the memory of a device. The relation between a component instance and \na component implementation is the same as that between an object and a class. Once in operation, \neach component instance may create and manage its own data structures. There are a number of \ndifferent ways in which the instantiation can be achieved. The distinguishing factor is the \nelement in the architecture that controls the instantiation. In existing component models, \ninstantiation is typically controlled by the component infrastructure, a component container, \nor a component factory.\n• Binding In the context of component-based systems, binding is the creation of a link between \ntwo or more component instances. Binding can be done at design-time, compile-time or run-time.\n\nAt design time and compile time, the binding is done by the developer. These types of binding \nare called early binding.", "token_count": 512, "start_token": 347424, "end_token": 347936, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 753, "text": " or more component instances. Binding can be done at design-time, compile-time or run-time.\n\nAt design time and compile time, the binding is done by the developer. These types of binding \nare called early binding. Run-time binding is also called late binding, or dynamic binding, \nsince each invocation may, in principle, be to another instance of the component. The link \nbetween component instances may be used for communication and navigation. The distinguishing \naspect of the different ways in which binding can be organized in a component model is the \nparty that initiates the binding.\nWe distinguish first-party binding and third-party binding. In first-party binding, a \ncomponent instance binds itself to another component. In third-party binding, a binding between \ncomponent instances is created by a party other than those being bound. Consider the scenario \nwhere a binding is constructed between component A and component B. In first-party binding, \ncomponent A asks a registry where to find component B and the registry provides A with a \nreference to B; A knows about the component which it wishes to collaborate. In third-party \nbinding, another party, say C, manages the binding between A and B. C can connect A to B and \nacts as a controller; components A and B act as slaves to the controller.\nCommunication To facilitate communication between components, a component infrastructure must \nprovide some interaction mechanisms. The interaction styles supported are partially defined \nby the architectural styles that the component model supports. The communication styles that \na component infrastructure supports determine a number of the quality properties that systems \nbuilt using these components can obtain. For instance, some communication styles favor \nefficiency over flexibility. The most common style is request -response as implemented by \nmethod-calling. This style is the basis of all imperative programming languages and does not \nrequire any special facilities from the component infrastructure. The next most common style \nis events. The event style is often used in combination with request - response. It is typically \nused for notification, e.g. of exceptions. The publish - subscribe style of communication can \nbe seen as a generalization of the event style to distributed systems. Streaming is often used \nin systems that are aimed at multimedia processing.\nDiscovery A component model needs to define a mechanism by which components in the system can \nbe discovered. A", "token_count": 512, "start_token": 347886, "end_token": 348398, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 754, "text": " a generalization of the event style to distributed systems. Streaming is often used \nin systems that are aimed at multimedia processing.\nDiscovery A component model needs to define a mechanism by which components in the system can \nbe discovered. A discovery mechanism is needed to support dynamic binding. Discovery mechanisms \nare most prominent in component models with run-time binding. In systems with design-time or \ncompile-time binding, the discovery is typically guided by the designer or developer. In \nsystems with runtime binding, a registry is commonly used for the discovery of components. \nDynamic binding is a main characteristic of service-oriented architectures; see also Chapter\n19.\nAnnouncement of capabilities Usually the capabilities of a component are expressed by the \ninterfaces that it implements. The way in which interfaces are specified differs between \ncomponent models. Some component models introduce a special language for expressing interfaces \nothers use programming languages to specify the interfaces.\nComponent and application development support Component models have a variety development \nfeatures. For example, COM and .NET support development of components independent of \nprogramming language, whereas Enterprise Java-Beans (EJB) supports platform independence. \nLanguage independence Some component models support development of components in different \nprogramming languages. In order to achieve interoperability between the components developed\n\nin different programming languages, the interfaces must be specified independent of the \nprogramming language. Usually an interface description language (IDL) is used for this purpose.\n• Platform independence Some component models offer platform independence; this means that \nexecutable components can be executed on different platforms. This is usually achieved using \nan intermediate language. This intermediate language can be interpreted at run-time or compiled \nby a just-in-time (JIT) compiler.\n• Analysis support During development of individual components and applications, it may be \ndesirable to have analysis techniques. These techniques can be used to prove the correctness \nof the software or to predict quality properties of assemblies of components.\n• Support for upgrading and extension Software evolves. The value and the economic lifetime of \na device and the software on it can be increased by supporting the upgrading and extension \nof the software. Component models can support upgrading and extension at different stages of \nthe software life cycle (design, compile time, run time, etc.). The current trend is that \nupgrading and extension is shifting more and more", "token_count": 512, "start_token": 348348, "end_token": 348860, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 755, "text": " \nof the software. Component models can support upgrading and extension at different stages of \nthe software life cycle (design, compile time, run time, etc.). The current trend is that \nupgrading and extension is shifting more and more to the run-time phase of the software life \ncycle.\n• Support for quality properties When developing software, the functionality of the software \nis not the only concern. We also have to deal with quality properties such as performance, \nsecurity, and reliability. Which quality properties are important very much depends on the \nproblem domain. The quality properties that are important may introduce all kinds of \nrestrictions on a component model.\n18.3. COMPONENT-BASED DEVELOPMENT PROCESS AND \nCOMPONENT LIFE CYCLE\nThe process of component-based system development differs from the ’classical’  development processes \nof software systems as discussed in Chapter 3.  The main difference is in the separation of the development \nprocess of components from the development process of systems. Since the component-based approach is \na relatively young approach in software engineering, the main emphasis in the area has been on the \ndevelopment of technologies, while process modeling for CBSE is still a relatively unexplored area. \nThis section analyzes the basic characteristics of the component-based approach and its impact on the \ndevelopment process and life cycle models. The generic life cycle of component-based systems and the \nlife cycle of components are discussed, and the different types of development processes are discussed \nin detail: architecture-driven component development, product-line development, and COTS-based \ndevelopment.\nThe main idea of the component-based approach is the building of systems from already existing components. \nThis assumption has several consequences for the system life cycle:\n• The development processes of component-based systems are kept separate from those of the \ncomponents. The components should already have been developed, and possibly used in other \nproducts, when the system development process starts.\n• Component assessment is a new, possibly separate, process for finding and evaluating components. \nComponent assessment can be part of the main process but many advantages are gained if the\n\nprocess is performed separately. The result of the process is a repository of components that \ninclude specifications, descriptions, documented tests, and the executable components \nthemselves.\n• The activities in the", "token_count": 512, "start_token": 348810, "end_token": 349322, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 756, "text": " but many advantages are gained if the\n\nprocess is performed separately. The result of the process is a repository of components that \ninclude specifications, descriptions, documented tests, and the executable components \nthemselves.\n• The activities in the component-based development processes are different from those in a \nnon-component-based approach. For the system-level process, the emphasis is on finding the \nproper components and verifying and integrating them. For the component-level process, design \nfor reuse is the main concern.\n18.3.1. Component-Based System Development Process\nTo illustrate the specifics of the component-based development process we use the simple waterfall \nmodel as a reference. However, the illustration can relatively simply also be applied to other \ndevelopment processes. Figure 18. 6 shows the main activities of a typical component-based waterfall \nlife cycle model: requirements engineering, analysis and design, implementation, test, release, and \nmaintenance.\nThe primary idea of the component-based approach is to (re)use the existing components instead of \nimplementing them whenever possible. For this reason, the availability of existing components must \nbe considered even in the requirements and design phases.\n• Requirements engineering: In a non-component-based approach, the requirements specification \nis one of the inputs to the development of the system. In a component-based approach, it is \nsomewhat different: the requirements specification also considers the availability of existing \ncomponents. The requirements specification is not only input to the later stages, but is also \na result of the design and implementation decisions. This was touched upon when we discussed \nCOTS selection in Section 9. 1. 5.\n\nFigure 18.6. Component-based waterfall life cycle model\nAnalysis and design: The design phase of component-based systems follows the same pattern as \nthe design phase of customary development models. It consists of an architectural design phase \nfollowed by the detailed design phase. From the software architecture, the architectural \ncomponents are identified. These components are not necessarily the same as the implementation \ncomponents, but they should be identified and specified in the detailed design as assemblies \nof existing components. As in the requirements process, a tradeoff between the desired design \nand a possible design using existing components must be analyzed. In addition to this, there \nare many assumptions that must be taken", "token_count": 512, "start_token": 349272, "end_token": 349784, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 757, "text": " design as assemblies \nof existing components. As in the requirements process, a tradeoff between the desired design \nand a possible design using existing components must be analyzed. In addition to this, there \nare many assumptions that must be taken into consideration during design. For example, it must \nbe decided which component models will be used. This decision has an impact on the architectural \nmodel as well as on certain system quality properties.\nImplementation: The implementation phase includes less coding than in a more traditional \ndevelopment process for implementing functions and focuses more on the selection of available \ncomponents. In an ideal case, there is no coding at all. In practice, components often have \nto be adapted to fit the requirements and design specification. Required functionality that \nis not provided by any existing component must be implemented and the relevant stakeholders \nhave to decide whether these new functions are imple mented in the form of new components that \ncan be reused later. An inevitable part of the implementation of a component-based system is \nthe ’  glue’  code which connects components, enables their intercommunication and, if necessary, \nsolves possible mismatches. In the ideal case, glue code can be generated automatically.\n\n• Integration: The integration phase includes activities that build the system from the incoming \nparts. The integration phase does not include ’  creative’  activities in the sense of creating \nnew functions by producing new code. For this reason, it is desirable to automate and \nrationalize the integration process as much as possible. The integration phase is however very \nimportant, as it is the ’moment of truth’.  Problems arise which are due to architectural \nmismatches of incoming components or unwanted behavior of different quality properties at the \nsystem level. That is why the integration phase is tightly connected to the system test phase \nin which the system functions and quality properties are verified.\n• Test: In CBSE, the need for component verification is apparent since the system developers \ntypically have no control over component quality, component functions, etc., as the components \ncould have been developed in another project with other purposes. The tests performed in \nisolated components are usually not enough since their behavior can be different in the \nassemblies and in other environments. The Ariane example from Section 1. 4. 1 is a case in point.\n• Release", "token_count": 512, "start_token": 349734, "end_token": 350246, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 758, "text": " The tests performed in \nisolated components are usually not enough since their behavior can be different in the \nassemblies and in other environments. The Ariane example from Section 1. 4. 1 is a case in point.\n• Release: The release phase includes packaging of the software in forms suitable for delivery \nand installation. The CBSE release phase is not significantly different from a ’classical’ \nrelease phase.\n• Maintenance: The maintenance approach of CBSE is to replace old components by alternative \ncomponents or by adding new components to the system. The paradigm of the maintenance process \nis similar to that for development: find a proper component, test it, adopt it if necessary, \nand integrate it into the system.\nFigure 18. 6 shows a simplified and idealized process. Its assumption is that the components selected \nand used are sufficiently close to the units identified in the design process that the selection and \nadaptation processes require (significantly) less effort than the components’  implementation. Further, \nthe figure shows only the process related to system development and not the supporting processes that \nhave to do with the assessment of components and the development of components.\n18.3.2. Component Assessment\nWhile development of component-based systems significantly decreases the detailed design and \nimplementation effort during system development, it requires additional effort in other activities. \nFor example, instead of implementing the required functions, developers have to search for components \nthat provide such functionality. Developers must also verify that the selected components provide (or \napproximate) the desired functionality, and that they can successfully be integrated with other \ncomponents. A consequence might be that the best components are not selected but rather the components \nthat best fit together.\nTo make the system development process efficient, many assessment activities can be performed \nindependently, separate from system development. A generic assessment process includes the following \nactivities:\n• Find From an unlimited component space, find the components that might provide the required \nfunctionality.\n\n• Select The candidate components found are compared and ranked. A component that is most suitable \nfor the given requirements and constraints is selected. The ranked list of components should \nbe maintained throughout system development so that alternatives for a function can quickly \nbe found.\n• Verify Verification is part of the component selection process. The first level of verification \nincludes", "token_count": 512, "start_token": 350196, "end_token": 350708, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 759, "text": " is selected. The ranked list of components should \nbe maintained throughout system development so that alternatives for a function can quickly \nbe found.\n• Verify Verification is part of the component selection process. The first level of verification \nincludes testing functional and certain quality properties of a component in isolation. A \nsecond level of verification involves testing the component in combination with other \ncomponents integrated in an assembly.\n• Store When a component is assumed to be a good candidate for the current or future applications, \nit is stored in a component repository. The repository should not only include the component \nitself, but also additional information (meta-data) that can be useful in further exploitation \nof the component. Examples of such meta-data are measured results of component performance, \nknown problems, response time, tests passed, and test results.\n18.3.3. Component Development Process\nThe component development process is in many respects similar to the system development process: \nrequirements must be captured, analyzed, and defined; the component must be designed, implemented, \nverified, validated, and delivered. When building a new component, developers will reuse other \ncomponents and will use similar procedures of component evaluation as for system development. There \nis, however, a significant difference: components are intended for reuse in (many) different products, \nmany of them yet to be designed. The consequences of this difference are the following:\n• There is greater difficulty in managing requirements.\n• Greater efforts are needed to develop reusable units.\n• Greater efforts are needed to provide component specifications and additional material that \nhelp developers and consumers of the components.\nBelow, we highlight the specific characteristics of activities of a component development and \nmaintenance process.\nRequirements Engineering. Requirements specification and analysis is a combination of a top-down and \na bottom-up process. The requirements elicitation should be the result of the requirements specification \nat the system level. However, since the components are also built for future systems, not even yet \nplanned, these system requirements have not necessarily been identified. For this reason the process \nof capturing and identifying requirements is more complex. It must address ranges of requirements and \npossible reusability. Reusability is related to generality, thus the generality of the components should \nbe addressed explicitly.\nAnalysis and Design. The input to the design phase in the component development process", "token_count": 512, "start_token": 350658, "end_token": 351170, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 760, "text": " of requirements and \npossible reusability. Reusability is related to generality, thus the generality of the components should \nbe addressed explicitly.\nAnalysis and Design. The input to the design phase in the component development process comes from \nsystem design, system constraints, and system concerns. Since such systems do not necessarily exist \nyet, the component designer must make many assumptions about the system. Many assumptions and \nconstraints are determined by selecting a component technology. The component technology determines, \nfor example, possible component interactions, certain solutions built into the technology (such as\n\ntransactions or security mechanisms), and assumptions of system resources (such as scheduling policies) \nFor this reason, it is most likely that a component model and a component technology that implements \nthat model must be chosen at design time.\nFor a component to be reusable, it must be designed in a more general way than a component tailored \nfor a unique situation. Components intended to be reused require adaptability. This increases the size \nand complexity of the components. At the same time, they must be concrete and simple enough to serve \nparticular requirements in an efficient way. This requires more design and development effort. \nDeveloping a reusable component may require three to four times more resources than developing a \ncomponent which serves a specific purpose (Mili et al.,  2002).\nImplementation. Implementation of components is, to a large extent, determined by the component \ntechnology selected. The component technology provides support in programming languages and automation \nof component compositions. It may include many services and provide many solutions that are important \nfor the application domain. Good examples of such support are transactions management, database \nmanagement, security, and interoperability support for distributed systems provided by component \ntechnologies such as .NET, J2EE, or C0M+.\nIntegration. Components are built to be easily integrated into systems. For this reason, integration \nconsiderations must be continuously in focus. Usually, component technology provides good support for \ncomponents integration and integration is being performed on a daily basis.\nTest. Test activities are of particular importance for two reasons. First, the component should be \nvery carefully tested since its usage and environment context is not obvious. No specific conditions \nshould be taken for granted, but extensive tests and different techniques of verification should be \nperformed. Second, it is highly desirable that", "token_count": 512, "start_token": 351120, "end_token": 351632, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 761, "text": " should be \nvery carefully tested since its usage and environment context is not obvious. No specific conditions \nshould be taken for granted, but extensive tests and different techniques of verification should be \nperformed. Second, it is highly desirable that the tests and test results are documented and delivered \nwith the component to system developers.\nRelease. Release and delivery of the components is the phase where (assemblies of) components are \npackaged into sets that are suitable for distribution and installation. Such a package not only includes \nthe executable components, but also additional information and assets (meta-data that specifies \ndifferent properties, additional documentation, test procedures, test results, etc.).\nMaintenance. A specific aspect of maintenance in component-based systems is the relation between a \ncomponent and the systems it is used in. If a bug in a component is fixed, the question is to which \nsystems a new version of the component should be delivered. Who will be responsible for the update: \nthe component producer or each of its consumers? There is also the question of who is responsible for \ncomponent maintenance: is this a responsibility of the component producer or the producer of the system \nthis component is part of? Do component producers have the obligation to fix bugs and support updates \nin the systems that make use of their components? Can they provide support in return for additional \npayment?\nEven more difficult problems are related to ’blame analysis’.  The issue is related to a manifestation \nof a fault and the origin of the fault itself. A fault might be detected in one component, but the \ncause of that fault might be in another component. For example, due to a high frequency of input in\n\ncomponent A, component A requires more CPU time. As a consequence, component B does not complete its \nexecution during the interval assumed by component C. Component C then issues a time-out error and \na user of component C gets the impression that an answer from component C was not delivered. A first \nanalysis shows that the problem is in component C, then B, then A, and finally in the input to A. The \nquestion is: who performs this analysis if the producers of components A, B, and C are different? Such \nsituations can be regulated by contracts between the producers and consumers of the components, but \nthis requires additional effort and, in many cases, it", "token_count": 512, "start_token": 351582, "end_token": 352094, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 762, "text": " performs this analysis if the producers of components A, B, and C are different? Such \nsituations can be regulated by contracts between the producers and consumers of the components, but \nthis requires additional effort and, in many cases, it is not possible at all.\nThe above example shows that maintenance activities can be much more extensive than expected. For this \nreason, it is important that component producers build a strategy for performing maintenance and take \ncorresponding actions to ensure the realization of this strategy. For example, component producers \nmight decide to provide maintenance support; it is then important that they can reproduce the context \nin which the error manifested.\n18.4. ARCHITECTURAL APPROACHES IN COMPONENT-BASED \nDEVELOPMENT\nIndustrial practice has established several approaches to using component-based development. These \napproaches, while similar in using component technology, have quite different processes and different \nsolutions at the architectural level. In this section, we look at three approaches, all component-based, \nbut with quite different assumptions, goals and, consequently, processes.\n18.4.1. Architecture-Driven Component Development\nThis is a top-down approach. Here, components are identified as part of an architectural design. The \ncomponent izat ion of the architecture serves as away of achieving a high level of modularity. Components \nare not primarily developed for reuse, but rather as pieces to fit into the specified architectures \n(in the same way as pieces in a jigsaw puzzle). In the implementation, component-technologies (such \nas .Net) are used, but this is mainly because of the extensive support of component technology for \nmodeling and specification, because of easier implementation, and the possibility of using standard \nservices of a component technology. The genericity of these components is limited: they only have to \nfit the architecture they were designed for. Reusability and time-to-market issues are of less concern.\nAn example of this approach would be the software that controls flying an aircraft. It requires a \ndedicated architecture where each of the components has highly domain-specific functionality. However, \na component-based approach would allow replacing of individual components by newer versions.\n18.4.2. Product-Line Development\nThis approach has a strong top-down direction, but also some bottom-up elements.", "token_count": 512, "start_token": 352044, "end_token": 352556, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 763, "text": ". However, \na component-based approach would allow replacing of individual components by newer versions.\n18.4.2. Product-Line Development\nThis approach has a strong top-down direction, but also some bottom-up elements. In contrast to the \nprevious approach, this approach aims to enable efficient development of many variants of products\n\n- sometimes called a family of products or a product-line. Such families are common in consumer products \nsuch as mobile telephones, televisions, and home audio equipment. Product-line development tries to \ncater for easily making and maintaining many variants of a products with minimal technical diversity \nat minimal costs. The solution for this is sought in component-based architectures. This architecture \ndefines the common parts of the system and the parts that are variable.\nAs an example of this approach, consider a product family of consumer electronics products which includes \nCD players, DVD players, and mobile phones. In this case, careful design of the architecture would \nallow an MP3 decoding component to be integrated into the architecture of the CD player, DVD player, \nand mobile phone.\nThe component-based character of the architecture plays a crucial role: it enables reuse of components \nand efficient integration. Composability, reusability, and time-to-market are equally important.\nIt is characteristic of product lines that the architectural solution has a direct impact on the \ncomponent model. The component model must comply with the pre-defined reference architecture. In \npractice, many companies have developed their own component model that suits their proprietary \narchitecture. A second characteristic of product-line architectures is a high degree of concurrency \nbetween the component development process and product development process and a combination of top-down \nand bottom-up procedures.\n18.4.3. COTS-Based Development\nThis is mostly a bottom-up approach: it tries to assemble a system from existing components. The \narchitecture of the system is secondary to the combinations of components that are available.\nFrom the perspective of the system developer, the strongest driver for this approach is time to market: \nwhat components exist that we can quickly assemble into a system? For this approach to work, there \nmust be component developers that aim at developing highly reusable functionality. Overall, this \napproach assumes that the system development process is completely separate from the development \nprocesses of components", "token_count": 512, "start_token": 352506, "end_token": 353018, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 764, "text": " into a system? For this approach to work, there \nmust be component developers that aim at developing highly reusable functionality. Overall, this \napproach assumes that the system development process is completely separate from the development \nprocesses of components.\nWhile the COTS approach gives instant value in new functionality, there are a number of problems in \nthis approach that complicate its realization: because components were not designed to comply to a \ncomponent model or to fit together, this approach may run into problems of composability. This may \noccur if the semantics are not clear or if architectural properties of the components are not properly \nand adequately documented. For COTS-based development, component assessment plays a much more important \nrole than in the previous two approaches.\nAs an example of this approach consider a Web store. Web stores now have a fairly crystallized \narchitecture that has a fair amount of commonality with the architecture of many business information \nsystems. A Web-store system can be assembled by buying components that are sold as building blocks \non the software market. Typical components include: database, Webserver, search engine, payment handler\n\nand stock-control system. In this case, a selection is made of which (combination of) components is \nmost appealing and then an architecture is designed which integrates these components.\n18.4.4. Selecting an Approach\nWhich of these approaches is best or most CBSE-specific? There is no definitive answer. After a surge \nof enthusiasm in both industry and research, the COTS components market has decreased and does not \nshow revolutionary improvement. One of the reasons for that is that it is difficult to achieve \nreusability by being very general, effective, and simple and, at the same time, provide attractive \nfunctionality. Furthermore, there are problems of trustworthiness (who can guarantee that the component \nis correct?), component verification, and certification.\nThe product-line approach has been successful in many domains and its combination with CBSE is a \npromising approach. Possible threats are the increasing costs of development and maintenance of the \ncomponent technologies developed internally, and the pace of technological innovations in compilers, \ndebuggers, and integrated development environments. In some cases, the internally developed component \ntechnologies are replaced by widely used general-purpose component technologies, while keeping the \noverall product-line approach.\n18", "token_count": 512, "start_token": 352968, "end_token": 353480, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 765, "text": " compilers, \ndebuggers, and integrated development environments. In some cases, the internally developed component \ntechnologies are replaced by widely used general-purpose component technologies, while keeping the \noverall product-line approach.\n18.5. SUMMARY\nThe vision of assembling systems using independently developed components was first published by Mcllroy \n(1968). In his paper, Mcllroy identifies important concepts, such as component, binding, and variabili ty \nFollowing his paper on components, Mcllroy worked on the pipes-and-fiIters mechanism in the Unix \noperating system. The composition mechanism of pipes and filters is still unique in its genericity \nand simplicity.\nThe goals of component-based software engineering are to\n• reduce development time,\n• improve productivity, and\n• improve the evolvability and maintainability of software systems.\nIn order to enable composition of components the components need to be compatible. This compatibility \nis achieved by component models that define a set of conventions to which individual components must \nadhere. Component models are developed to satisfy the quality requirements of particular application \ndomains. In this chapter, we have discussed the common features of component models.\nTo successfully develop systems in a component-based manner, an architectural plan needs to be in place \nthat organizes how components fit together and how, once assembled, a system meets its quality \nrequirements. An architectural plan is essential when reuse of components is needed across a family \nof related products, a so-called software product line.\n\nThe process of CBSE is characterized by a separation of the development processes of the individual \ncomponents and the development process of the system that uses components.\n18.6. FURTHER READING\n(Szyperski, 1998) is a seminal book about component software; it contains chapters on CORBA, COM and \nJavaBeans. Wang and Qian (2005) discuss many different component models and give extensive code examples \n(Heine-man and Counci 11, 2001) is a comprehensive book on component-based software engineering that \ncovers development processes, design methods, component technologies, and legal issues. Szyperski (2003! \ndiscusses the state of the art in component technology. Cheesman and Daniels (2000) discuss the design \nof component-based systems.\nArchitecture-", "token_count": 512, "start_token": 353430, "end_token": 353942, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 766, "text": ", and legal issues. Szyperski (2003! \ndiscusses the state of the art in component technology. Cheesman and Daniels (2000) discuss the design \nof component-based systems.\nArchitecture-driven component development is discussed in (Crnkovic and Larsson, 2002a). Software \nproduct lines are discussed in (Clements and Northrop, 2002) and (Weiss et al.,  1999). (Morisio et \nal., 2002b) discuss COTS-based software development. Crnkovic and Larsson (2002b) discuss the \nchallenges of component-based software development and illustrate them with a case study.\nResearch on CBSE has largely focused on mechanisms for modularization. Only recently, has the notion \nof composition become recognized as a subject of study in its own right. For example, mixins (Bracha \nand Cook, 1990) generalize the type of composition provided by the inheritance mechanism of \nobject-oriented languages. (Achermann et al.,  2000) discuss language support that enables us to \nconstruct more complex composition recipes from simpler ones. Another direction of research is looking \nto identify the units of software that best match the needs of software engineers when assembling systems \nExamples of other types of unit of composition are features (Turner et al.,  1999) and aspects (Suvee \net al., 2006).\n18.6.1. Exercises\n1. What is a component?\n2. What are the benefits of CBSE?\n3. How are components and component models related?\n4. Discuss the stages of a component life cycle.\n5. How does a component specification differ from a component interface?\n6. Describe four ways in which quality can be managed in a component model.\n7. What is the difference between early binding and late binding?\n8. What is the difference between first-party binding and third-party binding?\n9. How does the component-based software development process differ from the more traditional \nsoftware development process discussed in Parts I and II of this book?\n10. Why is a component assessment process needed in CBSE?\n11. Why is software architecture important for CBSE?\n12. Discuss the main differences between:\no architecture-driven component development, \no product-line development, and\n\no COTS-based development.\n", "token_count": 512, "start_token": 353892, "end_token": 354404, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 767, "text": "E?\n11. Why is software architecture important for CBSE?\n12. Discuss the main differences between:\no architecture-driven component development, \no product-line development, and\n\no COTS-based development.\n13. What are differences between CBSE and reuse?\n14. Recommend which aspects of a component should be covered by its specification.\n15. ^Putting two stone bricks or blocks of LEGO together does not yield a stone brick or a LEGO \nblock, but the result of such a composition is again composable. What is happening here? What \nis kept invariant by composition? What are the similarities and differences between composing \nwith LEGO blocks and composing with software components?\n16. ^  Which mechanisms in different programming paradigms (imperative, functional, logical) can \nbe considered as composition mechanisms? See, for example, (Assman, 2003).\n17. ^Provide a list of issues that may cause incompatibility (and hence incomposability) between \ncomponents.\n18. ^Mechanisms in the execution platform play an important role in enabling run-time \ncomposition of software components. Are such infrastuctural mechanisms also needed for \ncomposing electronics components? Give reasons.\n\nChapter 19. Service Orientation\nLEARNING OBJECTIVES\n• To understand the essentials of service orientation\n• To know the characteristics of a service-oriented architecture (SOA)\n• To know how Web services implement services\n• To know the essentials of service-oriented software engineering (SOSE)\nNOTE\nIn service orientation, a system is made up of services that are discovered dynamically. The use of \nservices gives rise to a typical overall architecture: the service-oriented architecture (SOA). The \nusual implementation of a service-oriented system is via Web services that make heavy use of open \nstandards. Service orientation is more than just a technology. It marks a shift from producing software \nto using software.\nMy wife and I like to visit the local Italian restaurant. It provides an excellent service. There is \nan elaborate menu to choose from. You can either pick individual dishes or select one of the suggested \nmenus. The waiters are vintage Italian, but understand the orders if articulated carefully. The orders \nare conmunicated with the kitchen by yelling the number on the menu (I guess, because my Italian is \n", "token_count": 512, "start_token": 354354, "end_token": 354866, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 768, "text": " the suggested \nmenus. The waiters are vintage Italian, but understand the orders if articulated carefully. The orders \nare conmunicated with the kitchen by yelling the number on the menu (I guess, because my Italian is \nquite bad). It seems to work, since invariably the dish asked for arrives at our table.\nThe Italian restaurant provides a service. The above story uses the three basic ingredients of services:\n• services, which may consist of other services (the restaurant service consists of a choice \nof menus and drinks)\n• service descriptions (the details listed on the menu)\n• service communication (the yelling of orders).\nService orientation is a popular development model these days. It grew out of component-based software \nengineering (CBSE), and heavily uses the Web. A service resembles a component in CBSE; a service \ndescription resembles a CORBA or .NET description of a component; and service communication resembles \na remote procedure call. Though services, service descriptions, and service communication resemble \nwell-known concepts, they differ slightly from these concepts. Taken together, these differences make \nservice-orientation really different from component-based approaches.\nIf one component in a component-based system makes use of another component, the selection of that \ncomponent is made at design time. The caller knows all the details of the callee that it needs to know: \nname, parameters, quality. The composition can be tested before it is put into operation. There often \nare a lot of tacit dependencies between the two components: they most likely run, and have to run, \non the same platform, for example.\n\nThis is not true if services are used. In a service-oriented system, one service (component) may ask \nfor another service (component), but the selection is made dynamically. In a voice-recognition \napplication, for example, we may need a service to remove noise from a taped message. There may be \nseveral candidate services that deliver the functionality asked for. They may differ in price, quality \nof the noise removal, speed, and so on. They may be written in different languages and run on different \nplatforms. The selection of a specific noise-reduction service is done dynamically and, potentially, \na different one may be chosen each time it is needed. This latter aspect is what makes a service-oriented \napproach truly", "token_count": 512, "start_token": 354816, "end_token": 355328, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 769, "text": "\nplatforms. The selection of a specific noise-reduction service is done dynamically and, potentially, \na different one may be chosen each time it is needed. This latter aspect is what makes a service-oriented \napproach truly different from CBSE. * *  The major characteristics of services are further discussed in \nSection 19.1.\nJ Actually, the difference is not as sharp as suggested here. We may argue that the use of such patterns \nas the factory pattern also allows for the dynamic selection of components.\nThe use of services gives rise to a service-oriented architecture (SOA) in which services interact \nthrough a messaging engine, the service bus. The coordination of services is taken care of in a dedicated \ncoordination layer. The service-oriented architecture is discussed in Section 19.2.\nThe usual implementation of a service-oriented system is via Web services. Often, Web services and \nservice orientation are viewed as synonyms. However, Web services are an implementation means to realize \nservice-oriented systems. Web services make heavy use of a number of open standards, such as XML, SOAP, \nand others. Section 19. 3 introduces the main open standards used to realize Web services. These standards \ndescribe only the syntax level. For example, SOAP is used to describe how services exchange messages. \nBut it only describes the syntax of the messages, not their semantics. (Berners-Lee et al.,  2001) \ndescribe an extension of the current Web in which information has a meaning. This second-generation \nWeb is called the ’  semantic web’.  In the semantic web, services also carry semantics. These semantics \ncan be used in service discovery, composition, and so on. Second-generation Web services languages \nwill exploit these semantics. These second-generation languages are beyond the scope of this chapter.\nService orientation has its impact on the various phases of the software development life cycle. This \nhas resulted in the notion of service-oriented software engineering (SOSE), discussed in Section 19. 4.\nService orientation is more than just a technology. Traditional software engineering approaches are \ngeared towards the production of software. Organizations using these traditional approaches build \ncomplete software solutions or individual components. Their customers buy these solutions and then, \nusually, own them. They have to install the software on their machines, and receive regular patches", "token_count": 512, "start_token": 355278, "end_token": 355790, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 770, "text": " towards the production of software. Organizations using these traditional approaches build \ncomplete software solutions or individual components. Their customers buy these solutions and then, \nusually, own them. They have to install the software on their machines, and receive regular patches \nor have to buy the next version or release.\nThis is not true in a service-oriented approach. Service orientation marks a shift from producing \nsoftware to using software. In service orientation, an organization need not host the software, need \nnot keep track of versions and releases, need not ensure that the software evolves with the wishes \nand requests of its users, and so on. The software is ’  somewhere’  and is deployed on an as-needed basis. \nTo emphasize this shift in perspective, service-orientation is sometimes referred to as software as \na service (SaaS).\n\n19.1. SERVICES, SERVICE DESCRIPTIONS, AND SERVICE \nCOMMUNICATION\nThe notion of service-oriented design goes back to the early 1990s. Service orientation has driven \nthe *  intelligent network services’  of the telecommunications domain. Telecommunications services such \nas free-phone (e.g., 800 services) and credit-card billing are built on top of complex distributed \nsystems and require the cooperation of large numbers of computers, databases, peripherals, and networks \n(Margaria and Steffen, 2006).\nIn some sense, services are just like components: a system is made up of a collection of communicating \nservices. Most of the important characteristics of services as listed in Table 19. 1 resemble well-known \ncharacteristics of ’ordinary’  components. If well-designed, ordinary components are also loosely \ncoupled (this is one of the design criteria discussed in Chapter 12), adhere to a contract (often phrased \nin terms of pre- and post-conditions), hide their logic (information hiding), and so on. Yet, the \ncharacteristics of services differ subtly from those of software components, as discussed below.\nServices can be discovered Services are discovered dynamically. This characteristic has repercussions \nfor many of the other characteristics and makes services distinctly different from the components in \na component-based system.\nService discovery means that, given a description of what the service is supposed to do (the contract), \na dynamic search is done for candidate services that are capable", "token_count": 512, "start_token": 355740, "end_token": 356252, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 771, "text": " makes services distinctly different from the components in \na component-based system.\nService discovery means that, given a description of what the service is supposed to do (the contract), \na dynamic search is done for candidate services that are capable of fulfilling that contract. This \nprocess is depicted in Figure 19.1.  One service, the service requestor, sends a lookup request for \nanother service to a service registry. If a suitable candidate service is found, its details are returned \nto the service requestor, which can then be bound to that candidate service, the service provider. \nOf course, the candidate service first has to register itself by publishing information in the registry. \nThe registry thus acts like a phone directory.\nTable 19.1. Main characteristics of services\nServices can be discovered\nServices can be composed to form larger services\nServices adhere to a service contract\nServices are loosely coupled\nServices are stateless\nServices are autonomous\nServices hide their logic\nServices are reusable\nServices use open standards\n\nTable 19.1. Main characteristics of services\nServices can be discovered\nServices facilitate interoperability\nFigure 19.1. Service discovery and communication\nConsider for example our library system. At the highest level, we might distinguish services that deal \nwith membership administration, catalog administration, and a news service. The latter is intended \nto provide a window on the surrounding world to the community of library users. It may link to relevant \ngovernment regulations, healthcare institutes, and so on. The news service may consist of a number \nof smaller, more specialized services, the invocation of which depends on the user query. It may invoke \na service provided by the local hospital if the query concerns healthcare, a service provided by local \ngovernment if the query concerns government regulations, or a Google-like service.\nThe suitability of a service for a given service consumer request depends on the contract it offers. \nThe service consumer may also take other considerations into account when choosing a particular service. \nFor instance, depending on demand load, complexity of the question, and other parameters, a service \nat a particular location may be selected. The dynamism of service orientation thus offers a way of \noptimizing use of computer resources.\nDynamic discovery can also be used to increase the robustness and fault tolerance of applications. \nIn our news service example, the quality of answers to news requests may not be known in advance", "token_count": 512, "start_token": 356202, "end_token": 356714, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 772, "text": " way of \noptimizing use of computer resources.\nDynamic discovery can also be used to increase the robustness and fault tolerance of applications. \nIn our news service example, the quality of answers to news requests may not be known in advance. So \na query to one news service provider may yield an answer which is not considered adequate by the service \nrequestor. The latter may then dynamically try another provider. The same can be done if a given news \nservice provider fails to return an answer within a certain time frame. The result is a more robust, \nmore fault-tolerant, service assembly.\nServices can be composed to form larger services In our library system, services invoke other services \nto deal with part of their service offering. Viewed the other way round, these smaller services are\n\ncomposed to form larger services. Conceptually, this is not different from the way small components \nare building blocks for larger components in CBSE.\nServices adhere to a contract If the query concerns healthcare, we may have other options besides the \nlocal hospital, such as health insurance companies and local drugstores. The services of insurance \ncompanies may require membership. The healthcare service may be slow and the information returned very \nreliable. The drugstore service may be fast but the information returned somewhat less reliable. Figure \n19. 2 shows schematically how a healthcare query might be handled. Four candidate services have \nregistered themselves in the registry: Hospital, InsuranceA, InsuranceB and Drugstore, \ntogether with their characteristics with respect to cost, speed, and reliability of information. If \nthe healthcare inquiry service asks for a service which is both free and reliable, Hospital is \nselected, the link is made, and the query is executed. J\n1  In Figure 19.2,  the numbers in brackets indicate the order in which messages are exchanged.\nFigure 19.2. Example service discovery and communication\n(4)\nThe input of the request to the registry should contain everything that is needed to do the search \nand return a satisfactory answer. In an ordinary component-based system, the invocation of a component \ncontains all the information the called component needs to do its job but there is often a lot of tacit \ninformation shared between components. This tacit information is known to the designer, but is not \nexplicitly encoded. It is shared knowledge between the components, but nowhere stated", "token_count": 512, "start_token": 356664, "end_token": 357176, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 773, "text": " needs to do its job but there is often a lot of tacit \ninformation shared between components. This tacit information is known to the designer, but is not \nexplicitly encoded. It is shared knowledge between the components, but nowhere stated explicitly. \nTypically, this involves things such as:\n• platform characteristics, such as the version of the database management system, the operating \nsystem, and the network and message protocols\n• quality information, such as performance, reliability, availability, and so on\n\n• design decisions that go beyond an individual component; for example, different components \nfrom an insurance portfolio may all tacitly assume that the renewal date is 1 April.\nThis information is not tacitly shared in a service-oriented system. Platform characteristics need \nnot be the same for all components in a service-oriented setting. Web services (see Section 19.3) and \nthe associated open standards allow for a smooth bridging of platform differences. Other types of \ninformation have to be made explicit, though. Both components and services work according to a contract. \nIn the case of components, this contract lists functional obligations. For services, the contract lists \nboth functional and quality obligations.\nIf it is required that a service has certain performance characteristics, this has to be specified \nin the service request. And, conversely, candidate services have to publish their performance \ncharacteristics. During the search, performance requirements can then be compared against the \nperformance offerings of candidate services and a suitable candidate can be chosen.\nNot all quality information, however, is easy to specify. How for instance should the information \nreliability of the news services in our library example be specified? Is a choice between two options \n(reliable and notsoreliable) sufficient? And what do these qualifications mean?\nFor all types of quality information, the question remains how the service requestor should assure \nitself of the promised characteristics. A health insurance company may desire to present itself as \na reliable source of information. But how can the news service know or ascertain that the promised \ninformation reliability level will indeed be reached? We may want to have stronger evidence than the \nmere promise of the service provider.\nOne possible way to handle this is to have an independent, trusted intermediary that collects evidence \nof the quality characteristics of a service. For example, if some party has been using the service \nand experienced certain", "token_count": 512, "start_token": 357126, "end_token": 357638, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 774, "text": " promise of the service provider.\nOne possible way to handle this is to have an independent, trusted intermediary that collects evidence \nof the quality characteristics of a service. For example, if some party has been using the service \nand experienced certain quality levels, these can be reported to the trusted intermediary and can be \nused to update the available quality information of that service. This process is not that different \nfrom similar processes that have been proposed for collecting and disseminating quality information \nfor commercial off-the-shelf (COTS) components. In the case of services, we need to explicitly model \nthis information in such a way that it can be dynamically used by other services.\nCollectively, the set of quality characteristics promised or required by a service is termed Quality \nof Service (QoS). This term is used in contexts such as telephony, networking, and streaming media \nto denote performance requirements one party asks for and another party has to comply with. A related \nterm is Service Level Agreement (SLA). This notion also has been around for many years, most notably \nin deployment contexts, where the SLA describes certain levels of availability, throughput, and so \non, that parties agree on. Both terms are used in the context of services to denote the quality part \nof a service contract.\nA service may offer more than one QoS level. For instance, a voice-recognition service may offer a \nfast but somewhat noisy result, or a much better result at a slower speed. It is then up to the service \nconsumer to choose between these QoS levels.\n\nServices are loosely coupled Because of the dynamic discoverability, we cannot tacitly assume anything \nfrom a service found. Everything two interacting services need to know from each other has to be passed \nexplicitly. A natural consequence then is that we aim for a situation in which they need as little \ninformation as possible. So we want services to be loosely coupled. This is a well-known decomposition \ncriterion in every software design method. But in the realm of services, loose coupling also means \nloose coupling at the business level. A healthcare inquiry from the news service of the library system \nmay be answered by a service provider hitherto completely unknown.\nServices are stateless Since the selection of a service is done dynamically, potentially at least a \ndifferent candidate may be selected each time a certain service is", "token_count": 512, "start_token": 357588, "end_token": 358100, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 775, "text": " service of the library system \nmay be answered by a service provider hitherto completely unknown.\nServices are stateless Since the selection of a service is done dynamically, potentially at least a \ndifferent candidate may be selected each time a certain service is needed. At some point in time, service \nInSUranceA from health insurance company CompA might be selected, while next time service \nHospital from the City Hospital might be the preferred option. The coupling between the library \non one side and CompA and City Hospital on the other side is thus very loose. A consequence of this \ntype of loose coupling is that services have to be stateless.\nServices are autonomous; services hide their logic A service cannot retain information that is saved \nfor a future invocation. The next invocation may well be to another service with the same functionality, \nbut from a different provider.\nIn our library example, the news service has its own rules which determine how its process is structured. \nIts logic does not depend on other services of the library, such as those that have to do with membership \nadministration or the catalog administration. This works two ways: the news service is autonomous and \nits internal logic is hidden.\nServices are reusable A service models a business process. As such, a service is usually not very \nfine-grained. In our library example, one business process may have to do with the handling of fines, \nwhile another has to do with the complete administration of library items. Borrowing a book is not \na business process and is not modeled as such in a separate service. Deciding on the proper granularity \nof services often raises much debate in service-oriented development. An important criterion is that \nservices should be reusable.\nServices use open standards In order that different companies can produce and use a variety of services, \nthey communicate through open standards. When two applications cooperate through a proprietary standard \nit may not be all that easy to change to another provider for either of them. If the provider of those \napplications does not disclose the way these applications interface, one is forced to change both. \nIf the provider does disclose the interface, there might well not be a ready solution available, and \na solution has to be developed that matches the particular interface. So the user organization in many \ncases is confronted with a package deal. This is known as vendor lock-in. Vendor", "token_count": 512, "start_token": 358050, "end_token": 358562, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 776, "text": " might well not be a ready solution available, and \na solution has to be developed that matches the particular interface. So the user organization in many \ncases is confronted with a package deal. This is known as vendor lock-in. Vendor lock-in does not occur \nif open standards are used. Any provider can decide to abide by those open standards, and thus enter \nthe market. There are open standards for how services are described, how they communicate, how data \nis transferred between services, and so on. Some of the main open standards in use for service-oriented \nsystems are discussed in Section 19.3.\nServices facilitate interoperability A consequence of the use of open standards and the loose coupling \nbetween services is that interoperability is eased. In more classical approaches, the integration of,\n\nsay, the news services provided by insurance companies and hospitals on the one hand, and a library \ninformation system on the other, poses challenges because of proprietary and incompatible data formats, \nplatform differences, and so on. With services, these incompatibilities are partly hidden inside \nindividual services, and partly subsumed by the open standards. Interoperability, within and across \norganizational boundaries, is thus made a lot easier.\nThe characteristics of services do not come about automatically. They have to be designed in. The \nservice-oriented architecture (SOA), discussed in Section 19.2,  promotes realization of those \ncharacteristics. Section 19. 4 gives further guidelines for the design of services.\n19.2. SERVICE-ORIENTED ARCHITECTURE (SOA)\nA system that is composed of a collection of services that send and receive messages has an architecture, \nlike any other system. If no structure is imposed on the way the services are connected through message \nsending, a bowl of spaghetti results: a spaghetti-oriented architecture. But this is not what we usually \nmean by the acronym SOA.\nIn the world of services, the term SOA is often used to denote any system built out of services or \none utilizing Web services. We, however, confine the term to standing for a specific architectural \nstyle that has become widely used (see Figure 19. 3). It has two layers of services, called the business \nservice layer and infrastructure service layer. The services in these layers communicate through a \nservice bus. Finally, the coordination of", "token_count": 512, "start_token": 358512, "end_token": 359024, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 777, "text": "style that has become widely used (see Figure 19. 3). It has two layers of services, called the business \nservice layer and infrastructure service layer. The services in these layers communicate through a \nservice bus. Finally, the coordination of services is done in the coordination layer.\nIn this architectural style, services do not send each other messages directly, which would result \nin the spaghetti style mentioned above. Rather, they do so via a service bus, an event-based messaging \nengine. This bus acts as an intermediary between services. Services send their messages to the bus, \nwhich in turn redirects them to the appropriate receiver of the message.\n\nFigure 19.3. SOA architectural style\nThe service bus solves major complexity problems that often face application integration projects. \nThis is also the area from which the service bus concept comes. A rather straightforward application \nintegration effort consists of just putting a wrapper around existing legacy applications. These \nwrappers hide data formats and internal details and provide an XML-based Web interface instead. This \nis not a viable solution in the long run, though, because of platform differences between applications. \nTo solve this type of integration problem, the notion of an enterprise service bus (ESB) was developed.\nA similar type of bus is used in a service-oriented architecture .  As well as routing messages, the \nservice bus usually also takes care of a number of other issues that services have to deal with, such \nas:\n• Mediation: protocol translation, data transformations, dealing with platform differences and \nother adaptations needed for services that use different protocols, data formats, and so on, \nto cooperate\n• Quality of Service: issues that have to do with security, the reliable delivery of messages, \nand so on\n• Management: monitoring or logging service usage and gathering audit information.\nConceptually, we have depicted the service bus as a centralized entity. It may be implemented as such, \nin a broker or hub style. It may also be implemented in a decentralized way, in smart endpoints of \nmessage exchanges.\n\nThe business service layer contains services that represent distinct pieces of business logic. The \ninfrastructure service layer contains services that represent supporting activities, such as the \nstoring and shipping of data.\nFinally, the interaction between services has to be coordinated. For example, a sequence of services \nmay have to be invoked", "token_count": 512, "start_token": 358974, "end_token": 359486, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 778, "text": "\ninfrastructure service layer contains services that represent supporting activities, such as the \nstoring and shipping of data.\nFinally, the interaction between services has to be coordinated. For example, a sequence of services \nmay have to be invoked in a certain order. Or, if a sequence of services is to be invoked to form one \ncoherent transaction, we may want to ensure that the whole chain of services has been executed. If \na failure is discovered somewhere in the chain, services that have already been executed have to be \nundone. To model service interaction, special languages have been developed that express these types \nof coordination issues. These coordination languages generally grew out of languages for workflow \nmanagement.\nCoordination languages for services come in two flavors: orchestration and choreography. In \norchestration, there is a central place where coordination takes place. In choreography, there is no \nsuch central place: coordination is distributed. This resembles an orchestra with its conductor and \na ballet performance, respectively. In practice, orchestration languages are used more often than \nchoreography languages.\nLogically, the coordination layer addresses services in the business and infrastructure service layer. \nPhysically, this linkage is via the services bus, since all message exchanges go via this mediation \ncomponent.\n19.3. WEB SERVICES\nWeb services are an implementation way of realizing services. Web services use a standardized way to \nintegrate services across the Internet. The main open standards used to realize Web services are:\n• Extensible Markup Language (XML), which has the primary goal of sharing data between \napplications\n• Simple Object Access Protocol (SOAP), used to transfer messages between services\n• Web Services Description Language (WSDL), used to describe available services\n• Universal Description, Discovery, and Integration (UDDI), used to list the available services.\nIn the context of Web services, XML is used to structure messages. In particular, SOAP messages, WSDL \ndocuments, and UDDI descriptions are all encoded as XML documents.\nThese open standards achieve interoperability between two services. What they do not achieve is \nintegration of a collection of services. If a collection of services is to be integrated into a \nservice-oriented system, there are certain global rules or constraints that such a conglomerate has \nto obey. For instance, if a complex insurance", "token_count": 512, "start_token": 359436, "end_token": 359948, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 779, "text": "integration of a collection of services. If a collection of services is to be integrated into a \nservice-oriented system, there are certain global rules or constraints that such a conglomerate has \nto obey. For instance, if a complex insurance service consists of several smaller services, we may \nrequire that a transaction is completed entirely. If this cannot be achieved, parts that have been \nrealized have to be undone. Also, we may wish to be able to roll back to earlier points in the process. \nThis requires a language to express the flow of process steps. One such language is the Business Process\n\nExecution Language for Web Services (BPEL4WS). This type of language is used at the coordination layer \nof the SOA (Figure 19.3).\nFigure 19.4 gives an example of how we may combine WSDL and BPEL4WS in a typical application. WSDL \nis used to describe individual services. These services are implemented in some language, say Java. \nThe flow of process steps is *  programned’  in BPEL4WS. Each individual process step refers to a service \nin WSDL. This can be applied recursively. So the complete composition as given in Figure 19. 4 may be \nreferred to as a service in some other WSDL description, and used as a single entity in another \ncomposition.\nWhen two components (services, applications, and so on) communicate over a network, they do so via \na protocol, such as FTP for file transfer and SMTP for mail transfer. These protocols provide containers \nof information, such as ’file’  and ’mailbox’,  as well as operations to put information into those \ncontainers and get information out of them. In a similar way, Web services realize connectivity between \nnetwork nodes. A SOAP message definition also provides for a container, and ways for the message sender \nto put the message into the container and for the message receiver to get the message out of the container. \nHowever, the SOAP user defines his own message format in each SOAP definition. In that sense, SOAP \nis not a protocol, but a language to define new protocols. The same holds for WSDL and other Web services \nstandards.\nFigure 19.4. Coordination of Web services\ncoordination\nThe Web", "token_count": 512, "start_token": 359898, "end_token": 360410, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 780, "text": " SOAP \nis not a protocol, but a language to define new protocols. The same holds for WSDL and other Web services \nstandards.\nFigure 19.4. Coordination of Web services\ncoordination\nThe Web services open standards form a stack, known as the Web services stack; see Figure 19. 5.  At \nthe lowest level of this stack, we encounter the familiar network protocols. At the next level, SOAP \ndeals with the interaction between services. WSDL and UDDI reside at the next higher level. They concern \nthe description and discovery of services. At the highest level, BPEL4WS is concerned with the \ncomposition of services. At all levels above the network layer, XML is used as the \ndocument-representation language.\n\nThere are many other, more specialized open standards related to Web services. WS-Security for example \ndeals with the integrity and confidentiality of messages. It describes how to make SOAP messages secure. \nWS-ReliableMessaging deals with the reliable delivery of messages. WS-Policy allows for the description \nof policies of service providers and consumers, with respect to QoS, for example. Further information \non these open standards can be found at the websites of OASIS and W3C, the two main consortia in the \narea of Web services.\nFigure 19.5. The Web services stack\ncomposition \ndescription \nmessages \nnetwork\nThe most popular underlying technology platforms to realize Web services are J2EE and .  NET. J2EE provides \ndifferent types of component, such as Enterprise JavaBeans (EJBs) and servlets, to realize Web services. \nThe main API for processing messages is JAX-RPC (Java API for XML-based RPC). In the .NET environment, \nWeb services are represented by units of programming logic called Assemblies. An Assembly consists \nof one or more classes. The .NET class library provides classes for processing SOAP messages, WSDL \ndefinitions, and so on.\n19.3.1. Extensible Markup Language (XML)\nXML grew out of HTML, the language used to describe the format and layout of Web pages. HTML has a \nfixed set of elements that are used to describe Web pages. In XML, elements are not predefined. The ", "token_count": 512, "start_token": 360360, "end_token": 360872, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 781, "text": ")\nXML grew out of HTML, the language used to describe the format and layout of Web pages. HTML has a \nfixed set of elements that are used to describe Web pages. In XML, elements are not predefined. The \nuser of XML can define his own vocabulary in an XML schema. The vocabulary defines the language used \nin a specific set of documents. Documents can be encoded in XML conforming to the schema.\nFor instance, in our library system, we may have a schema called library that defines the syntax \nof documents that describe library items. All items in the library can be encoded using this schema. \nA small example is given in Figure 19.6.\nBPEL4WS\nWSDL UDDI\nSOAP\nHTTP. FTP. etc.\ndiscovery\n\nFigure 19.6. XML example\n<?xml version=\"1.0\"? »\n< JDOCTYPE library SYSTEM \"library.dtd\">\n<libitem category=\"Novel\">\n<title>What is the What* \\title>  \n<author>Dave Eggers< \\author -  \n<year *2007< \\year'^\n< \\libitem>\nThe first lines in the example tell us that XML version 1.0 is used, and the XML schema used is called \nlibrary. The next lines have the familiar syntax of HTML, but the keywords used are different. These \nkeywords are defined in the schema, in this case a Document Type Definition called library, dtd. \nThe example describes one library item in the category Novel, and lists the title, author, and year \nof publication of that novel.\nAn XML schema defines one or more trees, nested categorizations of constructs. In the example of Figure \n19. 6,  it is a very simple tree in which a 1 ibitem has three child nodes. XML provides a way to structure \nthis type of hierarchical information. It is only about syntax. An XML document carries no semantics, \nthough. Any XML document having a structure that conforms to the 1 ibitem schema will be accepted \nas a valid library item.\nXML has evolved into more powerful languages that do allow for the inclusion of semantic information \nin documents. The main exponent of this is the Ontology Web Language (OWL). The semantic information \nincluded can be used in service discovery and mapping processes", "token_count": 512, "start_token": 360822, "end_token": 361334, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 782, "text": " evolved into more powerful languages that do allow for the inclusion of semantic information \nin documents. The main exponent of this is the Ontology Web Language (OWL). The semantic information \nincluded can be used in service discovery and mapping processes. Where XML is the basis for \nfirst-generation, syntax-based Web services, OWL is the basis for second-generation, semantics-based \nWeb services.\nXML is used to represent all kinds of data in Web services. Web services communicate by sending each \nother data formatted as XML documents. SOAP messages are XML documents, the entries in a UDDI are XML \ndocuments, and the service descriptions of WSDL are XML documents. XML documents are omnipresent in \nWeb services. The flexibility of XML and its wide support in industry are a major factor in the success \nof Web services.\nOften, items from different XML schema have to be combined in one document. Since names in a single \nXML document have to be unique, each vocabulary is given its own namespace, and names are then prefixed \nwith a reference to the namespace where that name is defined. For example, SOap I binding refers \nto binding as defined in the WSDL namespace for SOAP bindings (see Figure 19.7). It is customary \nto use the prefix ths:  to refer to the current document (’this namespace’).\n\n19.3.2. Simple Object Access Protocol (SOAP)\nThe Simple Object Access Protocol is the format for exchanging messages between Web services. A SOAP \nmessage is sent from a SOAP sender of one service to the SOAP receiver of another service, possibly \nvia SOAP intermediaries at intermediate services. The message is contained in a SOAP envelope. This \nenvelope in turn has an optional header and a mandatory body. The header is like the address on an \nenvelope or the header of an email message. It contains information that identifies intermediaries \nand meta information about the SOAP message. The body is the container for the actual data being \ntransferred.\nA SOAP message is unidirectional. It defines a message from one service to another, not a conversation \nbetween services. If we have to cope with conversation issues and state information that has to be \nkept between two messages, this has to be done at higher levels such as", "token_count": 512, "start_token": 361284, "end_token": 361796, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 783, "text": " It defines a message from one service to another, not a conversation \nbetween services. If we have to cope with conversation issues and state information that has to be \nkept between two messages, this has to be done at higher levels such as WSDL or BPEL4WS.\n19.3.3. Web Services Description Language (WSDL)\nWSDL is used to define individual Web services. A short example of a WSDL definition is given in Figure\n19. 7.  This example shows the four main parts of a Web service definition:\n• Web service interfaces, labeled portType. This is similar to a component interface as used \nin component-based software engineering. A service interface has a name and a series of \noperations.\n\nFigure 19.7. WSDL example\n\n•;defini tions names *  Healthcar©Information•\ntargetNamespaces *http:  / /example .org/HeaIthcarelnformat ion \n.wsdl\" >\n-  message names\"GetHealthcarelnformationlnput\" >\n•part names \"body* element s*xsd:\nHealthcarelnformationRequest'X >\n-.message names'GetHealthcarelnformationOutput* - »\n-part na»e=\"body* element=Hxsd:\nHealthcareInformationResult\"\\ •\nvportType names” Heal thcarelnformationPortType\" - \n-operation names*GetHealthcareInformation\">\n•  input messages a  ths:GetHealthcareInformationlnput”\\ \n-  output messages\"ths2\nGetHealthcarelnformationOutput \"\\ >\n-  \\operation -\n-  \\portType>\n•binding names\"HealthcarelnformationSoapBinding\" \ntype =*ths:HealthcareInformationPortType\" - \n.soap:binding style = 'document\" \ntransport » •someURI*\\>\n-  operation names •GetHealthcarelnformation*:\ninput -\n•  soap:body use s \"literal*\\ >\n•  \\input- \noutput >\n-soap:body use = \"literal*\\ •\n< \\output>\n< \\operation>\n- \\binding>\n-service names\"HealthcarelnformationService\":\n•  port names\" HealthcarelnformationPort\"\nbind", "token_count": 512, "start_token": 361746, "end_token": 362258, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 784, "text": "ap:body use = \"literal*\\ •\n< \\output>\n< \\operation>\n- \\binding>\n-service names\"HealthcarelnformationService\":\n•  port names\" HealthcarelnformationPort\"\nbindings ” ths:Heal thcarelnf ormat ionSoapBinding *  > \nsoap:address locations\"http: //example.org/ \nHealthcareInformtion\"\\ >\n< \\port*\n-  \\service~-\n< \\definitions -\nMessages, labeled message. When an operation is executed, messages may be exchanged.\n\n• Bindings, whic h define transport and format details for the operations and messages of an \ninterface. An interface (portType) can have multiple bindings.\n• Services, which describe the collection of endpoints for accessing a service. An endpoint, \nor port, is a combination of a binding and a network address. A service can have several ports \nof the same portType, but with different bindings. The behavior of these ports then is \nsemantically equivalent, but one may, for instance, be faster than the other.\nThe portTypes and Messages describe the abstract interface description, while Bindongs and Services \ndescribe the concrete, implementation part of the service description.\nThe example in Figure 19. 7 concerns the news component service of our library system. One of the \noperations of interface HealthcarelnformationPortType is\nGetHealthcarelnformation, which retrieves healthcare information. This operation is a \nrequest - response type of operation. It has an input message GetHealthcarelnformat ionlnput \nand an output operation GetHealthcarelnformationoutput. Other possibilities are: one-way \n(only input), notification (only output) and solicit - response (output message followed by an \nacknowledgement).\nNext a binding, Healthcarelnformat ionSoapBinding, is defined and tied to an actual service \nfound at http: //examp 1 e. org/Hea 1 thcareInformation.  It uses the WSDL 1. 1 binding for SOAP 1. 1 endpoints. \nThe request - response combination used in GetHealthcarelnformation need not be similarly \ncombined in the actual binding. For example, the two messages may be exchanged in two actual \ncommunications.\nThis example only scratches the", "token_count": 512, "start_token": 362208, "end_token": 362720, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 785, "text": ". \nThe request - response combination used in GetHealthcarelnformation need not be similarly \ncombined in the actual binding. For example, the two messages may be exchanged in two actual \ncommunications.\nThis example only scratches the surface of WSDL. There are many other features that WSDL has, such \nas the ability to decompose large service descriptions into smaller ones, and the ability to describe \nfaults, i.e. events that disrupt the normal flow of messages. Also, WSDL builds on and uses other open \nstandards, such as those for building namespaces.\n19.3.4. Universal Description, Discovery, and Integration (UDDI)\nThe UDDI is a registry of service descriptions. A UDDI allows one to publish and search for services. \nA UDDI registry is either public or private. The original vision behind UDDI was to have a huge public \nregistry, very much like a phone directory, in which every organization would publish its services. \nReality is different. Many organizations do not want their services to be made available outside the \norganization. Others only want to make services available to partner organizations. The current version \noffers different levels of visibility for service descriptions.\nEntries in a UDDI registry have three main parts:\n• b u s i n e S s E n t i t y :  information about the organization that publishes the services: name, \ndescription, a unique identifier, and so on\n• businessservices:  descriptive information about the actual services provided by the \norganization, such as a unique identifier for each service\n\n• bindingTemplateS:  technical information to link services to implementation information \na binding template may point to a website or it may point to the actual service description.\nEntries are stored in XML format. These entries are quite complex and are not really meant for humans. \nThe keys used to identify an organization or service, for instance, can be readable names such as a \ndomain name, but they often look like a rather complex bar code. Interaction with the registry is done \nby SOAP messages.\nHaving different registries rather than one global registry poses additional challenges very similar \nto the challenges of distributed databases. For instance, keys and other information may have to be \nmapped between registries. The interaction between a collection of", "token_count": 512, "start_token": 362670, "end_token": 363182, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 786, "text": ".\nHaving different registries rather than one global registry poses additional challenges very similar \nto the challenges of distributed databases. For instance, keys and other information may have to be \nmapped between registries. The interaction between a collection of registries has to obey the policies \nof the organizations that make use of those registries. The interface to such a set of UDDI registries \nis often through publishing and inquiry systems in which these policies are embedded. There is however \nno standard for how to encode the information to be published in a UDDI registry. If our news service \nlooks for a service Healthcarelnquiry and the hospital has published its service as \nHealthcarelnformation, it will never be selected.\n19.3.5. Business Process Execution Language for Web Services  \n(BPEL4WS)\nBPEL4WS is a language for programming-in-the-large. It has variables, if_then_else statements, \nwhile statements, and so on. But the elementary objects are not numbers and strings, but process \nsteps. A BPEL4WS ’program’  describes the workflow of a business process.\nThe three main parts of a BPEL4WS process definition are (see also Figure 19. 8):\n• partnerLinks, which define dependencies between services\n• variables, which store information to be kept between service invocations\n• a workflow model, which expresses the sequence of process steps to be executed.\nA process has a number of partner services that participate in the process. For the news services, \npossible partner services are HealthcarelnformationService (see Figure 19.7) and \nHospital Informat ionService. For each such partner service, the BPEL4WS process definition \nprovides a partnerLinkType element that identifies the corresponding portType elements from \nthe WSDL definition.\n\nFigure 19.8. BPEL4WS skeleton process definition\n•process name=\"NewsServiceProcess\">\n< partnerLinks >\n« -  \\partnerLinks\n<variables *\n\\variables >\n<sequence>\n< \\sequence>\n< \\process>\nFigure 19.9. BPEL4WS partnerLinks\n-  partnerLinks -\n-partnerLink name = \"RequestLT*\npartnerlinkType=*HealthcarelnformationServicePortType\"  \nmyRole=\"He", "token_count": 512, "start_token": 363132, "end_token": 363644, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 787, "text": "Figure 19.9. BPEL4WS partnerLinks\n-  partnerLinks -\n-partnerLink name = \"RequestLT*\npartnerlinkType=*HealthcarelnformationServicePortType\"  \nmyRole=\"Hea1thcarelnformtionServiceProvider\"\\ •\n- partnerLink name=\"HospitalRequestLT\"\npartnerlinktype=*HospitalInformationServicePortType\"  \npartnerRole=\"HospitalInformationServiceProvider\"\\>\n-  \\partnerLinks •\nFigure 19.9 gives an example that defines two partnerlinkTypeS I  RequestLT and \nHospitalRequestLT. Two roles are distinguished for these links: myRole and partnerRole. \nmyRole is used when the service is invoked by a client service, i. e. the service acts as a provider. \npartnerRole is used when the service invokes another service. The partnerRole then identifies \nthe partner service that is invoked. A service can both be invoked and invoke other services in the \nsame partnerLink. In that case, both roles occur in the same partnerLink.\nInformation on partner links is also embedded in the WSDL definition of services. It resembles the \ninformation given in Figure 19. 9.\n\nThe variables part of a BPEL4WS process definition is used to store state information related to \nthe workflow. For example, the news service may store the healthcare information received from, say, \nthe drugstore service, examine its contents and invoke the hospital service if the information received \nis of low quality. Each variable has a type, which has to be given upon definition of that variable.\nIn a real news service interaction, there will be many requests for information, and many receipts, \nthat co-exist, i.e. there will be many instances of the news service. Within a specific interaction, \nthere thus has to be a way of connecting the right reply to a given request. This is similar to ordinary \nbusiness transactions, where many orders may be ’alive’  concurrently. It is customary to identify \nparticular orders by a specific token, say a purchase order number, which is used during the whole \nworkflow. It is used when the order is shipped, when it is being paid, when enquiries are made, and \nso on. In service interactions, similar tokens are used as part of", "token_count": 512, "start_token": 363594, "end_token": 364106, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 788, "text": ", which is used during the whole \nworkflow. It is used when the order is shipped, when it is being paid, when enquiries are made, and \nso on. In service interactions, similar tokens are used as part of the messages being exchanged. Messages \nare correlated to relate operations within a service instance, for example to connect a news reply \nto the corresponding request.\nFinally, the S e q u e n c e  part of a BPEL4WS process definition gives the sequential order in which \nprocess steps are to be executed. BPEL4WS offers a number of constructs to express workflow logic in \nthe process definition. Figure 19. 10 gives a short example. The workflow starts with a receive \nconstruct, which means that the process waits for a matching message to arrive. Then, the \nDrUgStoreHealthcarelnformation service is invoked. This delivers an OutputRequest \nwhich is inspected in a BPEL4WS if statement. If the Quality element of the result is large enough, \nwe’re done. Otherwise, the HospitalHealthcarelnformation service is invoked. Finally, the \nreply construct sends a result message as an answer to the receive construct. This pair constitutes \nthe request - response operation that was mentioned in the WSDL portType of the healthcare \ninformation service.\nBPEL4WS is an orchestration language. There is central control (just as the conductor of an orchestra \nis in control). In a choreography language, such as the Web Services Choreography Description Language \n(WS-CDL), no such central control exists. In a WS-CDL, each participant remains autonomous. A WS-CDL \ndescription defines a number of interactions (message exchanges) together with their ordering \nconstraints. In particular, WS-CDL has no notion of global variables. Variables may be shared between \nparticipants in an interaction, so that state information can still be retained. Many other aspects \nof BPEL4WS show up in WS-CDL too, though sometimes under a different name. WS-CDL is not executable, \nwhile BPEL4WS is.\n\nFigure 19.10. Outline BPEL4WS workflow\nsequence >\n-receive name = MInfoRequestM  \n...\\ •\n* .  invoke name=*  DrugstoreHealthcarelnformation\"", "token_count": 512, "start_token": 364056, "end_token": 364568, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 789, "text": ".\n\nFigure 19.10. Outline BPEL4WS workflow\nsequence >\n-receive name = MInfoRequestM  \n...\\ •\n* .  invoke name=*  DrugstoreHealthcarelnformation\"\n...\\ -  \nswitch-\n'.case condition*\"GetVariableProperty<'OutputRequest',  \n'Quality') 1  •’  \"threshold\"\"\n-  \\case -\n-  otherwise -\n-  invoke naine= \" Hospi talHeal thcarelnf ormati on \"\\>\n-  \\otherwise •\n•  reply ...\nvariables*In£oResult\"\\ *\n•  \\sequence -\n19.4. SERVICE-ORIENTED SOFTWARE ENGINEERING\nServices, and compositions of services, need to be engineered too. This process is known as \nservice-oriented engineering (SOE) or service-oriented software engineering (SOSE). At a global level, \nthe SOSE life cycle is not different from the ordinary software life cycle, and consists of phases \nsuch as analysis, architecture, design, testing, construction. Each of the SOSE phases however is subtly \ndifferent from its non-service-oriented counterpart. Below, we discuss the analysis, architecture, \nand design phases, since this is where the service-specific elements are most visible. An overview \nof these SOSE phases is given in Table 19. 2.  The process, of course, is not linear but iterative, both \nacross and within phases.\nSometimes, a distinction is made between organizations that develop individual services and \norganizations that develop applications built out of a collection of available services. This is similar \nto software product-line development organizations, where a distinction is made between the component \ndevelopment organization and the application development organization. The latter develops the overall \narchitecture and builds products using components developed by the component organization.\nA service, be it simple or composite, models a business process. The first step in the analysis phase \nscopes the service: which business process will be handled by the service, what is its start and end, \nwho are the participants, what is the input and output of the process? This first step determines the \nboundaries for the steps to follow.\n\nEspecially for larger business processes, there will be existing applications that automate part of", "token_count": 512, "start_token": 364518, "end_token": 365030, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 790, "text": ", \nwho are the participants, what is the input and output of the process? This first step determines the \nboundaries for the steps to follow.\n\nEspecially for larger business processes, there will be existing applications that automate part of \nthe process. These may be (legacy) applications from within the organization, or components and services \nthat may be acquired from elsewhere. The gap analysis step determines which existing elements can be \nreused in the realization of this service. The gap analysis is similar to a COTS selection process \nas discussed in Section 9. 1.5.\nTable 19.2. Main SOSE phases\nSOSE phase Detailed steps\nAnalysis Determine scope\nGap analysis\nArchitecture Decompose process\nCompose specific SOA\nDesign Design services and their interfaces\nDesign business process\nThe architecture phase starts with a decomposition of the process into its constituent process steps \nand their interactions. Workflow modeling notations and languages can be used for this purpose. These \nresemble the process modeling notations discussed in Section 3. 7.  Usage scenarios are devised and used \nto manually test the process flow developed and identify any missing steps. These usage scenarios are \nalso used to group services into composite ones.\nNext, a particular instance of the SOA, as discussed in Section 19.2,  is chosen. The service layers \nare determined, the Web services standards to be used are determined, as well as rules for how they \nare applied (such as which namespaces are used and where they are positioned).\nFinally, the design phase concerns the design of individual services and their interfaces, as well \nas the detailed design of the service-oriented business process. In terms of the SOA architectural \nstyle, this concerns the detailed design of the service layers and the coordination layer, respectively. \nAt the level of Web services, the former concerns the SOAP/WSDL level, while the latter concerns the \nBPEL4WS level.\nThough SOSE and the more familiar software engineering approaches look similar, there are important \ndifferences for which no adequate SOSE solution has been found yet (see (Papazoglou et al.,  2006) and \n(Tsai et al., 2007)):\n• Existing software process modeling techniques and their notations (RUP, UML) are not very well \nsuited for", "token_count": 512, "start_token": 364980, "end_token": 365492, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 791, "text": "apazoglou et al.,  2006) and \n(Tsai et al., 2007)):\n• Existing software process modeling techniques and their notations (RUP, UML) are not very well \nsuited for modeling business aspects. There exist numerous techniques and notations \nspecifically aimed at the business level, such as the Business Process Modeling Notation (BPMN, \nsee www. bpmn. org).  BPMN is a graphical, flowchart-like notation for depicting workflows. It\n\nis still an open question as to how to combine existing software engineering techniques and \nnotations with their business-oriented counterparts.\n• For services, design principles such as coupling and cohesion apply as well. The precise \ndefinition of design principles for services and their associated measures are still open to \ndebate.\n• For services too, different versions exist in parallel. Version management for services has \nto be integrated with service discovery schemes, so that users can decide to keep using older \nversions even in the presence of newer ones.\n• The engineering of services is collaborative and crosses organizational boundaries. The issues \nare similar to those found in global software engineering. For services, particular attention \nneeds to be paid at integration issues at each phase of the life cycle. Different partners \nwill use different techniques and notations for expressing requirements, designs, and so on.\n• Certain engineering tasks have to be done at run time. If a new version of a service comes \nalong, it has to be analyzed and tested while the complete service assembly of which it is \npart is up and running.\n19.5. SUMMARY\nServices have a long history in the world of telephony. Many of the achievements made there are currently \nbeing reinvented and translated to the general world of software engineering.\nThe most important characteristic that distinguishes services from ordinary software components is \nthat services can be dynamically discovered, based on a description of what the service is supposed \nto accomplish. This description contains both functional and quality information. Service providers \npublish their service descriptions in a registry, after which service requestors can search the registry \nfor candidate services.\nThe efforts to realize service orientation so far have been largely directed at the syntax level: how \nto program services, how to hook them together, and so on. The semantic level of domain-specific \nlibraries of", "token_count": 512, "start_token": 365442, "end_token": 365954, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 792, "text": " candidate services.\nThe efforts to realize service orientation so far have been largely directed at the syntax level: how \nto program services, how to hook them together, and so on. The semantic level of domain-specific \nlibraries of services has hardly been touched yet. This is similar to what happened in the area of \nreuse and components. Efforts to add a level of semantics are underway. (Berners-Lee et al.,  2001) \ndescribe an extension of the current Web in which information has a meaning. In this semantic Web, \nservices also carry semantics. These semantics can be used in service discovery, composition, and so \non. New standards are being developed in which this semantic information is embedded. XML is the basis \nfor the first generation of Web services open standards. The Ontology Web Language (OWL) is the basis \nfor the second, semantics-oriented, generation of standards.\nThe widely used service-oriented architecture (SOA) consists of a number of business and infrastructure \nservices that communicate via a message engine, the service bus, and a coordination layer that handles \nthe workflow of and interaction between the services.\nThe realization of services calls for specific software engineering techniques, service-oriented \nsoftware engineering (SOSE). The main phases of the life cycle for developing services are the same \nas those for developing components. There are specific elements though, especially in the analysis\n\nand design phases, where the alignment between business aspects and technical solutions is stressed. \nThere are also many open issues where it comes to the engineering of services.\n19.6. FURTHER READING\n(Erl, 2005) is a good textbook on service orientation. It makes a clear distinction between the \nconceptual issues and implementation issues incurred by Web services. (Papazoglou, 2008) is a very \ncomprehensive textbook on Web services. (Turner et al.,  2003) describe the software-as-a-service (SaaS) \nconcept. (CACM, 2003) and (CACM, 2006) are special journal issues that deal with service orientation. \nThere is an annual International Conference on Service-Oriented Computing (ICS0C), in which research \non service orientation is reported. One of the striking characteristics of the research reported there \nis that it seems disconnected from much of mainstream software engineering research", "token_count": 512, "start_token": 365904, "end_token": 366416, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 793, "text": " annual International Conference on Service-Oriented Computing (ICS0C), in which research \non service orientation is reported. One of the striking characteristics of the research reported there \nis that it seems disconnected from much of mainstream software engineering research.\nTwo important consortia in the area of open standards are the Organization for the Advancement of \nStructured Information Standards (OASIS) and the World Wide Web Consortium (W3C). Each has technical \ncommittees that endorse standards. W3C is known for its work on XML, SOAP, WSDL, and many other \nWeb-related languages.\nMore information about XML can be found at www. w3. org/TR/XML.  For OWL, see www. w3. org/2004/0WL.  For \nSOAP 1. 1, see www. w3. org/TR/soap.  We used WSDL version 1. 1 in the example in Section 19. 3. 3;  see the \nW3C report at www. w3. org/TR/wsdl.  More information about UDDI can be found at http://uddi.  xml, org, \nhosted by OASIS. We used BPEL4WS version 1. 1 in Section 19.3.5;  see\nwww-128. ibm. com/developerworks/library/specification/ws-bpel.  BPEL4WS is developed by a consortium \nconsisting of BEA Systems, IBM, and Microsoft, among others. It is being standardized as Web Services \nBusiness Process Execution Language (WSBPEL) by OASIS, see www. oasis-open, org.  The Web Services \nChoreography Language (WS-CDL) is being developed by W3C; see www. w3. org/TR/ws-cdl-10.  Peltz (2003) \ndiscusses the difference between orchestration and choreography. (Curbera et al.,  2002) provide an \nintroduction to SOAP, WSDL, and UDDI. The research origins of middleware, including Web service \nmiddleware such as SOAP and WSDL, is discussed in (Emmerich et al.,  2007).\nThe platform technologies underlying Web services change quickly. Good starting", "token_count": 512, "start_token": 366366, "end_token": 366878, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 794, "text": "I. The research origins of middleware, including Web service \nmiddleware such as SOAP and WSDL, is discussed in (Emmerich et al.,  2007).\nThe platform technologies underlying Web services change quickly. Good starting points are \nhttp://java.  sun. com/Webservices for Java developments and \nhttp://msdn2.  microsoft. com/en~us/Webservices for .NET developments.\nThe SOSE life cycle discussed in Section 19. 4 is loosely based on (Erl, 2005) and (Papazoglou and van \nden Heuvel, 2006). SOSE challenges are discussed in (Papazoglou et al.,  2006) and (Tsai et al.,  2007).\n19.6.1. Exercises\n1. What is a service?\n2. Explain how service discovery works.\n3. What are the main characteristics of services?\n\n4. Explain the terms Quality of Service and Service Level Agreement in the context of service \norientation.\n5. Why is the use of open standards essential for realizing services?\n6. What does the software-as-a-service (SaaS) perspective entail?\n7. What is the Web services stack?\n8. What are the main parts of a WSDL Web service definition?\n9. Explain the role of BPEL4WS.\n10. Describe the SOSE development life cycle.\n11. Discuss the differences and commonalities between CBSE and SOA.\n12. ^  In terms of the categorization of viewpoints given in Chapter 11,  how would you classify \nthe view given in Figure 19. 3? Can you think of other architecture viewpoints that might be \nrelevant?\n13. ^  Write an essay on the prospective role of second-generation Web service languages in \nservice orientation.\n14. ^Write an essay on the role of version control in SOSE.\n15. ^  For a non-service-oriented system you have been involved in, identify the business \nfunctions supported and design a collection of services that could realize its functionality.\n\nChapter 20. Global Software Development\nLEARNING OBJECTIVES\n• To understand the main issues that impact global software development\n• To know different approaches for addressing the challenges of global software development\nNOTE\nIn global software development projects, work is", "token_count": 512, "start_token": 366828, "end_token": 367340, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 795, "text": "Chapter 20. Global Software Development\nLEARNING OBJECTIVES\n• To understand the main issues that impact global software development\n• To know different approaches for addressing the challenges of global software development\nNOTE\nIn global software development projects, work is distributed over sites that operate in different time \nzones and geographical locations. People working at these different sites may differ widely in culture. \nThe specific challenges imposed by this distance in time, place, and culture are discussed in this \nchapter. These challenges concern the way people communicate and collaborate, and the way work is \ncoordinated and controlled.\nA friend of mine runs a small Dutch software company that develops websites for organizations such \nas healthcare insurance agencies and municipal bodies. The requirements engineering and design is done \nin the Netherlands. Implementation and unit testing is outsourced to an Eastern European partner. \nManagement and acceptance testing is again the responsibility of the Dutch company.\nThe reason for this division of labor is primarily cost - at the time of writing, salaries are still \nquite a bit lower in Eastern Europe than in the Netherlands. The technical competence of the Eastern \nEuropean partner is very high. Consequently, the technical quality of their work is very high as well. \nBut they have much less feeling for user interface issues. As long as all items appear on the website, \nthey do not care so much about fonts, colors, and the like. The end result is that a lot of extra \ncommunication about these user interface issues is required, and the result often leaves much room \nfor improvement.\nUntil fairly recently, software development was mostly a collocated activity. Today’s software \ndevelopment often is a global activity. The challenges of the globalization of software development \nare discussed in Section 20. 1 and Section 20.2 discusses ways to tackle these challenges.\nMembers of a collocated development team are usually housed within walking distance. Psychology tells \nus that if one has to walk more than 30 meters or climb the stairs, one is inclined to reinvent the \nwheel rather than ask a colleague. So, preferably, development teams share a project room or a ’war \nroom’.  Experimental studies such as (Teasley et al.,  2002) confirm that the frequent informal exchanges \nthat result from being collocated foster collaboration, information sharing, mutual learning, and \nefficient communication. Communication between developers that are more than 30 meters apart is as \n", "token_count": 512, "start_token": 367290, "end_token": 367802, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 796, "text": "asley et al.,  2002) confirm that the frequent informal exchanges \nthat result from being collocated foster collaboration, information sharing, mutual learning, and \nefficient communication. Communication between developers that are more than 30 meters apart is as \ninfrequent as communication between developers at different sites. This is just one challenge of being \nglobal.\nThe tasks of the members of a software development team are interdependent. They coordinate their \nactivities to reach a set of common goals and share the responsibility for reaching those goals.\n\nTraditional, collocated software development fits this picture. A global, or virtual, team has the \nsame goals and objectives, but it has multiple sites. It operates across different time zones and \ngeographical locations, and may involve different organizations. Members of a virtual team use a variety \nof media (telephone, email, teleconferencing, etc.) for communication.\nMany organizations have outsourced or offshored\" part of their work to lower the labor cost. Currently, \nmostly the ’low-end’  tasks are offshored to low-wage countries, while ’high-end’  activities such as \nrequirements engineering and architecture remain in high-wage countries. It is by no means sure that \nsituation will continue (Aspray et al.,  2006). But other factors also play a role when deciding on \nwhere to locate software development activities:\nJ Outsourcing means that work is done by a third party. Offshoring means that it is done in a different \ncountry from the contracting organization.\n• faster delivery because of ’  follow-the-sun’  development: Software development is started by \na team of developers at one development site and, when their work day ends, it is shifted to \na team in a place where the work day is starting. In theory, work can continue around the clock.\n• access to a larger pool of developers: In some countries there is a permanent shortage of skilled \ndevelopers. To alleviate this problem, work can be moved to a country where there is an abundance \nof skilled developers.\n• better modularization of work: By its nature, global development requires that work is split \ninto modules that require as little communication between development teams as is possible. \nGlobal development thus encourages desirable design properties.\nThere is very little proof that these alleged advantages actually material", "token_count": 512, "start_token": 367752, "end_token": 368264, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 797, "text": ": By its nature, global development requires that work is split \ninto modules that require as little communication between development teams as is possible. \nGlobal development thus encourages desirable design properties.\nThere is very little proof that these alleged advantages actually materialize (Conchiiir et al.,  2006). \nFor example, around-the-clock development often results in working shifts that overlap in time, so \nthat developers at different sites can have direct contact. Work then shifts to these overlapping hours. \nIt may also result in a lot of overtime at either side to make sure that direct contact is possible. \nCost advantages are offset against higher travel costs, higher maintenance costs, and so on. Even if \nthe wages at offshoring sites are about 10% of those in the Western hemisphere, actual cost savings \nare more likely to be in the 20 -40% range (Matloff, 2005).\n20.1. CHALLENGES OF GLOBAL SYSTEM DEVELOPMENT\nThe essence of a collocated team is that many things are shared. The team shares some set of tools \nand uses the same process. Team members have the same background and share an understanding of the \njob to be done. Team members share information at frequent informal meetings in the lobby or at the \ncoffee machine. (Perry et al.,  1994) observed that developers in a particular organization spent up \nto 75 minutes per day in unplanned personal interaction. Sometimes, development teams share the same \noffice area on purpose, to stimulate interaction and speed things up. A shared room is also one of \nthe distinguishing practices of agile development.\nThese mechanisms all disappear when work is distributed. The challenges that face global software \ndevelopment all have to do with distance: temporal distance, geographical distance, and sociocultural\n\ndistance. Along a second dimension, the challenges of global software development can also be classified \nin three categories (Agerfalk et al.,  2006):\n• communication and collaboration between team members: Individual team members need to exchange \ninformation and work together.\n• coordination between tasks: The work to be done at different sites needs to be coordinated.\n• control of the work: Management must keep in control of the work done at different sites.\nTable 20. 1 lists the main challenges according to this two-dimensional classification. Below, we discuss \neach of the entries in this table.", "token_count": 512, "start_token": 368214, "end_token": 368726, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 798, "text": "• control of the work: Management must keep in control of the work done at different sites.\nTable 20. 1 lists the main challenges according to this two-dimensional classification. Below, we discuss \neach of the entries in this table. Note that many of the issues discussed are interrelated; the borders \nbetween entries are not that clear-cut.\nTable 20.1. Challenges of global system development (based on \n(Agerfalk et a I., 2006); (Clerc et al., 2007))\nTemporal Distance Geographical Sociocultural\nCommunication Effective communication Effective information exchange Build a Cultural misunderstandings \nteam\nCoordination Coordination costs Task awareness Sense of urgency Effective cooperation\nControl Delays Accurate status information Uniform Quality and expertise \nprocess\nEffective communication When team members are at different locations, communication means are often \nasynchronous (email, for example). Asynchronous communication is less effective than synchronous \ncommunication. It is not possible to get an immediate clarification if a message is not understood. \nProblems may crop up at a later stage because people take the risk of not contacting a colleague at \na remote site, but guess an answer and tacitly accept the risks.\nCoordination costs For global software development projects, coordination costs are often larger them \nfor collocated projects. In some cases, representatives from the client organization are located at \na development site for the duration of the project. Key people such as managers and architects frequently \ntravel to the different teams to have onsite meetings. The infrastructure tends to be more expensive \ntoo, in terms of bandwidth, videoconferencing hardware and software, and so on.\nDelays When an issue arises that requires information from another site, it often incurs a delay. One \nmay have to wait for the next teleconference meeting, send an email and wait for the other side to \nreact, and so on. Asynchronous communication easily leads to delays where the same issue in a collocated \nteam would be dealt with immediately simply by walking down the corridor and engaging in a discussion \nwith the person involved.\n\nFor example, suppose a change request only touches upon the code base owned by a local site. Any problems \na developer may have in handling this request can be solved by consulting a nearby colleague. If on \nthe other hand a change request is multi-site, a developer at one site may", "token_count": 512, "start_token": 368676, "end_token": 369188, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 799, "text": " code base owned by a local site. Any problems \na developer may have in handling this request can be solved by consulting a nearby colleague. If on \nthe other hand a change request is multi-site, a developer at one site may have to communicate with \na colleague at another site. If he knows which person to contact, he can send him an email and wait \nfor a reply. If not, he first has to find out which person to contact. Initiating contact in a global \nproject is even more difficult if more than two people are involved. Either way, delays are incurred.\nEffective information exchange When teams are at geographically different sites, there is less informal, \nunplanned contact. During unplanned meetings at the coffee machine, highly valuable and relevant \ninformation is exchanged. Small issues that are easily settled in an unplanned meeting in the hall \nby a collocated team may have to be ’saved’  until the next formal teleconference meeting in a global \nsetting. Chances are then that a number of these smaller issues remain unresolved for a long time or \nare forgotten altogether. Unplanned social meetings also help people build up an awareness of what \nis important and what is not, and what the future of the project will bring. These issues are often \nlargest at the start of a project, simply because one doesn’t yet know team members at the other sites.\nEffective information exchange is especially important during the early stages of a project. Damian \nand Zowghi (2003) report difficulties in handling requirements in a global software development \nenvironment. An often-used medium for exchanging such information is email. But email is a poor medium \nin which to handle ambiguities and may lead to lengthy discussions without actually resolving the issue. \nEmails raising a difficult requirements issue may not be answered immediately and end up in a stack, \nultimately to be forgotten.\nIn a global setting, partners in information exchange often speak a different native language. It then \nbecomes more difficult to exchange requirements unambiguously. It may be difficult to find the proper \nterms for domain entities. Income tax laws in my country make use of very special regulations that \nare difficult to express at all, let alone unambiguously. Partners in another country will have \ndifficulties in interpreting them properly; they may use their background knowledge of their own tax \nrules", "token_count": 512, "start_token": 369138, "end_token": 369650, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 800, "text": " use of very special regulations that \nare difficult to express at all, let alone unambiguously. Partners in another country will have \ndifficulties in interpreting them properly; they may use their background knowledge of their own tax \nrules to infer a likely meaning. In such circumstances, it may take a long time before problems related \nto misunderstood requirements come to the surface.\nIndividual members of a global team often have difficulties identifying appropriate expertise at other \nsites. As a consequence, they do not know whom to contact with a specific information request. (Fussell \net al.,  1998) identify four types of awareness problem in distributed teams:\n• activity awareness: what are the others doing?\n• availability awareness: when can I reach them?\n• process awareness: what are they doing?\n• perspective awareness: what are they thinking and why?\nEhrlich and Chang (2006) found that people communicate more frequently with someone else if they know \nwhat this person is working on, when they know this person from a previous project, or have some general \nidea about his knowledge and expertise. This suggests that improving awareness and familiarity of other \nteam members in a global team helps. This and other studies also found that team boundaries are often\n\npermeable. People do not only rely on information from their immediate colleagues in the development \nteam. They have a personal network that they rely upon, especially for technical matters.\nIn collocated teams, inadequate knowledge management is often compensated for by personal contact and \nknowing who knows what. Distributed teams need more thorough means of knowledge management. Local \nmeetings may result in decisions that are not properly captured and disseminated to the other teams \nthat need to know about them. The latter then have to guess things or rediscover them.\nBuild a team Building a team in a global development project is hampered because of the temporal and \ngeographical distance. As a result, there is a higher chance of mismatches in terminology and definitions, \nresulting in communication overhead and delays.\nCollocated teams tend to be more cohesive than global teams because of their daily interaction, physical \nproximity, similar background, and so on. In a global setting, team members from different sites may \nconsider themselves as part of different teams rather than one global team. Such feelings may lead \nto a ’them and us’  attitude between teams at", "token_count": 512, "start_token": 369600, "end_token": 370112, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 801, "text": " and so on. In a global setting, team members from different sites may \nconsider themselves as part of different teams rather than one global team. Such feelings may lead \nto a ’them and us’  attitude between teams at different sites. This attitude is more likely to occur \nwhen the teams have different roles, such as a designer team at one site and a development team at \nanother. This may result in negative attitudes and conflicts. Weak ties between team members impede \nthe transfer of complex knowledge (Hansen, 1999). Usually, the knowledge that needs to be exchanged \nbetween sites of a distributed software development project is quite complex in nature. It would thus \nhelp to strengthen ties in a distributed software development project.\nAn issue closely related to team building is trust. Distance makes it difficult to build up relationships \nin which there is mutual trust. During the early phases, when requirements are being negotiated, trust \nis essential. Parties in this negotiating process may leave certain issues deliberately open or \nambiguous. They may have a hidden agenda. Developers may keep things hidden from their manager to protect \ntheir position. Conversely, a manager may hide information from the developers so as not to alarm them \nat an early stage, and so on. In a collocated development team, many issues are resolved in open meetings. \nIn a global setting, there is ample room for bilateral contact through emails, phone calls, and so \non. Information then is spread to some people and not to others, possibly adding to the level of distrust. \nDistrust is further increased if emails are used as a weapon, for instance by copying management each \ntime a problem is reported to a colleague.\nIf sites in a global project do not see themselves as partners, it may result in ’  uncharitable’  behavior \n(Herbsleb and Grinter, 1999). For instance, a person at one site might say that a certain change cannot \nbe made. The recipient of this message at the other site may construe this as meaning that that person \nis not willing to make the effort.\nPeople may feel that multi-site development is a first step towards reducing jobs. They will then not \nbe inclined to communicate freely. If they do, their knowledge may be transferred to others, and they \nbecome easier to replace.\nTask awareness In a global setting, work assignments may not be", "token_count": 512, "start_token": 370062, "end_token": 370574, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 802, "text": " reducing jobs. They will then not \nbe inclined to communicate freely. If they do, their knowledge may be transferred to others, and they \nbecome easier to replace.\nTask awareness In a global setting, work assignments may not be understood properly. This may easily \nlead to long discussions that add up to delays. For example, the precise distribution of responsibilities \nbetween a development team and the integration test team may not be understood properly and lead to\n\nlong discussions between the two. Unlike single-site projects, in globally distributed projects, the \namount of discussion generally does not decrease in the course of the project.\nTeam members do not only coordinate work through an input - process - output model. There is more to \ncoordination of work than the formal exchange of messages. A team builds up a shared mental model of \nthe work to be done. Team members have to know what is to be done, what the other team members know, \nand the goals of colleagues. By studying what designers do, (Curtis et al.,  1988) found that performance \nis improved when team members have a shared mental model. Building such a shared model is a lot easier \nwhen the team is collocated.\nSense of urgency Multi-site development may result in differences in the perceived sense of urgency \nof handling requests. For example, a developer at one site may ask for clarification of some requirement \nin an email to a colleague at another site. The person receiving the email may not read his email for \na while, or postpone an immediate answer. The developer in turn may be sitting idle, waiting for a \nreply. Direct contact with colleagues at the same site makes it easier to convey the urgency of a help \nrequest. Asynchronous communication such as sending emails lowers the perceived sense of urgency. The \nlack of a sense of urgency induces delays.\nAccurate status information In a global setting, it is difficult to exert effective control. For instance, \nif a team at one site exceeds its plan, that team can easily blame management at a remote site that \n’  has no idea of the complexity of our subsystem’.\nTracking status is essential in a global software development project. If code is developed at different \nsites and has to be integrated at a third site, management needs to have accurate status information. \nIf the schedule slips at one development site, it will also slip", "token_count": 512, "start_token": 370524, "end_token": 371036, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 803, "text": " essential in a global software development project. If code is developed at different \nsites and has to be integrated at a third site, management needs to have accurate status information. \nIf the schedule slips at one development site, it will also slip at the integration site. If status \ninformation is inaccurate, it may easily give rise to feelings of frustration elsewhere.\nUniform process It is important to have a uniform process strategy. Having nonuniform processes \nintroduces delays. For example, one site may have a dedicated team for integration testing, while \nintegration testing may be the responsibility of each subsystem team at another site. The integration \nteam needs assistance from developers when issues arise, and this is complicated when developers have \nto deal with different processes. At integration time, speed is paramount to quickly resolve bugs \ndiscovered.\nEstablishing a uniform process requires negotiation. It is part of establishing common ground between \nsites. It usually does not work to simply impose one site’s process upon another. This creates ’them \nand us’  feelings, as mentioned before, and inhibits mutual trust.\nOn the other hand, different sites are likely to use different tools and methods, because of history, \nculture, or other reasons. Management must be able to accommodate these differences. The manager has \nto become an orchestrator rather than a dictator.\nCultural misunderstandings There are different kinds of culture: corporate culture, technical culture, \nand national culture. Corporate culture has to do with the organization one works in. Some organizations \nfor instance have an open communication culture, others communicate through formal channels only.\n\nTechnical culture has to do with the development processes followed. Some organizations are much more \nconcerned about the quality of products shipped than others. National culture has to do with differences \nbetween people from different parts of the world. In the words of Browning (1994):\nAmerican managers have a hamburger style of management. They start with sweet talk - the top of the \nhamburger bun. Then the criticism is slipped in - the meat. Finally, some encouraging words - the \nbottom bun. With the Germans, all one gets is the meat. With the Japanese, all one gets is the buns; \none has to smell the meat.\nCulture is one of the most important challenges to be addressed in global software development. People \nfrom different parts of the world", "token_count": 512, "start_token": 370986, "end_token": 371498, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 804, "text": " meat. With the Japanese, all one gets is the buns; \none has to smell the meat.\nCulture is one of the most important challenges to be addressed in global software development. People \nfrom different parts of the world exhibit cultural differences. This ranges from simple dress codes, \nsuch as wearing a tie or not, to issues of hierarchy and structure, sense of time, and communication \nstyle. Cultural differences also impact the ease with which certain types of software can be developed. \nMiddleware and embedded software are relatively culture-neutral. Application software, for example \nan end-user application to handle mortgages, is more culture-specific and thus requires more careful \ncommunication.\nHofstede (1997) deals with cultural differences at the national level. His book is based on research \ndone between 1967 and 1973 at IBM, long before the era of global software development. Many years later, \nit was found to be very useful for designing user interfaces, in particular websites. And now it is \nfound to be useful in grasping cultural issues in global software development. Hofstede distinguishes \nfive dimensions along which cultural differences can be observed:\n• power distance In a culture with high power distance, status, wealth, and similar factors \ndetermine one’s hierarchical status. In a culture with low power distance, individuals are \nconsidered equal.\n• collectivism versus individualism In a collectivistic culture, individuals are part of a group \nto which they Eire loyal. In an individualistic culture, everyone looks after himself, and \npersonal interests take priority over those of the group one belongs to.\n• femininity versus masculinity This dimension has to do with gender values, where the more \nmasculine values are earnings, challenges, and recognition while the more feminine values are \ngood working relationships, cooperation, and employment security.\n• uncertainty avoidance This dimension reflects how tolerant people are when placed in an \nunfamiliar or new situation. A high value indicates that the culture is based on strict rules \nand procedures to mitigate uncertainty. A low value indicates the culture is more flexible \nin handling uncertainty.\n• long-term versus short-term orientation Long-term orientation is characterized by values such \nas persistence in pursuing goals, observing order, thrift. Short-term orientation is \ncharacterized by protecting one’s face, personal steadiness, respect", "token_count": 512, "start_token": 371448, "end_token": 371960, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 805, "text": " versus short-term orientation Long-term orientation is characterized by values such \nas persistence in pursuing goals, observing order, thrift. Short-term orientation is \ncharacterized by protecting one’s face, personal steadiness, respect for tradition.\nOf these, power distance, collectivism versus individualism, and uncertainty avoidance have the \nstrongest impact on global software development.\nPeople from Asia value personal relationships within a team more than the task at hand. The \nNorth-American and European culture on the other hand is very task-oriented. In a cross-Pacific meeting,\n\nteam members from Singapore and Thailand might first have some small talk and inform about family issues, \nwhile team members from North America skip the introductions and come to business right away. In other \nwords, the Individualism Index (IDV) is higher for North-Americans and Europeans than it is for people \nfrom Asia.\nPeople from different places also have a different power distance. This is relevant for hierarchical \nrelations within teams. In Northern America and Europe, managers have to convince their team members \nand team members may argue with their manager’s decisions. In Asia, people respect authority: the power \ndistance is large. This might clash when people from different cultures get to work in the same team. \nAn American manager may expect discussion and not get it; a manager from Asia may be surprised by the \nopposition he encounters from his American team members.\nFinally, societies with a low value for uncertainty avoidance (UAI) have better mechanisms for coping \nwith uncertainty. They can deal with agile approaches, ill-defined requirements documents, and so on. \nCultures with a high value for UAI favor waterfall models, heavy processes, strict change control \nprocedures. Latin America and Japan have a high UAI value, whereas North America and India have low \nUAI value. European scores are quite mixed.\nCultural differences thus impact global software development. It should be noted that most of the current \ninsight is anecdotal and common sense. Hofstede’s dimensions provide a way to categorize issues that \nplay a role. The above statements about cultural differences between, say, Europe and Asia, are \nsimplifications of reality. For instance, there are large regional differences within Europe. Though \nthe power distance is low for most European countries, it is relatively high", "token_count": 512, "start_token": 371910, "end_token": 372422, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 806, "text": " above statements about cultural differences between, say, Europe and Asia, are \nsimplifications of reality. For instance, there are large regional differences within Europe. Though \nthe power distance is low for most European countries, it is relatively high for Belgium and France \n(see (Hofstede, 1997)).\nEffective cooperation Cooperation between team members from different cultures imposes problems: \ndifferences in vocabulary, a possible reluctance on either side to ask questions, differences in \ncommunication style, and so on. A team member one side, for instance, may prefer direct contact through \na phone call or videoconference contact, while his colleague may prefer to send email.\nIn collocated projects, as well as multi-site projects, it is important to know ’  who is who’,  to recognize \nindividuals, and acknowledge their expertise. This is a lot easier when members are located at the \nsame site. Once contact has been initiated, people are more willing to overcome cultural differences \nin order to communicate and cooperate effectively.\nQuality and expertise It is difficult to assess the quality and expertise of remote partners. A CMM \nlevel 5 certificate in itself does not guarantee quality. What matters is the level of technical \nexpertise, and this level is often difficult to assess from a distance.\n20.2. HOW TO OVERCOME DISTANCE\nOlson and Olson (2000) identified four concepts that are important for making distributed development \nsucceed:\n\n• common ground,\n• coupling of work,\n• collaboration readiness,\n• technology readiness.\n20.2.1. Common Ground\nCommon ground refers to the knowledge team members have in common, and that they are aware of. If you \ndiscuss part of a design with a close and knowledgeable colleague, mentioning the name of a particular \ndesign pattern might suffice, while a much longer explanation is used when explaining the same concept \nto a novice on the team. Non-verbal communication is taken into account as well, and may adjust our \nassumptions on the fly of what people know or understand. Common ground is established dynamically. \nThis is much easier if the team is collocated.\nTechnology such as videoconferencing or other high bandwidth channels helps to establish common ground, \nbut it remains a difficult issue. People prefer to contact a colleague from their own location, if \nthere is", "token_count": 512, "start_token": 372372, "end_token": 372884, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 807, "text": " team is collocated.\nTechnology such as videoconferencing or other high bandwidth channels helps to establish common ground, \nbut it remains a difficult issue. People prefer to contact a colleague from their own location, if \nthere is one at the remote site. The more common ground people from different sites have, the easier \ncommunication is. For newly established teams, such common ground has to be developed, for instance \nthrough site visits.\nIt is better to do more frequent traveling at the beginning of the project, to build common ground. \nTravel can also be used to build liaisons. A person from site A who has traveled to site B is known \nto people at site B. Whenever they have questions regarding the work of site A, they are more likely \nto contact the person they know. One may even exploit this phenomenon and use it to build liaisons. \nFor instance, that person may travel to site B regularly, to maintain and foster the mutual contacts.\nAchieving common ground is also known as socialization. Socialization refers to the process by which \none learns what behaviors are desirable, and which knowledge and skills are required to do one’s job. \nThe most obvious examples of socialization are the introduction of a new member to the team, and a \nkick-off meeting at the beginning of a global software development project. Socialization in global \nteams takes place both in face-to-face meetings, and through electronic media such as emails, \nteleconferencing, and so on. It is generally acknowledged that face-to-face meetings are essential. \nSince software development projects are usually quite long running, there may be a need to re-socialize \n(Oshri et al.,  2007): the ties established at the kick-off meeting simply fade away over time.\nSince global software development projects tend to have regular face-to-face meetings, it is natural \nto incorporate the socialization aspects into those meetings. It is good practice to reserve some time \nspecifically for socialization purposes. Otherwise the meeting will be completely filled with urgent \nproject matters such as requirements conflicts, change requests, planning of the next release, and \nso on. The social element that ’  comes for free’  in a collocated project has to be planned for in a \nglobal project. Another way of implementing socialization is to", "token_count": 512, "start_token": 372834, "end_token": 373346, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 808, "text": " planning of the next release, and \nso on. The social element that ’  comes for free’  in a collocated project has to be planned for in a \nglobal project. Another way of implementing socialization is to have experts travel around or have \nthe project manager visit sites outside the regular schedule of the face-to-face meetings.\n\nInteraction in global software development often follows a rhythm: intense meetings are scheduled at \nregular intervals and in between those intervals interaction is less intense (Maznevski and Chudoba, \n2000). The intense meetings are used to discuss important aspects, make far-reaching decisions such \nas the global partitioning of a system, and build relationships. The intervals between intense meetings \ntend to be shorter at the beginning of the project. They can be wider apart once the tasks are known. \nThe reason for having periodic intense meetings rather than letting the situation at hand determine \nwhether such a meeting is appropriate is logistical. It is often not feasible to gather the project \nmanager, lead architect, and end-user representative at short notice.\nAn extensive survey of outsourcing projects confirmed that intense interactions between sites is the \nmost important success factor in such projects, more so than coordination tools, CMM level, and upfront \ninvestment in architectural modeling (Tiwana, 2004).\n20.2.2. Coupling of Work\nCoupling refers to the amount and extent of communication required in performing tasks. Collocated \nteams can communicate very effectively in informal ways. Ambiguities can easily be solved over a cup \nof coffee and are less likely to play a major role because of the common ground people share. Certain \ntasks, such as brainstorming over design issues, are very collaborative and difficult to handle in \na distributed fashion. It is better to design the organization such that tasks that require much \ncollaboration are done at the same spot. Tasks that require little interaction can be executed at \ndifferent sites. So, programming or testing relatively independent subsystems can be done at different \nsites. Clear and unambiguous communication is of paramount importance in such circumstances, since \nthere is likely to be less common ground between the sites.\n20.2.3. Collaboration Readiness\nIf an organization has no culture of cooperation or sharing, it will have difficulty operating \nsuccessfully in a global software development effort", "token_count": 512, "start_token": 373296, "end_token": 373808, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 809, "text": "\nthere is likely to be less common ground between the sites.\n20.2.3. Collaboration Readiness\nIf an organization has no culture of cooperation or sharing, it will have difficulty operating \nsuccessfully in a global software development effort. The transition to a sharing and cooperating \norganization requires changing work habits, learning new tools, and so on. Incentives are needed to \nmake employees change their habits and make them ready for collaboration. Collaboration readiness not \nonly applies to individuals but also to the organization as a whole.\n20.2.4. Technology Readiness\nFinally, the technology has to be there. With the advent of the Web and the availability of advanced \ngroupware tools, such as weblogs, wikis, and so on, this is less of an issue now than it was ten years \nago. Global software development projects use these Internet technologies to support communication \nand collaboration in a variety of ways:\n• Project management tools, usually workflow-oriented, allow people to synchronize their work.\n\n• Web-enabled versions of familiar tools, such as those for requirements tracking, planning, \nbudget, and so on help people to coordinate their work remotely. For example, (Lanubile et \nal.,  2003) discusses a Web-based support system for distributed software inspections.\n• An infrastructure to automate builds and tests provides the ability to control them remotely \n(Spanjers et al.,  2006).\n• Web-based project repositories, such as workspaces, store and share files intelligently \nbetween sites.\n• Real-time collaboration tools bridge the soft skills gap in distributed work.\n• Knowledge management technology finds information and people.\nA lot of knowledge of a software development organization is kept in unstructured forms: FAQs, mailing \nlists, email repositories, bug reports, lists of open issues, and so on. Lightweight tools such as \nwikis, weblogs, and yellow pages are other examples of relatively unstructured repositories to share \ninformation in global projects. In the knowledge management literature, this strategy is known as the \npersonalization strategy. Each person has his own way to structure the knowledge. The threshold for \ncontribution is usually low, but the effort expended in finding useful information is higher. Another \nstrategy is codification, where the knowledge is codified in a structured way that can be used while ", "token_count": 512, "start_token": 373758, "end_token": 374270, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 810, "text": " the knowledge. The threshold for \ncontribution is usually low, but the effort expended in finding useful information is higher. Another \nstrategy is codification, where the knowledge is codified in a structured way that can be used while \nquerying. An advantage of the codification strategy is that the information has the same form and \nstructure. A disadvantage is the extra effort it takes to cast the information in the form required. \nA hybrid strategy may be used to have the best of both worlds (Desouza et al.,  2006).\n(Gao et al.,  2002) describe PIMS, a Web-based problem information management system. PIMS not only \nprovides Web-based access to support the various problem-reporting tasks, such as problem reporting, \nstatus tracking, and information search, but it also allows for customization. Different users of the \nsystem may configure their own workflow for handling problem reports, define their own report formats, \nand use their own data formats. Teams in a global software development project may thus employ their \nown local processes, yet communicate and coordinate their work through a shared system.\nThe mere availability of tools that support global development is not sufficient, though. Efficient \nuse of these technologies also depends on properties of the organization (policies, rewards, incentives) \nand the degree to which people understand the technology (Orlikowski, 1992).\nWe may distinguish two types of communication media in global software development projects: simple \nmedia such as email messages and phone calls, and rich media such as teleconference meetings and site \nvisits. In effective teams, form follows function (Maznevski and Chudoba, 2000): simple messages are \nhandled by simple media, while complex messages are handled by rich media. In ineffective global teams, \none may find lengthy discussions on somewhat irrelevant issues in a teleconference call, while essential \ndecisions are communicated in a short email message.\nIt is important for an organization to capture the lessons learned to prevent future development projects \nmaking the same mistakes over and over again. Capturing the lessons learned is especially difficult \nin global software development projects because the knowledge is spread. The root cause of a certain \nperformance problem may be a combination of decisions of a functional nature at one site and decisions \nabout data storage at another.\n\nOne way to capture such lessons learned is through", "token_count": 512, "start_token": 374220, "end_token": 374732, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 811, "text": " because the knowledge is spread. The root cause of a certain \nperformance problem may be a combination of decisions of a functional nature at one site and decisions \nabout data storage at another.\n\nOne way to capture such lessons learned is through Communities of Practice (CoPs). A community of \npractice is a, usually informal, group of people who share certain knowledge. For instance, all software \narchitects of an organization may form a community of practice. Such a community creates knowledge, \nshares it, may have regular meetings to discuss their field of expertise, and makes their knowledge \naccessible to others, for instance through a website. Many software development organizations have \nsuch communities of practice. They capture and foster the collective knowledge of the organization. \nCommunities of practice often span boundaries: experts from different projects and different branches \nof the organization can be members of the same community.\n20.2.5. Organizing Work in Global Software Development\nThere are two ways in which one may address the lack of informal communication in global software \ndevelopment projects:\n• reduce the need for informal communication, and\n• provide technologies that ease informal communication.\nUsually, a combination of both is used.\nReducing the need or communication, be it formal or informal, is usually achieved through organizational \nmeans. Typically, people that have to interact a lot are located at the same site. This not only reduces \nthe need for communication, but also makes the coordination of work a lot easier. For instance, experts \nin a certain area, such as user interfaces, are put together at the same site. User interfaces for \nall the systems of an enterprise are then developed at that site. Alternatively, the gross structure \nof the system, the architecture, can be used to divide work amongst sites. This can be seen as a variation \nof Conway’s Law (Conway, 1968), which states that the structure of a product mirrors the organizational \nstructure of the people who designed it. If three groups are involved in the development of a system, \nthat system will have three major subsystems. This way of decomposing work is the \nprogramming-in-the-large equivalent of Parnas’  advice to consider a module as a ’responsibility \nassignment rather than a subprogram’  (Parnas, 1972). A third way is to split up tasks", "token_count": 512, "start_token": 374682, "end_token": 375194, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 812, "text": "-the-large equivalent of Parnas’  advice to consider a module as a ’responsibility \nassignment rather than a subprogram’  (Parnas, 1972). A third way is to split up tasks according to \nlife cycle phases: design is done at one site, development at a second, testing at a third.\nEach of these organizational means has advantages and disadvantages. Each may work well, but problems \nmay arise if a lot of coordination is required that crosses the boundaries of the division. Many projects \nrequire more than one functional area. A system needs a user interface, a database, security protection, \nand so on. If each site has a specific expertise, many projects will require a lot of cross-site \ncoordination. If different sites are responsible for different subsystems, problems may arise with \ntasks that involve more than one subsystem, such as integration testing. If different sites are \nresponsible for different life cycle phases, this may incur delays. For instance, the development site \nmay decide not to ship code to the testing site until all the components have been developed, and the \nsite responsible for testing will have to wait for the code to be shipped.\nDivision of work amongst sites is not only guided by objective arguments. For instance, if different \nsites develop different components, a political battle may ensue as to who is going to develop which\n\ncomponent. A component whose requirements are volatile, or one that critically depends on hardware \nthat has not been acquired yet, may easily lead to problems and had thus better be the responsibility \nof someone else. On the other hand, a high-visibility component may be attractive to develop. This \nway, politics enters the picture when it comes to division of labor.\nThe three main ways of coordinating work in global software development are architecture, plans, and \nprocesses (Herbsleb and Grinter, 1999). The architecture of a system establishes a division of \nresponsibilities into independent building blocks. The design and implementation of the building blocks \nmay be assigned to different sites. Plans describe when milestones are reached and who does what. \nProcesses describe how the software is going to be developed. All three are needed.\nGlobal software development at first sight seems to better fit the more traditional development \nparadigms in which a lot of effort is spent at the beginning on delineating and", "token_count": 512, "start_token": 375144, "end_token": 375656, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 813, "text": " how the software is going to be developed. All three are needed.\nGlobal software development at first sight seems to better fit the more traditional development \nparadigms in which a lot of effort is spent at the beginning on delineating and documenting tasks. \nThese tasks can then be assigned to different teams. Agile methods seem less fit for global software \ndevelopment, because of the need for very frequent communication and the onsite presence of a customer. \nPaasivara and Lassenius (2006) argue that many of the agile practices not only pose challenges for \nglobal system development, but can also be seen as benefits. Provided suitable tools for communication \nare in place, the frequent communication that is typical for agile projects may actually help \ncommunication in the project, foster team building, increase mutual awareness of people, and so on. \nContinuous integration and testing gives fast feedback, so that issues come to the front very quickly. \nMisunderstandings between teams thus have a better chance to surface quickly, before they become a \nbig problem.\nGlobal software development is orthogonal to outsourcing. Distributed teams may or may not be part \nof the same company. Most of the challenges are in essence independent of this distinction, but are \nlikely to be larger in the case of outsourcing. In an outsourcing context, cultural differences tend \nto be larger, company policies might differ, and there is less background between the parties involved. \nThis poses greater challenges for communication, coordination, and control. Partial answers to these \ngreater challenges are dependencies (for example, all development is outsourced) and strict contractual \nagreements for controlling purposes.\n20.3. SUMMARY\nGlobal software development poses a number of challenges that have to do with distance in time, place, \nand culture. These challenges concern the way people communicate and collaborate, and the way work \nis coordinated and controlled. The most striking challenges concern:\n• finding ways to deal with the lack of informal communication between team members, and\n• handling cultural differences.\nSoftware developers in a collocated team exchange a lot of valuable information in informal and unplanned \nmeetings. The information exchanged is tacit and becomes part of the shared knowledge of that group \nof developers. Such informal exchange is not possible in a global development project and this needs \nto be catered for in a different way: through regular site visits,", "token_count": 512, "start_token": 375606, "end_token": 376118, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 814, "text": " information exchanged is tacit and becomes part of the shared knowledge of that group \nof developers. Such informal exchange is not possible in a global development project and this needs \nto be catered for in a different way: through regular site visits, teleconferencing, Web-based tools\n\nto share knowledge, and so on. Intense interaction between sites is the most important success factor \nin global software development projects (Tiwana, 2004).\nCultural differences also impact global software development. The main dimensions along which cultural \ndifferences affect global software development are:\n• power distance: Is a person’s hierarchical status important or are individuals considered \nequal?\n• collectivism versus individualism: Are individuals part of a group or do personal interests \ntake priority?\n• uncertainty avoidance: Is the culture flexible about uncertainty?\nA number of techniques and tools are emerging to overcome the challenges of global software development. \nThe International Conference on Global Software Engineering (ICGSE) is fully devoted to the topic. \nTo paraphrase Brooks (1987): each of the many solutions proposed will contribute its mite. But we should \nnot expect miracles. Distance still matters (Olson and Olson, 2000).\n20.4. FURTHER READING\nCase studies of global software development and the issues encountered are discussed by Damian and \nZowghi (2003). (Herbsleb and Mockus, 2003) is an empirical study into delays induced by multi-site \ndevelopment. Further case studies are reported in (Herbsleb and Grinter, 1999), (Herbsleb et al.,  2005), \n(Casey and Richardson, 2006), (Damian, 2007), and (DeLone et al.,  2005). (Software, 2001) and (Software, \n2006a) are special journal issues devoted to global software development. (Carmel, 1999) is a well-known \ntextbook on global software development.\nThe 30 meter threshold for information exchange stems from (Allen, 1977). Different coordination \nmechanisms for distributed development are discussed in (Grinter et al.,  1999). Herbsleb (2007) provides \na concise overview of the state of the art. (Desouza et al.,  2006) discuss knowledge management in \nglobal software development.\nCritical success factors of multi-site development are discussed in (Olson and Olson", "token_count": 512, "start_token": 376068, "end_token": 376580, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 815, "text": " provides \na concise overview of the state of the art. (Desouza et al.,  2006) discuss knowledge management in \nglobal software development.\nCritical success factors of multi-site development are discussed in (Olson and Olson, 2000). (Ramasubbu \net al.,  2005) translate these success factors into a process maturity framework to deal with distributed \ndevelopment. (Hofstede, 1997) is the seminal text on cultural differences amongst organizations. \nCultural issues in software development are given special attention in (Krishna et al.,  2004) and \n(Borchers, 2003).\n20.4.1. Exercises\n1. What is global software development?\n2. In what ways does global software development incur delays?\n3. What makes team building more difficult in global software development?\n4. Discuss Hofstede’s cultural dimensions and how they apply to distributed software development.\n\nWhy is common ground important in software development?\nExplain how Conway’s Law relates to global software development.\n^  Write an essay on the role of informal communication in software development.\n^Suppose you have to manage a project with teams in Boston and Bangalore. The project has \nto develop a Web-based system that helps people select their healthcare insurance. Discuss \nhow you would split up tasks between those teams.\n^Discuss the advantages and disadvantages of using a personalization and codification \napproach to share knowledge between development sites.\n\nBibliography\nAbdel-Hamid, T., Sengupta, K., and Ronan, D. (1993). Softwa re Project Control: An\nExperimental Investigation of Judgment with Fallible Info rmation. IEEE Transactions\non Software Engineering , 19(6):603--612.\nAberdour, M. (2007). Achieving Quality in Open Source Softw are. IEEE Software ,\n24(1):58--64.\nAbrahamsson, P., Salo, O., Ronkainen, J., and Warsta, J. (20 02). Agile Software\nDevelopment Methods. Technical report, VTT Publications 4 78, VTT, Finland.\nAbran, A. and Robillard, P. (1992). Function Points: A Study of Their Measurement\nProcesses and Scale Transformations. Journal of Systems and Software , 25(2):171--184", "token_count": 512, "start_token": 376530, "end_token": 377042, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 816, "text": "TT, Finland.\nAbran, A. and Robillard, P. (1992). Function Points: A Study of Their Measurement\nProcesses and Scale Transformations. Journal of Systems and Software , 25(2):171--184.\nAbran, A. and Robillard, P. (1996). Function Points Analysi s: An Empirical Study of\nIts Measurement Processes. IEEE Transactions on Software Engineering , 22(12):895--910.\nAdams, E. (1984). Optimizing Preventive Service of Softwar e Products. IBM Journal\nof Research and Development , 28(1):2--14.\nAlbrecht, A. (1979). Measuring Applications Development P roductivity. In Proceedings\nApplication Development Symposium , pages 83--92. SHARE/GUIDE.\nAlbrecht, A. and Gaffney, J. (1983). Software Function, Sou rce Lines of Code, and\nDevelopment Effort Prediction: A Software Science Validat ion. IEEE Transactions on\nSoftware Engineering , 9(6):639--648.\nAlexander, C. (1979). The Timeless Way of Building . Oxford University Press.\nAlexander, C. (1999). The Origins of Pattern Theory. IEEE Software , 16(5):71--82.\nAlexander, C., Ishikawa, S., and Silverstein, M. (1977). A Pattern Language . Oxford\nUniversity Press.\nAmbriola, V., Conradi, R., and Fuggetta, A. (1997). Assessi ng Process-Centered\nSoftware Engineering Environments. ACM Transactions on Software Engineering and\nMethodology, 6(3):283--328.\n520 BIBLIOGRAPHY\nArisholm, A. and Sjøberg, D. (2004). Evaluating the Effect o f a Delegated versus\nCentralized Control Style on the Maintainability of Object -Oriented Software.\nIEEE Transactions on Software Engineering , 30(8):521--534.\nArmour, P. (2001). Zeppelins and Jet Planes: A Metaphor for M odern Software\nProjects. Communications of the ACM , 44(10):13--15.\nAtkinson, C. (2000). Socio-Technical and Soft Approaches t o Information Require-\nments Elicitation in the Post-Methodology Era", "token_count": 512, "start_token": 376992, "end_token": 377504, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 817, "text": ". Communications of the ACM , 44(10):13--15.\nAtkinson, C. (2000). Socio-Technical and Soft Approaches t o Information Require-\nments Elicitation in the Post-Methodology Era. Requirements Engineering Journal ,\n5(2):67--73.\nAustin, R. and Devin, L. (2003). Beyond Requirements: Softw are Making as Art. IEEE\nSoftware, 20(1):93--95.\nBaber, R. (1982). Software Reﬂected . North-Holland Publishing Company.\nBabich, W. (1986). Software Conﬁguration Management . Addison-Wesley.\nBaddoo, N. and Hall, T. (2003). De-motivators for software p rocess improvement:\nan anlysis of practitioners’ views. Journal of Systems and Software , 66(1):23--34.\nBaker, F. (1972). Chief Programmer Team Management of Produ ction Programming.\nIBM Systems Journal , 11(1):56--73.\nBanker, R., Datar, S., Kemerer, C., and Zweig, D. (1993). Sof tware Complexity and\nMaintenance Costs. Communications of the ACM , 36(11):81--94.\nBanker, R., Kauffman, R., and Kumar, R. (1991). An Emperical Test of Object-Based\nOutput Measurement Metrics in a Computer Aided Software Eng ineering (CASE)\nEnvironment. Journal of Management Information Systems , 8(3):127--150.\nBaram, G. and Steinberg, G. (1989). Selection Criteria for A nalysis and Design CASE\nTools. ACM Software Engineering Notes , 14(6):73--80.\nBarnard, H., Metz, R., and Price, A. (1986). A Recommended Pr actice for Describing\nSoftware Designs: IEEE Standards Project 1016. IEEE Transactions on Software\nEngineering, 12(2):258--263.\nBarstow, D., Shrobe, H., and Sandewall, E., editors (1984). Interactive Programming\nEnvironments. McGraw-Hill.\nBasili, V. (1990). Viewing Maintenance as Reuse-Oriented S oftware Development.\nIEEE Software , 7(1):", "token_count": 512, "start_token": 377454, "end_token": 377966, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 818, "text": " E., editors (1984). Interactive Programming\nEnvironments. McGraw-Hill.\nBasili, V. (1990). Viewing Maintenance as Reuse-Oriented S oftware Development.\nIEEE Software , 7(1):19--25.\nBasili, V., Briand, L., Condon, S., Kim, Y.-M., Melo, W., and Valen, J. (1996).\nUnderstanding and Predicting the Process of Software Maint enance Releases. In\nProceedings International Conference on Software Mainten ance (ICSM’96) , pages 464--474.\nIEEE.\nBIBLIOGRAPHY 521\nBasili, V. and Selby, R. (1987). Comparing the Effectivenes s of Software Testing\nStrategies. IEEE Transactions on Software Engineering , 13(12):1278--1296.\nBass, L., Clements, P., and Kazman, R. (2003). Software Architecture in Practice . Addison\nWesley, second edition.\nBatini, C., Ceri, S., and Navathe, S. (1992). Conceptual Database Design: An Entity--\nRelationship Approach . Benjamin Cummings.\nBeck, K. (2000). Extreme Programming Explained . Addison-Wesley.\nBeck, K. (2003). Test-Driven Development . Addison-Wesley.\nBeck, K. and Cunningham, W. (1989). A Laboratory For Teachin g Object-Oriented\nThinking. In OOPSLA ’89 Proceedings, ACM SIGPLAN Notices 24(10) , pages 1--6.\nBeck, K. et al. (2001). Manifesto for Agile Software Develop ment.\nBeizer, B. (1995). Black Box Testing . John Wiley & Sons.\nBellay, B. and Gall, H. (1998). An Evaluation of Reverse Engi neering Tool Capabilities.\nJournal of Software Maintenance: Research and Practice , 10:305--331.\nBenington, H. (1983). Production of Large Computer Program s. In Proceedings ONR\nSymposium (1956), reprinted in Annals of the History of Comp uting 5(4) , pages 350--361.\nBennett, K. (1998). Do Program Transformations Help Revers e Engineering? In\nProceedings International Conference on Software", "token_count": 512, "start_token": 377916, "end_token": 378428, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 819, "text": "), reprinted in Annals of the History of Comp uting 5(4) , pages 350--361.\nBennett, K. (1998). Do Program Transformations Help Revers e Engineering? In\nProceedings International Conference on Software Mainten ance (ICSM’98) , pages 247--254.\nIEEE.\nBennett, K. and Rajlich, V. (2000). Software Maintenance an d Evolution: a Roadmap.\nIn Finkelstein, A., editor, The Future of Software Engineering , pages 73--87. ACM Press.\nBergland, G. and Gordon, R. (1981). Tutorial: Software Design Strategies . IEEE, EZ389.\nBersoff, E. and Davis, A. (1991). Impacts of Life Cycle Model s on Software\nConﬁguration Management. Communications of the ACM , 34(8):104--118.\nBeyer, H. and Holtzblatt, K. (1995). Apprenticing with the C ustomer. Communications\nof the ACM , 38(5):45--52.\nBieman, J., Jain, D., and Yang, H. (2001). OO Design Patterns , Design Structure,\nand Program Changes: An Industrial CaseStudy. In Proceedings International Conference\non Software Maintenance (ICSM’01) , pages 580--589. IEEE.\nBifﬂ, S. and Halling, M. (2002). Investigating the Inﬂuence of Inspector Capability\nFactors with Four Inspection Techniques on Inspection Perf ormance. In Proceedings\n8th IEEE International Software Metrics Symposium , pages 107--17. IEEE.\n522 BIBLIOGRAPHY\nBiggerstaff, J., Mitbander, B., and Webster, D. (1994). Pro gram Understanding and\nthe Concept Assignment Problem. Communications of the ACM , 37(5):72--83.\nBiggerstaff, T. (1989). Design Recovery for Maintenance an d Reuse. IEEE Computer ,\n22(7):36--50.\nBinder, R. (2000). Testing Object-Oriented Systems . Addison-Wesley.\nBisbal, J., Lawless, D., Wu, B., and Grimson, J. (1999). Lega cy Information Systems:\nIssues and Directions. IEEE Software , 16(", "token_count": 512, "start_token": 378378, "end_token": 378890, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 820, "text": " Systems . Addison-Wesley.\nBisbal, J., Lawless, D., Wu, B., and Grimson, J. (1999). Lega cy Information Systems:\nIssues and Directions. IEEE Software , 16(5):103--111.\nBlum, B. (1994). A Taxonomy of Software Development Methods . Communications of\nthe ACM , 37(11):82--94.\nBoehm, B. (1975). Some Experience with Automated Aids to the Design of Large-\nScale Reliable Software. In Proceedings International Conference on Reliable Softwar e, ACM\nSIGPLAN Notices 10(6) , pages 105--113. ACM.\nBoehm, B. (1976). Software Engineering. IEEE Transactions on Computers , C-25(12):1226-\n-1241.\nBoehm, B. (1981). Software Engineering Economics . Prentice-Hall.\nBoehm, B. (1983). The Economics of Software Maintenance. In Proceedings Software\nMaintenance Workshop , pages 9--37. IEEE, 83CH1982-8.\nBoehm, B. (1984a). Software Life Cycle Factors. In Vick, C. a nd Ramamoorthy, C.,\neditors, Handbook of Software Engineering , pages 494--518. Van Nostrand Reinhold.\nBoehm, B. (1984b). Verifying and Validating Software Requi rements and Design\nSpeciﬁcations. IEEE Software , 1(1):75--88.\nBoehm, B. (1987a). Improving Software Productivity. IEEE Computer , 20(9):43--57.\nBoehm, B. (1987b). Industrial Software Metrics Top 10 List. IEEE Software , 4(5):84--85.\nBoehm, B. (1988). A Spiral Model of Software Development and Enhancement. IEEE\nComputer, 21(5):61--72.\nBoehm, B. (1989). Software Risk Management . IEEE.\nBoehm, B. and Basili, V. (2001). Software Defect Reduction T op 10 List. IEEE\nComputer, 34(1):135--137.\nBoehm, B., Brown, J., Kaspar, H., Lipow, M., MacLeod, G., and Merrit, M. (1978).\nCharacter", "token_count": 512, "start_token": 378840, "end_token": 379352, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 821, "text": ". IEEE\nComputer, 34(1):135--137.\nBoehm, B., Brown, J., Kaspar, H., Lipow, M., MacLeod, G., and Merrit, M. (1978).\nCharacteristics of Software Quality . Number 1 in TRW Series of Software Technology.\nNorth-Holland.\nBIBLIOGRAPHY 523\nBoehm, B., Clark, B., Horowitz, E., Westland, C., Madachy, R ., and Selby, R. (1995).\nCost Models for Future Software Life Cycle Processes: COCOM O 2.0. Annals of\nSoftware Engineering , 1:57--94.\nBoehm, B. and Sullivan, K. (1999). Software economics: stat us and prospects.\nInformation and Software Technology , 41(14):937--946.\nBoehm, B. and Turner, R. (2003). Balancing Agility and Discipline . Addison-Wesley.\nBoehm et al. , B. (1997). COCOMO II Model Deﬁnition Manual. Technical rep ort,\nUniversity of Southern California.\nB ¨ ohm, C. and Jacopini, G. (1966). Flow Diagrams, Turing Mac hines, and Languages\nWith Only Two Formation Rules. Communications of the ACM , 9(5):366--371.\nBohrer, K., Johnson, V., Nilsson, A., and Rudin, B. (1998). B usiness Process\nComponents for Distributed Object Applications. Communications of the ACM ,\n41(6):43--48.\nBooch, G. (1994). Object-Oriented Analysis and Design with Applications . Benjamin-\nCummings, second edition.\nBooch, G., Rumbaugh, J., and Jacobson, I. (1999). UML User Guide . Addison Wesley.\nBounds, G., Yorks, L., Adams, M., and Ranney, G. (1994). Beyond Total Quality\nManagement. McGraw-Hill.\nBrooks, F. (1995). The Mythical Man-Month . Addison-Wesley, second edition.\nBrooks, Jr., F. (1987). No Silver Bullet: Essence and Accide nts of Software Engineering.\nIEEE Computer , 20(4):10", "token_count": 512, "start_token": 379302, "end_token": 379814, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 822, "text": " Mythical Man-Month . Addison-Wesley, second edition.\nBrooks, Jr., F. (1987). No Silver Bullet: Essence and Accide nts of Software Engineering.\nIEEE Computer , 20(4):10--20.\nBrooks, R. (1983). Towards a Theory of the Comprehension of C omputer Programs.\nInternational Journal of Man-Machine Studies , 18:543--554.\nBrown, W., Malveau, R., III, H. M., and Mowbray, T. (1998). AntiPatterns: Refactoring\nSoftware, Architectures, and Projects in Crisis . John Wiley & Sons.\nBudgen, D. (2003). Software Design . Addison Wesley, second edition.\nBurch, E. and Kung, H.-J. (1997). Modeling Software Mainten ance Requests: A\nCaseStudy. In Proceedings International Conference on Software Mainten ance (ICSM’97) ,\npages 40--47.\nBuschmann, F., Meunier, R., Rohnert, H., Sommerlad, P., and Stal, M. (1996). A\nSystem of Patterns . John Wiley & Sons.\nBush, E. (1985). The Automatic Restructuring of COBOL. In Proceedings Conference on\nSoftware Maintenance , pages 35--41. IEEE.\n524 BIBLIOGRAPHY\nBuxton, J. and Randell, B., editors (1969). Software Engineering Techniques, Report on a\nConference. NATO Scientiﬁc Affairs Division, Rome.\nCACM (1993a). Special Issue on Participatory Design. Communications of the ACM ,\n36(6).\nCACM (1993b). Special Issue on Project Organization and Man agement. Communi-\ncations of the ACM , 36(10).\nCACM (1997). Special issue The Quality Approach: Is It Deliv ering. Communications\nof the ACM , 40(6).\nCameron, J. (1989). JSP & JSD, The Jackson Approach to Software Development . IEEE.\nCarmel, E., Whitaker, R., and George, J. (1993). PD and Joint Application Design: A\nTransatlantic Comparison. Communications of the ACM , 36(6):40--48.\nCha, S., Leveson", "token_count": 512, "start_token": 379764, "end_token": 380276, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 823, "text": " E., Whitaker, R., and George, J. (1993). PD and Joint Application Design: A\nTransatlantic Comparison. Communications of the ACM , 36(6):40--48.\nCha, S., Leveson, N., and Shimeall, T. (1988). Safety Veriﬁc ation in MURPHY using\nFault-Tree Analysis. In Proceedings 10th International Conference on Software Eng ineering\n(ICSE10), pages 377--386. IEEE.\nChapin, N. (1987). The Job of Software Maintenance. In Proceedings Conference on\nSoftware Maintenance , pages 4--12. IEEE.\nChapin, N., Hale, J., Khan, K., amil, J., and Tan, W.-G. (2001 ). Types of software\nevolution and software maintenance. Journal of Software Maintenance and Evolution:\nResearch and Practice , 13:3--30.\nChen, P. (1976). The Entity--Relationship Model: Toward a U nifying View of Data.\nACM Transactions on Data Base Systems , 1(1):9--36.\nChidamber, S. and Kemerer, C. (1994). A Metrics Suite for Obj ect Oriented Design.\nIEEE Transactions on Software Engineering , 20(6):476--493.\nChikofsky, E. (1990). CASE & Reengineering: From Archeolog y to Software Pere-\nstroika. In Proceedings 12th International Conference on Software Eng ineering (ICSE12) , page\n122. IEEE.\nChikofsky, E. and Cross II, J. (1990). Reverse Engineering a nd Design Recovery: A\nTaxonomy. IEEE Software , 7(1):13--18.\nChurcher, N. and Shepperd, M. (1995). Comments on ‘A Metrics Suite for Object\nOriented Design’. IEEE Transactions on Software Engineering , 21(3):263--265.\nCiolkowski, M., Laitenberger, O., and Bifﬂ, S. (2003). Soft ware Reviews: The State\nof the Practice. IEEE Software , 20(6):46--51.\nBIBLIOGRAPHY 525\nClarke, L., Podgurski, A., Richardson, D., and Zeil, S. (198 9). A Formal Evaluation", "token_count": 512, "start_token": 380226, "end_token": 380738, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 824, "text": " IEEE Software , 20(6):46--51.\nBIBLIOGRAPHY 525\nClarke, L., Podgurski, A., Richardson, D., and Zeil, S. (198 9). A Formal Evaluation\nof Data Flow Path Selection Criteria. IEEE Transactions on Software Engineering ,\n15(11):1318--1332.\nClements, P., Bachman, F., Bass, L., Garlan, D., Ivers, J., L ittle, R., Nord, R., and\nStafford, J. (2003). Documenting Software Architectures: Views and Beyond . Addison\nWesley.\nClements, P., Kazman, R., and Klein, M. (2002). Evaluating Software Architectures: Methods\nand Case Studies . Addison-Wesley.\nClements, P. and Northrop, L. (2001). Software Product Lines: Practices and Patterns .\nAddison-Wesley.\nCMMI Product Team (2002). /BV /C5 /C5 /C1\n/CB /C5\nfor Systems Engineering/Software\nEngineering, Version 1.1, Staged Representation. Technic al report, CMU/SEI-\n2002-TR-002, Software Engineering Institute.\nCoad, P. and Yourdon, E. (1991). Object-Oriented Analysis . Yourdon Press, second\nedition.\nCoakes, J. and Coakes, E. (2000). Speciﬁcations in Context: Stakeholders, Systems\nand Modelling of Conﬂict. Requirements Engineering Journal , 5(2):103--113.\nCockburn, A. (1996). The Interaction of Social Issues and So ftware Architecture.\nCommunications of the ACM , 39(10):40--46.\nCockburn, A. (2001). Writing Effective Use Cases . Addison-Wesley.\nCockburn, A. (2002). Agile Software Development . Addison-Wesley.\nColeman, D. (1996). Fusion with Use Cases: Extending Fusion for\nRequirements Modelling. Technical report, available thro ugh URL\nhttp://www.hpl.hp.com/fusion/index.html.\nColeman, D., Arnold, P., Bodoff, S., Dollin, C., Gilchrist, H., Hayes", "token_count": 512, "start_token": 380688, "end_token": 381200, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 825, "text": " available thro ugh URL\nhttp://www.hpl.hp.com/fusion/index.html.\nColeman, D., Arnold, P., Bodoff, S., Dollin, C., Gilchrist, H., Hayes, F., and Jeremaes,\nP. (1994). Object-Oriented Development: The FUSION Method . Prentice-Hall.\nCollofello, J. and Woodﬁeld, S. (1989). Evaluating the Effe ctiveness of Reliability-\nAssurance Techniques. Journal of Systems and Software , 9(3):191--195.\nConklin, J. (1987). Hypertext: An Introduction and Survey. IEEE Computer , 20(9):17-\n-41.\nConklin, J. and Begeman, M. (1988). gIBIS: A Hypertext Tool f or Exploratory Policy\nDiscussion. ACM Transactions on Ofﬁce Information Systems , 6(4):303--331.\nConradi, R. and Fuggetta, A. (2002). Improving Software Pro cess Improvement. IEEE\nSoftware, 19(4):92--99.\n526 BIBLIOGRAPHY\nConradi, R., Fuggetta, A., and Jaccheri, M. (1998). Six Thes es on Software Process\nResearch. In Gruhn, V., editor, Software Process Technology, 6th European workshop,\nEWSPT’98. Springer Verlag, LNCS 1487.\nConstantine, L. (1993). Work Organization: Paradigms for P roject Management and\nOrganization. Communications of the ACM , 36(10):34--43.\nConte, S., Dunsmore, H., and Shen, V. (1986). Software Engineering Metrics and Models .\nBenjamin Cummings.\nCook, S., Harrison, R., Lehman, M., and Wernick, P. (2006). E volution in software\nsystems: foundations for the SPE classiﬁcation scheme. Journal of Software Maintenance\nand Evolution: Research and Practice , 18(1):1--35.\nCorby, T. (1989). Program Understanding: Challenge for the 1990s. IBM Systems\nJournal, 28(2):294--306.\nCorkill, D. (1997). Countdown to Success:", "token_count": 512, "start_token": 381150, "end_token": 381662, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 826, "text": "):1--35.\nCorby, T. (1989). Program Understanding: Challenge for the 1990s. IBM Systems\nJournal, 28(2):294--306.\nCorkill, D. (1997). Countdown to Success: Dynamic Objects, GBB, and RADARSET-\n1. Communications of the ACM , 40(5):48--58.\nC ˆ ot ´ e, M.-A., Suryn, W., and Georgiadou, E. (2006). Softwa re Quality Model\nRequirements for Software Quality Engineering. In Proceedings 14th International\nSoftware Quality Management & INSPIRE Conference .\nCouger, J. and Zawacki, R. (1980). Motivating and Managing Computer Personnel . Wiley.\nCrowston, K. and Howison, J. (2006). Assesing the Health of O pen Source\nCommunities. IEEE Computer , 39(5):89--91.\nCugola, G., di Nitto, E., Fuggetta, A., and Ghezzi, C. (1996) . A framework for\nFormalizing Inconsistencies and Deviations in Human-Cent ered Systems. ACM\nTransactions on Software Engineering and Methodology , 5(3):191--230.\nCugola, G. and Ghezzi, C. (1998). Software Processes: a Retr ospective and a Path to\nthe Future. Software Process -- Improvement and Practice , 4(3):101--123.\nCurrit, P., Dyer, M., and Mills, H. (1986). Certifying the Re liability of Software.\nIEEE Transactions on Software Engineering , 12(1):3--11.\nCurtis, B. (1989). Three Problems Overcome with Behavioral Models of the Software\nDevelopment Process. In Proceedings 11th International Conference on Software Eng ineering\n(ICSE11), pages 398--399. IEEE.\nCurtis, B., Krasner, H., and Iscoe, N. (1988). A Field Study o f the Software Design\nProcess for Large Systems. Communications of the ACM , 31(11):1268--1287.\nCurtis, B., Krasner, H., Shen, V., and Iscoe, N. (1987). On Bu ilding Software Process\nModels Under the Lamppost. In Proceedings 9", "token_count": 512, "start_token": 381612, "end_token": 382124, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 827, "text": "68--1287.\nCurtis, B., Krasner, H., Shen, V., and Iscoe, N. (1987). On Bu ilding Software Process\nModels Under the Lamppost. In Proceedings 9th International Conference on Software\nEngineering (ICSE9) , pages 96--103.\nBIBLIOGRAPHY 527\nCurtis, B., Sheppard, S., and Milliman, P. (1979). Third Tim e Charm: Stronger\nPrediction of Programmer Performance by Software Complexi ty Metrics. In\nProceedings 4th International Conference on Software Engi neering (ICSE4) , pages 356--360.\nIEEE.\nCusumano, M. (1989). The Software Factory: A Historical Int erpretation. IEEE\nSoftware, 6(2):23--30.\nDarcy, D. (2005). The Structural Complexity of Software: An Experimental Test.\nIEEE Transactions on Software Engineering , 31(11):982--995.\nDarcy, D. and Kemerer, C. (2005). OO Metrics in Practice. IEEE Software , 22(6):17--\n19.\nDarke, P. and Shanks, G. (1996). Stakeholder Viewpoints in R equirements Deﬁnition:\nA Framework for Understanding Viewpoint Development Appro aches. Requirements\nEngineering Journal , 1:88--105.\nDart, S. (1990). Spectrum of Functionality in Conﬁguration Management Systems.\nTechnical report, CMU/SEI-90-TR-11, Software Engineerin g Institute.\nDart, S., Ellison, R., Feiller, P., and Habermann, A. (1987) . Software Development\nEnvironments. IEEE Computer , 20(11):18--28.\nDavenport, T. (1993). Process Innovation: Reengineering Work through Informati on Technology .\nHarvard Business School Press, Cambridge, MA.\nDavis, A. (1993). Software Requirements: Objects, Functions and State . Prentice-Hall, second\nedition.\nDavis, A. (1995). Object-Oriented Requirements to Object- Oriented Design: An\nEasy Transition? Journal of Systems and Software , 30(1 & 2):151--159.\nDavis, A. (2005). Just Enough Requirements", "token_count": 512, "start_token": 382074, "end_token": 382586, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 828, "text": " A. (1995). Object-Oriented Requirements to Object- Oriented Design: An\nEasy Transition? Journal of Systems and Software , 30(1 & 2):151--159.\nDavis, A. (2005). Just Enough Requirements Management . Dorset House.\nDavis, G. (1982). Strategies for Information Requirements Determination. IBM\nSystems Journal , 21(1):4--30.\nDekleva, S. (1992). Delphi Study of Software Maintenance Pr oblems. In Proceedings\nInternational Conference on Software Maintenance (ICSM’9 2), pages 10--17. IEEE.\nDelisle, N. and Garlan, D. (1990). Applying Formal Speciﬁca tion to Industrial\nProblems: A Speciﬁcation of an Oscilloscope. IEEE Software , 7(5):29--37.\nDeMarco, T. (1979). Structured Analysis and System Speciﬁcation . Prentice-Hall.\nDeMarco, T. (1982). Controlling Software Projects . Yourdon Press.\n528 BIBLIOGRAPHY\nDeMarco, T. and Lister, T. (1989). Software Development: St ate of the Art vs.\nState of the Practice. In Proceedings 11th International Conference on Software Eng ineering\n(ICSE11), pages 271--275. IEEE.\nDeMarco, T. and Lister, T. (1999). Peopleware: Productive Projects and Teams . Dorset\nHouse, second edition.\nDeMillo, R., Lipton, R., and Perlis, A. (1979). Social Proce sses and the Proofs of\nTheorems and Programs. Communications of the ACM , 22(5):271--280.\nDeRemer, F. and Kron, H. (1976). Programming-in-the-large Versus Programming-\nin-the-small. IEEE Transactions on Software Engineering , 2(2):80--86.\nDevanbu, P., Brachman, R., Selfridge, P., and Ballard, B. (1 991). LASSIE: A\nKnowledge-Based Software Information System. Communications of the ACM ,\n34(5):34--49.\nDiaz, M. and Sligo, J. (1997). How Software Process Improvem ent Helped Motorola.\nIEEE Software , 14(5", "token_count": 512, "start_token": 382536, "end_token": 383048, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 829, "text": " System. Communications of the ACM ,\n34(5):34--49.\nDiaz, M. and Sligo, J. (1997). How Software Process Improvem ent Helped Motorola.\nIEEE Software , 14(5):75--81.\nDobrica, L. and Niemel ¨ a, E. (2002). A Survey of Software Arc hitecture Analysis\nMethods. IEEE Transactions on Software Engineering , 28(7):638--653.\nDolotta, T., Haight, R., and Mashey, J. (1978). UNIX Time-Sh aring System: The\nProgrammer’s Workbench. The Bell System Technical Journal , 57(6):2177--2200.\nDowns, E., Clare, P., and Coe, I. (1992). SSADM: Structured Systems Analysis and Design\nMethod. Prentice-Hall, second edition.\nDucasse, S., G ˆ\nırba, T., and Kuhn, A. (2006). Distribution Map. In Proceedings\nInternational Conference on Software Maintenance (ICSM’0 6), pages 203--212. IEEE.\nDunsmore, A., Roper, M., and Wood, M. (2002). Further Invest igations into the\nDevelopment and Evaluation of Reading Techniques for Objec t-Oriented Code\nInspection. In Proceedings 24th International Conference on Software Eng ineering (ICSE24) ,\npages 47--57. IEEE.\nEischen, K. (2002). Software Development: An Outsider’s Vi ew. IEEE Computer ,\n35(5):36--44.\nEl Emam, K., Benlarbi, S., Goel, N., and Rai, S. (2001). The Co nfounding Effect of\nClass Size on the Validity of Object-Oriented Metrics. IEEE Transactions on Software\nEngineering, 27(7):630--650.\nEl Emam, K., Drouin, J., and Melo, W. (1997). SPICE: The Theory and Practice of Software\nProcess Improvement and Capability Determination . IEEE.\nEl Emam, K. and Madhavji, N. (1995). The Reliability of Measu ring Organizational\nMaturity. Software Process -- Improvement and Practice , 1(1):3--25.\nBIBL", "token_count": 512, "start_token": 382998, "end_token": 383510, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 830, "text": ".\nEl Emam, K. and Madhavji, N. (1995). The Reliability of Measu ring Organizational\nMaturity. Software Process -- Improvement and Practice , 1(1):3--25.\nBIBLIOGRAPHY 529\nElshoff, J. (1976). Measuring Commercial PL-1 Programs Usi ng Halstead’s Criteria.\nACM SIGPLAN Notices , 11(5):38--76.\nEpstein, R. (1997). The Case of the Killer Robot . John Wiley & Sons.\nErdogmus, H., Morisio, M., and Torchiano, M. (2005). On the E ffectiveness of\nthe Test-First Approach to Programming. IEEE Transactions on Software Engineering ,\n31(3):226--237.\nEstublier, J., Leblang, D., van der Hoek, A., Conradi, R., Cl emm, G., Tichy, W.,\nand Wiborg-Weber, D. (2005). Impact of Software Engineerin g Research on\nthe Practice of Software Conﬁguration Management. ACM Transactions on Software\nEngineering and Methodology , 14(4):383--430.\nFagan, M. (1976). Design and Code Inspections to Reduce Erro rs in Program\nDevelopment. IBM Systems Journal , 15(3):182--211.\nFagan, M. (1986). Advances in Inspections. IEEE Transactions on Software Engineering ,\n12(7):744--751.\nFairley, D. (2002). Making Accurate Estimates. IEEE Software , 19(6):61--63.\nFang, Y. and Neufeld, D. (2006). Should I Stay or Should I Go? W orker Commitment\nto Virtual Organizations. In Proceedings 39th Hawaii International Conference on Infor mation\nSciences (HICSS) . IEEE.\nFayad, M. (1997). Software Development Process: A Necessar y Evil. Communications\nof the ACM , 40(9):101--103.\nFayad, M. and Laitinen, M. (1997). Process Assessment Consi dered Wasteful.\nCommunications of the ACM , 40(11):125--128.\nFeldman, S. (1978). Make: A Program for M", "token_count": 512, "start_token": 383460, "end_token": 383972, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 831, "text": " Laitinen, M. (1997). Process Assessment Consi dered Wasteful.\nCommunications of the ACM , 40(11):125--128.\nFeldman, S. (1978). Make: A Program for Maintaining Compute r Programs. Technical\nreport, AT&T.\nFenton, N. and Pﬂeeger, S. L. (1996). Software Metrics: A Rigorous & Practical Approach .\nThomson Computer Press, second edition.\nFetzer, J. H. (1988). Program Veriﬁcation: The Very Idea. Communications of the ACM ,\n31(9):1048--1063. See also ref: Communications of the ACM 32(3):374--381 (1989)\nand 32(4):506--512 (1989).\nFischer, G. (1986). From Interactive to Intelligent System s. In Skwirzynski, J., editor,\nSoftware System Design Methods , volume 22 of NATO ASI Series F: Computer and Systems\nSciences, pages 185--212. Springer Verlag.\nFischer, M. and Gall, H. (2004). Visualizing feature evolut ion of large-scale software\nbased on problem and modiﬁcation report data. Journal of Software Maintenance and\nEvolution: Research and Practice , pages 385--403.\n530 BIBLIOGRAPHY\nFitzgerald, B. and O’Kane, T. (1999). A Longitudinal Study o f Software Process\nImprovement. IEEE Software , 16(3):37--51.\nFitzsimmons, A. and Love, T. (1978). A Review and Evaluation of Software Science.\nACM Computing Surveys , 10(1):3--18.\nFjelstad, R. and Hamlen, W. (1979). Application Program Mai ntenance Study: Report\nto our Respondents. In Proceedings of GUIDE 48 .\nFlowers, S. (1996). Software Failure: Management Failure . John Wiley & Sons.\nFloyd, C., Mehl, W.-M., Reisin, F.-M., Schmidt, G., and Wolf , G. (1989). Out of\nScandinavia: Alternative Approaches to Software Design an d System Development.\nHuman-Computer Interaction , 4:253--350.\nFolmer,", "token_count": 512, "start_token": 383922, "end_token": 384434, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 832, "text": "., Schmidt, G., and Wolf , G. (1989). Out of\nScandinavia: Alternative Approaches to Software Design an d System Development.\nHuman-Computer Interaction , 4:253--350.\nFolmer, E., van Gurp, J., and Bosch, J. (2003). A Framework fo r Capturing the Rela-\ntionship between Usability and Software Architecture. Software Process Improvement\nand Practice , 8(2):67--87.\nFowler, M. (1999). Refactoring: Improving the Design of Existing Code . Addison Wesley.\nFowler, M. (2003). Who Needs an Architect. IEEE Software , 20(5):11--13.\nFowler, M. (2004). UML Distilled . Addison Wesley, third edition.\nFrankl, P. and Weiss, S. (1993). An Experimental Comparison of the Effectiveness\nof Branch Testing and Data Flow Testing. IEEE Transactions on Software Engineering ,\n19(8):774--787.\nFrankl, P., Weiss, S., and Hu, C. (1997). All-Uses vs Mutatio n Testing: An\nExperimental Comparison of Effectiveness. Journal of Systems and Software , 38(3):235-\n-253.\nFrankl, P. and Weyuker, E. (1993a). A Formal Analysis of the F ault-Detection Ability\nof Testing Methods. IEEE Transactions on Software Engineering , 19(3):202--213.\nFrankl, P. and Weyuker, E. (1993b). Provable Improvements o n Branch Testing. IEEE\nTransactions on Software Engineering , 19(10):962--975.\nFreeman, P. and Wasserman, A., editors (1983). Tutorial: Software Design Techniques .\nIEEE EZ514.\nFuggetta, A. (1993). A Classiﬁcation of CASE Technology. IEEE Computer , 26(12):25-\n-38.\nFuggetta, A. and Wolf, A., editors (1996). Software Process -- Improvement and Practice .\nJohn Wiley & Sons.\nBIBLIOGRAPHY 531\nGamma, E., Helm, R., Johnson, R., and Vlissides, J. (1995). Design Patterns: Elements of\nReusable Object-Oriented Software . Addison-Wesley", "token_count": 512, "start_token": 384384, "end_token": 384896, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 833, "text": "OGRAPHY 531\nGamma, E., Helm, R., Johnson, R., and Vlissides, J. (1995). Design Patterns: Elements of\nReusable Object-Oriented Software . Addison-Wesley.\nGane, C. and Sarson, T. (1979). Structured Analysis and Systems Analysis: Tools and\nTechniques. Prentice-Hall.\nGarlan, D., Kaiser, G., and Notkin, D. (1992). Using Tool Abs traction to Compose\nSystems. IEEE Computer , 25(6):30--38.\nGarmus, D. and Herron, D. (1996). Measuring the Software Process: A Practical Guide to\nFunctional Measurements . Prentice-Hall.\nGartner (2001). Describing the Capability Maturity Model. Measure IT .\nGarvin, D. (1984). What does ‘Product Quality’ really mean? Sloan Management Review .\nGelperin, D. and Hetzel, B. (1988). The Growth of Software Te sting. Communications\nof the ACM , 31(6):687--695.\nGibson, V. and Senn, J. (1989). System Structure and Softwar e Maintenance\nPerformance. Communications of the ACM , 32(3):347--358.\nGilb, T. (1988). Principles of Software Engineering Management . Addison-Wesley.\nGilb, T. and Graham, D. (1993). Software Inspection . Addison Wesley.\nGˆ\nırba, T. and Ducasse, S. (2006). Modeling history to analyze software evolution.\nJournal of Software Maintenance and Evolution: Research an d Practice , 18:207--236.\nGˆ\nırba, T., Ducasse, S., and Lanza, M. (2004). Yesterday’s Wea ther: Guiding early\nreverse engineering efforts by summarizing the evolution o f changes. In Proceedings\nInternational Conference on Software Maintenance (ICSM’0 4), pages 40--49. IEEE.\nGodfrey, M. and Tu, Q. (2000). Evolution in Open Source Softw are: A Case Study.\nIn Proceedings 2000 International Conference on Software Mai ntenance (ICSM’00) , pages\n131--142. IEEE.\nGoguen, J. (1986).", "token_count": 512, "start_token": 384846, "end_token": 385358, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 834, "text": " Evolution in Open Source Softw are: A Case Study.\nIn Proceedings 2000 International Conference on Software Mai ntenance (ICSM’00) , pages\n131--142. IEEE.\nGoguen, J. (1986). An Introduction to OBJ: A Language for Wri ting and Testing\nFormal Algebraic Program Speciﬁcations. In Gehani, N. and M cGettrick, A.,\neditors, Software Speciﬁcation Techniques , pages 391--419. Addison-Wesley.\nGoguen, J. and Jirotka, M., editors (1994). Requirements Engineering: Social and Technical\nIssues. Academic Press, Boston.\nGoguen, J. and Linde, C. (1993). Techniques for Requirement s Elicitation. In\nProceedings 1st International Symposium on Requirements E ngineering (RE93) , pages 152--164,\nSan Diego. IEEE.\n532 BIBLIOGRAPHY\nGoodenough, J. and Gerhart, S. (1975). Toward a Theory of Tes t Data Selection.\nIEEE Transactions on Software Engineering , 1(2):156--173.\nGopal, A., Krishnan, M., Mukhopadhyay, T., and Goldenson, D . (2002). Mea-\nsurement Programs in Software Development: Determinants o f Success. IEEE\nTransactions on Software Engineering , 28(9):863--875.\nGordon, V. and Bieman, J. (1994). Rapid Prototyping: Lesson s Learned. IEEE Software ,\n12(1):85--95.\nGotel, O. and Finkelstein, A. (1994). An Analysis of the Requ irements Traceability\nProblem. In Proceedings International Conference on Requirements Eng ineering, pages 94--101.\nIEEE.\nGotterbarn, D. (1999). How the New Software Engineering Cod e of Ethics Affects\nYou. IEEE Software , 16(6):58--64.\nGrady, R. and Caswell, D. (1987). Software Metrics: Establishing a Company-Wide Program .\nPrentice-Hall.\nGrady, R. and van Slack, T. (1994). Key Lessons in Achieving W idespread Inspection\nUse. IEEE Software , 11(", "token_count": 512, "start_token": 385308, "end_token": 385820, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 835, "text": "rics: Establishing a Company-Wide Program .\nPrentice-Hall.\nGrady, R. and van Slack, T. (1994). Key Lessons in Achieving W idespread Inspection\nUse. IEEE Software , 11(4):46--57.\nGreevy, O., Ducasse, S., and G ˆ\nırba, T. (2006). Analyzing software evolution through\nfeature views. Journal of Software Maintenance and Evolution: Research an d Practice , pages\n425--456.\nGuindon, R. and Curtis, B. (1988). Control of Cognitive Proc esses during Design:\nWhat Tools Would Support Software Designers? In Proceedings CHI’88 , pages\n263--268. ACM.\nGunning, R. (1968). The Technique of Clear Writing . McGraw-Hill.\nGyim ´ othy, T., Ferenc, R., and Siket, I. (2005). Empirical V alidation of Object-\nOriented Metrics on Open Source Software for Fault Predicti on. IEEE Transactions\non Software Engineering , 31(10):897--910.\nHall, T. and Fenton, N. (1997). Implementing Effective Soft ware Metrics Programs.\nIEEE Software , 14(2):55--65.\nHalstead, M. (1977). Elements of Software Science . North-Holland Publishing Company.\nHamlet, D. and Taylor, R. (1990). Partition Testing Does Not Inspire Conﬁdence.\nIEEE Transactions on Software Engineering , 16(12):1402--1411.\nHarel, D. (1988). On Visual Formalisms. Communications of the ACM , 31(5):514--530.\nHarrison, W. (2004). Clueless--and Oblivious. IEEE Software , 21(3):5--7.\nBIBLIOGRAPHY 533\nHarrold, M. (1999). Testing Evolving Software. Journal of Systems and Software ,\n47(2/3):173--181.\nHarrold, M., Offutt, A., and Tewary, K. (1997). An Approach t o Fault Modeling and\nFault Seeding Using the Program Dependence Graph. Journal of Systems and Software ,\n36(3):273--295.\nHatley, D. and Pir", "token_count": 512, "start_token": 385770, "end_token": 386282, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 836, "text": "ary, K. (1997). An Approach t o Fault Modeling and\nFault Seeding Using the Program Dependence Graph. Journal of Systems and Software ,\n36(3):273--295.\nHatley, D. and Pirbhai, I. (1988). Strategies for Real-Time System Speciﬁcation . Dorset\nHouse.\nHeemstra, F. (1989). How Much Does Software Cost . PhD thesis, Technical University\nof Eindhoven, The Netherlands. In Dutch.\nHenderson Sellers, B. (1992). Modularization and McCabe’s Cyclomatic Complexity.\nCommunications of the ACM , 35(12):17--19.\nHenri, S. and Kafura, D. (1981). Software Structure Metrics Based on Information\nFlow. IEEE Transactions on Software Engineering , 7(5):510--518.\nHenry, J. and Cain, J. (1997). Comparison of Perfective and C orrective Software\nMaintenance. Journal of Software Maintenance: Research and Practice , 9:281--297.\nHerbsleb, J., Zubrow, D., Goldenson, D., Hayes, W., and Paul k, M. (1997). Software\nQuality and the Capability Maturity Model. Communications of the ACM , 40(6):30--40.\nHighsmith, J. (2004). Agile Project Management . Addison-Wesley.\nHirschheim, R. and Klein, H. (1989). Four Paradigms of Infor mation Systems\nDevelopment. Communications of the ACM , 32(10):1199--1216.\nHitz, M. and Montazeri, B. (1996). Chidamber and Kemerer’s M etrics Suite: A\nMeasurement Theory Perspective. IEEE Transactions on Software Engineering , 22(4):267-\n-271.\nHo, W. and Olsson, R. (1996). A Layered Model for Building Deb ugging and\nMonitoring Tools. Journal of Systems and Software , 34(3):211--222.\nHødalsvik, G. and Sindre, G. (1993). On the purpose of Object -Oriented Analysis.\nIn OOPSLA’93 Proceedings, ACM SIGPLAN Notices 28 (10) , pages 240--255.\nHofman, H.", "token_count": 512, "start_token": 386232, "end_token": 386744, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 837, "text": ". (1993). On the purpose of Object -Oriented Analysis.\nIn OOPSLA’93 Proceedings, ACM SIGPLAN Notices 28 (10) , pages 240--255.\nHofman, H. and Lehner, F. (2001). Requirements Engineering as a Success Factor in\nSoftware Projects. IEEE Software , 18(4):58--66.\nHofmeister, C., Kruchten, P., Nord, R., Obbink, H., Ran, A., and America, P. (2007).\nA General Model of Software Architecture Design Derived fro m Five Industrial\nApproaches. Journal of Systems and Software , 80(1):106--126.\n534 BIBLIOGRAPHY\nHops, J. and Sherif, J. (1995). Development and Application of Composite Com-\nplexity Models and a Relative Complexity Metric in a Softwar e Maintenance\nEnvironment. Journal of Systems and Software , 31(2):157--169.\nHosier, W. (1961). Pitfalls and Safeguards in Real-Time Dig ital Systems With\nEmphasis on Programming. IRE Transactions on Engineering Management , pages 99--115.\nHowden, W. (1982). Validation of Scientiﬁc Programs. ACM Computing Surveys ,\n14(2):193--227.\nHowden, W. (1985). The Theory and Practice of Functional Tes ting. IEEE Software ,\n2(5):6--17.\nHumphrey, W. (1988). Characterizing the Software Process: A Maturity Framework.\nIEEE Software , 5(2):73--79.\nHumphrey, W. (1989). Managing the Software Process . SEI Series in Software Engineering.\nAddison-Wesley.\nHumphrey, W. (1996). Using a Deﬁned and Measured Personal So ftware Process.\nIEEE Software , 13(3):77--88.\nHumphrey, W. (1997a). Introduction to the Personal Software Process . Addison-Wesley.\nHumphrey, W. (1997b). Managing Technical People . Addison-Wesley.\nHumphrey, W., Kitson, D., and Kasse, T. (1989). The State of S oftware Engineering\nPractice: A Preliminary Report. In Proceedings 11th", "token_count": 512, "start_token": 386694, "end_token": 387206, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 838, "text": " Technical People . Addison-Wesley.\nHumphrey, W., Kitson, D., and Kasse, T. (1989). The State of S oftware Engineering\nPractice: A Preliminary Report. In Proceedings 11th International Conference on Software\nEngineering (ICSE11) , pages 277--288. IEEE.\nHunt, A. and Thomas, D. (2003). Pragmatic Unit Testing . The Pragmatic Bookshelf.\nIEEE (2000). IEEE Recommended Practice for Architectural D escription of Software-\nIntensive Systems. Technical report, IEEE.\nIEEE1012 (1986). IEEE Standard for Software Veriﬁcation and Validation Plan s. IEEE Std\n1012.\nIEEE1219 (1992). IEEE Standard for Software Maintenance . IEEE Std 1219.\nIEEE610 (1990). IEEE Standard Glossary of Software Engineering Terminolog y. IEEE Std\n610.12.\nIEEE730 (1989). IEEE Standard for Software Quality Assurance Plans . IEEE Std 730.\nIEEE828 (1990). IEEE Standard for Software Conﬁguration Management Plans . IEEE Std 828.\nRevision of IEEE Std 828-1983.\nIEEE829 (1998). IEEE Standard for Software Test Documentation . IEEE Std 829.\nBIBLIOGRAPHY 535\nIEEE830 (1993). IEEE Recommended Practice for Software Requirements Speci ﬁcations . IEEE Std\n830.\nIEEE983 (1986). IEEE Standard on Software Quality Assurance planning . IEEE Std 983.\nIivari, J. (1996). Why are CASE tools not used? Communications of the ACM , 39(10):94-\n-103.\nIshikawa, K. (1985). What Is Total Quality Control? The Japanese Way . Prentice-Hall.\nISO9126 (2001). ISO/IEC 9126-1: Software Engineering -- Product Quality -- Part 1: Quality\nModel. ISO.\nJackson, M. (1975). Principles of Program Design . Academic Press.\nJackson, M. (1983). System Development . Prentice-Hall.\nJankowski, D. (1994). The Feasibility of CASE Structured An alysis Methodology\nSupport. ACM Software Engineering Notes , 19(2):72--82.\nJanzen, D. and Sa", "token_count": 512, "start_token": 387156, "end_token": 387668, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 839, "text": ".\nJankowski, D. (1994). The Feasibility of CASE Structured An alysis Methodology\nSupport. ACM Software Engineering Notes , 19(2):72--82.\nJanzen, D. and Saiedian, H. (2005). Test-Driven Developmen t: Concepts, Taxonomy,\nand Future Direction. IEEE Computer , 38(9):43--50.\nJarzabek, S. and Huang, R. (1998). The Case for User-Centere d CASE Tools.\nCommunications of the ACM , 41(8):93--98.\nJarzabek, S. and Wang, G. (1998). Model-based Design of Reve rse Engineering\nTools. Journal of Software Maintenance: Research and Practice , 10:353--380.\nJeffries, R., Anderson, A., and Hendrickson, C. (2001). Extreme Programming Installed .\nAddison-Wesley.\nJeske, D. and Zhang, X. (2005). Some successful approaches t o software reliability\nmodeling in industry. Journal of Systems and Software , 74(1):85--100.\nJ ´ ez ´ equel, J.-M. and Meyer, M. (1997). Design by Contract: The Lessons of Ariane.\nIEEE Computer , 30(1):129--130.\nJohnson, L. (1998). A View From the 1960s: How the Software In dustry Began. IEEE\nAnnals of the History of Computing , 20(1):36--42.\nJonassen Hass, A. (2002). Conﬁguration Management Principles and Practice . Addison-\nWesley.\nJones, C. (1986). Programming Productivity . McGraw-Hill.\nJones, C. (1989). Software Enhancement Modelling. Journal of Software Maintenance:\nResearch and Practice , 1(2):91--100.\n536 BIBLIOGRAPHY\nJones, C. (1999). The Euro, Y2K, and the US Software Labor Sor tage. IEEE Software ,\n16(3):55--61.\nJones, C. (2006). The Economics of Software Maintenance in t he Twenty First\nCentury, Version 3, February 14, 2006. Technical report, ht tp://www.spr.com.\nJørgensen, M. (2005). Practical Guidelines", "token_count": 512, "start_token": 387618, "end_token": 388130, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 840, "text": " The Economics of Software Maintenance in t he Twenty First\nCentury, Version 3, February 14, 2006. Technical report, ht tp://www.spr.com.\nJørgensen, M. (2005). Practical Guidelines for Expert-Jud gment-Based Software Effort\nEstimation. IEEE Software , 22(3):57--63.\nJørgensen, M. and Grimstad, S. (2004). Over-optimism in Sof tware Development\nProjects: ”The winner’s curse”. Improve, Software Process Improvement Newsletter , (4).\nJSS (1995). Special issue on Software Metrics. Journal of Systems and Software , 31(2).\nJuristo, N., Moreno, A., and Silva, A. (2002). Is he European Industry Moving toward\nSolving Requirements Engineering Problems? IEEE Software , 19(6):70--77.\nJuristo, N., Moreno, A., and Vegas, S. (2004). Reviewing 25 Y ears of Testing\nTechnique Experiments. Empirical Software Engineering , 9:7--44.\nKamsties, E. and Lott, C. (1995). An Emperical Evaluation of Three Defect-Detection\nTechniques. In Sch ¨ afer, W. and Botella, P., editors, Software Engineering -- ESEC ’95,\nLNCS 989 , pages 362--383. Springer Verlag.\nKaner, C. and Bond, W. (2004). Software Engineering Metrics : What Do They\nMeasure and How Do We Know. In Proceedings 10th International Software Metrics\nSymposium (Metrics 2004) , pages 1--12. IEEE.\nKano (1993). Kano’s Methods for Understanding Customer-de ﬁned Quality. Center\nfor Quality of Management Journal , 2(4):3--36.\nKarlstr ¨ om, D. and Runeson, P. (2005). Combining Agile Meth ods with State-Gate\nProject Management. IEEE Software , 22(3):43--49.\nKazman, R., Bass, L., and Klein, M. (2006). The essential com ponents of software\narchitecture design and analysis. Journal of Systems and Software , 79(8):1207--1216.\nKeen, P. (1991).", "token_count": 512, "start_token": 388080, "end_token": 388592, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 841, "text": " L., and Klein, M. (2006). The essential com ponents of software\narchitecture design and analysis. Journal of Systems and Software , 79(8):1207--1216.\nKeen, P. (1991). Shaping the Future: Business Design through Information Te chnology. Harvard\nBusiness School Press, Cambridge, MA.\nKeil, M. and Carmel, E. (1995). Customer-Developer Links in Software Development.\nCommunications of the ACM , 38(5):33--44.\nKemerer, C. (1993). Reliability of Function Points Measure ment. Communications of the\nACM, 36(2):85--97.\nKemerer, C. and Porter, B. (1992). Improving the Reliabilit y of Function Point\nMeasurement: An Empirical Study. IEEE Transactions on Software Engineering ,\n18(11):1011--1024.\nBIBLIOGRAPHY 537\nKemerer, C. and Slaughter, S. (1997). Determinants of Softw are Maintenance\nProﬁles: An Empirical Investigation. Journal of Software Maintenance: Research and\nPractice, 9:235--251.\nKernighan, B. and Mashey, J. (1981). The UNIX Programming En vironment. IEEE\nComputer, 14(4):12--24.\nKing, D. (1988). Creating Effective Software: Computer Program Design Usin g the Jackson\nMethodology. Yourdon Press.\nKitchenham, B. and Pﬂeeger, S. (1996). Software Quality: Th e Elusive Target. IEEE\nSoftware, 13(1):12--21.\nKitchenham, B., Pﬂeeger, S., and Fenton, N. (1995). Towards a Framework\nfor Software Measurement Validation. IEEE Transactions on Software Engineering ,\n21(12):929--943.\nKlein, G., Jiang, J., and Tesch, D. (2002). Wanted: Project T eams with a Blend of IS\nProfessional Orientations. Communications of the ACM , 45(6):81--87.\nKnight, J. and Ammann, P. (1985). An Experimental Evaluatio n of Simple Methods\nfor Seeding Program Errors. In Proceedings 8th International Conference on Software\nEngineering (IC", "token_count": 512, "start_token": 388542, "end_token": 389054, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 842, "text": "(6):81--87.\nKnight, J. and Ammann, P. (1985). An Experimental Evaluatio n of Simple Methods\nfor Seeding Program Errors. In Proceedings 8th International Conference on Software\nEngineering (ICSE8) , pages 337--342. IEEE.\nKnight, J. and Myers, E. (1993). An Improved Inspection Tech nique. Communications\nof the ACM , 36(11):50--61.\nKohno, T., Stubbleﬁeld, A., Rubin, A., and Wallach, D. (2004 ). Analysis of an\nElectronic Voting System. In Proceedings IEEE Symposium on Security and Privacy , pages\n27--42.\nKoontz, H. and O’Donnell, C. (1972). Principles of Management: An Analysis of Managerial\nFunctions. McGraw-Hill.\nKotonya, G. and Sommerville, I. (1997). Requirements Engineering, Processes and Techniques .\nJohn Wiley & Sons.\nKrasner, G. and Pope, S. (1988). A cookbook for using the Mode l--View--Controller\nuser interface paradigm in Smalltalk-80. Journal of Object Oriented Programming ,\n1(3):26--49.\nKraut, R. and Streeter, L. (1995). Coordination in Software Development. Communi-\ncations of the ACM , 38(3):69--81.\nKrogstie, J. (1994). On the Distinction between Functional Development and\nFunctional Maintenance. Journal of Software Maintenance: Research and Practice , 7:383--\n403.\n538 BIBLIOGRAPHY\nKruchten, P. (1995). The 4 + 1 View Model of Architecture. IEEE Software ,\n12(6):42--50.\nKruchten, P. (1999). The Software Architect. In Software Architecture (WICSA1) , pages\n563--583. Kluwer Academic Publishers.\nKruchten, P. (2003). The Rational Uniﬁed Process, An Introduction . Addison-Wesley, third\nedition.\nKruglinski, D. (1996). Inside Visual C++ . Microsoft Press.\nKung, H.-J. and Hsu, C. (1998). Software Maintenance Life Cy cle Model. In\nProceedings International Conference", "token_count": 512, "start_token": 389004, "end_token": 389516, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 843, "text": "\nKruglinski, D. (1996). Inside Visual C++ . Microsoft Press.\nKung, H.-J. and Hsu, C. (1998). Software Maintenance Life Cy cle Model. In\nProceedings International Conference on Software Mainten ance (ICSM’98) , pages 113--121.\nKuvaja, P., Simila, J., Krzanik, L., Bicego, A., Koch, G., an d Saukonen, S. (1994). Soft-\nware Process Assessment and Improvement: the BOOTSTRAP apr oach. Blackwell Publishers,\nOxford, UK.\nLamsweerde, A. v. (2001). Goal-Oriented Requirements Engi neering: A Guided Tour.\nIn Proceedings 5th International Symposium on Requirements E ngineering (RE’01) , pages 1--13.\nIEEE.\nLaToza, T., Venolia, G., and DeLine, R. (2006). Maintaining Mental Models: A\nStudy of Developer Work Habits. In Proceedings 28th International Conference on Software\nEngineering (ICSE28) , pages 492--501. ACM.\nLawrence, M. (1981). Programming Methodology, Organizati onal Environment, and\nProgramming Productivity. Journal of Systems and Software , 2:257--269.\nLea, D. (1994). Christopher Alexander: An Introduction for Object-Oriented Design-\ners. ACM Software Engineering Notes , 19(1):39--46.\nLederer, A. and Prasad, J. (2000). Software management and c ost estimating eroor.\nJournal of Systems and Software , 50(1):33--42.\nLefﬁngwell, D. and Widrig, D. (2000). Managing Software Requirements -- A Uniﬁed\nApproach. Addison-Wesley.\nLehman, M. (1974). Programs, Cities and Students: Limits to Growth? Number 9 in Inaugural\nLecture Series. Imperial College, Londen.\nLehman, M. (1980). Programs, Life Cycles, and Laws of Softwa re Evolution. Proceedings\nof the IEEE , 68(9):1060--1076.\nLehman, M. (1987). Process Models, Process Programs, Progr", "token_count": 512, "start_token": 389466, "end_token": 389978, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 844, "text": "1980). Programs, Life Cycles, and Laws of Softwa re Evolution. Proceedings\nof the IEEE , 68(9):1060--1076.\nLehman, M. (1987). Process Models, Process Programs, Progr amming Support. In\nProceedings 9th International Conference on Software Engi neering (ICSE9) , pages 14--16. IEEE.\nLehman, M. and Belady, L., editors (1985). Program Evolution . Number 27 in APIC\nStudies in Data Processing. Academic Press.\nBIBLIOGRAPHY 539\nLehman, M., Ramil, J., Wernick, P., Perry, D., and Turski, W. (1997). Metrics and\nLaws of Software Evolution -- The Nineties View. In Proceedings 4th International\nSymposium On Software Metrics (Metrics 97) , pages 20--32. IEEE.\nLethbridge, T., Singer, J., and Forward, A. (2003). How Soft ware Engineers Use\nDocumentation: The State of the Practice. IEEE Software , 20(6):35--39.\nLeveson, N. (1986). Software Safety: What, Why, and How. ACM Computing Surveys ,\n18(2):125--164.\nLeveson, N. (1991). Software Safety Issues in Embedded Comp uter Systems.\nCommunications of the ACM , 34(2):34--46.\nLeveson, N. (1992). High-Pressure Steam Engines and Comput er Software. In\nProceedings 14th International Conference on Software Eng ineering (ICSE14) , pages 2--14.\nIEEE.\nLeveson, N. and Turner, C. (1993). An Invesigation of the The rac-25 Accidents.\nIEEE Computer , 26(7):18--41.\nLewandowski, S. (1998). Frameworks for Component-Based Cl ient/Server Comput-\ning. ACM Computing Surveys , 30(1):3--27.\nLi, W. and Henry, S. (1993). Object-Oriented Metrics that Pr edict Maintainability.\nJournal of Systems and Software , 23(2):111--122.\nLientz, B. and Swanson, E. (1980). Software Maintenance Management . Addison-Wesley.", "token_count": 512, "start_token": 389928, "end_token": 390440, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 845, "text": " Metrics that Pr edict Maintainability.\nJournal of Systems and Software , 23(2):111--122.\nLientz, B. and Swanson, E. (1980). Software Maintenance Management . Addison-Wesley.\nLinger, R., Mills, H., and Witt, B. (1979). Structured Programming, Theory and Practice .\nAddison-Wesley.\nLott, C. (1993). Process and Measurement Support in SEEs. ACM Software Engineering\nNotes, 18(4):83--93.\nLoucopoulos, P. and Karakostas, V. (1995). Systems Requirements Engineering . McGraw-\nHill.\nLubars, M., Meredith, G., Potts, C., and Richter, C. (1992). Object-Oriented Analysis\nfor Evolving Systems. In Proceedings 14th International Conference on Software Eng ineering\n(ICSE14), pages 173--185. IEEE.\nLyons, M. (1981). Salvaging Your Software Asset (Tools Base d Maintenance). In\nAFIPS Conference Proceedings , volume 50, pages 337--341.\nLyu, M., editor (1995). Handbook of Software Reliability Engineering . McGraw-Hill.\nMacala, R., Stuckey, Jr., L., and Gross, D. (1996). Managing Domain-Speciﬁc,\nProduct-Line Development. IEEE Software , 13(3):57--68.\n540 BIBLIOGRAPHY\nMacLean, A., Young, R., Bellotti, V., and Moran, T. (1991). Q uestions, Options, and\nCriteria: Elements of Design Space Analysis. Human-Computer Interaction , 6:201--250.\nMacro, A. and Buxton, J. (1987). The Craft of Software Engineering . Addison-Wesley.\nMaiden, N., Gizikis, A., and Robertson, S. (2004). Provokin g Creativity: Imagine\nWhat Your Requirements Could Be Like. IEEE Software , 21(5):68--75.\nMaiden, N. and Ncube, C. (1998). Acquiring COTS Software Sel ection Requirements.\nIEEE Software , 15(2):46--56.\nM ¨ antyl ¨ a, M., Vanhanen, J., and Lassenius, C. (", "token_count": 512, "start_token": 390390, "end_token": 390902, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 846, "text": "iring COTS Software Sel ection Requirements.\nIEEE Software , 15(2):46--56.\nM ¨ antyl ¨ a, M., Vanhanen, J., and Lassenius, C. (2003). A Tax onomy and an Initial\nEmpirical Study of Bad Smells in Code. In Proceedings International Conference on Software\nMaintenance (ICSM’03) , pages 381--384.\nMaranzano, J., Rozsypal, S., Zimmerman, G., Warnken, G., Wi rth, P., and Weiss, D.\n(2005). Architecture Reviews: Practice and Experience. IEEE Software , 22(2):34--43.\nMartin, J. (1991). Rapid Application Development . MacMillan.\nMartin, R. (2002). Agile Software Development, Principles, Patterns and Prac tices. Prentice-Hall.\nMartin, R. and Osborne, W. (1983). Guidance on Software Maintenance . National Bureau\nof Standards, Washington. NBS Special Publication 500-106 .\nMata-Toledo, R. and Gustafson, D. (1992). A Factor Analysis of Software Complexity\nMeasures. Journal of Systems and Software , 17(3):267--273.\nMaximilien, E. and Williams, L. (2003). Assessing Test-Dri ven Development at\nBM. In Proceedings 25th International Conference on Software Eng ineering (ICSE25) , pages\n564--569. IEEE.\nMcCabe, T. (1976). A Complexity Measure. IEEE Transactions on Software Engineering ,\n2(4):308--320.\nMcCall, J., Richards, P., and Walters, G. (1977). Factors in Software Quality.\nTechnical Report RADC-TR-77-369, US Department of Commerc e.\nMcClure, R. (1968). Production-Management Aspects. In Nau r and Randell (1968),\npage 72.\nMcCracken, D. and Jackson, M. (1981). A Minority Dissenting Position. In et al. ,\nW. C., editor, Systems Analysis and Design: A foundation for the 1980’s , pages 551--553.\nNorth Holland.\nMcIlroy, M. (1968). Mass-Produced Software Components. In Naur and Randell\n(1968),", "token_count": 512, "start_token": 390852, "end_token": 391364, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 847, "text": " Analysis and Design: A foundation for the 1980’s , pages 551--553.\nNorth Holland.\nMcIlroy, M. (1968). Mass-Produced Software Components. In Naur and Randell\n(1968), pages 88--98.\nBIBLIOGRAPHY 541\nMedvidovic, N. and Taylor, R. (2000). A Classiﬁcation and Co mparison Framework\nfor Software Architecture Description Languages. IEEE Transactions on Software\nEngineering, 26(1):70--93.\nMens, T. and Tourw ´ e, T. (2004). A Survey of Software Refacto ring. IEEE Transactions\non Software Engineering , 30(2):126--139.\nMetzger, P. (1987). Managing Programming People . Prentice-Hall.\nMeyer, B. (1985). On Formalism in Speciﬁcations. IEEE Software , 2(1):6--26.\nMeyer, B. (1992). Design by Contract. IEEE Computer , 25(10):40--51.\nMeyer, B. (1996). Reality: A cousin twice removed. IEEE Computer , 29(7):96--97.\nMiller, B., Fredrikson, L., and So, B. (1990). An Experiment al Study of the Reliability\nof UNIX Facilities. Communications of the ACM , 33(12):32--44.\nMills, H., Dyer, M., and Linger, R. (1987). Cleanroom Softwa re Engineering. IEEE\nSoftware, 4(5):19--25.\nMintzberg, H. (1983). Structures in Fives: Designing Effective Organizations . Prentice-Hall.\nMockus, A., Fielding, R., and Herbsleb, J. (2000). A Case Stu dy of Open Source\nSoftware Development: The Apache Server. In Proceedings 22nd International Conference\non Software Engineering (ICSE22) , pages 263--272. IEEE.\nMoran, T. and Carroll, J. (1994). Design Rationale: Concepts, Techniques, and Use . Lawrence\nErlbaum Associates.\nMorisio, M., Seaman, C., Basili, V., Parra, A., Kraft, S., an d Condon, S. (2002).\nCOTS-based software", "token_count": 512, "start_token": 391314, "end_token": 391826, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 848, "text": " . Lawrence\nErlbaum Associates.\nMorisio, M., Seaman, C., Basili, V., Parra, A., Kraft, S., an d Condon, S. (2002).\nCOTS-based software development: Processes and open issue s. Journal of Systems\nand Software , 61(3):189--199.\nMotschnig-Pitrik, R. (1996). Analyzing the Notions of Attr ibute, Aggregate, Part and\nMember in Data/Knowledge Modeling. Journal of Systems and Software , 33(2):113--\n122.\nMoynihan, T. (1996). An Experimental Comparison of Object- Orientation and\nFunctional-Decomposition as Paradigms for Communicating System Functionality\nto Users. Journal of Systems and Software , 33(2):163--170.\nMoynihan, T. (2000). Coping with ‘requirements-uncertain ty’: the theories-of-\naction of experienced IS/software project managers. Journal of Systems and Software ,\n53(2):99--109.\nMusa, J., Iannino, A., and Okumoto, K. (1987). Software Reliability: Measurement,\nPrediction, Application . McGraw-Hill.\n542 BIBLIOGRAPHY\nMustapic, G., Wall, A., Norstr ¨ om, C., Crnkovic, I., Sandst r ¨ om, K., Fr ¨ oberg, J., and\nAndersson, J. (2004). Real World Inﬂuences on Software Arch itecture -- Interviews\nwith Industrial System Experts. In Proceedings 4th Working IEEE/IFIP Conference on\nSoftware Architecture (WICSA4) , pages 101--111. IEEE.\nMyers, G. (1979). The Art of Software Testing . John Wiley & Sons.\nMyers, G. (2004). The Art of Software Testing . Wiley, second edition.\nMyers, W. (1986). Can Software for the SDI ever be Error-Free ? IEEE Computer ,\n19(10):61--67.\nMyers, W. (1988). Shuttle Code Achieves Very Low Error Rate. IEEE Software ,\n5(5):93--95.\nMylopoulos, J., Chung, L., Liao,", "token_count": 512, "start_token": 391776, "end_token": 392288, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 849, "text": "):61--67.\nMyers, W. (1988). Shuttle Code Achieves Very Low Error Rate. IEEE Software ,\n5(5):93--95.\nMylopoulos, J., Chung, L., Liao, S., Wang, H., and Yu, E. (200 1). Exploring\nAlternatives during Requirements Analysis. IEEE Software , 18(1):92--96.\nNaur, P. and Randell, B., editors (1968). Software Engineering, Report on a Conference .\nNATO Scientiﬁc Affairs Division, Garmisch.\nNelson, E. (1966). Management Handbook for the Estimation of Computer Program ming Costs .\nSystems Development Corp. AD-A648750.\nNeumann, P. (1995). Computer-Related Risks . Addison-Wesley.\nNiessink, F. and van Vliet, H. (1997). Predicting Maintenan ce Effort with Function\nPoints. In Proceedings International Conference on Software Mainten ance (ICSM’97) , pages\n32--39. IEEE.\nNiessink, F. and van Vliet, H. (1998a). Towards Mature IT Ser vices. Software Process\n-- Improvement and Practice , 4(2):55--71.\nNiessink, F. and van Vliet, H. (1998b). Towards Mature Measu rement Programs.\nIn Nesi, P. and Lehner, F., editors, Proceedings 2nd Euromicro Conference on Software\nMaintenance and Reengineering , pages 82--88. IEEE.\nNiessink, F. and van Vliet, H. (1999). Software Maintenance from a Service\nPerspective. Technical report, Vrije Universiteit.\nNorden, P. (1970). Useful Tools for Project Management. In S tarr, M., editor,\nManagement of Production , pages 71--101. Penguin Books.\nNosek, J. and Palvia, P. (1990). Software Maintenance Manag ement: Changes in the\nLast Decade. Journal of Software Maintenance: Research and Practice , 2(3):157--174.\nOffutt, A., Harrold, M., and Kolte, P. (1993). A Software Met ric System for Module\nCoupling. Journal of Systems and Software , 20(3", "token_count": 512, "start_token": 392238, "end_token": 392750, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 850, "text": " 2(3):157--174.\nOffutt, A., Harrold, M., and Kolte, P. (1993). A Software Met ric System for Module\nCoupling. Journal of Systems and Software , 20(3):295--308.\nBIBLIOGRAPHY 543\nOffutt, A. and Lee, S. (1994). An Emperical Evaluation of Wea k Mutation. IEEE\nTransactions on Software Engineering , 20(5):337--344.\nOsterweil, L. (1987). Software Processes Are Software Too. In Proceedings 9th\nInternational Conference on Software Engineering (ICSE9) , pages 2--13. IEEE.\nOz, E. (1994). When Professional Standards are Lax: The CONF IRM Failure and its\nLessons. Communications of the ACM , 37(10):29--36.\nPage, D., Williams, P., and Boyd, D. (1993). Report of the Inquiry into the London Ambulance\nService. South West Thames Regional Health Authority.\nParnas, D. (1972). On the Criteria to be Used in Decomposing S ystems Into Modules.\nCommunications of the ACM , 15(12):1053--1058.\nParnas, D. (1978). Designing Software for Ease of Extension and Contraction. In\nProceedings 3rd International Conference on Software Engi neering (ICSE3) , pages 264--277.\nIEEE.\nParnas, D. (1985). Software Aspects of Strategic Defense Sy stems. ACM Software\nEngineering Notes , 10(5):15--23.\nParnas, D. (1987). SDI ‘Red Herrings’ Miss the Boat. IEEE Computer , 20(2):6--7.\nParnas, D. and Clements, P. (1986). A Rational Design Proces s: How and Why to\nFake it. IEEE Transactions on Software Engineering , 12(2):251--257.\nParnas, D. and Lawford, M. (2003a). Inspection’s Role in Sof tware Quality Insurance.\nIEEE Software , 20(4):16--20.\nParnas, D. and Lawford, M. (2003b). The Role of Inspection in Software Quality\nAssurance. IEEE Transactions on", "token_count": 512, "start_token": 392700, "end_token": 393212, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 851, "text": " Sof tware Quality Insurance.\nIEEE Software , 20(4):16--20.\nParnas, D. and Lawford, M. (2003b). The Role of Inspection in Software Quality\nAssurance. IEEE Transactions on Software Engineering , 29(8):674--676.\nParnas, D. and Weiss, D. (1987). Active Design Reviews: Prin ciples and Practices.\nJournal of Systems and Software , 7(4):259--265.\nParrish, A. and Zweben, S. (1995). On the Relationships Amon g the All-Uses, All-\nDU-Paths, and All-Edges Testing Criteria. IEEE Transactions on Software Engineering ,\n21(12):1006--1009.\nPatel, S., Chu, W., and Baxter, R. (1992). A Measure for Compo site Module Cohesion.\nIn Proceedings 14th International Conference on Software Eng ineering (ICSE14) , pages 38--48.\nIEEE, Melbourne.\nPerry, D. and Kaiser, G. (1991). Models of Software Developm ent Environments.\nIEEE Transactions on Software Engineering , 17(3):283--295.\nPerry, D. and Wolf, A. (1992). Foundations for the Study of So ftware Architecture.\nACM Software Engineering Notes , 17(4):40--52.\n544 BIBLIOGRAPHY\nPeterson, J. (1981). Petri Net Theory and the Modelling of Systems . Prentice-Hall.\nPetroski, H. (1994). Design Paradigms: Case Histories of Error and Judgment in En gineering.\nCambridge University Press.\nPﬂeeger, S. (1995). Maturity, Models and Goals: How to Build a Metrics Plan. Journal\nof Systems and Software , 31(2):143--155.\nPﬂeeger, S. (2000). Risky business: what we have yet to learn about risk management.\nJournal of Systems and Software , 53(3):265--273.\nPigoski, T. (1996). Practical Software Maintenance . John Wiley & Sons.\nPintelas, P. and Kallistros, V. (1989). An Overview of Some S oftware Design\nLanguages. Journal of Systems and Software , 10", "token_count": 512, "start_token": 393162, "end_token": 393674, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 852, "text": " (1996). Practical Software Maintenance . John Wiley & Sons.\nPintelas, P. and Kallistros, V. (1989). An Overview of Some S oftware Design\nLanguages. Journal of Systems and Software , 10(2):125--138.\nPohl, K. (1993). The Three Dimensions of Requirements Engin eering. In Rolland, C.,\nBodart, F., and Cauvet, C., editors, Proceedings Fifth International Conference on Advanced\nInformation Systems Engineering (CAiSE’93) , pages 275--292. Springer Verlag.\nPohl, K., B ¨ ockle, G., and van der Linden, F. (2005). Software Product Line Engineering .\nSpringer Verlag.\nPorter, A., Siy, H., Mockus, A., and Votta, L. (1998). Unders tanding the Sources\nof Variation in Software Inspections. ACM Transactions on Software Engineering and\nMethodology, 7(1):41--79.\nPorter, A., Siy, H., Toman, C., and Votta, L. (1997). An Exper iment to Assess the\nCost-Beneﬁts of Code Inspections in Large Scale Software De velopments. IEEE\nTransactions on Software Engineering , 23(6):329--346.\nPorter, A., Votta, Jr., L., and Basili, V. (1995). Comparing Detection Methods for\nSoftware Requirements Inspections: A Replicated Experime nt. IEEE Transactions on\nSoftware Engineering , 21(6):563--575.\nPost, G., Kagan, A., and Keim, R. (1998). A Comparative Evalu ation of CASE Tools.\nJournal of Systems and Software , 44(2):87--96.\nPoston, R. (1987). Preventing Most-Probable Errors in Requ irements. IEEE Software ,\n4(5):81--83.\nPotts, C. (1993). Software-Engineering Research Revisite d. IEEE Software , 10(5):19--\n28.\nPower, L. and Weiss, Z., editors (1987). Addendum to the Proceedings of OOPSLA87 .\nACM.\nPutnam, L. (1978). A General Empirical Solution to the Macro Software Sizing and\nEstimating", "token_count": 512, "start_token": 393624, "end_token": 394136, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 853, "text": " and Weiss, Z., editors (1987). Addendum to the Proceedings of OOPSLA87 .\nACM.\nPutnam, L. (1978). A General Empirical Solution to the Macro Software Sizing and\nEstimating Problem. IEEE Transactions on Software Engineering , 4(4):345--361.\nBIBLIOGRAPHY 545\nRaba (2004). Trusted Agent Report Diebold AccuVote-TS Voti ng System. RABA\nTechnologies.\nRahgozar, M. and Oroumchian, F. (2003). An effective strate gy for legacy systems\nevolution. Journal of Software Maintenance and Evolution: Research an d Practice , 15:325--\n344.\nRainer, A. and Hall, T. (2003). A quantitative and qualitati ve analysis of factors\naffecting software processes. Journal of Systems and Software , 66(1):7--22.\nRamos, I., Berry, D., and Carvalho, J. (2005). Requirements engineering for organi-\nzational transformation. Information and Software Technology , 47(5):479--495.\nRaymond, E. (1999). The Cathedral and The Bazaar . O’Reilly.\nReddin, W. (1970). Managerial Effectiveness . McGraw-Hill.\nRedmond, J. and Ah-Chuen, R. (1990). Software Metrics: A Use r’s Perspective.\nJournal of Systems and Software , 13(2):97--110.\nRedwine, S. and Riddle, W. (1985). Software Technology Matu ration. In Proceedings\n8th International Conference on Software Engineering (ICS E8), pages 189--200. IEEE.\nReifer, D. (2000). Web Development: Estimating Quick-to-M arket Software. IEEE\nSoftware, 17(6):57--64.\nReiss, S. (1990). Connecting Tools Using Message Passing in the Field Environment.\nIEEE Software , 7(4):57--66.\nRettig, M. (1991). Nobody Reads Documentation. Communications of the ACM ,\n34(7):19--24.\nRobertson, J. (2002). Eureka! Why Analysts Should Invent Re quirements. IEEE\nSoftware, 19(4):20--22.\nRochkind, M. (1975", "token_count": 512, "start_token": 394086, "end_token": 394598, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 854, "text": "7):19--24.\nRobertson, J. (2002). Eureka! Why Analysts Should Invent Re quirements. IEEE\nSoftware, 19(4):20--22.\nRochkind, M. (1975). The Source Code Control System. IEEE Transactions on Software\nEngineering, 1(4):364--370.\nRothermel, G. and Harrold, M. (1996). Analyzing Regression Test Selection Tech-\nniques. IEEE Transactions on Software Engineering , 22(8):529--551.\nRoyce, W. (1970). Managing the Development of Large Softwar e Systems: Concepts\nand Techniques. In Proceedings IEEE WESCON , pages 1--9. IEEE.\nRoyce, W. (1998). Software Project Management: A Uniﬁed Framework . Addison-Wesley.\nRozanski, N. and Woods, E. (2005). Software Systems Architecture: Working with Stakeholders\nusing Viewpoints and Perspectives . Addison-Wesley.\n546 BIBLIOGRAPHY\nRumbaugh, J., Blaha, M., Premerlani, W., Eddy, F., and Loren sen, W. (1991).\nObject-Oriented Modeling and Design . Prentice-Hall.\nRumbaugh, J., Jacobson, I., and Booch, G. (1999). The Uniﬁed Modeling Language Reference\nManual. Addison Wesley.\nRysselberghe, F. v. and Demeyer, S. (2004). Studying Softwa re Evolution Informtion\nBy Visualizing the Change History. In Proceedings International Conference on Software\nMaintenance (ICSM’04) , pages 328--337. IEEE.\nSaaty, T. (1990). Multicriteria Decision Making -- The Analytic Hierarchy Pr ocess. Volume I,\nAHP Series, McGraw Hill.\nSawyer, S. (2001). A Market-Based Perspective on Informati on Systems Development.\nCommunications of the ACM , 44(11):97--102.\nSchach, S., Jin, B., Yu, L., Heler, G., and Offutt, J. (2003). Determining the\nDistribution of Maintenance Categories: Survey versus Mea surement. Empirical\nSoftware Engineering , 8:351--365.\n", "token_count": 512, "start_token": 394548, "end_token": 395060, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 855, "text": " Yu, L., Heler, G., and Offutt, J. (2003). Determining the\nDistribution of Maintenance Categories: Survey versus Mea surement. Empirical\nSoftware Engineering , 8:351--365.\nSchwaber, K. and Beedle, M. (2002). Agile Software Development with Scrum . Prentice-Hall.\nSebillotte, S. (1988). Hierarchical Planning as a Method fo r Task-Analysis: The\nExample of Ofﬁce Task Analysis. Behaviour and Information Technology , 7(3):275--293.\nSelby, R., Basili, V., and Baker, F. (1987). Cleanroom Softw are Development. IEEE\nTransactions on Software Engineering , 13(9):1027--1037.\nSerrano, N. and Ciordia, I. (2004). Ant: Automating the Proc ess of Building\nApplications. IEEE Software , 21(6):89--91.\nSharon, D. and Bell, R. (1995). Tools That Bind: Creating Int egrated Environments.\nIEEE Software , 12(2):76--85.\nShaw, M. (1996). Some Patterns for Software Architectures. In Proceedings Second\nWorkshop on Pattern Languages for Programming . Addison-Wesley.\nShaw, M. and Clements, P. (1996). A Field Guide to Boxology: P reliminary\nClassiﬁcation of Architectural Styles for Software System s. Technical report,\nCarnegie Mellon University/Software Engineering Institu te.\nShaw, M., DeLine, R., Klein, D., Ross, T., Young, D., and Zele snik, G. (1995).\nAbstractions for Software Architecture and Tools to Suppor t Them. IEEE Transactions\non Software Engineering , 21(4):314--335.\nShaw, M. and Garlan, D. (1996). Software Architecture: Perspectives on an Emerging Discip line.\nPrentice-Hall.\nBIBLIOGRAPHY 547\nShepperd, M. (1990). Design Metrics: An Empirical Analysis . Software Engineering\nJournal, 5(1):3--10.\nShepperd, M. and Ince, D. (1993). A Critique of Three Metrics . Journal of Systems and\nSoftware, 26(", "token_count": 512, "start_token": 395010, "end_token": 395522, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 856, "text": "pirical Analysis . Software Engineering\nJournal, 5(1):3--10.\nShepperd, M. and Ince, D. (1993). A Critique of Three Metrics . Journal of Systems and\nSoftware, 26(3):197--210.\nSimmons, P. (1996). Quality Outcomes: Determining Busines s Value. IEEE Software ,\n13(1):25--32.\nSinger, J. (1998). Practices of Software Maintenance. In Proceedings International\nConference on Software Maintenance (ICSM’98) , pages 139--145. IEEE.\nSinger, J., Eles, R., and Storey, M.-A. (2005). NavTracks: S upporting Navigation in\nSoftware Maintenance. In Proceedings International Conference on Software Mainten ance\n(ICSM’05), pages 325--334. IEEE.\nSoftware (1994). Special issue on Process Improvement. IEEE Software , 11(4).\nSoftware (1996a). Special Issue on Managing Large Software Projects. IEEE Software ,\n13(4).\nSoftware (1996b). Special Issue on Software Tools Assessme nt. IEEE Software , 13(5).\nSoftware (1997a). Special issue on Managing Risk. IEEE Software , 14(3).\nSoftware (1997b). Special issue on Measurement. IEEE Software , 14(2).\nSoftware (1999). Special Issue on Critical Success Factors . IEEE Software , 16(3).\nSoftware (2000). Special Issue: Software Estimation. IEEE Software , 17(6):22--70.\nSoftware (2003). Special Issue: State of the Practice in Sof tware Engineering. IEEE\nSoftware, 20(6).\nSoftware (2005). Special issue: Adapting Agility. IEEE Software , 22(3):17--49.\nSoftware (2006). Special issue: Software Architecture. IEEE Software , 23(2):22--87.\nSoloway, E. (1986). Learning to Program = Learning to Constr uct Mechanisms and\nExplanations. Communications of the ACM , 29(9):850--858.\nSoloway, E. and Ehrlich, K. (1984). Empirical Studies of Pro gramming Knowledge.\nIEEE Transactions on Software Engineering , 10(5):595--609.\nSommerville, I. (2005). Integrated Requirements Engineer ing: A Tutorial. IEEE\nSoftware, 22", "token_count": 512, "start_token": 395472, "end_token": 395984, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 857, "text": " Empirical Studies of Pro gramming Knowledge.\nIEEE Transactions on Software Engineering , 10(5):595--609.\nSommerville, I. (2005). Integrated Requirements Engineer ing: A Tutorial. IEEE\nSoftware, 22(1):16--23.\nSommerville, I., Bentley, R., Rodden, T., and Sawyer, P. (19 94). Cooperative System\nDesign. The Computer Journal , 37(5):357--366.\n548 BIBLIOGRAPHY\nSommerville, I. and Sawyer, P. (1997). Viewpoints: princip les, problems and a\npractical approach to requirements engineering. Annals of Software Engineering ,\n3:101--130.\nSoni, D., Nord, R., and Hofmeister, C. (1995). Software Arch itecture in Industial\nApplications. In Proceedings 17th International Conference on Software Eng ineering (ICSE17) ,\npages 196--207. IEEE.\nSousa, M. and Mozeira, H. (1998). A Survey on the Software Mai ntenance Process.\nIn Proceedings International Conference on Software Mainten ance (ICSM’98) , pages 265--274.\nIEEE.\nSpector, A. and Gifford, D. (1986). A Computer Science Persp ective of Bridge\nDesign. Communications of the ACM , 29(4):267--283.\nSPIP (2006). Special Issues: Understanding Free/Open Sour ce Software Development\nProcesses. Software Process: Improvement and Practice , 11(2):93--211.\nSt ˚ alhane, T., Borgersen, P., and Arnesen, K. (1997). In Sea rch of the Customer’s\nQuality View. Journal of Systems and Software , 38(1):85--94.\nStapleton, J., editor (2003). DSDM, Business Focused Development . Addison-Wesley,\nsecond edition.\nStark, G. and Oman, P. (1997). Software Maintenance Managem ent Strategies:\nObservations from the Field. Journal of Software Maintenance: Research and Practice ,\n9:365--378.\nStevens, W., Myers, G., and Constantine, L. (1974). Structu red Design. IBM Systems\nJournal, 13(2):115--139.\nSt", "token_count": 512, "start_token": 395934, "end_token": 396446, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 858, "text": ": Research and Practice ,\n9:365--378.\nStevens, W., Myers, G., and Constantine, L. (1974). Structu red Design. IBM Systems\nJournal, 13(2):115--139.\nStroud, J. (1967). The Fine Structure of Psychological Time . Annals NY Academy of\nSciences, 138:623--631.\nSucci, G., Pedrycz, W., Stefanovic, M., and Miller, J. (2003 ). Practical assessment of\nthe models for identiﬁcation of defect-prone classes in obj ect-oriented commercial\nsystems using design metrics. Journal of Systems and Software , 65(1):1--12.\nSuryn, W., Hailey, V., and Coster, A. (July/August 2004). Ho ge potential user base\nfor ISO/IEC 90003. ISO Management Systems , pages 34--39.\nSutcliffe, A. (1988). Jackson System Development . Prentice-Hall.\nSutcliffe, A., Maiden, N., Minocha, S., and Manuel, D. (1998 ). Supporting\nScenario-Based Requirements Engineering. IEEE Transactions on Software Engineering ,\n24(12):1072--1088.\nBIBLIOGRAPHY 549\nSutton, S., Heimbigner, D., and Osterweil, L. (1990). Langu age Constructs for\nManaging Change in Process-centered Environments. In SIGSOFT’90, Proceedings of\nthe Fourth Symposium on Software Development Environments . ACM.\nSwanson, E. and Beath, C. (1990). Departmentalization in So ftware Development\nand Maintenance. Communications of the ACM , 33(6):658--667.\nSymons, C. (1988). Function Point Analysis: Difﬁculties an d Improvements. IEEE\nTransactions on Software Engineering , 14(1):2--11.\nTahvanainen, V.-P. and Smolander, K. (1990). An annotated C ASE Bibliography.\nACM Software Engineering Notes , 15(1):79--92.\nTaivalsaari, A. (1993). On the Notion of Object. Journal of Systems and Software ,\n21(1):3--16.\nTan, W.-G. and Gable", "token_count": 512, "start_token": 396396, "end_token": 396908, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 859, "text": "(1):79--92.\nTaivalsaari, A. (1993). On the Notion of Object. Journal of Systems and Software ,\n21(1):3--16.\nTan, W.-G. and Gable, G. (1998). Attitudes of Maintenance Pe rsonnel Towards\nMaintenance Work: A Comparative Analysis. Journal of Software Maintenance: Research\nand Practice , 10:59--74.\nTanenbaum, A., van Staveren, H., Keizer, E., and Stevenson, J. (1983). A Practical\nToolkit for Making Portable Compilers. Communications of the ACM , 26(9):654--662.\nTapscott, D. and Caston, A. (1993). Paradigm Shift: The New Promise of Information\nTechnology. McGraw-Hill.\nTrammell, C., Binder, L., and Snyder, C. (1992). The Automat ed Production Control\nDocumentation System: A Case Study in Cleanroom Software En gineering. ACM\nTransactions on Software Engineering and Methodology , 1(1):81--94.\nTripp, L. (1988). A Survey of Graphical Notations for Progra m Design -- An Update.\nACM Software Engineering Notes , 13(4):39--44.\nTrSE (1998). Special Issue on Scenario Management. IEEE Transactions on Software\nEngineering, 24(12).\nTyree, J. and Akerman, A. (2005). Architecture Decisions: D emystifying Architecture.\nIEEE Software , 22(2):19--27.\nvan der Linden, F. and M ¨ uller, J. (1995). Creating Architec tures with Building Blocks.\nIEEE Software , 12(6):51--60.\nvan Deursen, A., Hofmeister, C., Koschke, R., Moonen, L., an d Riva, C. (2004).\nSymphony: View-Driven Software Architecture Reconstruct ion. In Proceedings 4th\nWorking IEEE/IFIP Conference on Software Architecture (WI CSA4), pages 122--132. IEEE.\nvan Genuchten, M. (1991). Towards a Software Factory . PhD thesis, Technical University\nof Eindhoven, The Netherlands.\n550 BIBLIOGRAPHY\nVerner, J. and Cer", "token_count": 512, "start_token": 396858, "end_token": 397370, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 860, "text": ". IEEE.\nvan Genuchten, M. (1991). Towards a Software Factory . PhD thesis, Technical University\nof Eindhoven, The Netherlands.\n550 BIBLIOGRAPHY\nVerner, J. and Cerpa, N. (1997). Prototyping: Does Your View of its Advantages\nDepend on Your Job. Journal of Systems and Software , 36(1):3--16.\nVessey, I. and Conger, S. (1994). Requirements Speciﬁcatio n: Learning Object,\nProcess, and Data Methodologies. Communications of the ACM , 37(5):102--113.\nvon Mayrhauser, A. and Vans, A. (1995). Program Comprehensi on During Software\nMaintenance and Evolution. IEEE Computer , 28(8):44--55.\nvon Mayrhauser, A., Vans, A., and Howe, A. (1997). Program Un derstanding\nBehaviour during Enhancement of Large-scale Software. Journal of Software Mainte-\nnance: Research and Practice , 9:299--327.\nWallace, L. and Keil, M. (2004). Software Project Risks and T heir Effect on Project\nOutcomes. Communications of the ACM , 47(4):68--73.\nWalston, C. and Felix, C. (1977). A Method of Programming Mea surement and\nEstimation. IBM Systems Journal , 16(1):54--73.\nWarnier, J.-D. (1974). Logical Construction of Programs . Stenfert Kroese.\nWeber, D. (1996). Change Sets Versus Change Packages. In Som merville, I.,\neditor, Proceedings Workshop on Software Conﬁguration Management (SCM6), pages 25--35.\nSpringer, LNCS1167.\nWegner, P. (1984). Capital-Intensive Software Technology . IEEE Software , 1(3):7--45.\nWegner, P. (1992). Dimensions of Object-Oriented Modeling . IEEE Computer ,\n25(10):12--21.\nWeidenhaupt, K., Pohl, K., Jarke, M., and Haumer, P. (1998). Scenarios in System\nDevelopment: Current Practice. IEEE Software , 15(2):34--45.\nWe", "token_count": 512, "start_token": 397320, "end_token": 397832, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 861, "text": "idenhaupt, K., Pohl, K., Jarke, M., and Haumer, P. (1998). Scenarios in System\nDevelopment: Current Practice. IEEE Software , 15(2):34--45.\nWeinberg, G. (1971). The Psychology of Computer Programming . Van Nostrand Reinhold.\nWeller, E. (1993). Lessons from Three Years of Inspection Da ta. IEEE Software ,\n10(5):38--45.\nWendel, I. (1986). Software Tools of the Pleistocene. Software Maintenance News ,\n4(10):20.\nWeyuker, E. (1988). The Evaluation of Program-Based Softwa re Test Data Adequacy\nCriteria. Communications of the ACM , 31(6):668--675.\nWeyuker, E. (1990). The Cost of Data Flow Testing: An Empiric al Study. IEEE\nTransactions on Software Engineering , 16(2):121--128.\nWeyuker, E. (1993). More Experience with Data Flow Testing. IEEE Transactions on\nSoftware Engineering , 19(9):912--919.\nBIBLIOGRAPHY 551\nWhittaker, J. (2000). What Is Software Testing? And Why Is It So Hard. IEEE\nSoftware, 17(1):70--79.\nWhittaker, J. and Voas, J. (2000). Toward a More Reliable The ory of Software\nReliability. IEEE Computer , 33(12):36--42.\nWiborg-Weber, D. (1997). Change Sets versus Change Package s: Comparing\nImplementations of Change-Based SCM. In Proceedings 7th International Workshop on\nSoftware Conﬁguration Management (SCM’7) , pages 25--35. Springer LNCS 1235.\nWiegers, K. (2002). Peer Reviews in Software --- A Practical Guide . Addison-Wesley.\nWieringa, R. (1996). Requirements Engineering: Frameworks for Understanding . John Wiley &\nSons.\nWieringa, R. (1998). A Survey of Structured and Object-Orie nted Software Speciﬁ-\ncation Methods and Techniques. ACM Computing Surveys , 30(4):459--527.\nWing, J. (1988", "token_count": 512, "start_token": 397782, "end_token": 398294, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 862, "text": " (1998). A Survey of Structured and Object-Orie nted Software Speciﬁ-\ncation Methods and Techniques. ACM Computing Surveys , 30(4):459--527.\nWing, J. (1988). A Study of 12 Speciﬁcations of the Library Pr oblem. IEEE Software ,\n5(4):66--76.\nWohlwend, H. and Rosenbaum, S. (1994). Schlumberger’s Soft ware Improvement\nProgram. IEEE Transactions on Software Engineering , 20(11):833--839.\nWolverton, R. (1974). The Cost of Developing Large-Scale So ftware. IEEE Transactions\non Computers , pages 615--636.\nWood, M., Roper, M., Brooks, A., and Miller, J. (1997). Compa ring and Combining\nSoftware Defect Detection Techniques. In Jazayeri, M. and S chauer, H., editors,\nProceedings 6th European Software Engineering Conference , LNCS 1301 , pages 262--277.\nSpringer Verlag.\nXia, F. (2000). On the Concept of Coupling, its Modeling and M easurement. Journal\nof Systems and Software , 50(1):75--84.\nYeh, D. and Jeng, J.-H. (2002). An empirical study of the inﬂu ence of departmen-\ntalization and organizational position on software mainte nance. Journal of Software\nMaintenance and Evolution: Research and Practice , 14:65--82.\nYourdon, E. and Constantine, L. (1975). Structured Design . Yourdon Press.\nYu, L. and Chen, K. (2006). An Empirical Study of the Maintena nce Effort. In\nProceedings 8th International Conference on Software Engi neering and Knowledge Engineering\n(SEKE), pages 242--245.\nZelkowitz, M. (1988). Resource Utilization During Softwar e Development. Journal\nof Systems and Software , 8(4):331--336.\n552 BIBLIOGRAPHY\nZhu, H. (1996). A Formal Analysis of the Subsume Relation Bet ween Software Test\nAdequacy Criteria. IEEE Transactions on Software Engineering , 22(4):248--", "token_count": 512, "start_token": 398244, "end_token": 398756, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
{"chunk_id": 863, "text": " BIBLIOGRAPHY\nZhu, H. (1996). A Formal Analysis of the Subsume Relation Bet ween Software Test\nAdequacy Criteria. IEEE Transactions on Software Engineering , 22(4):248--255.\nZhu, H., Hall, P., and May, J. (1997). Software Unit Test Cove rage and Adequacy.\nACM Computing Surveys , 29(4):366--427.\nZucconi, L. (1989). Selecting a CASE Tool. ACM Software Engineering Notes , 14(2):42-\n-44.\n", "token_count": 128, "start_token": 398706, "end_token": 398834, "source_file": "data\\textbooks\\[Hans_van_Vliet]_Software_Engineering_Principles_(BookFi)-2.pdf"}
